{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0496,  0.0070,  0.0000],\n",
      "        [ 0.0498,  0.0061,  0.0000],\n",
      "        [ 0.0437,  0.0062,  0.0000],\n",
      "        [ 0.0345,  0.0007,  0.0000],\n",
      "        [ 0.0452,  0.0051,  0.0000],\n",
      "        [ 0.0523,  0.0057,  0.0000],\n",
      "        [ 0.0338,  0.0123,  0.0000],\n",
      "        [ 0.0430, -0.0007,  0.0000],\n",
      "        [ 0.0573, -0.0015,  0.0000],\n",
      "        [ 0.0503,  0.0064,  0.0000],\n",
      "        [ 0.0382, -0.0021,  0.0000],\n",
      "        [ 0.0127, -0.0046,  0.0000],\n",
      "        [ 0.0167, -0.0008,  0.0000],\n",
      "        [ 0.0406,  0.0068,  0.0000],\n",
      "        [ 0.0383,  0.0060,  0.0000],\n",
      "        [ 0.0459, -0.0013,  0.0000],\n",
      "        [ 0.0409,  0.0035,  0.0000],\n",
      "        [ 0.0464,  0.0034,  0.0000],\n",
      "        [ 0.0225, -0.0011,  0.0000],\n",
      "        [ 0.0616,  0.0025,  0.0000],\n",
      "        [ 0.0493, -0.0017,  0.0000],\n",
      "        [ 0.0503, -0.0019,  0.0000],\n",
      "        [ 0.0545,  0.0032,  0.0000],\n",
      "        [ 0.0378,  0.0074,  0.0000],\n",
      "        [ 0.0486,  0.0102,  0.0000],\n",
      "        [ 0.0630,  0.0103,  0.0000],\n",
      "        [ 0.0509, -0.0029,  0.0000],\n",
      "        [ 0.0653,  0.0037,  0.0000],\n",
      "        [ 0.0515,  0.0029,  0.0000],\n",
      "        [ 0.0340, -0.0005,  0.0000],\n",
      "        [ 0.0395, -0.0007,  0.0000],\n",
      "        [ 0.0228,  0.0047,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0798, 0.0720, 0.0702, 0.0687, 0.0661, 0.0649, 0.0599, 0.0722, 0.0721,\n",
      "         0.0586, 0.0508, 0.0505, 0.0414, 0.0659, 0.0665, 0.0760, 0.0631, 0.0712,\n",
      "         0.0501, 0.0699, 0.0671, 0.0754, 0.0779, 0.0667, 0.0600, 0.0716, 0.0695,\n",
      "         0.0847, 0.0750, 0.0578, 0.0656, 0.0405],\n",
      "        [0.0779, 0.0695, 0.0656, 0.0605, 0.0602, 0.0632, 0.0573, 0.0718, 0.0692,\n",
      "         0.0606, 0.0459, 0.0442, 0.0414, 0.0660, 0.0592, 0.0739, 0.0581, 0.0646,\n",
      "         0.0529, 0.0675, 0.0644, 0.0649, 0.0781, 0.0638, 0.0543, 0.0676, 0.0596,\n",
      "         0.0714, 0.0701, 0.0535, 0.0613, 0.0446]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0070, 0.0058, 0.0052, 0.0052, 0.0053, 0.0065, 0.0055, 0.0064, 0.0069,\n",
      "        0.0059, 0.0038, 0.0030, 0.0030, 0.0059, 0.0051, 0.0068, 0.0053, 0.0064,\n",
      "        0.0037, 0.0074, 0.0063, 0.0057, 0.0071, 0.0052, 0.0053, 0.0072, 0.0065,\n",
      "        0.0072, 0.0069, 0.0044, 0.0055, 0.0033], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0058, 0.0059], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0142,  0.0077,  0.0000],\n",
      "        [ 0.0218,  0.0108,  0.0000],\n",
      "        [ 0.0103,  0.0092,  0.0000],\n",
      "        [ 0.0151,  0.0007,  0.0000],\n",
      "        [ 0.0098,  0.0020,  0.0000],\n",
      "        [ 0.0166,  0.0160,  0.0000],\n",
      "        [ 0.0121,  0.0091,  0.0000],\n",
      "        [ 0.0191,  0.0068,  0.0000],\n",
      "        [ 0.0173,  0.0059,  0.0000],\n",
      "        [ 0.0136,  0.0101,  0.0000],\n",
      "        [ 0.0006,  0.0027,  0.0000],\n",
      "        [ 0.0014, -0.0003,  0.0000],\n",
      "        [ 0.0053,  0.0012,  0.0000],\n",
      "        [ 0.0086,  0.0131,  0.0000],\n",
      "        [ 0.0167,  0.0129,  0.0000],\n",
      "        [ 0.0200,  0.0058,  0.0000],\n",
      "        [ 0.0133,  0.0070,  0.0000],\n",
      "        [ 0.0243,  0.0116,  0.0000],\n",
      "        [ 0.0083,  0.0022,  0.0000],\n",
      "        [ 0.0232,  0.0128,  0.0000],\n",
      "        [ 0.0228,  0.0126,  0.0000],\n",
      "        [ 0.0114,  0.0039,  0.0000],\n",
      "        [ 0.0167,  0.0046,  0.0000],\n",
      "        [ 0.0086,  0.0068,  0.0000],\n",
      "        [ 0.0101,  0.0068,  0.0000],\n",
      "        [ 0.0180,  0.0127,  0.0000],\n",
      "        [ 0.0136,  0.0074,  0.0000],\n",
      "        [ 0.0213,  0.0043,  0.0000],\n",
      "        [ 0.0250,  0.0140,  0.0000],\n",
      "        [ 0.0147,  0.0009,  0.0000],\n",
      "        [ 0.0141,  0.0092,  0.0000],\n",
      "        [ 0.0106,  0.0034,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0834, 0.0754, 0.0741, 0.0708, 0.0687, 0.0683, 0.0638, 0.0747, 0.0750,\n",
      "         0.0614, 0.0522, 0.0533, 0.0441, 0.0696, 0.0696, 0.0789, 0.0660, 0.0729,\n",
      "         0.0533, 0.0723, 0.0701, 0.0782, 0.0812, 0.0703, 0.0641, 0.0750, 0.0722,\n",
      "         0.0887, 0.0785, 0.0612, 0.0699, 0.0419],\n",
      "        [0.0814, 0.0729, 0.0690, 0.0627, 0.0627, 0.0663, 0.0608, 0.0744, 0.0721,\n",
      "         0.0634, 0.0475, 0.0468, 0.0440, 0.0695, 0.0618, 0.0770, 0.0607, 0.0664,\n",
      "         0.0560, 0.0701, 0.0674, 0.0675, 0.0817, 0.0672, 0.0577, 0.0708, 0.0621,\n",
      "         0.0748, 0.0734, 0.0566, 0.0649, 0.0464]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0071, 0.0059, 0.0054, 0.0052, 0.0053, 0.0067, 0.0058, 0.0064, 0.0070,\n",
      "        0.0060, 0.0037, 0.0032, 0.0033, 0.0062, 0.0053, 0.0069, 0.0054, 0.0063,\n",
      "        0.0040, 0.0074, 0.0064, 0.0057, 0.0071, 0.0054, 0.0056, 0.0073, 0.0065,\n",
      "        0.0073, 0.0070, 0.0047, 0.0059, 0.0033], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0060, 0.0060], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0473, -0.0081,  0.0000],\n",
      "        [ 0.0324, -0.0077,  0.0000],\n",
      "        [ 0.0319, -0.0059,  0.0000],\n",
      "        [ 0.0307, -0.0058,  0.0000],\n",
      "        [ 0.0368,  0.0040,  0.0000],\n",
      "        [ 0.0399, -0.0058,  0.0000],\n",
      "        [ 0.0299,  0.0025,  0.0000],\n",
      "        [ 0.0343, -0.0022,  0.0000],\n",
      "        [ 0.0373, -0.0011,  0.0000],\n",
      "        [ 0.0461,  0.0085,  0.0000],\n",
      "        [ 0.0231, -0.0050,  0.0000],\n",
      "        [ 0.0238, -0.0039,  0.0000],\n",
      "        [ 0.0155, -0.0016,  0.0000],\n",
      "        [ 0.0336,  0.0024,  0.0000],\n",
      "        [ 0.0362, -0.0043,  0.0000],\n",
      "        [ 0.0420, -0.0013,  0.0000],\n",
      "        [ 0.0324, -0.0049,  0.0000],\n",
      "        [ 0.0406, -0.0037,  0.0000],\n",
      "        [ 0.0222, -0.0041,  0.0000],\n",
      "        [ 0.0439, -0.0018,  0.0000],\n",
      "        [ 0.0378,  0.0007,  0.0000],\n",
      "        [ 0.0294, -0.0040,  0.0000],\n",
      "        [ 0.0458, -0.0064,  0.0000],\n",
      "        [ 0.0336,  0.0009,  0.0000],\n",
      "        [ 0.0339,  0.0039,  0.0000],\n",
      "        [ 0.0416,  0.0002,  0.0000],\n",
      "        [ 0.0325, -0.0020,  0.0000],\n",
      "        [ 0.0480, -0.0033,  0.0000],\n",
      "        [ 0.0320, -0.0009,  0.0000],\n",
      "        [ 0.0227, -0.0047,  0.0000],\n",
      "        [ 0.0303, -0.0020,  0.0000],\n",
      "        [ 0.0286, -0.0050,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0869, 0.0788, 0.0768, 0.0747, 0.0715, 0.0708, 0.0657, 0.0783, 0.0784,\n",
      "         0.0638, 0.0552, 0.0561, 0.0459, 0.0721, 0.0722, 0.0829, 0.0686, 0.0766,\n",
      "         0.0554, 0.0760, 0.0733, 0.0820, 0.0852, 0.0730, 0.0659, 0.0780, 0.0757,\n",
      "         0.0922, 0.0819, 0.0638, 0.0719, 0.0440],\n",
      "        [0.0850, 0.0762, 0.0716, 0.0664, 0.0655, 0.0688, 0.0625, 0.0783, 0.0756,\n",
      "         0.0660, 0.0505, 0.0492, 0.0456, 0.0720, 0.0643, 0.0812, 0.0632, 0.0703,\n",
      "         0.0581, 0.0739, 0.0705, 0.0711, 0.0858, 0.0698, 0.0592, 0.0739, 0.0654,\n",
      "         0.0780, 0.0767, 0.0589, 0.0666, 0.0488]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0073, 0.0060, 0.0054, 0.0054, 0.0054, 0.0067, 0.0058, 0.0066, 0.0072,\n",
      "        0.0061, 0.0039, 0.0033, 0.0033, 0.0062, 0.0053, 0.0071, 0.0055, 0.0065,\n",
      "        0.0040, 0.0076, 0.0065, 0.0059, 0.0073, 0.0054, 0.0055, 0.0074, 0.0067,\n",
      "        0.0074, 0.0072, 0.0047, 0.0058, 0.0034], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0062, 0.0062], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0419, -0.0075,  0.0000],\n",
      "        [ 0.0395, -0.0151,  0.0000],\n",
      "        [ 0.0392, -0.0142,  0.0000],\n",
      "        [ 0.0372, -0.0057,  0.0000],\n",
      "        [ 0.0419, -0.0045,  0.0000],\n",
      "        [ 0.0398, -0.0195,  0.0000],\n",
      "        [ 0.0317, -0.0044,  0.0000],\n",
      "        [ 0.0436, -0.0129,  0.0000],\n",
      "        [ 0.0487, -0.0092,  0.0000],\n",
      "        [ 0.0388, -0.0135,  0.0000],\n",
      "        [ 0.0309, -0.0122,  0.0000],\n",
      "        [ 0.0215, -0.0090,  0.0000],\n",
      "        [ 0.0192, -0.0097,  0.0000],\n",
      "        [ 0.0365, -0.0122,  0.0000],\n",
      "        [ 0.0349, -0.0147,  0.0000],\n",
      "        [ 0.0499, -0.0146,  0.0000],\n",
      "        [ 0.0388, -0.0100,  0.0000],\n",
      "        [ 0.0401, -0.0102,  0.0000],\n",
      "        [ 0.0183, -0.0051,  0.0000],\n",
      "        [ 0.0518, -0.0182,  0.0000],\n",
      "        [ 0.0399, -0.0131,  0.0000],\n",
      "        [ 0.0412, -0.0180,  0.0000],\n",
      "        [ 0.0540, -0.0136,  0.0000],\n",
      "        [ 0.0349, -0.0180,  0.0000],\n",
      "        [ 0.0378, -0.0053,  0.0000],\n",
      "        [ 0.0468, -0.0131,  0.0000],\n",
      "        [ 0.0473, -0.0125,  0.0000],\n",
      "        [ 0.0566, -0.0115,  0.0000],\n",
      "        [ 0.0480, -0.0195,  0.0000],\n",
      "        [ 0.0212, -0.0047,  0.0000],\n",
      "        [ 0.0372, -0.0088,  0.0000],\n",
      "        [ 0.0181, -0.0100,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0907, 0.0824, 0.0797, 0.0786, 0.0748, 0.0736, 0.0679, 0.0821, 0.0821,\n",
      "         0.0667, 0.0582, 0.0585, 0.0476, 0.0749, 0.0752, 0.0870, 0.0715, 0.0808,\n",
      "         0.0574, 0.0799, 0.0767, 0.0860, 0.0894, 0.0760, 0.0680, 0.0815, 0.0794,\n",
      "         0.0962, 0.0855, 0.0663, 0.0742, 0.0462],\n",
      "        [0.0887, 0.0798, 0.0746, 0.0698, 0.0682, 0.0715, 0.0649, 0.0818, 0.0790,\n",
      "         0.0689, 0.0530, 0.0519, 0.0478, 0.0750, 0.0669, 0.0851, 0.0658, 0.0736,\n",
      "         0.0606, 0.0774, 0.0738, 0.0745, 0.0900, 0.0729, 0.0615, 0.0771, 0.0686,\n",
      "         0.0814, 0.0802, 0.0617, 0.0691, 0.0512]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0074, 0.0062, 0.0055, 0.0056, 0.0055, 0.0067, 0.0058, 0.0068, 0.0073,\n",
      "        0.0062, 0.0041, 0.0034, 0.0033, 0.0063, 0.0054, 0.0073, 0.0056, 0.0067,\n",
      "        0.0040, 0.0077, 0.0066, 0.0061, 0.0075, 0.0055, 0.0055, 0.0075, 0.0068,\n",
      "        0.0075, 0.0073, 0.0048, 0.0058, 0.0035], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0063, 0.0064], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[0.0214, 0.0150, 0.0000],\n",
      "        [0.0211, 0.0041, 0.0000],\n",
      "        [0.0151, 0.0079, 0.0000],\n",
      "        [0.0231, 0.0145, 0.0000],\n",
      "        [0.0100, 0.0162, 0.0000],\n",
      "        [0.0284, 0.0087, 0.0000],\n",
      "        [0.0136, 0.0159, 0.0000],\n",
      "        [0.0299, 0.0126, 0.0000],\n",
      "        [0.0327, 0.0101, 0.0000],\n",
      "        [0.0242, 0.0143, 0.0000],\n",
      "        [0.0107, 0.0034, 0.0000],\n",
      "        [0.0125, 0.0081, 0.0000],\n",
      "        [0.0008, 0.0058, 0.0000],\n",
      "        [0.0212, 0.0085, 0.0000],\n",
      "        [0.0240, 0.0111, 0.0000],\n",
      "        [0.0184, 0.0111, 0.0000],\n",
      "        [0.0204, 0.0172, 0.0000],\n",
      "        [0.0225, 0.0163, 0.0000],\n",
      "        [0.0188, 0.0021, 0.0000],\n",
      "        [0.0323, 0.0115, 0.0000],\n",
      "        [0.0331, 0.0080, 0.0000],\n",
      "        [0.0221, 0.0135, 0.0000],\n",
      "        [0.0238, 0.0084, 0.0000],\n",
      "        [0.0075, 0.0105, 0.0000],\n",
      "        [0.0143, 0.0081, 0.0000],\n",
      "        [0.0301, 0.0136, 0.0000],\n",
      "        [0.0323, 0.0156, 0.0000],\n",
      "        [0.0343, 0.0191, 0.0000],\n",
      "        [0.0266, 0.0110, 0.0000],\n",
      "        [0.0178, 0.0020, 0.0000],\n",
      "        [0.0203, 0.0129, 0.0000],\n",
      "        [0.0109, 0.0051, 0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0955, 0.0860, 0.0844, 0.0806, 0.0787, 0.0791, 0.0734, 0.0857, 0.0861,\n",
      "         0.0709, 0.0591, 0.0595, 0.0499, 0.0799, 0.0797, 0.0902, 0.0757, 0.0840,\n",
      "         0.0604, 0.0836, 0.0806, 0.0891, 0.0929, 0.0803, 0.0736, 0.0866, 0.0828,\n",
      "         0.1015, 0.0900, 0.0694, 0.0801, 0.0476],\n",
      "        [0.0932, 0.0836, 0.0791, 0.0716, 0.0715, 0.0765, 0.0700, 0.0851, 0.0828,\n",
      "         0.0729, 0.0540, 0.0535, 0.0504, 0.0798, 0.0707, 0.0884, 0.0695, 0.0760,\n",
      "         0.0641, 0.0807, 0.0776, 0.0772, 0.0937, 0.0771, 0.0666, 0.0816, 0.0715,\n",
      "         0.0859, 0.0844, 0.0650, 0.0746, 0.0529]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0076, 0.0063, 0.0058, 0.0056, 0.0057, 0.0071, 0.0062, 0.0069, 0.0075,\n",
      "        0.0064, 0.0040, 0.0033, 0.0034, 0.0066, 0.0056, 0.0073, 0.0058, 0.0068,\n",
      "        0.0042, 0.0079, 0.0068, 0.0061, 0.0076, 0.0057, 0.0060, 0.0078, 0.0069,\n",
      "        0.0078, 0.0075, 0.0049, 0.0062, 0.0035], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0065, 0.0066], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 3.7935e-02,  1.7049e-03,  0.0000e+00],\n",
      "        [ 4.0555e-02, -4.9089e-03,  0.0000e+00],\n",
      "        [ 3.1342e-02,  2.6821e-03,  0.0000e+00],\n",
      "        [ 3.1406e-02,  3.5360e-03,  0.0000e+00],\n",
      "        [ 2.8729e-02,  7.1006e-03,  0.0000e+00],\n",
      "        [ 4.2021e-02,  2.3093e-03,  0.0000e+00],\n",
      "        [ 2.3911e-02,  9.5775e-03,  0.0000e+00],\n",
      "        [ 3.6422e-02,  3.3320e-03,  0.0000e+00],\n",
      "        [ 3.4530e-02,  1.1604e-02,  0.0000e+00],\n",
      "        [ 2.1954e-02,  6.2513e-03,  0.0000e+00],\n",
      "        [ 1.7984e-02,  1.2096e-03,  0.0000e+00],\n",
      "        [ 8.4224e-03,  3.4907e-03,  0.0000e+00],\n",
      "        [ 1.3802e-02, -4.9092e-03,  0.0000e+00],\n",
      "        [ 2.6068e-02,  7.5331e-03,  0.0000e+00],\n",
      "        [ 2.7420e-02,  2.7955e-03,  0.0000e+00],\n",
      "        [ 4.5118e-02,  7.9685e-04,  0.0000e+00],\n",
      "        [ 3.3180e-02, -3.4714e-04,  0.0000e+00],\n",
      "        [ 3.9872e-02,  3.9637e-03,  0.0000e+00],\n",
      "        [ 1.8302e-02,  5.6033e-03,  0.0000e+00],\n",
      "        [ 4.1060e-02,  9.9140e-03,  0.0000e+00],\n",
      "        [ 2.9964e-02,  8.2796e-03,  0.0000e+00],\n",
      "        [ 3.0654e-02, -6.6719e-04,  0.0000e+00],\n",
      "        [ 4.0337e-02, -5.9870e-05,  0.0000e+00],\n",
      "        [ 2.8157e-02,  1.5151e-04,  0.0000e+00],\n",
      "        [ 3.2419e-02,  5.9434e-03,  0.0000e+00],\n",
      "        [ 4.5026e-02,  9.2883e-03,  0.0000e+00],\n",
      "        [ 3.8201e-02,  1.0472e-02,  0.0000e+00],\n",
      "        [ 4.5281e-02,  5.7961e-03,  0.0000e+00],\n",
      "        [ 4.0079e-02,  5.3466e-03,  0.0000e+00],\n",
      "        [ 2.6215e-02, -2.1139e-03,  0.0000e+00],\n",
      "        [ 3.0338e-02,  7.9899e-03,  0.0000e+00],\n",
      "        [ 2.4811e-02, -6.1624e-03,  0.0000e+00]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0995, 0.0899, 0.0873, 0.0853, 0.0820, 0.0816, 0.0752, 0.0899, 0.0901,\n",
      "         0.0737, 0.0629, 0.0627, 0.0518, 0.0825, 0.0826, 0.0948, 0.0787, 0.0885,\n",
      "         0.0626, 0.0878, 0.0842, 0.0936, 0.0975, 0.0833, 0.0754, 0.0899, 0.0869,\n",
      "         0.1056, 0.0938, 0.0722, 0.0819, 0.0501],\n",
      "        [0.0973, 0.0874, 0.0815, 0.0763, 0.0748, 0.0789, 0.0715, 0.0896, 0.0869,\n",
      "         0.0759, 0.0578, 0.0562, 0.0521, 0.0823, 0.0733, 0.0932, 0.0723, 0.0807,\n",
      "         0.0662, 0.0853, 0.0811, 0.0815, 0.0985, 0.0799, 0.0678, 0.0849, 0.0755,\n",
      "         0.0895, 0.0881, 0.0675, 0.0759, 0.0558]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0077, 0.0064, 0.0058, 0.0058, 0.0058, 0.0072, 0.0062, 0.0071, 0.0076,\n",
      "        0.0065, 0.0041, 0.0034, 0.0035, 0.0066, 0.0057, 0.0075, 0.0059, 0.0070,\n",
      "        0.0042, 0.0081, 0.0070, 0.0063, 0.0078, 0.0058, 0.0060, 0.0079, 0.0071,\n",
      "        0.0079, 0.0076, 0.0050, 0.0062, 0.0036], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0067, 0.0067], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0547, -0.0051,  0.0000],\n",
      "        [ 0.0436, -0.0050,  0.0000],\n",
      "        [ 0.0415, -0.0023,  0.0000],\n",
      "        [ 0.0495, -0.0038,  0.0000],\n",
      "        [ 0.0452, -0.0051,  0.0000],\n",
      "        [ 0.0460, -0.0016,  0.0000],\n",
      "        [ 0.0424, -0.0041,  0.0000],\n",
      "        [ 0.0421, -0.0028,  0.0000],\n",
      "        [ 0.0561,  0.0022,  0.0000],\n",
      "        [ 0.0398, -0.0005,  0.0000],\n",
      "        [ 0.0275, -0.0054,  0.0000],\n",
      "        [ 0.0205, -0.0070,  0.0000],\n",
      "        [ 0.0192, -0.0036,  0.0000],\n",
      "        [ 0.0426,  0.0019,  0.0000],\n",
      "        [ 0.0370, -0.0042,  0.0000],\n",
      "        [ 0.0540, -0.0115,  0.0000],\n",
      "        [ 0.0382, -0.0119,  0.0000],\n",
      "        [ 0.0496, -0.0013,  0.0000],\n",
      "        [ 0.0234,  0.0002,  0.0000],\n",
      "        [ 0.0544, -0.0038,  0.0000],\n",
      "        [ 0.0482,  0.0005,  0.0000],\n",
      "        [ 0.0481, -0.0003,  0.0000],\n",
      "        [ 0.0460, -0.0076,  0.0000],\n",
      "        [ 0.0403, -0.0083,  0.0000],\n",
      "        [ 0.0354, -0.0098,  0.0000],\n",
      "        [ 0.0550, -0.0018,  0.0000],\n",
      "        [ 0.0502, -0.0066,  0.0000],\n",
      "        [ 0.0558, -0.0102,  0.0000],\n",
      "        [ 0.0591, -0.0089,  0.0000],\n",
      "        [ 0.0326,  0.0031,  0.0000],\n",
      "        [ 0.0357, -0.0036,  0.0000],\n",
      "        [ 0.0290, -0.0048,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1040, 0.0940, 0.0909, 0.0893, 0.0857, 0.0850, 0.0783, 0.0942, 0.0943,\n",
      "         0.0769, 0.0659, 0.0654, 0.0540, 0.0860, 0.0861, 0.0993, 0.0821, 0.0927,\n",
      "         0.0651, 0.0921, 0.0880, 0.0979, 0.1021, 0.0869, 0.0784, 0.0940, 0.0910,\n",
      "         0.1102, 0.0981, 0.0754, 0.0851, 0.0525],\n",
      "        [0.1020, 0.0914, 0.0851, 0.0798, 0.0786, 0.0829, 0.0750, 0.0941, 0.0913,\n",
      "         0.0797, 0.0605, 0.0579, 0.0541, 0.0862, 0.0769, 0.0976, 0.0759, 0.0853,\n",
      "         0.0688, 0.0899, 0.0851, 0.0854, 0.1032, 0.0835, 0.0710, 0.0894, 0.0793,\n",
      "         0.0940, 0.0924, 0.0702, 0.0794, 0.0583]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0079, 0.0066, 0.0059, 0.0060, 0.0059, 0.0072, 0.0062, 0.0072, 0.0078,\n",
      "        0.0066, 0.0043, 0.0036, 0.0035, 0.0067, 0.0058, 0.0077, 0.0060, 0.0071,\n",
      "        0.0043, 0.0082, 0.0071, 0.0064, 0.0080, 0.0059, 0.0060, 0.0080, 0.0073,\n",
      "        0.0080, 0.0078, 0.0051, 0.0062, 0.0037], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0069, 0.0069], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0532, -0.0012,  0.0000],\n",
      "        [ 0.0459, -0.0031,  0.0000],\n",
      "        [ 0.0462,  0.0023,  0.0000],\n",
      "        [ 0.0492, -0.0009,  0.0000],\n",
      "        [ 0.0462,  0.0038,  0.0000],\n",
      "        [ 0.0538, -0.0007,  0.0000],\n",
      "        [ 0.0407,  0.0068,  0.0000],\n",
      "        [ 0.0611, -0.0003,  0.0000],\n",
      "        [ 0.0616, -0.0069,  0.0000],\n",
      "        [ 0.0460,  0.0027,  0.0000],\n",
      "        [ 0.0391, -0.0057,  0.0000],\n",
      "        [ 0.0258, -0.0012,  0.0000],\n",
      "        [ 0.0221,  0.0038,  0.0000],\n",
      "        [ 0.0531,  0.0010,  0.0000],\n",
      "        [ 0.0466,  0.0077,  0.0000],\n",
      "        [ 0.0572, -0.0009,  0.0000],\n",
      "        [ 0.0530,  0.0041,  0.0000],\n",
      "        [ 0.0573,  0.0065,  0.0000],\n",
      "        [ 0.0229, -0.0094,  0.0000],\n",
      "        [ 0.0647,  0.0049,  0.0000],\n",
      "        [ 0.0549,  0.0014,  0.0000],\n",
      "        [ 0.0543,  0.0002,  0.0000],\n",
      "        [ 0.0585, -0.0040,  0.0000],\n",
      "        [ 0.0429,  0.0107,  0.0000],\n",
      "        [ 0.0413, -0.0075,  0.0000],\n",
      "        [ 0.0619, -0.0021,  0.0000],\n",
      "        [ 0.0611, -0.0107,  0.0000],\n",
      "        [ 0.0637, -0.0049,  0.0000],\n",
      "        [ 0.0531,  0.0013,  0.0000],\n",
      "        [ 0.0316, -0.0070,  0.0000],\n",
      "        [ 0.0521,  0.0002,  0.0000],\n",
      "        [ 0.0189, -0.0037,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1091, 0.0981, 0.0950, 0.0932, 0.0900, 0.0898, 0.0822, 0.0988, 0.0991,\n",
      "         0.0810, 0.0686, 0.0670, 0.0559, 0.0903, 0.0903, 0.1038, 0.0863, 0.0977,\n",
      "         0.0675, 0.0970, 0.0923, 0.1024, 0.1067, 0.0909, 0.0823, 0.0991, 0.0954,\n",
      "         0.1157, 0.1028, 0.0782, 0.0894, 0.0548],\n",
      "        [0.1070, 0.0956, 0.0893, 0.0831, 0.0825, 0.0876, 0.0791, 0.0985, 0.0959,\n",
      "         0.0839, 0.0627, 0.0599, 0.0565, 0.0907, 0.0808, 0.1020, 0.0798, 0.0894,\n",
      "         0.0718, 0.0943, 0.0893, 0.0892, 0.1078, 0.0876, 0.0751, 0.0942, 0.0832,\n",
      "         0.0988, 0.0970, 0.0733, 0.0839, 0.0608]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0081, 0.0067, 0.0060, 0.0061, 0.0061, 0.0074, 0.0063, 0.0074, 0.0080,\n",
      "        0.0068, 0.0044, 0.0036, 0.0036, 0.0068, 0.0059, 0.0079, 0.0061, 0.0073,\n",
      "        0.0044, 0.0084, 0.0072, 0.0066, 0.0081, 0.0060, 0.0061, 0.0082, 0.0074,\n",
      "        0.0082, 0.0079, 0.0052, 0.0063, 0.0038], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0071, 0.0071], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 1.9304e-02, -3.7752e-04,  0.0000e+00],\n",
      "        [ 3.0351e-03, -3.3408e-04,  0.0000e+00],\n",
      "        [ 1.1637e-02, -4.8165e-03,  0.0000e+00],\n",
      "        [ 1.8097e-02, -6.5152e-03,  0.0000e+00],\n",
      "        [ 1.8452e-02,  5.9420e-03,  0.0000e+00],\n",
      "        [ 9.8135e-03,  8.6594e-04,  0.0000e+00],\n",
      "        [ 1.1254e-02, -6.9600e-03,  0.0000e+00],\n",
      "        [ 1.6230e-02,  1.0044e-03,  0.0000e+00],\n",
      "        [ 1.6030e-02, -1.3405e-06,  0.0000e+00],\n",
      "        [ 1.5288e-02,  7.6352e-04,  0.0000e+00],\n",
      "        [ 1.2993e-02,  3.7381e-04,  0.0000e+00],\n",
      "        [ 9.9774e-03, -9.3148e-03,  0.0000e+00],\n",
      "        [ 4.0911e-03, -6.8221e-03,  0.0000e+00],\n",
      "        [ 8.2141e-03, -4.1910e-03,  0.0000e+00],\n",
      "        [ 1.0538e-02, -4.3824e-03,  0.0000e+00],\n",
      "        [ 1.4135e-02,  2.4039e-03,  0.0000e+00],\n",
      "        [ 1.4234e-02,  2.7808e-04,  0.0000e+00],\n",
      "        [ 1.3407e-02, -1.0034e-03,  0.0000e+00],\n",
      "        [ 7.9163e-03,  1.3545e-03,  0.0000e+00],\n",
      "        [ 1.8539e-02, -1.9510e-03,  0.0000e+00],\n",
      "        [ 1.5132e-02, -2.8415e-03,  0.0000e+00],\n",
      "        [ 1.3156e-02,  6.6305e-03,  0.0000e+00],\n",
      "        [ 1.8523e-02, -2.3023e-03,  0.0000e+00],\n",
      "        [ 1.0719e-02,  3.8595e-03,  0.0000e+00],\n",
      "        [ 8.7073e-03,  1.1062e-03,  0.0000e+00],\n",
      "        [ 1.4451e-02,  3.9231e-03,  0.0000e+00],\n",
      "        [ 1.6363e-02, -2.2561e-03,  0.0000e+00],\n",
      "        [ 1.8497e-02,  2.2768e-04,  0.0000e+00],\n",
      "        [ 1.6326e-02, -5.6216e-03,  0.0000e+00],\n",
      "        [ 1.1909e-02, -5.3671e-03,  0.0000e+00],\n",
      "        [ 7.2845e-03,  2.8844e-03,  0.0000e+00],\n",
      "        [ 7.4812e-03, -4.4851e-03,  0.0000e+00]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1137, 0.1027, 0.1003, 0.0960, 0.0930, 0.0943, 0.0876, 0.1019, 0.1027,\n",
      "         0.0847, 0.0704, 0.0711, 0.0599, 0.0952, 0.0943, 0.1078, 0.0899, 0.0998,\n",
      "         0.0722, 0.1001, 0.0965, 0.1060, 0.1112, 0.0958, 0.0878, 0.1033, 0.0989,\n",
      "         0.1207, 0.1074, 0.0831, 0.0950, 0.0566],\n",
      "        [0.1118, 0.1001, 0.0942, 0.0860, 0.0857, 0.0923, 0.0842, 0.1022, 0.0999,\n",
      "         0.0879, 0.0645, 0.0630, 0.0599, 0.0956, 0.0847, 0.1063, 0.0835, 0.0922,\n",
      "         0.0761, 0.0980, 0.0936, 0.0927, 0.1125, 0.0923, 0.0800, 0.0987, 0.0867,\n",
      "         0.1035, 0.1016, 0.0776, 0.0890, 0.0630]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0082, 0.0069, 0.0063, 0.0061, 0.0061, 0.0076, 0.0067, 0.0074, 0.0080,\n",
      "        0.0069, 0.0043, 0.0038, 0.0038, 0.0071, 0.0061, 0.0080, 0.0062, 0.0072,\n",
      "        0.0047, 0.0084, 0.0074, 0.0066, 0.0082, 0.0062, 0.0065, 0.0084, 0.0075,\n",
      "        0.0084, 0.0081, 0.0055, 0.0067, 0.0038], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0072, 0.0073], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 5.7527e-02, -1.8580e-03,  0.0000e+00],\n",
      "        [ 5.1685e-02, -8.9774e-03,  0.0000e+00],\n",
      "        [ 4.8476e-02,  3.9052e-03,  0.0000e+00],\n",
      "        [ 5.1343e-02, -6.9633e-03,  0.0000e+00],\n",
      "        [ 4.2685e-02,  8.0167e-03,  0.0000e+00],\n",
      "        [ 5.2793e-02,  6.3682e-03,  0.0000e+00],\n",
      "        [ 5.0672e-02, -6.7371e-03,  0.0000e+00],\n",
      "        [ 5.8811e-02,  5.6390e-04,  0.0000e+00],\n",
      "        [ 5.7236e-02, -6.3960e-03,  0.0000e+00],\n",
      "        [ 5.1807e-02,  4.8882e-03,  0.0000e+00],\n",
      "        [ 3.2961e-02,  6.4389e-03,  0.0000e+00],\n",
      "        [ 2.6235e-02, -4.1440e-03,  0.0000e+00],\n",
      "        [ 2.1861e-02,  4.5498e-04,  0.0000e+00],\n",
      "        [ 5.5218e-02,  1.9382e-03,  0.0000e+00],\n",
      "        [ 4.9093e-02, -2.5744e-03,  0.0000e+00],\n",
      "        [ 5.9675e-02, -1.5447e-03,  0.0000e+00],\n",
      "        [ 4.4399e-02, -2.0852e-04,  0.0000e+00],\n",
      "        [ 5.5369e-02,  1.3139e-05,  0.0000e+00],\n",
      "        [ 2.8837e-02, -3.6258e-03,  0.0000e+00],\n",
      "        [ 5.8768e-02, -4.7315e-03,  0.0000e+00],\n",
      "        [ 5.5710e-02, -5.8714e-03,  0.0000e+00],\n",
      "        [ 5.4971e-02,  4.4533e-03,  0.0000e+00],\n",
      "        [ 6.3531e-02,  2.0924e-03,  0.0000e+00],\n",
      "        [ 4.3435e-02,  1.3701e-03,  0.0000e+00],\n",
      "        [ 5.2961e-02,  4.8788e-03,  0.0000e+00],\n",
      "        [ 6.8235e-02, -1.2889e-03,  0.0000e+00],\n",
      "        [ 5.7793e-02, -2.2228e-03,  0.0000e+00],\n",
      "        [ 7.1803e-02, -4.5742e-03,  0.0000e+00],\n",
      "        [ 5.5494e-02, -8.0257e-03,  0.0000e+00],\n",
      "        [ 3.4528e-02, -3.0934e-03,  0.0000e+00],\n",
      "        [ 4.5066e-02,  7.3783e-03,  0.0000e+00],\n",
      "        [ 2.7349e-02, -4.5278e-03,  0.0000e+00]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1190, 0.1072, 0.1036, 0.1015, 0.0978, 0.0980, 0.0901, 0.1077, 0.1082,\n",
      "         0.0886, 0.0749, 0.0734, 0.0613, 0.0987, 0.0983, 0.1134, 0.0940, 0.1065,\n",
      "         0.0739, 0.1062, 0.1010, 0.1116, 0.1167, 0.0993, 0.0900, 0.1083, 0.1042,\n",
      "         0.1261, 0.1123, 0.0856, 0.0975, 0.0597],\n",
      "        [0.1171, 0.1046, 0.0973, 0.0912, 0.0902, 0.0959, 0.0867, 0.1080, 0.1053,\n",
      "         0.0920, 0.0688, 0.0650, 0.0614, 0.0991, 0.0883, 0.1119, 0.0874, 0.0985,\n",
      "         0.0781, 0.1041, 0.0981, 0.0978, 0.1182, 0.0957, 0.0820, 0.1035, 0.0916,\n",
      "         0.1083, 0.1064, 0.0800, 0.0913, 0.0664]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0084, 0.0070, 0.0063, 0.0064, 0.0064, 0.0077, 0.0067, 0.0077, 0.0083,\n",
      "        0.0071, 0.0046, 0.0038, 0.0037, 0.0071, 0.0062, 0.0082, 0.0064, 0.0076,\n",
      "        0.0046, 0.0088, 0.0075, 0.0069, 0.0084, 0.0063, 0.0064, 0.0086, 0.0077,\n",
      "        0.0086, 0.0082, 0.0054, 0.0066, 0.0040], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0074, 0.0075], grad_fn=<MeanBackward1>)\n",
      "Epoch 1/10, Accuracy: 0.4688\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0445, -0.0052,  0.0000],\n",
      "        [ 0.0429, -0.0071,  0.0000],\n",
      "        [ 0.0406,  0.0023,  0.0000],\n",
      "        [ 0.0286, -0.0115,  0.0000],\n",
      "        [ 0.0326, -0.0057,  0.0000],\n",
      "        [ 0.0510, -0.0090,  0.0000],\n",
      "        [ 0.0299, -0.0028,  0.0000],\n",
      "        [ 0.0527, -0.0099,  0.0000],\n",
      "        [ 0.0564, -0.0135,  0.0000],\n",
      "        [ 0.0443, -0.0121,  0.0000],\n",
      "        [ 0.0351, -0.0039,  0.0000],\n",
      "        [ 0.0228, -0.0108,  0.0000],\n",
      "        [ 0.0151, -0.0062,  0.0000],\n",
      "        [ 0.0419, -0.0039,  0.0000],\n",
      "        [ 0.0418, -0.0041,  0.0000],\n",
      "        [ 0.0501, -0.0193,  0.0000],\n",
      "        [ 0.0339, -0.0096,  0.0000],\n",
      "        [ 0.0437, -0.0062,  0.0000],\n",
      "        [ 0.0378, -0.0024,  0.0000],\n",
      "        [ 0.0610, -0.0166,  0.0000],\n",
      "        [ 0.0551, -0.0122,  0.0000],\n",
      "        [ 0.0377, -0.0106,  0.0000],\n",
      "        [ 0.0617, -0.0094,  0.0000],\n",
      "        [ 0.0308, -0.0049,  0.0000],\n",
      "        [ 0.0430, -0.0120,  0.0000],\n",
      "        [ 0.0515, -0.0121,  0.0000],\n",
      "        [ 0.0524, -0.0192,  0.0000],\n",
      "        [ 0.0490, -0.0147,  0.0000],\n",
      "        [ 0.0573, -0.0199,  0.0000],\n",
      "        [ 0.0336, -0.0130,  0.0000],\n",
      "        [ 0.0424, -0.0107,  0.0000],\n",
      "        [ 0.0200, -0.0069,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1241, 0.1121, 0.1084, 0.1060, 0.1018, 0.1023, 0.0942, 0.1119, 0.1127,\n",
      "         0.0925, 0.0779, 0.0775, 0.0647, 0.1031, 0.1023, 0.1184, 0.0979, 0.1103,\n",
      "         0.0779, 0.1105, 0.1055, 0.1164, 0.1220, 0.1039, 0.0944, 0.1129, 0.1087,\n",
      "         0.1315, 0.1173, 0.0900, 0.1022, 0.0622],\n",
      "        [0.1224, 0.1095, 0.1023, 0.0948, 0.0940, 0.1008, 0.0912, 0.1124, 0.1098,\n",
      "         0.0964, 0.0712, 0.0684, 0.0649, 0.1041, 0.0923, 0.1168, 0.0914, 0.1020,\n",
      "         0.0825, 0.1083, 0.1027, 0.1019, 0.1235, 0.1005, 0.0869, 0.1084, 0.0956,\n",
      "         0.1134, 0.1114, 0.0843, 0.0965, 0.0691]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0085, 0.0071, 0.0065, 0.0065, 0.0064, 0.0078, 0.0068, 0.0078, 0.0084,\n",
      "        0.0072, 0.0047, 0.0040, 0.0039, 0.0073, 0.0063, 0.0084, 0.0064, 0.0077,\n",
      "        0.0048, 0.0089, 0.0077, 0.0070, 0.0086, 0.0064, 0.0065, 0.0087, 0.0079,\n",
      "        0.0087, 0.0084, 0.0056, 0.0068, 0.0041], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0076, 0.0077], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0387, -0.0047,  0.0000],\n",
      "        [ 0.0268, -0.0008,  0.0000],\n",
      "        [ 0.0246,  0.0010,  0.0000],\n",
      "        [ 0.0328, -0.0073,  0.0000],\n",
      "        [ 0.0264, -0.0054,  0.0000],\n",
      "        [ 0.0218,  0.0071,  0.0000],\n",
      "        [ 0.0297, -0.0023,  0.0000],\n",
      "        [ 0.0283, -0.0097,  0.0000],\n",
      "        [ 0.0261, -0.0119,  0.0000],\n",
      "        [ 0.0284, -0.0147,  0.0000],\n",
      "        [ 0.0237, -0.0004,  0.0000],\n",
      "        [ 0.0070, -0.0081,  0.0000],\n",
      "        [ 0.0139, -0.0062,  0.0000],\n",
      "        [ 0.0255, -0.0116,  0.0000],\n",
      "        [ 0.0218, -0.0063,  0.0000],\n",
      "        [ 0.0329, -0.0011,  0.0000],\n",
      "        [ 0.0256, -0.0072,  0.0000],\n",
      "        [ 0.0413,  0.0015,  0.0000],\n",
      "        [ 0.0191, -0.0043,  0.0000],\n",
      "        [ 0.0275, -0.0012,  0.0000],\n",
      "        [ 0.0319, -0.0053,  0.0000],\n",
      "        [ 0.0269, -0.0038,  0.0000],\n",
      "        [ 0.0298, -0.0080,  0.0000],\n",
      "        [ 0.0202, -0.0031,  0.0000],\n",
      "        [ 0.0225, -0.0036,  0.0000],\n",
      "        [ 0.0360, -0.0008,  0.0000],\n",
      "        [ 0.0314, -0.0061,  0.0000],\n",
      "        [ 0.0305, -0.0107,  0.0000],\n",
      "        [ 0.0272,  0.0069,  0.0000],\n",
      "        [ 0.0180, -0.0066,  0.0000],\n",
      "        [ 0.0244, -0.0019,  0.0000],\n",
      "        [ 0.0176, -0.0010,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1298, 0.1172, 0.1138, 0.1099, 0.1062, 0.1074, 0.0994, 0.1167, 0.1178,\n",
      "         0.0971, 0.0806, 0.0807, 0.0680, 0.1084, 0.1072, 0.1235, 0.1025, 0.1144,\n",
      "         0.0817, 0.1153, 0.1105, 0.1211, 0.1274, 0.1090, 0.0996, 0.1183, 0.1134,\n",
      "         0.1377, 0.1227, 0.0944, 0.1077, 0.0646],\n",
      "        [0.1280, 0.1146, 0.1069, 0.0990, 0.0982, 0.1055, 0.0957, 0.1176, 0.1151,\n",
      "         0.1010, 0.0743, 0.0715, 0.0679, 0.1090, 0.0966, 0.1222, 0.0956, 0.1065,\n",
      "         0.0862, 0.1135, 0.1075, 0.1065, 0.1292, 0.1052, 0.0909, 0.1135, 0.1002,\n",
      "         0.1188, 0.1165, 0.0883, 0.1009, 0.0721]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0087, 0.0073, 0.0067, 0.0065, 0.0065, 0.0079, 0.0070, 0.0079, 0.0086,\n",
      "        0.0073, 0.0047, 0.0041, 0.0041, 0.0075, 0.0064, 0.0085, 0.0066, 0.0077,\n",
      "        0.0049, 0.0090, 0.0078, 0.0071, 0.0088, 0.0066, 0.0068, 0.0088, 0.0080,\n",
      "        0.0089, 0.0085, 0.0058, 0.0070, 0.0041], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0078, 0.0079], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[0.0497, 0.0227, 0.0000],\n",
      "        [0.0454, 0.0263, 0.0000],\n",
      "        [0.0508, 0.0262, 0.0000],\n",
      "        [0.0334, 0.0174, 0.0000],\n",
      "        [0.0377, 0.0110, 0.0000],\n",
      "        [0.0524, 0.0290, 0.0000],\n",
      "        [0.0375, 0.0193, 0.0000],\n",
      "        [0.0487, 0.0189, 0.0000],\n",
      "        [0.0443, 0.0251, 0.0000],\n",
      "        [0.0455, 0.0256, 0.0000],\n",
      "        [0.0337, 0.0178, 0.0000],\n",
      "        [0.0026, 0.0076, 0.0000],\n",
      "        [0.0275, 0.0123, 0.0000],\n",
      "        [0.0489, 0.0227, 0.0000],\n",
      "        [0.0314, 0.0246, 0.0000],\n",
      "        [0.0526, 0.0166, 0.0000],\n",
      "        [0.0367, 0.0194, 0.0000],\n",
      "        [0.0506, 0.0182, 0.0000],\n",
      "        [0.0239, 0.0131, 0.0000],\n",
      "        [0.0666, 0.0327, 0.0000],\n",
      "        [0.0339, 0.0274, 0.0000],\n",
      "        [0.0478, 0.0201, 0.0000],\n",
      "        [0.0540, 0.0253, 0.0000],\n",
      "        [0.0468, 0.0155, 0.0000],\n",
      "        [0.0390, 0.0187, 0.0000],\n",
      "        [0.0615, 0.0275, 0.0000],\n",
      "        [0.0406, 0.0185, 0.0000],\n",
      "        [0.0480, 0.0250, 0.0000],\n",
      "        [0.0567, 0.0229, 0.0000],\n",
      "        [0.0175, 0.0135, 0.0000],\n",
      "        [0.0427, 0.0256, 0.0000],\n",
      "        [0.0220, 0.0113, 0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1363, 0.1223, 0.1188, 0.1149, 0.1119, 0.1136, 0.1045, 0.1229, 0.1240,\n",
      "         0.1023, 0.0840, 0.0819, 0.0701, 0.1137, 0.1126, 0.1290, 0.1079, 0.1215,\n",
      "         0.0844, 0.1217, 0.1159, 0.1267, 0.1331, 0.1140, 0.1046, 0.1249, 0.1192,\n",
      "         0.1445, 0.1288, 0.0976, 0.1128, 0.0675],\n",
      "        [0.1345, 0.1197, 0.1115, 0.1039, 0.1037, 0.1113, 0.1004, 0.1239, 0.1213,\n",
      "         0.1063, 0.0778, 0.0726, 0.0700, 0.1141, 0.1015, 0.1280, 0.1007, 0.1135,\n",
      "         0.0889, 0.1200, 0.1130, 0.1117, 0.1352, 0.1099, 0.0952, 0.1199, 0.1057,\n",
      "         0.1249, 0.1224, 0.0912, 0.1055, 0.0755]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0090, 0.0074, 0.0068, 0.0067, 0.0068, 0.0083, 0.0073, 0.0082, 0.0088,\n",
      "        0.0076, 0.0048, 0.0039, 0.0040, 0.0077, 0.0067, 0.0086, 0.0069, 0.0081,\n",
      "        0.0049, 0.0093, 0.0080, 0.0072, 0.0089, 0.0068, 0.0070, 0.0092, 0.0082,\n",
      "        0.0092, 0.0088, 0.0058, 0.0072, 0.0042], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0080, 0.0081], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0302,  0.0097,  0.0000],\n",
      "        [ 0.0302, -0.0028,  0.0000],\n",
      "        [ 0.0346, -0.0068,  0.0000],\n",
      "        [ 0.0326,  0.0010,  0.0000],\n",
      "        [ 0.0372, -0.0005,  0.0000],\n",
      "        [ 0.0339, -0.0034,  0.0000],\n",
      "        [ 0.0327,  0.0016,  0.0000],\n",
      "        [ 0.0492,  0.0055,  0.0000],\n",
      "        [ 0.0402,  0.0062,  0.0000],\n",
      "        [ 0.0358, -0.0018,  0.0000],\n",
      "        [ 0.0198, -0.0016,  0.0000],\n",
      "        [ 0.0132, -0.0082,  0.0000],\n",
      "        [ 0.0261,  0.0036,  0.0000],\n",
      "        [ 0.0322,  0.0005,  0.0000],\n",
      "        [ 0.0175, -0.0010,  0.0000],\n",
      "        [ 0.0449,  0.0034,  0.0000],\n",
      "        [ 0.0238,  0.0096,  0.0000],\n",
      "        [ 0.0295,  0.0082,  0.0000],\n",
      "        [ 0.0335, -0.0046,  0.0000],\n",
      "        [ 0.0514,  0.0019,  0.0000],\n",
      "        [ 0.0324, -0.0009,  0.0000],\n",
      "        [ 0.0358,  0.0022,  0.0000],\n",
      "        [ 0.0498, -0.0052,  0.0000],\n",
      "        [ 0.0299, -0.0033,  0.0000],\n",
      "        [ 0.0256, -0.0106,  0.0000],\n",
      "        [ 0.0394, -0.0006,  0.0000],\n",
      "        [ 0.0424, -0.0035,  0.0000],\n",
      "        [ 0.0359, -0.0026,  0.0000],\n",
      "        [ 0.0448, -0.0070,  0.0000],\n",
      "        [ 0.0225,  0.0008,  0.0000],\n",
      "        [ 0.0262,  0.0035,  0.0000],\n",
      "        [ 0.0147, -0.0023,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1419, 0.1279, 0.1241, 0.1200, 0.1161, 0.1182, 0.1089, 0.1276, 0.1289,\n",
      "         0.1065, 0.0878, 0.0870, 0.0739, 0.1186, 0.1170, 0.1349, 0.1120, 0.1258,\n",
      "         0.0889, 0.1266, 0.1210, 0.1322, 0.1392, 0.1191, 0.1091, 0.1299, 0.1241,\n",
      "         0.1505, 0.1343, 0.1028, 0.1175, 0.0704],\n",
      "        [0.1403, 0.1253, 0.1170, 0.1082, 0.1077, 0.1164, 0.1054, 0.1286, 0.1263,\n",
      "         0.1110, 0.0809, 0.0770, 0.0740, 0.1195, 0.1059, 0.1337, 0.1049, 0.1173,\n",
      "         0.0940, 0.1249, 0.1181, 0.1164, 0.1413, 0.1152, 0.1002, 0.1252, 0.1101,\n",
      "         0.1304, 0.1280, 0.0963, 0.1108, 0.0787]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0091, 0.0076, 0.0070, 0.0068, 0.0069, 0.0084, 0.0074, 0.0082, 0.0089,\n",
      "        0.0077, 0.0049, 0.0042, 0.0042, 0.0078, 0.0067, 0.0088, 0.0069, 0.0081,\n",
      "        0.0051, 0.0094, 0.0082, 0.0074, 0.0091, 0.0069, 0.0071, 0.0093, 0.0083,\n",
      "        0.0093, 0.0089, 0.0060, 0.0073, 0.0043], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0083, 0.0084], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0605, -0.0130,  0.0000],\n",
      "        [ 0.0435, -0.0113,  0.0000],\n",
      "        [ 0.0330, -0.0054,  0.0000],\n",
      "        [ 0.0487, -0.0097,  0.0000],\n",
      "        [ 0.0400, -0.0029,  0.0000],\n",
      "        [ 0.0421, -0.0046,  0.0000],\n",
      "        [ 0.0433, -0.0059,  0.0000],\n",
      "        [ 0.0504, -0.0053,  0.0000],\n",
      "        [ 0.0573, -0.0111,  0.0000],\n",
      "        [ 0.0644, -0.0041,  0.0000],\n",
      "        [ 0.0375, -0.0100,  0.0000],\n",
      "        [ 0.0294, -0.0093,  0.0000],\n",
      "        [ 0.0316, -0.0091,  0.0000],\n",
      "        [ 0.0499, -0.0120,  0.0000],\n",
      "        [ 0.0409,  0.0011,  0.0000],\n",
      "        [ 0.0554, -0.0126,  0.0000],\n",
      "        [ 0.0467,  0.0029,  0.0000],\n",
      "        [ 0.0586, -0.0096,  0.0000],\n",
      "        [ 0.0244, -0.0085,  0.0000],\n",
      "        [ 0.0634, -0.0055,  0.0000],\n",
      "        [ 0.0533, -0.0029,  0.0000],\n",
      "        [ 0.0449, -0.0160,  0.0000],\n",
      "        [ 0.0560, -0.0092,  0.0000],\n",
      "        [ 0.0338, -0.0037,  0.0000],\n",
      "        [ 0.0347, -0.0019,  0.0000],\n",
      "        [ 0.0581, -0.0048,  0.0000],\n",
      "        [ 0.0499, -0.0005,  0.0000],\n",
      "        [ 0.0498, -0.0021,  0.0000],\n",
      "        [ 0.0538, -0.0079,  0.0000],\n",
      "        [ 0.0308, -0.0057,  0.0000],\n",
      "        [ 0.0430, -0.0083,  0.0000],\n",
      "        [ 0.0313, -0.0035,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1482, 0.1336, 0.1292, 0.1256, 0.1212, 0.1233, 0.1134, 0.1336, 0.1350,\n",
      "         0.1112, 0.0919, 0.0909, 0.0770, 0.1237, 0.1220, 0.1412, 0.1170, 0.1316,\n",
      "         0.0925, 0.1327, 0.1265, 0.1382, 0.1457, 0.1242, 0.1134, 0.1357, 0.1299,\n",
      "         0.1570, 0.1403, 0.1072, 0.1225, 0.0736],\n",
      "        [0.1465, 0.1311, 0.1215, 0.1138, 0.1125, 0.1209, 0.1092, 0.1348, 0.1322,\n",
      "         0.1157, 0.0853, 0.0812, 0.0772, 0.1243, 0.1101, 0.1403, 0.1093, 0.1230,\n",
      "         0.0977, 0.1310, 0.1235, 0.1222, 0.1482, 0.1200, 0.1036, 0.1305, 0.1156,\n",
      "         0.1360, 0.1337, 0.1006, 0.1148, 0.0825]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0092, 0.0077, 0.0070, 0.0071, 0.0070, 0.0084, 0.0074, 0.0085, 0.0091,\n",
      "        0.0078, 0.0051, 0.0043, 0.0043, 0.0079, 0.0068, 0.0090, 0.0070, 0.0083,\n",
      "        0.0052, 0.0096, 0.0083, 0.0076, 0.0093, 0.0070, 0.0071, 0.0094, 0.0085,\n",
      "        0.0094, 0.0091, 0.0061, 0.0074, 0.0044], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0085, 0.0086], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 5.4798e-02, -4.8132e-03,  0.0000e+00],\n",
      "        [ 4.9342e-02, -1.6276e-03,  0.0000e+00],\n",
      "        [ 5.0628e-02,  2.3988e-04,  0.0000e+00],\n",
      "        [ 4.7762e-02,  1.3039e-05,  0.0000e+00],\n",
      "        [ 3.8347e-02, -3.0207e-03,  0.0000e+00],\n",
      "        [ 5.6123e-02,  7.0280e-03,  0.0000e+00],\n",
      "        [ 3.7394e-02, -1.0384e-03,  0.0000e+00],\n",
      "        [ 5.4437e-02,  1.9854e-03,  0.0000e+00],\n",
      "        [ 5.3657e-02, -1.6565e-03,  0.0000e+00],\n",
      "        [ 4.7859e-02,  5.4698e-03,  0.0000e+00],\n",
      "        [ 3.2042e-02,  6.8719e-04,  0.0000e+00],\n",
      "        [ 3.2460e-02, -5.8103e-03,  0.0000e+00],\n",
      "        [ 2.0127e-02, -1.1691e-03,  0.0000e+00],\n",
      "        [ 5.2227e-02,  5.3605e-03,  0.0000e+00],\n",
      "        [ 4.7525e-02,  3.8593e-03,  0.0000e+00],\n",
      "        [ 5.4898e-02,  8.4725e-03,  0.0000e+00],\n",
      "        [ 4.2760e-02, -2.4270e-03,  0.0000e+00],\n",
      "        [ 5.5470e-02, -1.8425e-03,  0.0000e+00],\n",
      "        [ 3.0020e-02,  1.1642e-04,  0.0000e+00],\n",
      "        [ 5.6470e-02,  2.5240e-03,  0.0000e+00],\n",
      "        [ 5.3882e-02,  8.4989e-03,  0.0000e+00],\n",
      "        [ 5.9569e-02,  1.3621e-03,  0.0000e+00],\n",
      "        [ 5.7898e-02,  1.0727e-03,  0.0000e+00],\n",
      "        [ 4.7360e-02, -4.1472e-03,  0.0000e+00],\n",
      "        [ 4.4801e-02,  5.7932e-03,  0.0000e+00],\n",
      "        [ 5.7652e-02,  5.2685e-03,  0.0000e+00],\n",
      "        [ 5.2065e-02,  8.4259e-03,  0.0000e+00],\n",
      "        [ 7.2229e-02, -8.4215e-03,  0.0000e+00],\n",
      "        [ 5.5004e-02,  1.1763e-02,  0.0000e+00],\n",
      "        [ 2.9140e-02, -2.4927e-03,  0.0000e+00],\n",
      "        [ 4.8683e-02,  1.1554e-02,  0.0000e+00],\n",
      "        [ 2.1289e-02, -1.7303e-03,  0.0000e+00]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1552, 0.1395, 0.1343, 0.1319, 0.1273, 0.1289, 0.1178, 0.1406, 0.1418,\n",
      "         0.1166, 0.0968, 0.0937, 0.0795, 0.1289, 0.1275, 0.1480, 0.1226, 0.1393,\n",
      "         0.0956, 0.1400, 0.1325, 0.1448, 0.1525, 0.1294, 0.1177, 0.1422, 0.1364,\n",
      "         0.1643, 0.1467, 0.1110, 0.1269, 0.0773],\n",
      "        [0.1533, 0.1371, 0.1271, 0.1190, 0.1177, 0.1267, 0.1144, 0.1410, 0.1385,\n",
      "         0.1213, 0.0892, 0.0845, 0.0806, 0.1301, 0.1152, 0.1468, 0.1145, 0.1288,\n",
      "         0.1020, 0.1375, 0.1293, 0.1277, 0.1550, 0.1256, 0.1087, 0.1369, 0.1211,\n",
      "         0.1426, 0.1399, 0.1051, 0.1200, 0.0861]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0094, 0.0079, 0.0072, 0.0072, 0.0072, 0.0086, 0.0076, 0.0086, 0.0093,\n",
      "        0.0080, 0.0052, 0.0043, 0.0043, 0.0081, 0.0070, 0.0092, 0.0072, 0.0085,\n",
      "        0.0053, 0.0098, 0.0085, 0.0077, 0.0095, 0.0071, 0.0073, 0.0096, 0.0087,\n",
      "        0.0096, 0.0093, 0.0062, 0.0076, 0.0045], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0087, 0.0088], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0771,  0.0129,  0.0000],\n",
      "        [ 0.0662,  0.0103,  0.0000],\n",
      "        [ 0.0636,  0.0098,  0.0000],\n",
      "        [ 0.0661,  0.0099,  0.0000],\n",
      "        [ 0.0534,  0.0090,  0.0000],\n",
      "        [ 0.0720,  0.0122,  0.0000],\n",
      "        [ 0.0570,  0.0031,  0.0000],\n",
      "        [ 0.0780,  0.0024,  0.0000],\n",
      "        [ 0.0808,  0.0146,  0.0000],\n",
      "        [ 0.0625,  0.0025,  0.0000],\n",
      "        [ 0.0483,  0.0094,  0.0000],\n",
      "        [ 0.0270, -0.0015,  0.0000],\n",
      "        [ 0.0425,  0.0014,  0.0000],\n",
      "        [ 0.0726,  0.0083,  0.0000],\n",
      "        [ 0.0547, -0.0014,  0.0000],\n",
      "        [ 0.0762,  0.0095,  0.0000],\n",
      "        [ 0.0592,  0.0044,  0.0000],\n",
      "        [ 0.0814,  0.0095,  0.0000],\n",
      "        [ 0.0422,  0.0051,  0.0000],\n",
      "        [ 0.0921,  0.0085,  0.0000],\n",
      "        [ 0.0706,  0.0058,  0.0000],\n",
      "        [ 0.0706,  0.0132,  0.0000],\n",
      "        [ 0.0788,  0.0090,  0.0000],\n",
      "        [ 0.0606,  0.0075,  0.0000],\n",
      "        [ 0.0465,  0.0111,  0.0000],\n",
      "        [ 0.0756,  0.0112,  0.0000],\n",
      "        [ 0.0646,  0.0044,  0.0000],\n",
      "        [ 0.0709,  0.0107,  0.0000],\n",
      "        [ 0.0782,  0.0077,  0.0000],\n",
      "        [ 0.0468,  0.0132,  0.0000],\n",
      "        [ 0.0693,  0.0120,  0.0000],\n",
      "        [ 0.0329, -0.0010,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1626, 0.1456, 0.1405, 0.1373, 0.1335, 0.1360, 0.1242, 0.1474, 0.1486,\n",
      "         0.1228, 0.1005, 0.0960, 0.0826, 0.1354, 0.1340, 0.1544, 0.1288, 0.1461,\n",
      "         0.0995, 0.1469, 0.1389, 0.1512, 0.1592, 0.1354, 0.1237, 0.1497, 0.1429,\n",
      "         0.1722, 0.1538, 0.1157, 0.1335, 0.0805],\n",
      "        [0.1607, 0.1432, 0.1324, 0.1248, 0.1239, 0.1333, 0.1198, 0.1485, 0.1457,\n",
      "         0.1276, 0.0935, 0.0863, 0.0832, 0.1361, 0.1211, 0.1537, 0.1204, 0.1367,\n",
      "         0.1056, 0.1451, 0.1358, 0.1340, 0.1622, 0.1310, 0.1134, 0.1441, 0.1276,\n",
      "         0.1497, 0.1468, 0.1090, 0.1254, 0.0902]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0097, 0.0080, 0.0074, 0.0074, 0.0074, 0.0088, 0.0077, 0.0089, 0.0096,\n",
      "        0.0082, 0.0053, 0.0043, 0.0044, 0.0083, 0.0072, 0.0094, 0.0074, 0.0088,\n",
      "        0.0054, 0.0101, 0.0087, 0.0079, 0.0097, 0.0073, 0.0074, 0.0099, 0.0089,\n",
      "        0.0098, 0.0095, 0.0063, 0.0077, 0.0046], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0089, 0.0090], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0378,  0.0057,  0.0000],\n",
      "        [ 0.0348,  0.0032,  0.0000],\n",
      "        [ 0.0348,  0.0073,  0.0000],\n",
      "        [ 0.0388,  0.0042,  0.0000],\n",
      "        [ 0.0307,  0.0080,  0.0000],\n",
      "        [ 0.0412,  0.0008,  0.0000],\n",
      "        [ 0.0353,  0.0048,  0.0000],\n",
      "        [ 0.0337,  0.0024,  0.0000],\n",
      "        [ 0.0355,  0.0052,  0.0000],\n",
      "        [ 0.0359,  0.0175,  0.0000],\n",
      "        [ 0.0232,  0.0018,  0.0000],\n",
      "        [ 0.0166, -0.0008,  0.0000],\n",
      "        [ 0.0184,  0.0103,  0.0000],\n",
      "        [ 0.0330,  0.0062,  0.0000],\n",
      "        [ 0.0282,  0.0053,  0.0000],\n",
      "        [ 0.0353,  0.0096,  0.0000],\n",
      "        [ 0.0377,  0.0023,  0.0000],\n",
      "        [ 0.0395,  0.0024,  0.0000],\n",
      "        [ 0.0179,  0.0049,  0.0000],\n",
      "        [ 0.0455,  0.0122,  0.0000],\n",
      "        [ 0.0349,  0.0015,  0.0000],\n",
      "        [ 0.0354,  0.0067,  0.0000],\n",
      "        [ 0.0395,  0.0062,  0.0000],\n",
      "        [ 0.0263,  0.0101,  0.0000],\n",
      "        [ 0.0358,  0.0081,  0.0000],\n",
      "        [ 0.0490,  0.0072,  0.0000],\n",
      "        [ 0.0434, -0.0029,  0.0000],\n",
      "        [ 0.0442,  0.0057,  0.0000],\n",
      "        [ 0.0354,  0.0014,  0.0000],\n",
      "        [ 0.0222,  0.0026,  0.0000],\n",
      "        [ 0.0354,  0.0056,  0.0000],\n",
      "        [ 0.0217, -0.0006,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1695, 0.1523, 0.1474, 0.1426, 0.1384, 0.1421, 0.1306, 0.1528, 0.1546,\n",
      "         0.1279, 0.1042, 0.1019, 0.0876, 0.1418, 0.1393, 0.1610, 0.1340, 0.1506,\n",
      "         0.1052, 0.1524, 0.1451, 0.1572, 0.1662, 0.1419, 0.1304, 0.1560, 0.1486,\n",
      "         0.1795, 0.1606, 0.1219, 0.1404, 0.0836],\n",
      "        [0.1677, 0.1499, 0.1396, 0.1291, 0.1285, 0.1399, 0.1268, 0.1538, 0.1516,\n",
      "         0.1332, 0.0962, 0.0917, 0.0886, 0.1432, 0.1264, 0.1601, 0.1257, 0.1403,\n",
      "         0.1119, 0.1503, 0.1420, 0.1391, 0.1692, 0.1378, 0.1207, 0.1506, 0.1326,\n",
      "         0.1565, 0.1536, 0.1154, 0.1329, 0.0935]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0098, 0.0082, 0.0076, 0.0074, 0.0075, 0.0090, 0.0080, 0.0090, 0.0097,\n",
      "        0.0083, 0.0053, 0.0045, 0.0046, 0.0085, 0.0073, 0.0095, 0.0075, 0.0088,\n",
      "        0.0056, 0.0102, 0.0089, 0.0080, 0.0098, 0.0075, 0.0077, 0.0100, 0.0090,\n",
      "        0.0100, 0.0097, 0.0065, 0.0080, 0.0047], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0091, 0.0093], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0403,  0.0106,  0.0000],\n",
      "        [ 0.0370, -0.0067,  0.0000],\n",
      "        [ 0.0299,  0.0155,  0.0000],\n",
      "        [ 0.0362,  0.0097,  0.0000],\n",
      "        [ 0.0187,  0.0090,  0.0000],\n",
      "        [ 0.0325,  0.0093,  0.0000],\n",
      "        [ 0.0299,  0.0111,  0.0000],\n",
      "        [ 0.0383,  0.0070,  0.0000],\n",
      "        [ 0.0347, -0.0003,  0.0000],\n",
      "        [ 0.0245,  0.0049,  0.0000],\n",
      "        [ 0.0217,  0.0071,  0.0000],\n",
      "        [ 0.0157,  0.0005,  0.0000],\n",
      "        [ 0.0124, -0.0024,  0.0000],\n",
      "        [ 0.0286,  0.0138,  0.0000],\n",
      "        [ 0.0305,  0.0060,  0.0000],\n",
      "        [ 0.0177,  0.0005,  0.0000],\n",
      "        [ 0.0367,  0.0028,  0.0000],\n",
      "        [ 0.0329,  0.0128,  0.0000],\n",
      "        [ 0.0242,  0.0048,  0.0000],\n",
      "        [ 0.0351, -0.0028,  0.0000],\n",
      "        [ 0.0316,  0.0032,  0.0000],\n",
      "        [ 0.0258,  0.0054,  0.0000],\n",
      "        [ 0.0358,  0.0020,  0.0000],\n",
      "        [ 0.0279,  0.0028,  0.0000],\n",
      "        [ 0.0153,  0.0052,  0.0000],\n",
      "        [ 0.0353,  0.0096,  0.0000],\n",
      "        [ 0.0309,  0.0076,  0.0000],\n",
      "        [ 0.0389,  0.0089,  0.0000],\n",
      "        [ 0.0161,  0.0018,  0.0000],\n",
      "        [ 0.0223, -0.0012,  0.0000],\n",
      "        [ 0.0180,  0.0090,  0.0000],\n",
      "        [ 0.0221,  0.0006,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1771, 0.1591, 0.1540, 0.1489, 0.1445, 0.1485, 0.1365, 0.1595, 0.1616,\n",
      "         0.1339, 0.1087, 0.1064, 0.0915, 0.1482, 0.1456, 0.1683, 0.1400, 0.1574,\n",
      "         0.1100, 0.1597, 0.1517, 0.1642, 0.1737, 0.1484, 0.1362, 0.1631, 0.1554,\n",
      "         0.1875, 0.1679, 0.1274, 0.1466, 0.0873],\n",
      "        [0.1755, 0.1566, 0.1455, 0.1354, 0.1348, 0.1466, 0.1323, 0.1613, 0.1591,\n",
      "         0.1398, 0.1010, 0.0949, 0.0918, 0.1494, 0.1323, 0.1677, 0.1317, 0.1479,\n",
      "         0.1163, 0.1583, 0.1487, 0.1458, 0.1771, 0.1439, 0.1258, 0.1580, 0.1393,\n",
      "         0.1640, 0.1608, 0.1200, 0.1384, 0.0979]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0100, 0.0084, 0.0078, 0.0076, 0.0076, 0.0092, 0.0082, 0.0091, 0.0099,\n",
      "        0.0085, 0.0054, 0.0047, 0.0047, 0.0087, 0.0075, 0.0097, 0.0076, 0.0089,\n",
      "        0.0058, 0.0104, 0.0090, 0.0082, 0.0100, 0.0077, 0.0079, 0.0102, 0.0092,\n",
      "        0.0102, 0.0099, 0.0067, 0.0081, 0.0048], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0094, 0.0095], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0667, -0.0154,  0.0000],\n",
      "        [ 0.0693, -0.0082,  0.0000],\n",
      "        [ 0.0481, -0.0038,  0.0000],\n",
      "        [ 0.0576, -0.0059,  0.0000],\n",
      "        [ 0.0467, -0.0140,  0.0000],\n",
      "        [ 0.0569, -0.0063,  0.0000],\n",
      "        [ 0.0463, -0.0244,  0.0000],\n",
      "        [ 0.0723, -0.0148,  0.0000],\n",
      "        [ 0.0704, -0.0105,  0.0000],\n",
      "        [ 0.0531, -0.0111,  0.0000],\n",
      "        [ 0.0333, -0.0052,  0.0000],\n",
      "        [ 0.0218, -0.0107,  0.0000],\n",
      "        [ 0.0347, -0.0086,  0.0000],\n",
      "        [ 0.0520, -0.0047,  0.0000],\n",
      "        [ 0.0438, -0.0085,  0.0000],\n",
      "        [ 0.0711, -0.0116,  0.0000],\n",
      "        [ 0.0541, -0.0183,  0.0000],\n",
      "        [ 0.0595, -0.0078,  0.0000],\n",
      "        [ 0.0476, -0.0085,  0.0000],\n",
      "        [ 0.0765, -0.0159,  0.0000],\n",
      "        [ 0.0592, -0.0053,  0.0000],\n",
      "        [ 0.0508, -0.0058,  0.0000],\n",
      "        [ 0.0790, -0.0082,  0.0000],\n",
      "        [ 0.0430, -0.0159,  0.0000],\n",
      "        [ 0.0479, -0.0126,  0.0000],\n",
      "        [ 0.0724, -0.0120,  0.0000],\n",
      "        [ 0.0638, -0.0117,  0.0000],\n",
      "        [ 0.0653, -0.0217,  0.0000],\n",
      "        [ 0.0658, -0.0106,  0.0000],\n",
      "        [ 0.0474, -0.0078,  0.0000],\n",
      "        [ 0.0414, -0.0007,  0.0000],\n",
      "        [ 0.0385, -0.0106,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1849, 0.1662, 0.1599, 0.1565, 0.1512, 0.1545, 0.1416, 0.1672, 0.1691,\n",
      "         0.1399, 0.1146, 0.1108, 0.0950, 0.1541, 0.1516, 0.1763, 0.1461, 0.1657,\n",
      "         0.1142, 0.1675, 0.1586, 0.1720, 0.1819, 0.1544, 0.1412, 0.1703, 0.1628,\n",
      "         0.1957, 0.1753, 0.1326, 0.1515, 0.0915],\n",
      "        [0.1834, 0.1638, 0.1510, 0.1428, 0.1409, 0.1521, 0.1369, 0.1691, 0.1665,\n",
      "         0.1458, 0.1068, 0.0995, 0.0954, 0.1552, 0.1376, 0.1760, 0.1372, 0.1557,\n",
      "         0.1209, 0.1662, 0.1555, 0.1532, 0.1856, 0.1497, 0.1298, 0.1648, 0.1463,\n",
      "         0.1712, 0.1679, 0.1252, 0.1427, 0.1027]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0102, 0.0086, 0.0078, 0.0079, 0.0078, 0.0092, 0.0082, 0.0093, 0.0101,\n",
      "        0.0086, 0.0057, 0.0048, 0.0048, 0.0088, 0.0075, 0.0100, 0.0077, 0.0092,\n",
      "        0.0058, 0.0106, 0.0092, 0.0084, 0.0103, 0.0077, 0.0079, 0.0103, 0.0094,\n",
      "        0.0104, 0.0100, 0.0068, 0.0081, 0.0049], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0096, 0.0097], grad_fn=<MeanBackward1>)\n",
      "Epoch 2/10, Accuracy: 0.4844\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 5.3739e-02,  2.0636e-03,  0.0000e+00],\n",
      "        [ 5.1833e-02,  3.0774e-04,  0.0000e+00],\n",
      "        [ 4.2758e-02,  1.1888e-02,  0.0000e+00],\n",
      "        [ 5.0651e-02,  7.1177e-04,  0.0000e+00],\n",
      "        [ 5.1559e-02,  7.6389e-03,  0.0000e+00],\n",
      "        [ 5.0007e-02,  1.4460e-02,  0.0000e+00],\n",
      "        [ 4.4281e-02,  5.9987e-03,  0.0000e+00],\n",
      "        [ 4.8212e-02,  2.8653e-03,  0.0000e+00],\n",
      "        [ 5.4328e-02, -7.2275e-04,  0.0000e+00],\n",
      "        [ 5.0700e-02, -6.0675e-03,  0.0000e+00],\n",
      "        [ 3.5609e-02,  1.8673e-03,  0.0000e+00],\n",
      "        [ 2.0004e-02,  1.9836e-03,  0.0000e+00],\n",
      "        [ 2.6413e-02, -1.7041e-03,  0.0000e+00],\n",
      "        [ 4.2937e-02,  2.1382e-03,  0.0000e+00],\n",
      "        [ 4.6781e-02,  3.5359e-03,  0.0000e+00],\n",
      "        [ 5.5198e-02,  7.4049e-03,  0.0000e+00],\n",
      "        [ 6.2700e-02,  1.5770e-03,  0.0000e+00],\n",
      "        [ 5.4933e-02,  3.6537e-03,  0.0000e+00],\n",
      "        [ 1.5075e-02,  5.3478e-05,  0.0000e+00],\n",
      "        [ 6.6761e-02,  1.1741e-02,  0.0000e+00],\n",
      "        [ 4.7187e-02,  8.8332e-04,  0.0000e+00],\n",
      "        [ 5.2467e-02,  4.8718e-03,  0.0000e+00],\n",
      "        [ 5.2922e-02,  5.4675e-03,  0.0000e+00],\n",
      "        [ 5.6719e-02,  6.8972e-03,  0.0000e+00],\n",
      "        [ 4.7448e-02,  4.3264e-03,  0.0000e+00],\n",
      "        [ 6.0393e-02,  6.2438e-03,  0.0000e+00],\n",
      "        [ 5.7926e-02,  3.8055e-03,  0.0000e+00],\n",
      "        [ 7.3148e-02,  1.5060e-04,  0.0000e+00],\n",
      "        [ 5.3311e-02,  1.3131e-02,  0.0000e+00],\n",
      "        [ 2.6590e-02, -3.0061e-03,  0.0000e+00],\n",
      "        [ 5.2657e-02,  1.5542e-02,  0.0000e+00],\n",
      "        [ 2.3600e-02, -4.3283e-03,  0.0000e+00]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1936, 0.1735, 0.1670, 0.1633, 0.1583, 0.1622, 0.1482, 0.1755, 0.1773,\n",
      "         0.1469, 0.1193, 0.1143, 0.0987, 0.1614, 0.1587, 0.1843, 0.1531, 0.1740,\n",
      "         0.1184, 0.1758, 0.1661, 0.1796, 0.1901, 0.1614, 0.1478, 0.1787, 0.1705,\n",
      "         0.2048, 0.1834, 0.1378, 0.1588, 0.0956],\n",
      "        [0.1919, 0.1713, 0.1588, 0.1482, 0.1472, 0.1602, 0.1446, 0.1764, 0.1741,\n",
      "         0.1530, 0.1102, 0.1037, 0.1004, 0.1634, 0.1443, 0.1835, 0.1439, 0.1619,\n",
      "         0.1268, 0.1733, 0.1629, 0.1594, 0.1937, 0.1573, 0.1378, 0.1730, 0.1528,\n",
      "         0.1796, 0.1759, 0.1312, 0.1511, 0.1067]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0104, 0.0087, 0.0081, 0.0080, 0.0080, 0.0095, 0.0085, 0.0096, 0.0103,\n",
      "        0.0089, 0.0057, 0.0049, 0.0049, 0.0090, 0.0078, 0.0102, 0.0080, 0.0094,\n",
      "        0.0059, 0.0108, 0.0094, 0.0085, 0.0104, 0.0079, 0.0082, 0.0106, 0.0096,\n",
      "        0.0106, 0.0102, 0.0069, 0.0084, 0.0050], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0098, 0.0100], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0594, -0.0093,  0.0000],\n",
      "        [ 0.0430, -0.0051,  0.0000],\n",
      "        [ 0.0602, -0.0083,  0.0000],\n",
      "        [ 0.0463, -0.0181,  0.0000],\n",
      "        [ 0.0407, -0.0027,  0.0000],\n",
      "        [ 0.0541, -0.0044,  0.0000],\n",
      "        [ 0.0495, -0.0239,  0.0000],\n",
      "        [ 0.0613, -0.0211,  0.0000],\n",
      "        [ 0.0535, -0.0108,  0.0000],\n",
      "        [ 0.0476, -0.0094,  0.0000],\n",
      "        [ 0.0483, -0.0026,  0.0000],\n",
      "        [ 0.0266, -0.0217,  0.0000],\n",
      "        [ 0.0390, -0.0099,  0.0000],\n",
      "        [ 0.0585, -0.0171,  0.0000],\n",
      "        [ 0.0412, -0.0249,  0.0000],\n",
      "        [ 0.0580, -0.0138,  0.0000],\n",
      "        [ 0.0435, -0.0095,  0.0000],\n",
      "        [ 0.0538, -0.0170,  0.0000],\n",
      "        [ 0.0331, -0.0050,  0.0000],\n",
      "        [ 0.0712, -0.0128,  0.0000],\n",
      "        [ 0.0492, -0.0122,  0.0000],\n",
      "        [ 0.0493, -0.0103,  0.0000],\n",
      "        [ 0.0590, -0.0126,  0.0000],\n",
      "        [ 0.0386, -0.0112,  0.0000],\n",
      "        [ 0.0412, -0.0050,  0.0000],\n",
      "        [ 0.0566, -0.0102,  0.0000],\n",
      "        [ 0.0537, -0.0235,  0.0000],\n",
      "        [ 0.0496, -0.0179,  0.0000],\n",
      "        [ 0.0644, -0.0195,  0.0000],\n",
      "        [ 0.0342, -0.0040,  0.0000],\n",
      "        [ 0.0420, -0.0093,  0.0000],\n",
      "        [ 0.0194, -0.0073,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2015, 0.1815, 0.1749, 0.1702, 0.1640, 0.1686, 0.1551, 0.1818, 0.1844,\n",
      "         0.1527, 0.1242, 0.1214, 0.1045, 0.1686, 0.1650, 0.1923, 0.1589, 0.1795,\n",
      "         0.1253, 0.1824, 0.1732, 0.1872, 0.1986, 0.1687, 0.1547, 0.1858, 0.1775,\n",
      "         0.2132, 0.1913, 0.1454, 0.1660, 0.0996],\n",
      "        [0.2005, 0.1790, 0.1658, 0.1551, 0.1538, 0.1675, 0.1513, 0.1846, 0.1823,\n",
      "         0.1600, 0.1154, 0.1079, 0.1047, 0.1708, 0.1510, 0.1920, 0.1504, 0.1698,\n",
      "         0.1323, 0.1818, 0.1705, 0.1669, 0.2026, 0.1642, 0.1437, 0.1811, 0.1601,\n",
      "         0.1877, 0.1841, 0.1371, 0.1576, 0.1116]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0106, 0.0089, 0.0082, 0.0082, 0.0081, 0.0096, 0.0086, 0.0097, 0.0105,\n",
      "        0.0090, 0.0059, 0.0051, 0.0050, 0.0092, 0.0079, 0.0104, 0.0080, 0.0095,\n",
      "        0.0061, 0.0110, 0.0096, 0.0087, 0.0107, 0.0081, 0.0082, 0.0107, 0.0098,\n",
      "        0.0108, 0.0104, 0.0071, 0.0085, 0.0052], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0101, 0.0102], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0572, -0.0050,  0.0000],\n",
      "        [ 0.0324, -0.0139,  0.0000],\n",
      "        [ 0.0448, -0.0264,  0.0000],\n",
      "        [ 0.0349, -0.0104,  0.0000],\n",
      "        [ 0.0551, -0.0110,  0.0000],\n",
      "        [ 0.0531, -0.0143,  0.0000],\n",
      "        [ 0.0362, -0.0033,  0.0000],\n",
      "        [ 0.0488, -0.0126,  0.0000],\n",
      "        [ 0.0540, -0.0077,  0.0000],\n",
      "        [ 0.0531, -0.0204,  0.0000],\n",
      "        [ 0.0467, -0.0149,  0.0000],\n",
      "        [ 0.0262, -0.0005,  0.0000],\n",
      "        [ 0.0162, -0.0086,  0.0000],\n",
      "        [ 0.0345, -0.0236,  0.0000],\n",
      "        [ 0.0321, -0.0132,  0.0000],\n",
      "        [ 0.0466, -0.0091,  0.0000],\n",
      "        [ 0.0328, -0.0005,  0.0000],\n",
      "        [ 0.0437, -0.0028,  0.0000],\n",
      "        [ 0.0388, -0.0057,  0.0000],\n",
      "        [ 0.0616, -0.0102,  0.0000],\n",
      "        [ 0.0518, -0.0149,  0.0000],\n",
      "        [ 0.0523, -0.0209,  0.0000],\n",
      "        [ 0.0609, -0.0222,  0.0000],\n",
      "        [ 0.0355, -0.0119,  0.0000],\n",
      "        [ 0.0353, -0.0117,  0.0000],\n",
      "        [ 0.0524, -0.0177,  0.0000],\n",
      "        [ 0.0444, -0.0097,  0.0000],\n",
      "        [ 0.0537, -0.0091,  0.0000],\n",
      "        [ 0.0621, -0.0109,  0.0000],\n",
      "        [ 0.0366, -0.0057,  0.0000],\n",
      "        [ 0.0429, -0.0101,  0.0000],\n",
      "        [ 0.0241, -0.0029,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2106, 0.1895, 0.1824, 0.1779, 0.1715, 0.1768, 0.1619, 0.1903, 0.1927,\n",
      "         0.1600, 0.1297, 0.1266, 0.1088, 0.1763, 0.1723, 0.2010, 0.1661, 0.1879,\n",
      "         0.1306, 0.1912, 0.1812, 0.1954, 0.2075, 0.1762, 0.1617, 0.1947, 0.1856,\n",
      "         0.2227, 0.1999, 0.1517, 0.1733, 0.1040],\n",
      "        [0.2093, 0.1872, 0.1732, 0.1624, 0.1604, 0.1751, 0.1578, 0.1926, 0.1903,\n",
      "         0.1671, 0.1205, 0.1138, 0.1097, 0.1783, 0.1573, 0.2008, 0.1568, 0.1768,\n",
      "         0.1387, 0.1899, 0.1783, 0.1743, 0.2118, 0.1716, 0.1504, 0.1892, 0.1675,\n",
      "         0.1961, 0.1924, 0.1437, 0.1646, 0.1165]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0108, 0.0091, 0.0084, 0.0083, 0.0082, 0.0099, 0.0088, 0.0099, 0.0106,\n",
      "        0.0092, 0.0060, 0.0052, 0.0051, 0.0094, 0.0080, 0.0106, 0.0082, 0.0096,\n",
      "        0.0063, 0.0112, 0.0098, 0.0089, 0.0109, 0.0083, 0.0085, 0.0110, 0.0100,\n",
      "        0.0110, 0.0106, 0.0073, 0.0087, 0.0052], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0103, 0.0105], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0681,  0.0121,  0.0000],\n",
      "        [ 0.0490,  0.0135,  0.0000],\n",
      "        [ 0.0463,  0.0092,  0.0000],\n",
      "        [ 0.0584,  0.0131,  0.0000],\n",
      "        [ 0.0627,  0.0026,  0.0000],\n",
      "        [ 0.0486,  0.0017,  0.0000],\n",
      "        [ 0.0561,  0.0107,  0.0000],\n",
      "        [ 0.0594,  0.0187,  0.0000],\n",
      "        [ 0.0646,  0.0092,  0.0000],\n",
      "        [ 0.0513,  0.0008,  0.0000],\n",
      "        [ 0.0425,  0.0098,  0.0000],\n",
      "        [ 0.0289, -0.0005,  0.0000],\n",
      "        [ 0.0228,  0.0140,  0.0000],\n",
      "        [ 0.0592,  0.0057,  0.0000],\n",
      "        [ 0.0408,  0.0074,  0.0000],\n",
      "        [ 0.0676,  0.0079,  0.0000],\n",
      "        [ 0.0414,  0.0119,  0.0000],\n",
      "        [ 0.0647,  0.0105,  0.0000],\n",
      "        [ 0.0348,  0.0066,  0.0000],\n",
      "        [ 0.0622,  0.0129,  0.0000],\n",
      "        [ 0.0566,  0.0097,  0.0000],\n",
      "        [ 0.0584,  0.0175,  0.0000],\n",
      "        [ 0.0689,  0.0083,  0.0000],\n",
      "        [ 0.0528,  0.0019,  0.0000],\n",
      "        [ 0.0510, -0.0083,  0.0000],\n",
      "        [ 0.0666,  0.0055,  0.0000],\n",
      "        [ 0.0638,  0.0045,  0.0000],\n",
      "        [ 0.0540,  0.0046,  0.0000],\n",
      "        [ 0.0603,  0.0091,  0.0000],\n",
      "        [ 0.0405,  0.0050,  0.0000],\n",
      "        [ 0.0570,  0.0005,  0.0000],\n",
      "        [ 0.0182, -0.0046,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2207, 0.1977, 0.1904, 0.1855, 0.1800, 0.1860, 0.1699, 0.1995, 0.2023,\n",
      "         0.1682, 0.1352, 0.1296, 0.1127, 0.1846, 0.1806, 0.2098, 0.1743, 0.1978,\n",
      "         0.1354, 0.2011, 0.1898, 0.2042, 0.2167, 0.1841, 0.1699, 0.2046, 0.1945,\n",
      "         0.2333, 0.2094, 0.1574, 0.1819, 0.1086],\n",
      "        [0.2195, 0.1955, 0.1810, 0.1694, 0.1686, 0.1845, 0.1659, 0.2019, 0.1999,\n",
      "         0.1758, 0.1257, 0.1163, 0.1138, 0.1870, 0.1652, 0.2098, 0.1648, 0.1865,\n",
      "         0.1440, 0.1999, 0.1869, 0.1823, 0.2213, 0.1795, 0.1582, 0.1992, 0.1758,\n",
      "         0.2059, 0.2017, 0.1494, 0.1729, 0.1216]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0111, 0.0093, 0.0086, 0.0085, 0.0085, 0.0101, 0.0090, 0.0101, 0.0109,\n",
      "        0.0094, 0.0061, 0.0052, 0.0052, 0.0096, 0.0083, 0.0108, 0.0084, 0.0099,\n",
      "        0.0064, 0.0115, 0.0100, 0.0091, 0.0111, 0.0084, 0.0087, 0.0113, 0.0102,\n",
      "        0.0113, 0.0109, 0.0073, 0.0090, 0.0054], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0106, 0.0108], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[0.0673, 0.0176, 0.0000],\n",
      "        [0.0486, 0.0159, 0.0000],\n",
      "        [0.0488, 0.0144, 0.0000],\n",
      "        [0.0458, 0.0177, 0.0000],\n",
      "        [0.0490, 0.0081, 0.0000],\n",
      "        [0.0627, 0.0221, 0.0000],\n",
      "        [0.0422, 0.0172, 0.0000],\n",
      "        [0.0437, 0.0218, 0.0000],\n",
      "        [0.0502, 0.0241, 0.0000],\n",
      "        [0.0285, 0.0173, 0.0000],\n",
      "        [0.0452, 0.0110, 0.0000],\n",
      "        [0.0244, 0.0055, 0.0000],\n",
      "        [0.0124, 0.0100, 0.0000],\n",
      "        [0.0482, 0.0162, 0.0000],\n",
      "        [0.0397, 0.0113, 0.0000],\n",
      "        [0.0537, 0.0189, 0.0000],\n",
      "        [0.0344, 0.0182, 0.0000],\n",
      "        [0.0536, 0.0095, 0.0000],\n",
      "        [0.0325, 0.0125, 0.0000],\n",
      "        [0.0536, 0.0281, 0.0000],\n",
      "        [0.0511, 0.0183, 0.0000],\n",
      "        [0.0540, 0.0097, 0.0000],\n",
      "        [0.0576, 0.0219, 0.0000],\n",
      "        [0.0435, 0.0081, 0.0000],\n",
      "        [0.0399, 0.0087, 0.0000],\n",
      "        [0.0580, 0.0210, 0.0000],\n",
      "        [0.0499, 0.0128, 0.0000],\n",
      "        [0.0431, 0.0184, 0.0000],\n",
      "        [0.0630, 0.0172, 0.0000],\n",
      "        [0.0376, 0.0117, 0.0000],\n",
      "        [0.0464, 0.0219, 0.0000],\n",
      "        [0.0251, 0.0103, 0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2305, 0.2065, 0.1988, 0.1937, 0.1881, 0.1945, 0.1776, 0.2086, 0.2114,\n",
      "         0.1758, 0.1411, 0.1350, 0.1176, 0.1930, 0.1887, 0.2193, 0.1822, 0.2068,\n",
      "         0.1414, 0.2104, 0.1985, 0.2131, 0.2264, 0.1923, 0.1773, 0.2138, 0.2033,\n",
      "         0.2436, 0.2188, 0.1643, 0.1896, 0.1133],\n",
      "        [0.2296, 0.2042, 0.1893, 0.1769, 0.1765, 0.1935, 0.1740, 0.2113, 0.2092,\n",
      "         0.1841, 0.1310, 0.1208, 0.1186, 0.1957, 0.1731, 0.2192, 0.1727, 0.1952,\n",
      "         0.1503, 0.2094, 0.1957, 0.1905, 0.2313, 0.1877, 0.1660, 0.2088, 0.1841,\n",
      "         0.2156, 0.2111, 0.1560, 0.1809, 0.1269]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0113, 0.0095, 0.0088, 0.0086, 0.0087, 0.0104, 0.0093, 0.0104, 0.0111,\n",
      "        0.0096, 0.0062, 0.0052, 0.0053, 0.0099, 0.0085, 0.0110, 0.0086, 0.0101,\n",
      "        0.0065, 0.0117, 0.0102, 0.0092, 0.0113, 0.0086, 0.0089, 0.0115, 0.0104,\n",
      "        0.0115, 0.0111, 0.0075, 0.0092, 0.0055], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0109, 0.0110], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0534, -0.0051,  0.0000],\n",
      "        [ 0.0536,  0.0030,  0.0000],\n",
      "        [ 0.0560,  0.0010,  0.0000],\n",
      "        [ 0.0425,  0.0093,  0.0000],\n",
      "        [ 0.0468, -0.0150,  0.0000],\n",
      "        [ 0.0659,  0.0008,  0.0000],\n",
      "        [ 0.0474, -0.0011,  0.0000],\n",
      "        [ 0.0560,  0.0043,  0.0000],\n",
      "        [ 0.0689,  0.0006,  0.0000],\n",
      "        [ 0.0653,  0.0004,  0.0000],\n",
      "        [ 0.0377, -0.0109,  0.0000],\n",
      "        [ 0.0190, -0.0031,  0.0000],\n",
      "        [ 0.0219,  0.0064,  0.0000],\n",
      "        [ 0.0493,  0.0077,  0.0000],\n",
      "        [ 0.0543,  0.0040,  0.0000],\n",
      "        [ 0.0629,  0.0102,  0.0000],\n",
      "        [ 0.0560, -0.0006,  0.0000],\n",
      "        [ 0.0599,  0.0018,  0.0000],\n",
      "        [ 0.0402, -0.0045,  0.0000],\n",
      "        [ 0.0799,  0.0018,  0.0000],\n",
      "        [ 0.0586,  0.0012,  0.0000],\n",
      "        [ 0.0472, -0.0012,  0.0000],\n",
      "        [ 0.0662, -0.0065,  0.0000],\n",
      "        [ 0.0637, -0.0096,  0.0000],\n",
      "        [ 0.0530,  0.0026,  0.0000],\n",
      "        [ 0.0730,  0.0049,  0.0000],\n",
      "        [ 0.0648,  0.0023,  0.0000],\n",
      "        [ 0.0732,  0.0005,  0.0000],\n",
      "        [ 0.0716,  0.0080,  0.0000],\n",
      "        [ 0.0333,  0.0013,  0.0000],\n",
      "        [ 0.0538,  0.0021,  0.0000],\n",
      "        [ 0.0400,  0.0025,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2406, 0.2157, 0.2073, 0.2028, 0.1963, 0.2026, 0.1851, 0.2178, 0.2208,\n",
      "         0.1835, 0.1477, 0.1415, 0.1232, 0.2011, 0.1964, 0.2293, 0.1899, 0.2157,\n",
      "         0.1477, 0.2197, 0.2073, 0.2226, 0.2367, 0.2008, 0.1846, 0.2230, 0.2124,\n",
      "         0.2540, 0.2283, 0.1717, 0.1975, 0.1184],\n",
      "        [0.2397, 0.2135, 0.1976, 0.1853, 0.1841, 0.2016, 0.1816, 0.2205, 0.2185,\n",
      "         0.1921, 0.1371, 0.1274, 0.1245, 0.2041, 0.1800, 0.2294, 0.1800, 0.2033,\n",
      "         0.1573, 0.2186, 0.2045, 0.1991, 0.2418, 0.1962, 0.1730, 0.2178, 0.1925,\n",
      "         0.2250, 0.2204, 0.1634, 0.1887, 0.1325]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0115, 0.0097, 0.0090, 0.0089, 0.0089, 0.0105, 0.0094, 0.0106, 0.0113,\n",
      "        0.0098, 0.0064, 0.0054, 0.0054, 0.0100, 0.0086, 0.0112, 0.0088, 0.0103,\n",
      "        0.0067, 0.0119, 0.0104, 0.0095, 0.0115, 0.0088, 0.0090, 0.0117, 0.0106,\n",
      "        0.0117, 0.0113, 0.0077, 0.0093, 0.0056], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0111, 0.0113], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 6.7115e-02, -2.7813e-03,  0.0000e+00],\n",
      "        [ 7.1046e-02,  2.0022e-03,  0.0000e+00],\n",
      "        [ 4.6486e-02, -7.0355e-03,  0.0000e+00],\n",
      "        [ 6.3444e-02,  5.4961e-04,  0.0000e+00],\n",
      "        [ 5.3956e-02,  1.5041e-03,  0.0000e+00],\n",
      "        [ 6.5533e-02, -1.1217e-02,  0.0000e+00],\n",
      "        [ 4.8830e-02,  2.1970e-03,  0.0000e+00],\n",
      "        [ 5.6722e-02, -9.4565e-03,  0.0000e+00],\n",
      "        [ 6.5990e-02,  1.1829e-02,  0.0000e+00],\n",
      "        [ 6.0454e-02, -6.0493e-04,  0.0000e+00],\n",
      "        [ 3.5154e-02, -7.5589e-03,  0.0000e+00],\n",
      "        [ 4.5123e-02, -2.0781e-02,  0.0000e+00],\n",
      "        [ 3.2842e-02, -2.0632e-03,  0.0000e+00],\n",
      "        [ 4.9559e-02, -8.8331e-05,  0.0000e+00],\n",
      "        [ 5.8971e-02, -1.7576e-02,  0.0000e+00],\n",
      "        [ 7.0018e-02, -1.2298e-03,  0.0000e+00],\n",
      "        [ 5.4220e-02, -1.0049e-02,  0.0000e+00],\n",
      "        [ 6.7201e-02, -7.7098e-03,  0.0000e+00],\n",
      "        [ 3.6602e-02, -1.4054e-03,  0.0000e+00],\n",
      "        [ 7.3701e-02, -2.1849e-03,  0.0000e+00],\n",
      "        [ 7.1278e-02, -1.2374e-02,  0.0000e+00],\n",
      "        [ 6.7383e-02, -6.4473e-03,  0.0000e+00],\n",
      "        [ 6.6194e-02,  6.7044e-05,  0.0000e+00],\n",
      "        [ 5.3700e-02, -1.2404e-02,  0.0000e+00],\n",
      "        [ 5.7811e-02,  6.1401e-03,  0.0000e+00],\n",
      "        [ 6.9892e-02,  8.8795e-03,  0.0000e+00],\n",
      "        [ 7.0870e-02, -1.8205e-03,  0.0000e+00],\n",
      "        [ 8.1474e-02, -2.7335e-03,  0.0000e+00],\n",
      "        [ 7.3463e-02, -1.7771e-03,  0.0000e+00],\n",
      "        [ 5.3165e-02, -5.5822e-04,  0.0000e+00],\n",
      "        [ 5.6285e-02, -5.9980e-03,  0.0000e+00],\n",
      "        [ 3.8022e-02,  2.5393e-03,  0.0000e+00]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2511, 0.2252, 0.2159, 0.2119, 0.2046, 0.2115, 0.1926, 0.2280, 0.2308,\n",
      "         0.1917, 0.1549, 0.1474, 0.1283, 0.2097, 0.2050, 0.2398, 0.1983, 0.2259,\n",
      "         0.1537, 0.2301, 0.2167, 0.2326, 0.2476, 0.2092, 0.1920, 0.2328, 0.2221,\n",
      "         0.2650, 0.2385, 0.1792, 0.2056, 0.1238],\n",
      "        [0.2501, 0.2232, 0.2062, 0.1935, 0.1918, 0.2106, 0.1893, 0.2304, 0.2282,\n",
      "         0.2007, 0.1436, 0.1332, 0.1302, 0.2131, 0.1882, 0.2397, 0.1880, 0.2124,\n",
      "         0.1643, 0.2287, 0.2139, 0.2080, 0.2529, 0.2048, 0.1807, 0.2274, 0.2014,\n",
      "         0.2351, 0.2304, 0.1711, 0.1971, 0.1384]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0117, 0.0099, 0.0092, 0.0091, 0.0090, 0.0107, 0.0095, 0.0108, 0.0115,\n",
      "        0.0100, 0.0066, 0.0056, 0.0056, 0.0102, 0.0088, 0.0114, 0.0089, 0.0105,\n",
      "        0.0068, 0.0121, 0.0106, 0.0096, 0.0117, 0.0090, 0.0092, 0.0119, 0.0108,\n",
      "        0.0119, 0.0115, 0.0079, 0.0095, 0.0057], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0114, 0.0116], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0586, -0.0225,  0.0000],\n",
      "        [ 0.0560, -0.0180,  0.0000],\n",
      "        [ 0.0532, -0.0214,  0.0000],\n",
      "        [ 0.0508, -0.0208,  0.0000],\n",
      "        [ 0.0589, -0.0046,  0.0000],\n",
      "        [ 0.0516, -0.0213,  0.0000],\n",
      "        [ 0.0513, -0.0160,  0.0000],\n",
      "        [ 0.0620, -0.0241,  0.0000],\n",
      "        [ 0.0687, -0.0180,  0.0000],\n",
      "        [ 0.0588, -0.0012,  0.0000],\n",
      "        [ 0.0302, -0.0124,  0.0000],\n",
      "        [ 0.0159, -0.0120,  0.0000],\n",
      "        [ 0.0294, -0.0124,  0.0000],\n",
      "        [ 0.0463, -0.0207,  0.0000],\n",
      "        [ 0.0549, -0.0184,  0.0000],\n",
      "        [ 0.0570, -0.0149,  0.0000],\n",
      "        [ 0.0526, -0.0153,  0.0000],\n",
      "        [ 0.0582, -0.0237,  0.0000],\n",
      "        [ 0.0331, -0.0087,  0.0000],\n",
      "        [ 0.0683, -0.0194,  0.0000],\n",
      "        [ 0.0639, -0.0162,  0.0000],\n",
      "        [ 0.0578, -0.0183,  0.0000],\n",
      "        [ 0.0679, -0.0230,  0.0000],\n",
      "        [ 0.0518, -0.0093,  0.0000],\n",
      "        [ 0.0436, -0.0048,  0.0000],\n",
      "        [ 0.0643, -0.0169,  0.0000],\n",
      "        [ 0.0666, -0.0320,  0.0000],\n",
      "        [ 0.0755, -0.0152,  0.0000],\n",
      "        [ 0.0699, -0.0252,  0.0000],\n",
      "        [ 0.0461, -0.0142,  0.0000],\n",
      "        [ 0.0354, -0.0115,  0.0000],\n",
      "        [ 0.0362, -0.0102,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2620, 0.2352, 0.2256, 0.2210, 0.2130, 0.2208, 0.2016, 0.2374, 0.2409,\n",
      "         0.1998, 0.1615, 0.1546, 0.1345, 0.2192, 0.2135, 0.2504, 0.2066, 0.2351,\n",
      "         0.1611, 0.2401, 0.2263, 0.2426, 0.2585, 0.2185, 0.2006, 0.2431, 0.2318,\n",
      "         0.2765, 0.2491, 0.1876, 0.2144, 0.1292],\n",
      "        [0.2613, 0.2332, 0.2152, 0.2026, 0.2001, 0.2196, 0.1978, 0.2404, 0.2386,\n",
      "         0.2093, 0.1503, 0.1397, 0.1361, 0.2226, 0.1960, 0.2508, 0.1961, 0.2220,\n",
      "         0.1717, 0.2392, 0.2235, 0.2175, 0.2643, 0.2137, 0.1883, 0.2376, 0.2108,\n",
      "         0.2454, 0.2408, 0.1789, 0.2049, 0.1447]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0119, 0.0101, 0.0094, 0.0093, 0.0091, 0.0108, 0.0097, 0.0109, 0.0117,\n",
      "        0.0101, 0.0067, 0.0058, 0.0057, 0.0104, 0.0089, 0.0117, 0.0091, 0.0107,\n",
      "        0.0070, 0.0123, 0.0108, 0.0098, 0.0120, 0.0091, 0.0093, 0.0120, 0.0110,\n",
      "        0.0121, 0.0117, 0.0081, 0.0096, 0.0059], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0117, 0.0119], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 8.8370e-02,  5.4489e-04,  0.0000e+00],\n",
      "        [ 6.1279e-02,  1.4640e-03,  0.0000e+00],\n",
      "        [ 5.1129e-02, -1.0244e-02,  0.0000e+00],\n",
      "        [ 7.6183e-02, -9.8295e-03,  0.0000e+00],\n",
      "        [ 7.2422e-02,  5.9279e-03,  0.0000e+00],\n",
      "        [ 5.9505e-02, -1.8345e-03,  0.0000e+00],\n",
      "        [ 7.7711e-02, -4.4810e-04,  0.0000e+00],\n",
      "        [ 8.7910e-02,  1.1629e-03,  0.0000e+00],\n",
      "        [ 9.8236e-02,  3.3495e-04,  0.0000e+00],\n",
      "        [ 6.1663e-02,  7.5393e-03,  0.0000e+00],\n",
      "        [ 4.8144e-02, -4.1116e-03,  0.0000e+00],\n",
      "        [ 5.4444e-02, -2.7837e-03,  0.0000e+00],\n",
      "        [ 2.9739e-02,  8.0755e-03,  0.0000e+00],\n",
      "        [ 6.4307e-02, -2.0672e-03,  0.0000e+00],\n",
      "        [ 7.2204e-02, -1.7617e-03,  0.0000e+00],\n",
      "        [ 7.9191e-02,  5.8491e-03,  0.0000e+00],\n",
      "        [ 6.9023e-02,  7.2952e-03,  0.0000e+00],\n",
      "        [ 7.8948e-02, -1.4497e-03,  0.0000e+00],\n",
      "        [ 5.4168e-02, -5.1695e-03,  0.0000e+00],\n",
      "        [ 8.9045e-02,  5.3840e-03,  0.0000e+00],\n",
      "        [ 8.9584e-02, -1.6337e-03,  0.0000e+00],\n",
      "        [ 6.5276e-02, -9.2989e-03,  0.0000e+00],\n",
      "        [ 8.1853e-02,  1.4154e-05,  0.0000e+00],\n",
      "        [ 5.8419e-02,  4.2917e-03,  0.0000e+00],\n",
      "        [ 5.1163e-02, -4.2633e-03,  0.0000e+00],\n",
      "        [ 7.5955e-02, -6.6408e-03,  0.0000e+00],\n",
      "        [ 8.8853e-02, -8.1362e-03,  0.0000e+00],\n",
      "        [ 8.4310e-02, -1.0542e-02,  0.0000e+00],\n",
      "        [ 8.2996e-02, -1.1418e-03,  0.0000e+00],\n",
      "        [ 6.0108e-02, -1.7686e-03,  0.0000e+00],\n",
      "        [ 5.4380e-02,  3.2093e-03,  0.0000e+00],\n",
      "        [ 3.6622e-02,  1.1813e-03,  0.0000e+00]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2740, 0.2455, 0.2354, 0.2305, 0.2231, 0.2312, 0.2113, 0.2483, 0.2520,\n",
      "         0.2097, 0.1683, 0.1601, 0.1398, 0.2293, 0.2233, 0.2615, 0.2162, 0.2465,\n",
      "         0.1678, 0.2515, 0.2367, 0.2533, 0.2699, 0.2282, 0.2099, 0.2549, 0.2424,\n",
      "         0.2893, 0.2604, 0.1953, 0.2242, 0.1349],\n",
      "        [0.2736, 0.2435, 0.2249, 0.2111, 0.2101, 0.2309, 0.2080, 0.2518, 0.2501,\n",
      "         0.2199, 0.1565, 0.1437, 0.1414, 0.2333, 0.2057, 0.2619, 0.2058, 0.2333,\n",
      "         0.1788, 0.2511, 0.2341, 0.2272, 0.2760, 0.2235, 0.1978, 0.2498, 0.2208,\n",
      "         0.2576, 0.2522, 0.1862, 0.2150, 0.1509]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0122, 0.0103, 0.0095, 0.0095, 0.0094, 0.0111, 0.0099, 0.0112, 0.0120,\n",
      "        0.0104, 0.0069, 0.0058, 0.0058, 0.0106, 0.0091, 0.0119, 0.0093, 0.0110,\n",
      "        0.0071, 0.0126, 0.0110, 0.0101, 0.0122, 0.0093, 0.0095, 0.0124, 0.0113,\n",
      "        0.0124, 0.0120, 0.0082, 0.0098, 0.0060], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0120, 0.0121], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0612,  0.0235,  0.0000],\n",
      "        [ 0.0279,  0.0255,  0.0000],\n",
      "        [ 0.0202, -0.0009,  0.0000],\n",
      "        [ 0.0450,  0.0121,  0.0000],\n",
      "        [ 0.0295,  0.0074,  0.0000],\n",
      "        [ 0.0339,  0.0227,  0.0000],\n",
      "        [ 0.0437,  0.0035,  0.0000],\n",
      "        [ 0.0471,  0.0135,  0.0000],\n",
      "        [ 0.0520,  0.0166,  0.0000],\n",
      "        [ 0.0360,  0.0215,  0.0000],\n",
      "        [ 0.0308, -0.0006,  0.0000],\n",
      "        [ 0.0260, -0.0009,  0.0000],\n",
      "        [ 0.0175,  0.0090,  0.0000],\n",
      "        [ 0.0359,  0.0101,  0.0000],\n",
      "        [ 0.0323,  0.0150,  0.0000],\n",
      "        [ 0.0436,  0.0181,  0.0000],\n",
      "        [ 0.0320,  0.0274,  0.0000],\n",
      "        [ 0.0463,  0.0255,  0.0000],\n",
      "        [ 0.0330,  0.0026,  0.0000],\n",
      "        [ 0.0412,  0.0086,  0.0000],\n",
      "        [ 0.0472,  0.0193,  0.0000],\n",
      "        [ 0.0341,  0.0082,  0.0000],\n",
      "        [ 0.0364,  0.0131,  0.0000],\n",
      "        [ 0.0212,  0.0071,  0.0000],\n",
      "        [ 0.0219,  0.0235,  0.0000],\n",
      "        [ 0.0426,  0.0226,  0.0000],\n",
      "        [ 0.0461,  0.0206,  0.0000],\n",
      "        [ 0.0547,  0.0244,  0.0000],\n",
      "        [ 0.0324,  0.0038,  0.0000],\n",
      "        [ 0.0390,  0.0285,  0.0000],\n",
      "        [ 0.0261,  0.0117,  0.0000],\n",
      "        [ 0.0310,  0.0249,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2862, 0.2563, 0.2469, 0.2392, 0.2329, 0.2429, 0.2230, 0.2587, 0.2632,\n",
      "         0.2198, 0.1737, 0.1663, 0.1468, 0.2409, 0.2338, 0.2722, 0.2261, 0.2557,\n",
      "         0.1761, 0.2626, 0.2475, 0.2635, 0.2814, 0.2391, 0.2216, 0.2668, 0.2527,\n",
      "         0.3022, 0.2724, 0.2048, 0.2367, 0.1400],\n",
      "        [0.2860, 0.2543, 0.2357, 0.2196, 0.2198, 0.2426, 0.2193, 0.2629, 0.2616,\n",
      "         0.2306, 0.1620, 0.1489, 0.1480, 0.2448, 0.2156, 0.2730, 0.2155, 0.2431,\n",
      "         0.1870, 0.2628, 0.2450, 0.2369, 0.2880, 0.2341, 0.2084, 0.2619, 0.2308,\n",
      "         0.2697, 0.2640, 0.1948, 0.2265, 0.1570]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0125, 0.0105, 0.0098, 0.0096, 0.0096, 0.0114, 0.0103, 0.0114, 0.0123,\n",
      "        0.0106, 0.0069, 0.0059, 0.0060, 0.0109, 0.0094, 0.0121, 0.0095, 0.0111,\n",
      "        0.0073, 0.0128, 0.0113, 0.0102, 0.0124, 0.0096, 0.0099, 0.0126, 0.0114,\n",
      "        0.0127, 0.0122, 0.0084, 0.0102, 0.0061], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0122, 0.0124], grad_fn=<MeanBackward1>)\n",
      "Epoch 3/10, Accuracy: 0.4812\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0631,  0.0060,  0.0000],\n",
      "        [ 0.0579, -0.0078,  0.0000],\n",
      "        [ 0.0688, -0.0041,  0.0000],\n",
      "        [ 0.0615, -0.0007,  0.0000],\n",
      "        [ 0.0470,  0.0029,  0.0000],\n",
      "        [ 0.0656,  0.0018,  0.0000],\n",
      "        [ 0.0542,  0.0184,  0.0000],\n",
      "        [ 0.0763,  0.0090,  0.0000],\n",
      "        [ 0.0618, -0.0015,  0.0000],\n",
      "        [ 0.0692,  0.0045,  0.0000],\n",
      "        [ 0.0453, -0.0077,  0.0000],\n",
      "        [ 0.0348,  0.0003,  0.0000],\n",
      "        [ 0.0394,  0.0017,  0.0000],\n",
      "        [ 0.0779, -0.0060,  0.0000],\n",
      "        [ 0.0558,  0.0131,  0.0000],\n",
      "        [ 0.0711, -0.0023,  0.0000],\n",
      "        [ 0.0484,  0.0139,  0.0000],\n",
      "        [ 0.0678, -0.0021,  0.0000],\n",
      "        [ 0.0362,  0.0021,  0.0000],\n",
      "        [ 0.0707,  0.0043,  0.0000],\n",
      "        [ 0.0686,  0.0072,  0.0000],\n",
      "        [ 0.0668, -0.0017,  0.0000],\n",
      "        [ 0.0815, -0.0121,  0.0000],\n",
      "        [ 0.0482,  0.0080,  0.0000],\n",
      "        [ 0.0750, -0.0058,  0.0000],\n",
      "        [ 0.0783, -0.0021,  0.0000],\n",
      "        [ 0.0832,  0.0021,  0.0000],\n",
      "        [ 0.0759,  0.0109,  0.0000],\n",
      "        [ 0.0642,  0.0061,  0.0000],\n",
      "        [ 0.0447,  0.0034,  0.0000],\n",
      "        [ 0.0638, -0.0077,  0.0000],\n",
      "        [ 0.0254,  0.0093,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2987, 0.2676, 0.2574, 0.2505, 0.2428, 0.2532, 0.2312, 0.2701, 0.2751,\n",
      "         0.2292, 0.1822, 0.1742, 0.1532, 0.2511, 0.2431, 0.2847, 0.2356, 0.2677,\n",
      "         0.1835, 0.2745, 0.2584, 0.2753, 0.2941, 0.2492, 0.2312, 0.2784, 0.2640,\n",
      "         0.3151, 0.2841, 0.2134, 0.2463, 0.1466],\n",
      "        [0.2985, 0.2657, 0.2457, 0.2306, 0.2294, 0.2528, 0.2271, 0.2746, 0.2736,\n",
      "         0.2405, 0.1701, 0.1565, 0.1545, 0.2551, 0.2243, 0.2858, 0.2246, 0.2547,\n",
      "         0.1948, 0.2747, 0.2560, 0.2479, 0.3010, 0.2440, 0.2175, 0.2733, 0.2416,\n",
      "         0.2815, 0.2755, 0.2033, 0.2357, 0.1644]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0127, 0.0107, 0.0100, 0.0098, 0.0098, 0.0116, 0.0104, 0.0116, 0.0125,\n",
      "        0.0108, 0.0071, 0.0061, 0.0061, 0.0111, 0.0095, 0.0124, 0.0097, 0.0114,\n",
      "        0.0075, 0.0131, 0.0115, 0.0105, 0.0127, 0.0097, 0.0101, 0.0128, 0.0117,\n",
      "        0.0129, 0.0124, 0.0085, 0.0103, 0.0062], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0125, 0.0127], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0859, -0.0038,  0.0000],\n",
      "        [ 0.0604,  0.0051,  0.0000],\n",
      "        [ 0.0613, -0.0068,  0.0000],\n",
      "        [ 0.0641,  0.0119,  0.0000],\n",
      "        [ 0.0711, -0.0030,  0.0000],\n",
      "        [ 0.0779, -0.0082,  0.0000],\n",
      "        [ 0.0734,  0.0034,  0.0000],\n",
      "        [ 0.0897,  0.0084,  0.0000],\n",
      "        [ 0.0879,  0.0147,  0.0000],\n",
      "        [ 0.0736,  0.0087,  0.0000],\n",
      "        [ 0.0538,  0.0010,  0.0000],\n",
      "        [ 0.0467,  0.0092,  0.0000],\n",
      "        [ 0.0357, -0.0007,  0.0000],\n",
      "        [ 0.0694,  0.0074,  0.0000],\n",
      "        [ 0.0605,  0.0055,  0.0000],\n",
      "        [ 0.0821,  0.0009,  0.0000],\n",
      "        [ 0.0762,  0.0043,  0.0000],\n",
      "        [ 0.0852,  0.0134,  0.0000],\n",
      "        [ 0.0497,  0.0018,  0.0000],\n",
      "        [ 0.0892, -0.0003,  0.0000],\n",
      "        [ 0.0770,  0.0146,  0.0000],\n",
      "        [ 0.0752, -0.0007,  0.0000],\n",
      "        [ 0.0863,  0.0039,  0.0000],\n",
      "        [ 0.0689, -0.0023,  0.0000],\n",
      "        [ 0.0723,  0.0041,  0.0000],\n",
      "        [ 0.0850,  0.0039,  0.0000],\n",
      "        [ 0.0936,  0.0102,  0.0000],\n",
      "        [ 0.0960,  0.0097,  0.0000],\n",
      "        [ 0.0835, -0.0075,  0.0000],\n",
      "        [ 0.0593,  0.0008,  0.0000],\n",
      "        [ 0.0717,  0.0094,  0.0000],\n",
      "        [ 0.0337, -0.0042,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.3122, 0.2792, 0.2680, 0.2622, 0.2541, 0.2650, 0.2415, 0.2829, 0.2876,\n",
      "         0.2400, 0.1908, 0.1809, 0.1591, 0.2617, 0.2542, 0.2976, 0.2465, 0.2805,\n",
      "         0.1906, 0.2878, 0.2702, 0.2877, 0.3073, 0.2600, 0.2405, 0.2912, 0.2763,\n",
      "         0.3291, 0.2970, 0.2220, 0.2561, 0.1532],\n",
      "        [0.3116, 0.2776, 0.2562, 0.2414, 0.2393, 0.2637, 0.2372, 0.2868, 0.2855,\n",
      "         0.2510, 0.1782, 0.1643, 0.1613, 0.2658, 0.2341, 0.2988, 0.2343, 0.2657,\n",
      "         0.2034, 0.2873, 0.2674, 0.2591, 0.3147, 0.2547, 0.2262, 0.2852, 0.2527,\n",
      "         0.2937, 0.2880, 0.2126, 0.2451, 0.1716]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0130, 0.0109, 0.0102, 0.0101, 0.0100, 0.0118, 0.0106, 0.0119, 0.0128,\n",
      "        0.0110, 0.0073, 0.0062, 0.0062, 0.0113, 0.0097, 0.0126, 0.0099, 0.0116,\n",
      "        0.0076, 0.0134, 0.0117, 0.0107, 0.0129, 0.0099, 0.0102, 0.0131, 0.0119,\n",
      "        0.0131, 0.0127, 0.0087, 0.0104, 0.0064], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0128, 0.0130], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[0.0450, 0.0372, 0.0000],\n",
      "        [0.0359, 0.0352, 0.0000],\n",
      "        [0.0321, 0.0289, 0.0000],\n",
      "        [0.0382, 0.0235, 0.0000],\n",
      "        [0.0284, 0.0326, 0.0000],\n",
      "        [0.0294, 0.0337, 0.0000],\n",
      "        [0.0281, 0.0368, 0.0000],\n",
      "        [0.0298, 0.0321, 0.0000],\n",
      "        [0.0309, 0.0420, 0.0000],\n",
      "        [0.0368, 0.0395, 0.0000],\n",
      "        [0.0252, 0.0130, 0.0000],\n",
      "        [0.0200, 0.0145, 0.0000],\n",
      "        [0.0380, 0.0109, 0.0000],\n",
      "        [0.0370, 0.0314, 0.0000],\n",
      "        [0.0213, 0.0276, 0.0000],\n",
      "        [0.0403, 0.0401, 0.0000],\n",
      "        [0.0331, 0.0166, 0.0000],\n",
      "        [0.0453, 0.0321, 0.0000],\n",
      "        [0.0101, 0.0305, 0.0000],\n",
      "        [0.0389, 0.0382, 0.0000],\n",
      "        [0.0216, 0.0311, 0.0000],\n",
      "        [0.0454, 0.0380, 0.0000],\n",
      "        [0.0316, 0.0394, 0.0000],\n",
      "        [0.0361, 0.0286, 0.0000],\n",
      "        [0.0255, 0.0429, 0.0000],\n",
      "        [0.0324, 0.0509, 0.0000],\n",
      "        [0.0233, 0.0354, 0.0000],\n",
      "        [0.0377, 0.0503, 0.0000],\n",
      "        [0.0224, 0.0355, 0.0000],\n",
      "        [0.0270, 0.0274, 0.0000],\n",
      "        [0.0324, 0.0330, 0.0000],\n",
      "        [0.0131, 0.0191, 0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.3263, 0.2914, 0.2809, 0.2721, 0.2653, 0.2783, 0.2541, 0.2953, 0.3006,\n",
      "         0.2516, 0.1971, 0.1869, 0.1665, 0.2748, 0.2662, 0.3100, 0.2583, 0.2922,\n",
      "         0.1995, 0.3003, 0.2827, 0.2993, 0.3204, 0.2723, 0.2531, 0.3048, 0.2885,\n",
      "         0.3440, 0.3104, 0.2321, 0.2699, 0.1592],\n",
      "        [0.3260, 0.2898, 0.2687, 0.2505, 0.2504, 0.2776, 0.2502, 0.2998, 0.2988,\n",
      "         0.2635, 0.1843, 0.1691, 0.1687, 0.2793, 0.2457, 0.3114, 0.2463, 0.2776,\n",
      "         0.2126, 0.3003, 0.2801, 0.2698, 0.3282, 0.2669, 0.2389, 0.2993, 0.2644,\n",
      "         0.3080, 0.3014, 0.2220, 0.2588, 0.1785]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0132, 0.0111, 0.0105, 0.0101, 0.0102, 0.0122, 0.0110, 0.0121, 0.0130,\n",
      "        0.0113, 0.0073, 0.0063, 0.0064, 0.0116, 0.0100, 0.0128, 0.0102, 0.0118,\n",
      "        0.0078, 0.0136, 0.0120, 0.0108, 0.0131, 0.0102, 0.0106, 0.0134, 0.0121,\n",
      "        0.0135, 0.0130, 0.0089, 0.0109, 0.0064], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0131, 0.0133], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 5.6030e-02,  7.7732e-03,  0.0000e+00],\n",
      "        [ 4.5252e-02,  4.0494e-03,  0.0000e+00],\n",
      "        [ 3.1022e-02, -5.1730e-04,  0.0000e+00],\n",
      "        [ 4.4673e-02,  1.3425e-02,  0.0000e+00],\n",
      "        [ 3.3620e-02,  1.0356e-03,  0.0000e+00],\n",
      "        [ 5.7010e-02, -1.5135e-02,  0.0000e+00],\n",
      "        [ 3.0319e-02,  4.4581e-03,  0.0000e+00],\n",
      "        [ 5.4959e-02, -1.1040e-02,  0.0000e+00],\n",
      "        [ 3.3638e-02, -4.6761e-03,  0.0000e+00],\n",
      "        [ 4.2168e-02,  8.9938e-03,  0.0000e+00],\n",
      "        [ 2.5570e-02, -8.3287e-03,  0.0000e+00],\n",
      "        [ 3.0616e-02, -6.1292e-03,  0.0000e+00],\n",
      "        [ 4.0740e-02, -1.6273e-04,  0.0000e+00],\n",
      "        [ 3.7326e-02,  3.3287e-04,  0.0000e+00],\n",
      "        [ 2.6283e-02,  1.9034e-04,  0.0000e+00],\n",
      "        [ 6.8113e-02,  1.7370e-03,  0.0000e+00],\n",
      "        [ 4.7228e-02, -7.6171e-03,  0.0000e+00],\n",
      "        [ 6.4062e-02,  6.7305e-03,  0.0000e+00],\n",
      "        [ 3.1583e-02,  1.4557e-03,  0.0000e+00],\n",
      "        [ 5.1243e-02, -1.3038e-02,  0.0000e+00],\n",
      "        [ 4.2260e-02,  6.1440e-03,  0.0000e+00],\n",
      "        [ 4.3299e-02, -9.4073e-03,  0.0000e+00],\n",
      "        [ 4.9408e-02, -4.9137e-04,  0.0000e+00],\n",
      "        [ 3.9796e-02, -1.0616e-02,  0.0000e+00],\n",
      "        [ 4.1412e-02, -3.3030e-03,  0.0000e+00],\n",
      "        [ 4.3176e-02, -8.0271e-05,  0.0000e+00],\n",
      "        [ 5.0381e-02, -1.0338e-02,  0.0000e+00],\n",
      "        [ 4.3727e-02, -7.3226e-03,  0.0000e+00],\n",
      "        [ 4.6473e-02, -3.0078e-03,  0.0000e+00],\n",
      "        [ 4.4042e-02, -4.8383e-04,  0.0000e+00],\n",
      "        [ 5.9986e-02, -3.8039e-03,  0.0000e+00],\n",
      "        [ 3.0610e-02,  4.5089e-03,  0.0000e+00]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.3397, 0.3043, 0.2923, 0.2850, 0.2760, 0.2891, 0.2638, 0.3076, 0.3135,\n",
      "         0.2616, 0.2070, 0.1975, 0.1746, 0.2856, 0.2763, 0.3239, 0.2683, 0.3038,\n",
      "         0.2088, 0.3133, 0.2947, 0.3128, 0.3349, 0.2837, 0.2632, 0.3172, 0.3010,\n",
      "         0.3583, 0.3235, 0.2431, 0.2802, 0.1665],\n",
      "        [0.3400, 0.3026, 0.2796, 0.2627, 0.2612, 0.2891, 0.2598, 0.3132, 0.3125,\n",
      "         0.2748, 0.1936, 0.1777, 0.1761, 0.2907, 0.2559, 0.3256, 0.2566, 0.2899,\n",
      "         0.2217, 0.3142, 0.2924, 0.2824, 0.3430, 0.2781, 0.2486, 0.3123, 0.2765,\n",
      "         0.3216, 0.3145, 0.2319, 0.2692, 0.1866]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0134, 0.0114, 0.0107, 0.0105, 0.0104, 0.0122, 0.0111, 0.0123, 0.0132,\n",
      "        0.0114, 0.0076, 0.0066, 0.0066, 0.0118, 0.0101, 0.0131, 0.0103, 0.0119,\n",
      "        0.0080, 0.0138, 0.0122, 0.0111, 0.0134, 0.0104, 0.0107, 0.0136, 0.0124,\n",
      "        0.0137, 0.0132, 0.0092, 0.0110, 0.0066], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0134, 0.0137], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0728,  0.0129,  0.0000],\n",
      "        [ 0.0576,  0.0168,  0.0000],\n",
      "        [ 0.0307,  0.0169,  0.0000],\n",
      "        [ 0.0617,  0.0009,  0.0000],\n",
      "        [ 0.0662,  0.0034,  0.0000],\n",
      "        [ 0.0545,  0.0163,  0.0000],\n",
      "        [ 0.0602,  0.0144,  0.0000],\n",
      "        [ 0.0771,  0.0078,  0.0000],\n",
      "        [ 0.0835,  0.0091,  0.0000],\n",
      "        [ 0.0678,  0.0124,  0.0000],\n",
      "        [ 0.0299,  0.0136,  0.0000],\n",
      "        [ 0.0377,  0.0082,  0.0000],\n",
      "        [ 0.0354,  0.0032,  0.0000],\n",
      "        [ 0.0537,  0.0079,  0.0000],\n",
      "        [ 0.0546,  0.0256,  0.0000],\n",
      "        [ 0.0796, -0.0023,  0.0000],\n",
      "        [ 0.0576,  0.0189,  0.0000],\n",
      "        [ 0.0833,  0.0059,  0.0000],\n",
      "        [ 0.0410,  0.0055,  0.0000],\n",
      "        [ 0.0768,  0.0110,  0.0000],\n",
      "        [ 0.0779,  0.0156,  0.0000],\n",
      "        [ 0.0619,  0.0115,  0.0000],\n",
      "        [ 0.0639,  0.0088,  0.0000],\n",
      "        [ 0.0484,  0.0177,  0.0000],\n",
      "        [ 0.0435,  0.0129,  0.0000],\n",
      "        [ 0.0719,  0.0086,  0.0000],\n",
      "        [ 0.0807,  0.0035,  0.0000],\n",
      "        [ 0.0825,  0.0293,  0.0000],\n",
      "        [ 0.0705,  0.0002,  0.0000],\n",
      "        [ 0.0626, -0.0008,  0.0000],\n",
      "        [ 0.0572,  0.0070,  0.0000],\n",
      "        [ 0.0388,  0.0074,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.3552, 0.3174, 0.3044, 0.2973, 0.2890, 0.3024, 0.2759, 0.3222, 0.3279,\n",
      "         0.2743, 0.2164, 0.2039, 0.1809, 0.2985, 0.2888, 0.3383, 0.2806, 0.3191,\n",
      "         0.2167, 0.3285, 0.3082, 0.3266, 0.3497, 0.2957, 0.2745, 0.3325, 0.3149,\n",
      "         0.3742, 0.3383, 0.2525, 0.2923, 0.1740],\n",
      "        [0.3552, 0.3160, 0.2918, 0.2741, 0.2730, 0.3017, 0.2722, 0.3268, 0.3262,\n",
      "         0.2872, 0.2023, 0.1850, 0.1837, 0.3038, 0.2669, 0.3400, 0.2677, 0.3031,\n",
      "         0.2315, 0.3285, 0.3057, 0.2949, 0.3582, 0.2903, 0.2595, 0.3266, 0.2891,\n",
      "         0.3356, 0.3289, 0.2422, 0.2808, 0.1947]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0137, 0.0116, 0.0109, 0.0107, 0.0106, 0.0125, 0.0113, 0.0126, 0.0135,\n",
      "        0.0117, 0.0078, 0.0067, 0.0066, 0.0120, 0.0103, 0.0134, 0.0105, 0.0123,\n",
      "        0.0082, 0.0141, 0.0124, 0.0113, 0.0137, 0.0106, 0.0109, 0.0139, 0.0126,\n",
      "        0.0139, 0.0135, 0.0093, 0.0112, 0.0068], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0137, 0.0140], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0588,  0.0038,  0.0000],\n",
      "        [ 0.0589,  0.0128,  0.0000],\n",
      "        [ 0.0616,  0.0251,  0.0000],\n",
      "        [ 0.0585,  0.0120,  0.0000],\n",
      "        [ 0.0658,  0.0063,  0.0000],\n",
      "        [ 0.0569,  0.0180,  0.0000],\n",
      "        [ 0.0449,  0.0264,  0.0000],\n",
      "        [ 0.0714,  0.0207,  0.0000],\n",
      "        [ 0.0814,  0.0151,  0.0000],\n",
      "        [ 0.0754,  0.0260,  0.0000],\n",
      "        [ 0.0411,  0.0019,  0.0000],\n",
      "        [ 0.0187, -0.0017,  0.0000],\n",
      "        [ 0.0203,  0.0166,  0.0000],\n",
      "        [ 0.0711,  0.0257,  0.0000],\n",
      "        [ 0.0468,  0.0181,  0.0000],\n",
      "        [ 0.0801,  0.0153,  0.0000],\n",
      "        [ 0.0525,  0.0169,  0.0000],\n",
      "        [ 0.0741,  0.0163,  0.0000],\n",
      "        [ 0.0396,  0.0047,  0.0000],\n",
      "        [ 0.0659,  0.0337,  0.0000],\n",
      "        [ 0.0738,  0.0225,  0.0000],\n",
      "        [ 0.0589,  0.0091,  0.0000],\n",
      "        [ 0.0844,  0.0118,  0.0000],\n",
      "        [ 0.0614,  0.0160,  0.0000],\n",
      "        [ 0.0636,  0.0208,  0.0000],\n",
      "        [ 0.0791,  0.0272,  0.0000],\n",
      "        [ 0.0605,  0.0150,  0.0000],\n",
      "        [ 0.0831,  0.0227,  0.0000],\n",
      "        [ 0.0556,  0.0236,  0.0000],\n",
      "        [ 0.0345,  0.0024,  0.0000],\n",
      "        [ 0.0706,  0.0209,  0.0000],\n",
      "        [ 0.0282,  0.0054,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.3707, 0.3313, 0.3179, 0.3106, 0.3011, 0.3152, 0.2875, 0.3359, 0.3423,\n",
      "         0.2861, 0.2256, 0.2130, 0.1891, 0.3115, 0.3011, 0.3533, 0.2925, 0.3327,\n",
      "         0.2265, 0.3429, 0.3217, 0.3407, 0.3649, 0.3087, 0.2866, 0.3464, 0.3288,\n",
      "         0.3902, 0.3529, 0.2636, 0.3048, 0.1817],\n",
      "        [0.3712, 0.3298, 0.3047, 0.2868, 0.2854, 0.3155, 0.2837, 0.3417, 0.3412,\n",
      "         0.3004, 0.2112, 0.1921, 0.1911, 0.3172, 0.2790, 0.3553, 0.2800, 0.3177,\n",
      "         0.2410, 0.3438, 0.3196, 0.3082, 0.3740, 0.3031, 0.2715, 0.3414, 0.3028,\n",
      "         0.3512, 0.3435, 0.2522, 0.2929, 0.2034]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0140, 0.0118, 0.0111, 0.0109, 0.0109, 0.0128, 0.0115, 0.0129, 0.0138,\n",
      "        0.0119, 0.0079, 0.0067, 0.0068, 0.0123, 0.0106, 0.0136, 0.0107, 0.0125,\n",
      "        0.0083, 0.0144, 0.0127, 0.0115, 0.0139, 0.0108, 0.0112, 0.0141, 0.0129,\n",
      "        0.0142, 0.0137, 0.0095, 0.0114, 0.0069], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0141, 0.0143], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0456, -0.0070,  0.0000],\n",
      "        [ 0.0420, -0.0124,  0.0000],\n",
      "        [ 0.0358, -0.0086,  0.0000],\n",
      "        [ 0.0477,  0.0039,  0.0000],\n",
      "        [ 0.0308, -0.0117,  0.0000],\n",
      "        [ 0.0519, -0.0250,  0.0000],\n",
      "        [ 0.0386, -0.0064,  0.0000],\n",
      "        [ 0.0478, -0.0140,  0.0000],\n",
      "        [ 0.0360, -0.0176,  0.0000],\n",
      "        [ 0.0376, -0.0166,  0.0000],\n",
      "        [ 0.0248, -0.0121,  0.0000],\n",
      "        [ 0.0347, -0.0069,  0.0000],\n",
      "        [ 0.0214, -0.0041,  0.0000],\n",
      "        [ 0.0416, -0.0089,  0.0000],\n",
      "        [ 0.0497, -0.0150,  0.0000],\n",
      "        [ 0.0401, -0.0279,  0.0000],\n",
      "        [ 0.0593, -0.0114,  0.0000],\n",
      "        [ 0.0652, -0.0200,  0.0000],\n",
      "        [ 0.0104, -0.0073,  0.0000],\n",
      "        [ 0.0486, -0.0281,  0.0000],\n",
      "        [ 0.0530, -0.0208,  0.0000],\n",
      "        [ 0.0538, -0.0109,  0.0000],\n",
      "        [ 0.0299, -0.0131,  0.0000],\n",
      "        [ 0.0514, -0.0170,  0.0000],\n",
      "        [ 0.0384, -0.0233,  0.0000],\n",
      "        [ 0.0502, -0.0245,  0.0000],\n",
      "        [ 0.0522, -0.0296,  0.0000],\n",
      "        [ 0.0641, -0.0152,  0.0000],\n",
      "        [ 0.0420, -0.0336,  0.0000],\n",
      "        [ 0.0371, -0.0143,  0.0000],\n",
      "        [ 0.0457, -0.0139,  0.0000],\n",
      "        [ 0.0174, -0.0120,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.3862, 0.3458, 0.3317, 0.3241, 0.3138, 0.3289, 0.3002, 0.3502, 0.3570,\n",
      "         0.2986, 0.2356, 0.2236, 0.1981, 0.3249, 0.3137, 0.3689, 0.3049, 0.3461,\n",
      "         0.2367, 0.3576, 0.3359, 0.3552, 0.3812, 0.3222, 0.2992, 0.3614, 0.3428,\n",
      "         0.4068, 0.3684, 0.2758, 0.3179, 0.1896],\n",
      "        [0.3867, 0.3445, 0.3185, 0.2990, 0.2969, 0.3294, 0.2969, 0.3556, 0.3557,\n",
      "         0.3134, 0.2201, 0.2029, 0.2010, 0.3314, 0.2910, 0.3708, 0.2916, 0.3293,\n",
      "         0.2526, 0.3581, 0.3336, 0.3211, 0.3906, 0.3168, 0.2844, 0.3563, 0.3156,\n",
      "         0.3663, 0.3587, 0.2648, 0.3065, 0.2119]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0142, 0.0121, 0.0114, 0.0111, 0.0110, 0.0129, 0.0117, 0.0130, 0.0140,\n",
      "        0.0121, 0.0081, 0.0072, 0.0070, 0.0125, 0.0107, 0.0139, 0.0108, 0.0126,\n",
      "        0.0086, 0.0146, 0.0129, 0.0118, 0.0142, 0.0110, 0.0114, 0.0143, 0.0131,\n",
      "        0.0144, 0.0140, 0.0098, 0.0116, 0.0071], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0144, 0.0146], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1133, -0.0026,  0.0000],\n",
      "        [ 0.0816, -0.0130,  0.0000],\n",
      "        [ 0.0729, -0.0147,  0.0000],\n",
      "        [ 0.0676,  0.0002,  0.0000],\n",
      "        [ 0.0737,  0.0010,  0.0000],\n",
      "        [ 0.0888, -0.0151,  0.0000],\n",
      "        [ 0.0783,  0.0082,  0.0000],\n",
      "        [ 0.0882, -0.0077,  0.0000],\n",
      "        [ 0.1036,  0.0050,  0.0000],\n",
      "        [ 0.0756,  0.0019,  0.0000],\n",
      "        [ 0.0648, -0.0007,  0.0000],\n",
      "        [ 0.0459, -0.0045,  0.0000],\n",
      "        [ 0.0306, -0.0143,  0.0000],\n",
      "        [ 0.0908, -0.0014,  0.0000],\n",
      "        [ 0.0779,  0.0037,  0.0000],\n",
      "        [ 0.0934, -0.0008,  0.0000],\n",
      "        [ 0.0753, -0.0169,  0.0000],\n",
      "        [ 0.0886,  0.0037,  0.0000],\n",
      "        [ 0.0517,  0.0056,  0.0000],\n",
      "        [ 0.0902, -0.0087,  0.0000],\n",
      "        [ 0.0791, -0.0011,  0.0000],\n",
      "        [ 0.0863, -0.0158,  0.0000],\n",
      "        [ 0.0950, -0.0008,  0.0000],\n",
      "        [ 0.0689, -0.0108,  0.0000],\n",
      "        [ 0.0753,  0.0011,  0.0000],\n",
      "        [ 0.1017,  0.0056,  0.0000],\n",
      "        [ 0.0934, -0.0014,  0.0000],\n",
      "        [ 0.1073, -0.0112,  0.0000],\n",
      "        [ 0.0854, -0.0029,  0.0000],\n",
      "        [ 0.0521, -0.0073,  0.0000],\n",
      "        [ 0.0694,  0.0022,  0.0000],\n",
      "        [ 0.0507,  0.0091,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.4032, 0.3607, 0.3459, 0.3389, 0.3278, 0.3439, 0.3128, 0.3664, 0.3730,\n",
      "         0.3123, 0.2462, 0.2324, 0.2056, 0.3393, 0.3274, 0.3854, 0.3188, 0.3632,\n",
      "         0.2466, 0.3747, 0.3510, 0.3708, 0.3979, 0.3359, 0.3116, 0.3775, 0.3584,\n",
      "         0.4248, 0.3844, 0.2869, 0.3308, 0.1982],\n",
      "        [0.4038, 0.3595, 0.3315, 0.3138, 0.3106, 0.3434, 0.3084, 0.3725, 0.3717,\n",
      "         0.3271, 0.2311, 0.2109, 0.2084, 0.3452, 0.3033, 0.3880, 0.3049, 0.3463,\n",
      "         0.2628, 0.3755, 0.3485, 0.3362, 0.4080, 0.3298, 0.2949, 0.3716, 0.3306,\n",
      "         0.3826, 0.3743, 0.2754, 0.3178, 0.2218]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0145, 0.0123, 0.0116, 0.0115, 0.0113, 0.0132, 0.0119, 0.0134, 0.0143,\n",
      "        0.0124, 0.0083, 0.0072, 0.0070, 0.0127, 0.0109, 0.0142, 0.0111, 0.0130,\n",
      "        0.0087, 0.0150, 0.0132, 0.0121, 0.0145, 0.0112, 0.0115, 0.0146, 0.0134,\n",
      "        0.0148, 0.0142, 0.0099, 0.0118, 0.0073], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0147, 0.0150], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1293, -0.0356,  0.0000],\n",
      "        [ 0.0913, -0.0365,  0.0000],\n",
      "        [ 0.0886, -0.0403,  0.0000],\n",
      "        [ 0.1100, -0.0358,  0.0000],\n",
      "        [ 0.1011, -0.0284,  0.0000],\n",
      "        [ 0.0985, -0.0411,  0.0000],\n",
      "        [ 0.0922, -0.0282,  0.0000],\n",
      "        [ 0.1026, -0.0360,  0.0000],\n",
      "        [ 0.1164, -0.0458,  0.0000],\n",
      "        [ 0.0919, -0.0302,  0.0000],\n",
      "        [ 0.0671, -0.0273,  0.0000],\n",
      "        [ 0.0634, -0.0188,  0.0000],\n",
      "        [ 0.0530, -0.0250,  0.0000],\n",
      "        [ 0.0900, -0.0438,  0.0000],\n",
      "        [ 0.0915, -0.0343,  0.0000],\n",
      "        [ 0.1075, -0.0441,  0.0000],\n",
      "        [ 0.1104, -0.0316,  0.0000],\n",
      "        [ 0.1136, -0.0325,  0.0000],\n",
      "        [ 0.0579, -0.0122,  0.0000],\n",
      "        [ 0.1158, -0.0505,  0.0000],\n",
      "        [ 0.1111, -0.0398,  0.0000],\n",
      "        [ 0.0949, -0.0319,  0.0000],\n",
      "        [ 0.1022, -0.0470,  0.0000],\n",
      "        [ 0.0725, -0.0199,  0.0000],\n",
      "        [ 0.0931, -0.0412,  0.0000],\n",
      "        [ 0.1106, -0.0441,  0.0000],\n",
      "        [ 0.1196, -0.0522,  0.0000],\n",
      "        [ 0.1373, -0.0400,  0.0000],\n",
      "        [ 0.1047, -0.0557,  0.0000],\n",
      "        [ 0.0945, -0.0323,  0.0000],\n",
      "        [ 0.0962, -0.0297,  0.0000],\n",
      "        [ 0.0576, -0.0175,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.4204, 0.3764, 0.3601, 0.3537, 0.3414, 0.3573, 0.3255, 0.3822, 0.3893,\n",
      "         0.3252, 0.2580, 0.2436, 0.2151, 0.3533, 0.3407, 0.4026, 0.3314, 0.3784,\n",
      "         0.2573, 0.3909, 0.3661, 0.3872, 0.4157, 0.3496, 0.3242, 0.3935, 0.3741,\n",
      "         0.4424, 0.4010, 0.3001, 0.3440, 0.2072],\n",
      "        [0.4215, 0.3752, 0.3458, 0.3272, 0.3241, 0.3586, 0.3222, 0.3890, 0.3886,\n",
      "         0.3415, 0.2415, 0.2202, 0.2177, 0.3604, 0.3167, 0.4051, 0.3180, 0.3616,\n",
      "         0.2739, 0.3923, 0.3641, 0.3512, 0.4260, 0.3439, 0.3082, 0.3886, 0.3456,\n",
      "         0.3994, 0.3912, 0.2876, 0.3318, 0.2315]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0148, 0.0126, 0.0118, 0.0117, 0.0115, 0.0133, 0.0121, 0.0137, 0.0146,\n",
      "        0.0125, 0.0086, 0.0075, 0.0072, 0.0129, 0.0111, 0.0145, 0.0113, 0.0132,\n",
      "        0.0089, 0.0152, 0.0134, 0.0123, 0.0148, 0.0114, 0.0117, 0.0148, 0.0137,\n",
      "        0.0150, 0.0145, 0.0101, 0.0119, 0.0074], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0151, 0.0153], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0775, -0.0108,  0.0000],\n",
      "        [ 0.0639, -0.0017,  0.0000],\n",
      "        [ 0.0635, -0.0150,  0.0000],\n",
      "        [ 0.0850, -0.0132,  0.0000],\n",
      "        [ 0.0649,  0.0023,  0.0000],\n",
      "        [ 0.0565, -0.0052,  0.0000],\n",
      "        [ 0.0572, -0.0149,  0.0000],\n",
      "        [ 0.0625, -0.0034,  0.0000],\n",
      "        [ 0.0820, -0.0081,  0.0000],\n",
      "        [ 0.0818, -0.0059,  0.0000],\n",
      "        [ 0.0523, -0.0102,  0.0000],\n",
      "        [ 0.0348, -0.0157,  0.0000],\n",
      "        [ 0.0493, -0.0066,  0.0000],\n",
      "        [ 0.0737, -0.0114,  0.0000],\n",
      "        [ 0.0493, -0.0180,  0.0000],\n",
      "        [ 0.0844, -0.0064,  0.0000],\n",
      "        [ 0.0571, -0.0045,  0.0000],\n",
      "        [ 0.0775, -0.0121,  0.0000],\n",
      "        [ 0.0342, -0.0033,  0.0000],\n",
      "        [ 0.0765, -0.0223,  0.0000],\n",
      "        [ 0.0661, -0.0085,  0.0000],\n",
      "        [ 0.0706, -0.0032,  0.0000],\n",
      "        [ 0.0824, -0.0007,  0.0000],\n",
      "        [ 0.0503, -0.0129,  0.0000],\n",
      "        [ 0.0592,  0.0038,  0.0000],\n",
      "        [ 0.0813, -0.0098,  0.0000],\n",
      "        [ 0.0781,  0.0046,  0.0000],\n",
      "        [ 0.0765, -0.0047,  0.0000],\n",
      "        [ 0.0602, -0.0171,  0.0000],\n",
      "        [ 0.0450, -0.0002,  0.0000],\n",
      "        [ 0.0785, -0.0064,  0.0000],\n",
      "        [ 0.0400, -0.0051,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.4391, 0.3926, 0.3767, 0.3675, 0.3562, 0.3743, 0.3421, 0.3986, 0.4064,\n",
      "         0.3406, 0.2673, 0.2520, 0.2249, 0.3700, 0.3565, 0.4193, 0.3466, 0.3944,\n",
      "         0.2687, 0.4081, 0.3825, 0.4031, 0.4332, 0.3657, 0.3401, 0.4116, 0.3900,\n",
      "         0.4622, 0.4189, 0.3130, 0.3614, 0.2155],\n",
      "        [0.4400, 0.3916, 0.3618, 0.3405, 0.3380, 0.3749, 0.3385, 0.4055, 0.4055,\n",
      "         0.3573, 0.2508, 0.2288, 0.2279, 0.3771, 0.3312, 0.4223, 0.3322, 0.3771,\n",
      "         0.2864, 0.4094, 0.3804, 0.3659, 0.4443, 0.3597, 0.3232, 0.4063, 0.3606,\n",
      "         0.4174, 0.4086, 0.3008, 0.3484, 0.2409]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0151, 0.0128, 0.0121, 0.0119, 0.0117, 0.0137, 0.0125, 0.0139, 0.0149,\n",
      "        0.0129, 0.0086, 0.0075, 0.0074, 0.0133, 0.0114, 0.0147, 0.0116, 0.0135,\n",
      "        0.0091, 0.0155, 0.0137, 0.0125, 0.0151, 0.0117, 0.0120, 0.0152, 0.0139,\n",
      "        0.0153, 0.0148, 0.0103, 0.0123, 0.0076], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0154, 0.0156], grad_fn=<MeanBackward1>)\n",
      "Epoch 4/10, Accuracy: 0.4906\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0912,  0.0118,  0.0000],\n",
      "        [ 0.0564, -0.0012,  0.0000],\n",
      "        [ 0.0619,  0.0145,  0.0000],\n",
      "        [ 0.0753,  0.0145,  0.0000],\n",
      "        [ 0.0745,  0.0120,  0.0000],\n",
      "        [ 0.0646,  0.0077,  0.0000],\n",
      "        [ 0.0587,  0.0177,  0.0000],\n",
      "        [ 0.0649,  0.0191,  0.0000],\n",
      "        [ 0.0677,  0.0076,  0.0000],\n",
      "        [ 0.0533,  0.0243,  0.0000],\n",
      "        [ 0.0507,  0.0099,  0.0000],\n",
      "        [ 0.0303,  0.0178,  0.0000],\n",
      "        [ 0.0341,  0.0169,  0.0000],\n",
      "        [ 0.0542,  0.0117,  0.0000],\n",
      "        [ 0.0414,  0.0197,  0.0000],\n",
      "        [ 0.0796,  0.0245,  0.0000],\n",
      "        [ 0.0727,  0.0185,  0.0000],\n",
      "        [ 0.0727,  0.0228,  0.0000],\n",
      "        [ 0.0468, -0.0016,  0.0000],\n",
      "        [ 0.0791,  0.0204,  0.0000],\n",
      "        [ 0.0585,  0.0140,  0.0000],\n",
      "        [ 0.0750,  0.0098,  0.0000],\n",
      "        [ 0.0602,  0.0161,  0.0000],\n",
      "        [ 0.0475,  0.0055,  0.0000],\n",
      "        [ 0.0697,  0.0088,  0.0000],\n",
      "        [ 0.0805,  0.0114,  0.0000],\n",
      "        [ 0.0659,  0.0157,  0.0000],\n",
      "        [ 0.0945,  0.0189,  0.0000],\n",
      "        [ 0.0761,  0.0229,  0.0000],\n",
      "        [ 0.0537, -0.0019,  0.0000],\n",
      "        [ 0.0638,  0.0255,  0.0000],\n",
      "        [ 0.0270,  0.0013,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.4584, 0.4094, 0.3931, 0.3834, 0.3724, 0.3922, 0.3577, 0.4162, 0.4247,\n",
      "         0.3562, 0.2786, 0.2621, 0.2343, 0.3866, 0.3719, 0.4376, 0.3620, 0.4118,\n",
      "         0.2803, 0.4262, 0.3995, 0.4203, 0.4520, 0.3817, 0.3563, 0.4305, 0.4074,\n",
      "         0.4824, 0.4372, 0.3262, 0.3770, 0.2247],\n",
      "        [0.4594, 0.4085, 0.3777, 0.3551, 0.3532, 0.3921, 0.3538, 0.4231, 0.4239,\n",
      "         0.3730, 0.2612, 0.2390, 0.2379, 0.3938, 0.3455, 0.4406, 0.3469, 0.3930,\n",
      "         0.2991, 0.4272, 0.3973, 0.3817, 0.4635, 0.3755, 0.3387, 0.4245, 0.3770,\n",
      "         0.4361, 0.4265, 0.3138, 0.3635, 0.2512]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0154, 0.0131, 0.0124, 0.0121, 0.0120, 0.0140, 0.0128, 0.0142, 0.0152,\n",
      "        0.0131, 0.0088, 0.0077, 0.0076, 0.0136, 0.0117, 0.0150, 0.0118, 0.0137,\n",
      "        0.0093, 0.0158, 0.0140, 0.0128, 0.0154, 0.0120, 0.0124, 0.0155, 0.0142,\n",
      "        0.0157, 0.0151, 0.0105, 0.0126, 0.0077], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0157, 0.0160], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0616,  0.0028,  0.0000],\n",
      "        [ 0.0393, -0.0112,  0.0000],\n",
      "        [ 0.0542, -0.0100,  0.0000],\n",
      "        [ 0.0544, -0.0134,  0.0000],\n",
      "        [ 0.0316,  0.0081,  0.0000],\n",
      "        [ 0.0462, -0.0086,  0.0000],\n",
      "        [ 0.0381, -0.0081,  0.0000],\n",
      "        [ 0.0538, -0.0241,  0.0000],\n",
      "        [ 0.0565, -0.0037,  0.0000],\n",
      "        [ 0.0485, -0.0173,  0.0000],\n",
      "        [ 0.0444,  0.0002,  0.0000],\n",
      "        [ 0.0350, -0.0052,  0.0000],\n",
      "        [ 0.0381, -0.0114,  0.0000],\n",
      "        [ 0.0536, -0.0265,  0.0000],\n",
      "        [ 0.0362, -0.0105,  0.0000],\n",
      "        [ 0.0548, -0.0193,  0.0000],\n",
      "        [ 0.0378,  0.0081,  0.0000],\n",
      "        [ 0.0587,  0.0037,  0.0000],\n",
      "        [ 0.0314, -0.0140,  0.0000],\n",
      "        [ 0.0516, -0.0068,  0.0000],\n",
      "        [ 0.0349, -0.0082,  0.0000],\n",
      "        [ 0.0550, -0.0207,  0.0000],\n",
      "        [ 0.0714, -0.0179,  0.0000],\n",
      "        [ 0.0436, -0.0101,  0.0000],\n",
      "        [ 0.0469, -0.0042,  0.0000],\n",
      "        [ 0.0475, -0.0158,  0.0000],\n",
      "        [ 0.0579, -0.0087,  0.0000],\n",
      "        [ 0.0641, -0.0080,  0.0000],\n",
      "        [ 0.0474, -0.0063,  0.0000],\n",
      "        [ 0.0364,  0.0048,  0.0000],\n",
      "        [ 0.0500, -0.0130,  0.0000],\n",
      "        [ 0.0231, -0.0026,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.4775, 0.4272, 0.4101, 0.4000, 0.3874, 0.4079, 0.3732, 0.4336, 0.4422,\n",
      "         0.3716, 0.2906, 0.2751, 0.2454, 0.4035, 0.3874, 0.4564, 0.3767, 0.4281,\n",
      "         0.2932, 0.4441, 0.4168, 0.4381, 0.4713, 0.3982, 0.3712, 0.4485, 0.4246,\n",
      "         0.5027, 0.4559, 0.3414, 0.3935, 0.2344],\n",
      "        [0.4788, 0.4263, 0.3944, 0.3710, 0.3680, 0.4088, 0.3694, 0.4413, 0.4420,\n",
      "         0.3895, 0.2726, 0.2503, 0.2487, 0.4113, 0.3605, 0.4598, 0.3617, 0.4097,\n",
      "         0.3124, 0.4459, 0.4148, 0.3982, 0.4835, 0.3920, 0.3536, 0.4429, 0.3934,\n",
      "         0.4551, 0.4452, 0.3283, 0.3798, 0.2619]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0157, 0.0133, 0.0127, 0.0123, 0.0122, 0.0142, 0.0130, 0.0144, 0.0154,\n",
      "        0.0134, 0.0090, 0.0080, 0.0078, 0.0139, 0.0119, 0.0153, 0.0120, 0.0139,\n",
      "        0.0096, 0.0160, 0.0143, 0.0130, 0.0157, 0.0122, 0.0126, 0.0158, 0.0144,\n",
      "        0.0159, 0.0154, 0.0108, 0.0129, 0.0079], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0161, 0.0163], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0889,  0.0296,  0.0000],\n",
      "        [ 0.0955,  0.0343,  0.0000],\n",
      "        [ 0.0904,  0.0205,  0.0000],\n",
      "        [ 0.0868,  0.0039,  0.0000],\n",
      "        [ 0.0731,  0.0316,  0.0000],\n",
      "        [ 0.1014,  0.0328,  0.0000],\n",
      "        [ 0.0792,  0.0118,  0.0000],\n",
      "        [ 0.1053,  0.0062,  0.0000],\n",
      "        [ 0.1066,  0.0207,  0.0000],\n",
      "        [ 0.0967,  0.0079,  0.0000],\n",
      "        [ 0.0631,  0.0159,  0.0000],\n",
      "        [ 0.0347,  0.0020,  0.0000],\n",
      "        [ 0.0677,  0.0009,  0.0000],\n",
      "        [ 0.1001,  0.0073,  0.0000],\n",
      "        [ 0.0796,  0.0214,  0.0000],\n",
      "        [ 0.1079,  0.0189,  0.0000],\n",
      "        [ 0.0850,  0.0286,  0.0000],\n",
      "        [ 0.0934,  0.0260,  0.0000],\n",
      "        [ 0.0524, -0.0026,  0.0000],\n",
      "        [ 0.1163,  0.0221,  0.0000],\n",
      "        [ 0.0985,  0.0171,  0.0000],\n",
      "        [ 0.0893,  0.0074,  0.0000],\n",
      "        [ 0.1082,  0.0261,  0.0000],\n",
      "        [ 0.0745,  0.0206,  0.0000],\n",
      "        [ 0.0913,  0.0275,  0.0000],\n",
      "        [ 0.1129,  0.0264,  0.0000],\n",
      "        [ 0.1152,  0.0153,  0.0000],\n",
      "        [ 0.1037,  0.0298,  0.0000],\n",
      "        [ 0.1110,  0.0203,  0.0000],\n",
      "        [ 0.0748,  0.0197,  0.0000],\n",
      "        [ 0.0856,  0.0139,  0.0000],\n",
      "        [ 0.0639,  0.0187,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.4993, 0.4453, 0.4276, 0.4172, 0.4058, 0.4274, 0.3905, 0.4539, 0.4632,\n",
      "         0.3897, 0.3030, 0.2820, 0.2543, 0.4215, 0.4055, 0.4761, 0.3947, 0.4499,\n",
      "         0.3042, 0.4652, 0.4357, 0.4570, 0.4917, 0.4154, 0.3883, 0.4694, 0.4439,\n",
      "         0.5253, 0.4764, 0.3545, 0.4113, 0.2445],\n",
      "        [0.5008, 0.4446, 0.4107, 0.3878, 0.3859, 0.4277, 0.3861, 0.4622, 0.4629,\n",
      "         0.4081, 0.2851, 0.2564, 0.2575, 0.4293, 0.3772, 0.4802, 0.3789, 0.4311,\n",
      "         0.3237, 0.4676, 0.4337, 0.4163, 0.5048, 0.4086, 0.3688, 0.4635, 0.4119,\n",
      "         0.4760, 0.4653, 0.3409, 0.3963, 0.2735]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0161, 0.0136, 0.0129, 0.0126, 0.0125, 0.0145, 0.0133, 0.0148, 0.0158,\n",
      "        0.0137, 0.0092, 0.0079, 0.0078, 0.0141, 0.0122, 0.0156, 0.0123, 0.0144,\n",
      "        0.0097, 0.0165, 0.0146, 0.0133, 0.0160, 0.0124, 0.0128, 0.0161, 0.0148,\n",
      "        0.0163, 0.0157, 0.0110, 0.0131, 0.0081], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0164, 0.0167], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1216, -0.0148,  0.0000],\n",
      "        [ 0.0881, -0.0158,  0.0000],\n",
      "        [ 0.1055, -0.0064,  0.0000],\n",
      "        [ 0.0942, -0.0136,  0.0000],\n",
      "        [ 0.0808, -0.0015,  0.0000],\n",
      "        [ 0.0959, -0.0058,  0.0000],\n",
      "        [ 0.1017, -0.0032,  0.0000],\n",
      "        [ 0.0939, -0.0197,  0.0000],\n",
      "        [ 0.1120, -0.0252,  0.0000],\n",
      "        [ 0.0808, -0.0090,  0.0000],\n",
      "        [ 0.0868, -0.0085,  0.0000],\n",
      "        [ 0.0632, -0.0205,  0.0000],\n",
      "        [ 0.0525, -0.0124,  0.0000],\n",
      "        [ 0.1078, -0.0203,  0.0000],\n",
      "        [ 0.0842, -0.0078,  0.0000],\n",
      "        [ 0.1060, -0.0151,  0.0000],\n",
      "        [ 0.0715, -0.0015,  0.0000],\n",
      "        [ 0.0969, -0.0189,  0.0000],\n",
      "        [ 0.0621, -0.0091,  0.0000],\n",
      "        [ 0.1166, -0.0017,  0.0000],\n",
      "        [ 0.0882, -0.0121,  0.0000],\n",
      "        [ 0.0762, -0.0129,  0.0000],\n",
      "        [ 0.1222, -0.0205,  0.0000],\n",
      "        [ 0.0649,  0.0062,  0.0000],\n",
      "        [ 0.0907, -0.0140,  0.0000],\n",
      "        [ 0.1092, -0.0067,  0.0000],\n",
      "        [ 0.1058, -0.0236,  0.0000],\n",
      "        [ 0.0980, -0.0163,  0.0000],\n",
      "        [ 0.1172, -0.0142,  0.0000],\n",
      "        [ 0.0624, -0.0211,  0.0000],\n",
      "        [ 0.0878, -0.0026,  0.0000],\n",
      "        [ 0.0528, -0.0113,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.5199, 0.4646, 0.4459, 0.4354, 0.4220, 0.4446, 0.4062, 0.4724, 0.4824,\n",
      "         0.4053, 0.3160, 0.2973, 0.2663, 0.4392, 0.4212, 0.4970, 0.4103, 0.4677,\n",
      "         0.3186, 0.4843, 0.4541, 0.4768, 0.5130, 0.4326, 0.4045, 0.4884, 0.4627,\n",
      "         0.5470, 0.4964, 0.3703, 0.4275, 0.2554],\n",
      "        [0.5216, 0.4639, 0.4285, 0.4050, 0.4014, 0.4450, 0.4017, 0.4812, 0.4823,\n",
      "         0.4244, 0.2977, 0.2709, 0.2698, 0.4475, 0.3922, 0.5013, 0.3941, 0.4484,\n",
      "         0.3391, 0.4865, 0.4522, 0.4347, 0.5266, 0.4258, 0.3849, 0.4824, 0.4298,\n",
      "         0.4960, 0.4850, 0.3563, 0.4122, 0.2854]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0163, 0.0139, 0.0131, 0.0129, 0.0127, 0.0147, 0.0135, 0.0151, 0.0161,\n",
      "        0.0139, 0.0094, 0.0082, 0.0081, 0.0144, 0.0123, 0.0160, 0.0125, 0.0146,\n",
      "        0.0099, 0.0167, 0.0148, 0.0136, 0.0163, 0.0126, 0.0130, 0.0163, 0.0151,\n",
      "        0.0166, 0.0160, 0.0112, 0.0133, 0.0082], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0168, 0.0171], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0558, -0.0002,  0.0000],\n",
      "        [ 0.0511, -0.0076,  0.0000],\n",
      "        [ 0.0374, -0.0009,  0.0000],\n",
      "        [ 0.0333,  0.0028,  0.0000],\n",
      "        [ 0.0340, -0.0169,  0.0000],\n",
      "        [ 0.0397, -0.0007,  0.0000],\n",
      "        [ 0.0479, -0.0109,  0.0000],\n",
      "        [ 0.0626,  0.0106,  0.0000],\n",
      "        [ 0.0593,  0.0051,  0.0000],\n",
      "        [ 0.0094, -0.0060,  0.0000],\n",
      "        [ 0.0398, -0.0015,  0.0000],\n",
      "        [ 0.0155,  0.0032,  0.0000],\n",
      "        [ 0.0193,  0.0076,  0.0000],\n",
      "        [ 0.0455, -0.0011,  0.0000],\n",
      "        [ 0.0394, -0.0042,  0.0000],\n",
      "        [ 0.0366,  0.0016,  0.0000],\n",
      "        [ 0.0441, -0.0078,  0.0000],\n",
      "        [ 0.0494,  0.0122,  0.0000],\n",
      "        [ 0.0359,  0.0110,  0.0000],\n",
      "        [ 0.0456, -0.0043,  0.0000],\n",
      "        [ 0.0385, -0.0087,  0.0000],\n",
      "        [ 0.0427, -0.0013,  0.0000],\n",
      "        [ 0.0441,  0.0086,  0.0000],\n",
      "        [ 0.0451, -0.0121,  0.0000],\n",
      "        [ 0.0250, -0.0032,  0.0000],\n",
      "        [ 0.0383, -0.0045,  0.0000],\n",
      "        [ 0.0398,  0.0119,  0.0000],\n",
      "        [ 0.0544, -0.0043,  0.0000],\n",
      "        [ 0.0441, -0.0138,  0.0000],\n",
      "        [ 0.0378,  0.0103,  0.0000],\n",
      "        [ 0.0225,  0.0044,  0.0000],\n",
      "        [ 0.0174,  0.0016,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.5423, 0.4845, 0.4652, 0.4540, 0.4403, 0.4644, 0.4251, 0.4920, 0.5028,\n",
      "         0.4237, 0.3290, 0.3102, 0.2784, 0.4585, 0.4396, 0.5182, 0.4282, 0.4868,\n",
      "         0.3331, 0.5054, 0.4740, 0.4966, 0.5351, 0.4520, 0.4224, 0.5101, 0.4827,\n",
      "         0.5705, 0.5180, 0.3871, 0.4464, 0.2661],\n",
      "        [0.5442, 0.4839, 0.4474, 0.4221, 0.4191, 0.4653, 0.4211, 0.5010, 0.5029,\n",
      "         0.4436, 0.3098, 0.2826, 0.2818, 0.4673, 0.4097, 0.5227, 0.4117, 0.4666,\n",
      "         0.3543, 0.5084, 0.4722, 0.4528, 0.5493, 0.4451, 0.4024, 0.5043, 0.4486,\n",
      "         0.5179, 0.5066, 0.3727, 0.4309, 0.2972]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0167, 0.0141, 0.0135, 0.0131, 0.0130, 0.0151, 0.0139, 0.0153, 0.0164,\n",
      "        0.0142, 0.0095, 0.0085, 0.0083, 0.0147, 0.0126, 0.0162, 0.0128, 0.0147,\n",
      "        0.0103, 0.0170, 0.0151, 0.0138, 0.0166, 0.0130, 0.0134, 0.0167, 0.0153,\n",
      "        0.0169, 0.0163, 0.0115, 0.0136, 0.0084], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0172, 0.0174], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 1.2756e-01, -2.9248e-03,  0.0000e+00],\n",
      "        [ 1.0317e-01,  8.7708e-04,  0.0000e+00],\n",
      "        [ 1.0836e-01, -3.9233e-04,  0.0000e+00],\n",
      "        [ 1.2721e-01, -2.9414e-03,  0.0000e+00],\n",
      "        [ 1.0106e-01,  1.0945e-02,  0.0000e+00],\n",
      "        [ 1.1515e-01, -9.8085e-03,  0.0000e+00],\n",
      "        [ 1.0926e-01,  4.5303e-03,  0.0000e+00],\n",
      "        [ 1.2874e-01, -2.2955e-02,  0.0000e+00],\n",
      "        [ 1.4437e-01,  6.0836e-03,  0.0000e+00],\n",
      "        [ 1.1277e-01, -1.4028e-04,  0.0000e+00],\n",
      "        [ 7.9653e-02, -3.0314e-04,  0.0000e+00],\n",
      "        [ 6.9586e-02, -1.3211e-02,  0.0000e+00],\n",
      "        [ 6.5697e-02, -8.9365e-03,  0.0000e+00],\n",
      "        [ 1.1503e-01, -1.3393e-02,  0.0000e+00],\n",
      "        [ 8.8473e-02, -7.4952e-03,  0.0000e+00],\n",
      "        [ 1.4335e-01, -4.1528e-03,  0.0000e+00],\n",
      "        [ 1.0094e-01, -1.3088e-02,  0.0000e+00],\n",
      "        [ 1.3898e-01, -1.3542e-02,  0.0000e+00],\n",
      "        [ 8.5623e-02, -1.0154e-02,  0.0000e+00],\n",
      "        [ 1.3954e-01, -5.2077e-03,  0.0000e+00],\n",
      "        [ 1.1850e-01, -1.6291e-03,  0.0000e+00],\n",
      "        [ 1.2453e-01, -7.4692e-03,  0.0000e+00],\n",
      "        [ 1.3364e-01,  3.2196e-03,  0.0000e+00],\n",
      "        [ 1.1557e-01, -1.3306e-02,  0.0000e+00],\n",
      "        [ 1.1391e-01,  7.4739e-03,  0.0000e+00],\n",
      "        [ 1.4067e-01,  2.6321e-03,  0.0000e+00],\n",
      "        [ 1.2118e-01, -3.6386e-04,  0.0000e+00],\n",
      "        [ 1.5045e-01, -9.4645e-03,  0.0000e+00],\n",
      "        [ 1.2880e-01,  1.5587e-03,  0.0000e+00],\n",
      "        [ 1.0633e-01,  3.5625e-03,  0.0000e+00],\n",
      "        [ 1.1913e-01, -9.2648e-03,  0.0000e+00],\n",
      "        [ 6.4845e-02,  4.2220e-03,  0.0000e+00]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.5658, 0.5051, 0.4833, 0.4748, 0.4593, 0.4837, 0.4408, 0.5153, 0.5254,\n",
      "         0.4416, 0.3461, 0.3219, 0.2885, 0.4770, 0.4579, 0.5414, 0.4468, 0.5101,\n",
      "         0.3452, 0.5292, 0.4946, 0.5189, 0.5589, 0.4701, 0.4377, 0.5316, 0.5046,\n",
      "         0.5944, 0.5400, 0.4024, 0.4636, 0.2787],\n",
      "        [0.5680, 0.5045, 0.4656, 0.4414, 0.4375, 0.4857, 0.4377, 0.5248, 0.5257,\n",
      "         0.4630, 0.3252, 0.2930, 0.2924, 0.4871, 0.4277, 0.5458, 0.4301, 0.4896,\n",
      "         0.3678, 0.5320, 0.4930, 0.4733, 0.5733, 0.4636, 0.4185, 0.5264, 0.4696,\n",
      "         0.5408, 0.5285, 0.3876, 0.4488, 0.3106]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0170, 0.0144, 0.0137, 0.0135, 0.0133, 0.0153, 0.0140, 0.0157, 0.0167,\n",
      "        0.0145, 0.0099, 0.0085, 0.0084, 0.0150, 0.0129, 0.0166, 0.0130, 0.0152,\n",
      "        0.0103, 0.0174, 0.0154, 0.0142, 0.0170, 0.0132, 0.0135, 0.0170, 0.0157,\n",
      "        0.0172, 0.0166, 0.0117, 0.0138, 0.0086], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0176, 0.0178], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 1.1187e-01, -1.5240e-02,  0.0000e+00],\n",
      "        [ 1.0274e-01,  1.0168e-02,  0.0000e+00],\n",
      "        [ 8.8806e-02,  5.8324e-06,  0.0000e+00],\n",
      "        [ 7.9525e-02, -1.0114e-02,  0.0000e+00],\n",
      "        [ 9.0128e-02, -7.1667e-03,  0.0000e+00],\n",
      "        [ 1.2274e-01,  4.1666e-03,  0.0000e+00],\n",
      "        [ 1.0815e-01, -7.8134e-03,  0.0000e+00],\n",
      "        [ 1.0681e-01,  1.2822e-04,  0.0000e+00],\n",
      "        [ 1.2428e-01,  1.4037e-02,  0.0000e+00],\n",
      "        [ 1.0514e-01,  2.0587e-03,  0.0000e+00],\n",
      "        [ 9.2195e-02,  4.9294e-03,  0.0000e+00],\n",
      "        [ 5.4380e-02, -4.1420e-03,  0.0000e+00],\n",
      "        [ 5.3418e-02,  2.6434e-03,  0.0000e+00],\n",
      "        [ 1.0171e-01,  6.0430e-04,  0.0000e+00],\n",
      "        [ 8.2802e-02, -8.1827e-03,  0.0000e+00],\n",
      "        [ 1.1118e-01,  5.5213e-03,  0.0000e+00],\n",
      "        [ 8.0078e-02, -4.4323e-03,  0.0000e+00],\n",
      "        [ 1.0146e-01, -1.3906e-03,  0.0000e+00],\n",
      "        [ 8.3290e-02, -1.1349e-02,  0.0000e+00],\n",
      "        [ 1.3440e-01,  3.6827e-03,  0.0000e+00],\n",
      "        [ 1.1530e-01, -2.7360e-03,  0.0000e+00],\n",
      "        [ 8.6653e-02, -5.0519e-03,  0.0000e+00],\n",
      "        [ 1.2819e-01,  1.6719e-02,  0.0000e+00],\n",
      "        [ 9.0363e-02, -1.3945e-02,  0.0000e+00],\n",
      "        [ 1.0208e-01,  6.7552e-03,  0.0000e+00],\n",
      "        [ 1.2519e-01,  1.0273e-03,  0.0000e+00],\n",
      "        [ 1.0675e-01,  5.4499e-03,  0.0000e+00],\n",
      "        [ 1.0093e-01,  1.5518e-03,  0.0000e+00],\n",
      "        [ 1.3102e-01,  1.5383e-03,  0.0000e+00],\n",
      "        [ 9.2271e-02, -9.8943e-03,  0.0000e+00],\n",
      "        [ 1.0234e-01,  1.3990e-02,  0.0000e+00],\n",
      "        [ 7.0187e-02, -5.7253e-06,  0.0000e+00]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.5902, 0.5267, 0.5050, 0.4944, 0.4791, 0.5052, 0.4621, 0.5364, 0.5479,\n",
      "         0.4614, 0.3588, 0.3359, 0.3020, 0.4984, 0.4780, 0.5641, 0.4660, 0.5313,\n",
      "         0.3613, 0.5510, 0.5161, 0.5402, 0.5823, 0.4909, 0.4588, 0.5551, 0.5257,\n",
      "         0.6200, 0.5635, 0.4200, 0.4847, 0.2899],\n",
      "        [0.5925, 0.5263, 0.4862, 0.4603, 0.4565, 0.5064, 0.4583, 0.5468, 0.5482,\n",
      "         0.4831, 0.3380, 0.3060, 0.3058, 0.5082, 0.4461, 0.5693, 0.4483, 0.5102,\n",
      "         0.3843, 0.5541, 0.5144, 0.4935, 0.5977, 0.4838, 0.4377, 0.5491, 0.4896,\n",
      "         0.5640, 0.5515, 0.4049, 0.4683, 0.3234]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0174, 0.0147, 0.0140, 0.0138, 0.0136, 0.0156, 0.0144, 0.0160, 0.0171,\n",
      "        0.0148, 0.0100, 0.0088, 0.0086, 0.0153, 0.0132, 0.0169, 0.0133, 0.0155,\n",
      "        0.0106, 0.0177, 0.0157, 0.0144, 0.0173, 0.0135, 0.0139, 0.0173, 0.0160,\n",
      "        0.0176, 0.0170, 0.0119, 0.0141, 0.0088], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0179, 0.0182], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0987, -0.0296,  0.0000],\n",
      "        [ 0.0732, -0.0255,  0.0000],\n",
      "        [ 0.0576, -0.0279,  0.0000],\n",
      "        [ 0.0529, -0.0155,  0.0000],\n",
      "        [ 0.0771, -0.0289,  0.0000],\n",
      "        [ 0.0718, -0.0318,  0.0000],\n",
      "        [ 0.0684, -0.0268,  0.0000],\n",
      "        [ 0.0712, -0.0370,  0.0000],\n",
      "        [ 0.0931, -0.0229,  0.0000],\n",
      "        [ 0.0886, -0.0328,  0.0000],\n",
      "        [ 0.0566, -0.0215,  0.0000],\n",
      "        [ 0.0575, -0.0159,  0.0000],\n",
      "        [ 0.0341, -0.0200,  0.0000],\n",
      "        [ 0.0661, -0.0255,  0.0000],\n",
      "        [ 0.0691, -0.0238,  0.0000],\n",
      "        [ 0.0941, -0.0350,  0.0000],\n",
      "        [ 0.0514, -0.0199,  0.0000],\n",
      "        [ 0.0834, -0.0370,  0.0000],\n",
      "        [ 0.0626, -0.0331,  0.0000],\n",
      "        [ 0.0997, -0.0283,  0.0000],\n",
      "        [ 0.0792, -0.0283,  0.0000],\n",
      "        [ 0.0750, -0.0281,  0.0000],\n",
      "        [ 0.0948, -0.0512,  0.0000],\n",
      "        [ 0.0745, -0.0518,  0.0000],\n",
      "        [ 0.0708, -0.0306,  0.0000],\n",
      "        [ 0.0909, -0.0234,  0.0000],\n",
      "        [ 0.0594, -0.0257,  0.0000],\n",
      "        [ 0.0815, -0.0270,  0.0000],\n",
      "        [ 0.0880, -0.0350,  0.0000],\n",
      "        [ 0.0624, -0.0192,  0.0000],\n",
      "        [ 0.0627, -0.0335,  0.0000],\n",
      "        [ 0.0434, -0.0236,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.6144, 0.5492, 0.5263, 0.5160, 0.4982, 0.5254, 0.4811, 0.5589, 0.5706,\n",
      "         0.4806, 0.3747, 0.3530, 0.3157, 0.5192, 0.4968, 0.5883, 0.4844, 0.5522,\n",
      "         0.3775, 0.5737, 0.5379, 0.5629, 0.6072, 0.5119, 0.4780, 0.5775, 0.5481,\n",
      "         0.6453, 0.5872, 0.4391, 0.5048, 0.3025],\n",
      "        [0.6169, 0.5489, 0.5070, 0.4808, 0.4748, 0.5275, 0.4771, 0.5694, 0.5710,\n",
      "         0.5030, 0.3533, 0.3225, 0.3201, 0.5295, 0.4638, 0.5936, 0.4664, 0.5301,\n",
      "         0.4019, 0.5771, 0.5361, 0.5144, 0.6232, 0.5048, 0.4570, 0.5717, 0.5107,\n",
      "         0.5876, 0.5749, 0.4235, 0.4882, 0.3372]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0176, 0.0150, 0.0143, 0.0141, 0.0138, 0.0159, 0.0146, 0.0163, 0.0173,\n",
      "        0.0150, 0.0102, 0.0091, 0.0088, 0.0155, 0.0134, 0.0172, 0.0135, 0.0157,\n",
      "        0.0109, 0.0180, 0.0160, 0.0147, 0.0176, 0.0138, 0.0141, 0.0176, 0.0163,\n",
      "        0.0179, 0.0173, 0.0123, 0.0144, 0.0090], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0183, 0.0186], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0697, -0.0021,  0.0000],\n",
      "        [ 0.0634,  0.0067,  0.0000],\n",
      "        [ 0.0612,  0.0162,  0.0000],\n",
      "        [ 0.0643,  0.0042,  0.0000],\n",
      "        [ 0.0597,  0.0033,  0.0000],\n",
      "        [ 0.0595,  0.0184,  0.0000],\n",
      "        [ 0.0325,  0.0198,  0.0000],\n",
      "        [ 0.0682,  0.0291,  0.0000],\n",
      "        [ 0.0749,  0.0025,  0.0000],\n",
      "        [ 0.0621,  0.0210,  0.0000],\n",
      "        [ 0.0570, -0.0034,  0.0000],\n",
      "        [ 0.0168, -0.0002,  0.0000],\n",
      "        [ 0.0362,  0.0103,  0.0000],\n",
      "        [ 0.0599,  0.0209,  0.0000],\n",
      "        [ 0.0656,  0.0016,  0.0000],\n",
      "        [ 0.0727,  0.0118,  0.0000],\n",
      "        [ 0.0581,  0.0008,  0.0000],\n",
      "        [ 0.0719, -0.0007,  0.0000],\n",
      "        [ 0.0317,  0.0205,  0.0000],\n",
      "        [ 0.0686,  0.0177,  0.0000],\n",
      "        [ 0.0818, -0.0025,  0.0000],\n",
      "        [ 0.0828,  0.0155,  0.0000],\n",
      "        [ 0.0798,  0.0247,  0.0000],\n",
      "        [ 0.0464,  0.0317,  0.0000],\n",
      "        [ 0.0289,  0.0134,  0.0000],\n",
      "        [ 0.0631,  0.0180,  0.0000],\n",
      "        [ 0.0684,  0.0073,  0.0000],\n",
      "        [ 0.0585,  0.0127,  0.0000],\n",
      "        [ 0.0782,  0.0202,  0.0000],\n",
      "        [ 0.0469, -0.0156,  0.0000],\n",
      "        [ 0.0655,  0.0116,  0.0000],\n",
      "        [ 0.0302,  0.0078,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.6416, 0.5723, 0.5493, 0.5362, 0.5208, 0.5500, 0.5028, 0.5829, 0.5963,\n",
      "         0.5027, 0.3892, 0.3634, 0.3285, 0.5427, 0.5196, 0.6130, 0.5068, 0.5771,\n",
      "         0.3931, 0.5999, 0.5618, 0.5861, 0.6330, 0.5336, 0.4993, 0.6039, 0.5718,\n",
      "         0.6739, 0.6128, 0.4566, 0.5285, 0.3152],\n",
      "        [0.6446, 0.5720, 0.5299, 0.4994, 0.4969, 0.5530, 0.4998, 0.5939, 0.5972,\n",
      "         0.5267, 0.3662, 0.3309, 0.3328, 0.5542, 0.4863, 0.6185, 0.4888, 0.5545,\n",
      "         0.4184, 0.6036, 0.5603, 0.5357, 0.6495, 0.5264, 0.4787, 0.5987, 0.5332,\n",
      "         0.6148, 0.6005, 0.4405, 0.5121, 0.3509]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0180, 0.0153, 0.0147, 0.0142, 0.0141, 0.0162, 0.0150, 0.0166, 0.0177,\n",
      "        0.0154, 0.0103, 0.0092, 0.0090, 0.0159, 0.0137, 0.0175, 0.0138, 0.0160,\n",
      "        0.0111, 0.0183, 0.0164, 0.0149, 0.0179, 0.0140, 0.0145, 0.0180, 0.0166,\n",
      "        0.0183, 0.0176, 0.0125, 0.0148, 0.0091], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0187, 0.0190], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0981,  0.0222,  0.0000],\n",
      "        [ 0.0609,  0.0073,  0.0000],\n",
      "        [ 0.0586,  0.0349,  0.0000],\n",
      "        [ 0.0714,  0.0239,  0.0000],\n",
      "        [ 0.0747,  0.0197,  0.0000],\n",
      "        [ 0.0783,  0.0174,  0.0000],\n",
      "        [ 0.1116,  0.0166,  0.0000],\n",
      "        [ 0.0940,  0.0061,  0.0000],\n",
      "        [ 0.0852,  0.0112,  0.0000],\n",
      "        [ 0.0885,  0.0034,  0.0000],\n",
      "        [ 0.0395,  0.0150,  0.0000],\n",
      "        [ 0.0773,  0.0054,  0.0000],\n",
      "        [ 0.0370, -0.0003,  0.0000],\n",
      "        [ 0.0870,  0.0196,  0.0000],\n",
      "        [ 0.1029,  0.0038,  0.0000],\n",
      "        [ 0.0832,  0.0004,  0.0000],\n",
      "        [ 0.0819,  0.0140,  0.0000],\n",
      "        [ 0.0861,  0.0122,  0.0000],\n",
      "        [ 0.0526,  0.0098,  0.0000],\n",
      "        [ 0.0960,  0.0001,  0.0000],\n",
      "        [ 0.1039,  0.0093,  0.0000],\n",
      "        [ 0.0691,  0.0157,  0.0000],\n",
      "        [ 0.0778,  0.0089,  0.0000],\n",
      "        [ 0.0855,  0.0106,  0.0000],\n",
      "        [ 0.0693,  0.0177,  0.0000],\n",
      "        [ 0.0834,  0.0130,  0.0000],\n",
      "        [ 0.0912,  0.0137,  0.0000],\n",
      "        [ 0.1006,  0.0263,  0.0000],\n",
      "        [ 0.0892,  0.0132,  0.0000],\n",
      "        [ 0.0550,  0.0095,  0.0000],\n",
      "        [ 0.0700,  0.0120,  0.0000],\n",
      "        [ 0.0457,  0.0050,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.6687, 0.5965, 0.5726, 0.5593, 0.5429, 0.5741, 0.5266, 0.6079, 0.6223,\n",
      "         0.5250, 0.4062, 0.3792, 0.3423, 0.5664, 0.5418, 0.6391, 0.5284, 0.6016,\n",
      "         0.4101, 0.6261, 0.5858, 0.6110, 0.6598, 0.5568, 0.5215, 0.6301, 0.5960,\n",
      "         0.7023, 0.6392, 0.4761, 0.5514, 0.3287],\n",
      "        [0.6716, 0.5963, 0.5522, 0.5213, 0.5181, 0.5768, 0.5230, 0.6196, 0.6229,\n",
      "         0.5497, 0.3829, 0.3461, 0.3471, 0.5780, 0.5070, 0.6451, 0.5094, 0.5781,\n",
      "         0.4364, 0.6298, 0.5844, 0.5591, 0.6773, 0.5494, 0.4996, 0.6247, 0.5565,\n",
      "         0.6412, 0.6265, 0.4595, 0.5340, 0.3657]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0184, 0.0156, 0.0149, 0.0146, 0.0144, 0.0166, 0.0153, 0.0170, 0.0181,\n",
      "        0.0157, 0.0107, 0.0094, 0.0092, 0.0162, 0.0140, 0.0179, 0.0141, 0.0163,\n",
      "        0.0113, 0.0187, 0.0167, 0.0153, 0.0183, 0.0143, 0.0148, 0.0184, 0.0169,\n",
      "        0.0186, 0.0180, 0.0127, 0.0151, 0.0093], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0191, 0.0194], grad_fn=<MeanBackward1>)\n",
      "Epoch 5/10, Accuracy: 0.4812\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0760, -0.0225,  0.0000],\n",
      "        [ 0.0518, -0.0069,  0.0000],\n",
      "        [ 0.0410,  0.0096,  0.0000],\n",
      "        [ 0.0585, -0.0009,  0.0000],\n",
      "        [ 0.0565, -0.0084,  0.0000],\n",
      "        [ 0.0456, -0.0080,  0.0000],\n",
      "        [ 0.0662,  0.0057,  0.0000],\n",
      "        [ 0.0734,  0.0057,  0.0000],\n",
      "        [ 0.0464, -0.0124,  0.0000],\n",
      "        [ 0.0190, -0.0044,  0.0000],\n",
      "        [ 0.0319, -0.0033,  0.0000],\n",
      "        [ 0.0251, -0.0010,  0.0000],\n",
      "        [ 0.0235,  0.0162,  0.0000],\n",
      "        [ 0.0469, -0.0073,  0.0000],\n",
      "        [ 0.0552, -0.0063,  0.0000],\n",
      "        [ 0.0583, -0.0143,  0.0000],\n",
      "        [ 0.0602, -0.0065,  0.0000],\n",
      "        [ 0.0648,  0.0008,  0.0000],\n",
      "        [ 0.0386, -0.0069,  0.0000],\n",
      "        [ 0.0457,  0.0038,  0.0000],\n",
      "        [ 0.0416, -0.0150,  0.0000],\n",
      "        [ 0.0592, -0.0031,  0.0000],\n",
      "        [ 0.0537,  0.0046,  0.0000],\n",
      "        [ 0.0568,  0.0088,  0.0000],\n",
      "        [ 0.0438, -0.0144,  0.0000],\n",
      "        [ 0.0594, -0.0114,  0.0000],\n",
      "        [ 0.0695, -0.0092,  0.0000],\n",
      "        [ 0.0673, -0.0005,  0.0000],\n",
      "        [ 0.0549, -0.0086,  0.0000],\n",
      "        [ 0.0467, -0.0075,  0.0000],\n",
      "        [ 0.0251, -0.0059,  0.0000],\n",
      "        [ 0.0280, -0.0145,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.6972, 0.6218, 0.5969, 0.5830, 0.5658, 0.5989, 0.5479, 0.6333, 0.6486,\n",
      "         0.5475, 0.4234, 0.3950, 0.3575, 0.5904, 0.5643, 0.6664, 0.5505, 0.6267,\n",
      "         0.4278, 0.6526, 0.6111, 0.6368, 0.6879, 0.5800, 0.5446, 0.6569, 0.6214,\n",
      "         0.7320, 0.6664, 0.4968, 0.5737, 0.3427],\n",
      "        [0.7000, 0.6218, 0.5754, 0.5440, 0.5395, 0.6000, 0.5436, 0.6449, 0.6493,\n",
      "         0.5722, 0.3996, 0.3625, 0.3629, 0.6020, 0.5276, 0.6729, 0.5302, 0.6017,\n",
      "         0.4556, 0.6563, 0.6094, 0.5831, 0.7063, 0.5721, 0.5205, 0.6503, 0.5804,\n",
      "         0.6679, 0.6530, 0.4801, 0.5549, 0.3814]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0187, 0.0159, 0.0153, 0.0149, 0.0147, 0.0168, 0.0156, 0.0172, 0.0184,\n",
      "        0.0160, 0.0108, 0.0097, 0.0094, 0.0166, 0.0142, 0.0183, 0.0143, 0.0165,\n",
      "        0.0116, 0.0190, 0.0170, 0.0156, 0.0187, 0.0146, 0.0151, 0.0187, 0.0172,\n",
      "        0.0190, 0.0183, 0.0131, 0.0153, 0.0095], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0195, 0.0198], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 9.9249e-02,  3.8547e-03,  0.0000e+00],\n",
      "        [ 8.1626e-02, -1.3621e-03,  0.0000e+00],\n",
      "        [ 6.8252e-02,  2.1874e-02,  0.0000e+00],\n",
      "        [ 7.3974e-02,  7.0094e-03,  0.0000e+00],\n",
      "        [ 8.9726e-02, -1.2061e-02,  0.0000e+00],\n",
      "        [ 8.3754e-02,  3.1395e-03,  0.0000e+00],\n",
      "        [ 7.4444e-02,  1.8620e-03,  0.0000e+00],\n",
      "        [ 1.0004e-01,  1.3029e-02,  0.0000e+00],\n",
      "        [ 1.0139e-01,  7.4576e-03,  0.0000e+00],\n",
      "        [ 6.8052e-02, -3.5914e-03,  0.0000e+00],\n",
      "        [ 7.3225e-02,  1.8565e-02,  0.0000e+00],\n",
      "        [ 4.5027e-02, -4.8248e-03,  0.0000e+00],\n",
      "        [ 5.0916e-02,  8.4484e-03,  0.0000e+00],\n",
      "        [ 6.9807e-02,  2.1031e-02,  0.0000e+00],\n",
      "        [ 4.2375e-02,  3.3928e-03,  0.0000e+00],\n",
      "        [ 9.2841e-02,  1.0495e-04,  0.0000e+00],\n",
      "        [ 7.2753e-02, -6.4502e-03,  0.0000e+00],\n",
      "        [ 8.7122e-02,  4.9399e-03,  0.0000e+00],\n",
      "        [ 7.0742e-02,  9.9222e-03,  0.0000e+00],\n",
      "        [ 1.0180e-01,  1.1907e-02,  0.0000e+00],\n",
      "        [ 6.2028e-02, -6.7130e-03,  0.0000e+00],\n",
      "        [ 1.0787e-01,  9.5496e-03,  0.0000e+00],\n",
      "        [ 8.5768e-02,  1.5285e-02,  0.0000e+00],\n",
      "        [ 8.1227e-02, -7.6724e-04,  0.0000e+00],\n",
      "        [ 7.0953e-02,  5.1737e-03,  0.0000e+00],\n",
      "        [ 9.3950e-02,  7.3640e-03,  0.0000e+00],\n",
      "        [ 7.2860e-02,  6.7891e-03,  0.0000e+00],\n",
      "        [ 1.1098e-01, -7.2397e-03,  0.0000e+00],\n",
      "        [ 8.3054e-02,  1.2985e-02,  0.0000e+00],\n",
      "        [ 7.5836e-02, -3.5980e-03,  0.0000e+00],\n",
      "        [ 8.1830e-02,  3.5527e-03,  0.0000e+00],\n",
      "        [ 3.2189e-02, -1.2202e-02,  0.0000e+00]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.7265, 0.6480, 0.6215, 0.6086, 0.5899, 0.6240, 0.5708, 0.6609, 0.6761,\n",
      "         0.5715, 0.4420, 0.4116, 0.3725, 0.6146, 0.5879, 0.6952, 0.5738, 0.6543,\n",
      "         0.4456, 0.6805, 0.6375, 0.6637, 0.7175, 0.6044, 0.5665, 0.6849, 0.6486,\n",
      "         0.7630, 0.6945, 0.5176, 0.5978, 0.3577],\n",
      "        [0.7298, 0.6480, 0.5996, 0.5677, 0.5633, 0.6265, 0.5674, 0.6736, 0.6772,\n",
      "         0.5976, 0.4169, 0.3763, 0.3775, 0.6273, 0.5504, 0.7017, 0.5537, 0.6290,\n",
      "         0.4740, 0.6851, 0.6359, 0.6079, 0.7364, 0.5966, 0.5428, 0.6788, 0.6063,\n",
      "         0.6973, 0.6812, 0.4999, 0.5795, 0.3978]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0191, 0.0162, 0.0156, 0.0152, 0.0150, 0.0172, 0.0159, 0.0176, 0.0188,\n",
      "        0.0163, 0.0111, 0.0098, 0.0096, 0.0169, 0.0146, 0.0186, 0.0147, 0.0170,\n",
      "        0.0119, 0.0194, 0.0174, 0.0159, 0.0190, 0.0149, 0.0154, 0.0190, 0.0176,\n",
      "        0.0194, 0.0187, 0.0133, 0.0157, 0.0097], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0199, 0.0202], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0787,  0.0183,  0.0000],\n",
      "        [ 0.0797,  0.0216,  0.0000],\n",
      "        [ 0.0804,  0.0232,  0.0000],\n",
      "        [ 0.0674,  0.0048,  0.0000],\n",
      "        [ 0.0837, -0.0032,  0.0000],\n",
      "        [ 0.0726,  0.0329,  0.0000],\n",
      "        [ 0.0480,  0.0085,  0.0000],\n",
      "        [ 0.0827,  0.0013,  0.0000],\n",
      "        [ 0.0831,  0.0185,  0.0000],\n",
      "        [ 0.0729,  0.0121,  0.0000],\n",
      "        [ 0.0619,  0.0179,  0.0000],\n",
      "        [ 0.0298,  0.0036,  0.0000],\n",
      "        [ 0.0396,  0.0056,  0.0000],\n",
      "        [ 0.0794,  0.0153,  0.0000],\n",
      "        [ 0.0655,  0.0043,  0.0000],\n",
      "        [ 0.0824,  0.0257,  0.0000],\n",
      "        [ 0.0921,  0.0036,  0.0000],\n",
      "        [ 0.0842,  0.0261,  0.0000],\n",
      "        [ 0.0191,  0.0112,  0.0000],\n",
      "        [ 0.0886,  0.0166,  0.0000],\n",
      "        [ 0.0791,  0.0090,  0.0000],\n",
      "        [ 0.0931,  0.0112,  0.0000],\n",
      "        [ 0.0870,  0.0137,  0.0000],\n",
      "        [ 0.0736,  0.0051,  0.0000],\n",
      "        [ 0.0804,  0.0212,  0.0000],\n",
      "        [ 0.0831,  0.0262,  0.0000],\n",
      "        [ 0.0890,  0.0207,  0.0000],\n",
      "        [ 0.1003,  0.0195,  0.0000],\n",
      "        [ 0.1007,  0.0261,  0.0000],\n",
      "        [ 0.0440,  0.0028,  0.0000],\n",
      "        [ 0.0713,  0.0279,  0.0000],\n",
      "        [ 0.0117,  0.0225,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.7576, 0.6753, 0.6486, 0.6334, 0.6152, 0.6501, 0.5960, 0.6892, 0.7053,\n",
      "         0.5962, 0.4600, 0.4287, 0.3883, 0.6422, 0.6131, 0.7245, 0.5984, 0.6812,\n",
      "         0.4640, 0.7100, 0.6645, 0.6912, 0.7475, 0.6302, 0.5918, 0.7141, 0.6758,\n",
      "         0.7951, 0.7240, 0.5393, 0.6235, 0.3732],\n",
      "        [0.7611, 0.6754, 0.6260, 0.5914, 0.5879, 0.6533, 0.5923, 0.7028, 0.7066,\n",
      "         0.6232, 0.4338, 0.3918, 0.3933, 0.6551, 0.5743, 0.7316, 0.5777, 0.6554,\n",
      "         0.4933, 0.7148, 0.6631, 0.6337, 0.7672, 0.6220, 0.5675, 0.7080, 0.6321,\n",
      "         0.7272, 0.7103, 0.5210, 0.6046, 0.4147]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0195, 0.0166, 0.0159, 0.0155, 0.0153, 0.0175, 0.0163, 0.0180, 0.0191,\n",
      "        0.0166, 0.0113, 0.0100, 0.0098, 0.0173, 0.0149, 0.0190, 0.0150, 0.0172,\n",
      "        0.0121, 0.0198, 0.0177, 0.0162, 0.0194, 0.0152, 0.0157, 0.0194, 0.0179,\n",
      "        0.0198, 0.0191, 0.0135, 0.0160, 0.0099], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0204, 0.0206], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[0.0618, 0.0474, 0.0000],\n",
      "        [0.0716, 0.0223, 0.0000],\n",
      "        [0.0610, 0.0360, 0.0000],\n",
      "        [0.0541, 0.0297, 0.0000],\n",
      "        [0.0494, 0.0399, 0.0000],\n",
      "        [0.0835, 0.0211, 0.0000],\n",
      "        [0.0670, 0.0475, 0.0000],\n",
      "        [0.0513, 0.0320, 0.0000],\n",
      "        [0.0621, 0.0453, 0.0000],\n",
      "        [0.0775, 0.0371, 0.0000],\n",
      "        [0.0310, 0.0387, 0.0000],\n",
      "        [0.0336, 0.0227, 0.0000],\n",
      "        [0.0325, 0.0248, 0.0000],\n",
      "        [0.0447, 0.0292, 0.0000],\n",
      "        [0.0785, 0.0285, 0.0000],\n",
      "        [0.0621, 0.0261, 0.0000],\n",
      "        [0.0628, 0.0306, 0.0000],\n",
      "        [0.0718, 0.0371, 0.0000],\n",
      "        [0.0468, 0.0155, 0.0000],\n",
      "        [0.0973, 0.0405, 0.0000],\n",
      "        [0.0832, 0.0264, 0.0000],\n",
      "        [0.0474, 0.0398, 0.0000],\n",
      "        [0.0614, 0.0325, 0.0000],\n",
      "        [0.0757, 0.0231, 0.0000],\n",
      "        [0.0587, 0.0171, 0.0000],\n",
      "        [0.0847, 0.0352, 0.0000],\n",
      "        [0.0671, 0.0270, 0.0000],\n",
      "        [0.0807, 0.0440, 0.0000],\n",
      "        [0.0945, 0.0319, 0.0000],\n",
      "        [0.0539, 0.0138, 0.0000],\n",
      "        [0.0609, 0.0196, 0.0000],\n",
      "        [0.0673, 0.0191, 0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.7894, 0.7037, 0.6762, 0.6597, 0.6406, 0.6799, 0.6224, 0.7184, 0.7353,\n",
      "         0.6218, 0.4795, 0.4468, 0.4055, 0.6697, 0.6386, 0.7547, 0.6236, 0.7093,\n",
      "         0.4847, 0.7393, 0.6929, 0.7204, 0.7791, 0.6571, 0.6182, 0.7449, 0.7044,\n",
      "         0.8284, 0.7550, 0.5626, 0.6514, 0.3879],\n",
      "        [0.7933, 0.7037, 0.6531, 0.6159, 0.6124, 0.6834, 0.6193, 0.7325, 0.7368,\n",
      "         0.6500, 0.4519, 0.4080, 0.4107, 0.6836, 0.5991, 0.7619, 0.6023, 0.6827,\n",
      "         0.5153, 0.7442, 0.6916, 0.6607, 0.7995, 0.6491, 0.5938, 0.7387, 0.6593,\n",
      "         0.7585, 0.7409, 0.5435, 0.6327, 0.4309]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0199, 0.0169, 0.0163, 0.0158, 0.0156, 0.0180, 0.0166, 0.0183, 0.0195,\n",
      "        0.0170, 0.0115, 0.0102, 0.0100, 0.0176, 0.0152, 0.0193, 0.0153, 0.0176,\n",
      "        0.0124, 0.0201, 0.0180, 0.0165, 0.0197, 0.0156, 0.0161, 0.0198, 0.0182,\n",
      "        0.0201, 0.0194, 0.0138, 0.0164, 0.0101], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0208, 0.0210], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1194, -0.0078,  0.0000],\n",
      "        [ 0.1119, -0.0044,  0.0000],\n",
      "        [ 0.0877, -0.0226,  0.0000],\n",
      "        [ 0.0910, -0.0051,  0.0000],\n",
      "        [ 0.0851, -0.0070,  0.0000],\n",
      "        [ 0.1206, -0.0061,  0.0000],\n",
      "        [ 0.0982,  0.0042,  0.0000],\n",
      "        [ 0.1080, -0.0020,  0.0000],\n",
      "        [ 0.1194, -0.0129,  0.0000],\n",
      "        [ 0.0923, -0.0173,  0.0000],\n",
      "        [ 0.0877, -0.0204,  0.0000],\n",
      "        [ 0.0650, -0.0048,  0.0000],\n",
      "        [ 0.0532, -0.0186,  0.0000],\n",
      "        [ 0.1119, -0.0108,  0.0000],\n",
      "        [ 0.0976, -0.0080,  0.0000],\n",
      "        [ 0.1054, -0.0155,  0.0000],\n",
      "        [ 0.0920, -0.0097,  0.0000],\n",
      "        [ 0.1079, -0.0184,  0.0000],\n",
      "        [ 0.0562,  0.0081,  0.0000],\n",
      "        [ 0.1221, -0.0196,  0.0000],\n",
      "        [ 0.1229,  0.0013,  0.0000],\n",
      "        [ 0.0995, -0.0142,  0.0000],\n",
      "        [ 0.1072, -0.0100,  0.0000],\n",
      "        [ 0.0807, -0.0078,  0.0000],\n",
      "        [ 0.0957, -0.0136,  0.0000],\n",
      "        [ 0.1224, -0.0101,  0.0000],\n",
      "        [ 0.1223, -0.0036,  0.0000],\n",
      "        [ 0.1200, -0.0267,  0.0000],\n",
      "        [ 0.1077, -0.0103,  0.0000],\n",
      "        [ 0.0932, -0.0055,  0.0000],\n",
      "        [ 0.1020, -0.0265,  0.0000],\n",
      "        [ 0.0587,  0.0031,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.8223, 0.7334, 0.7038, 0.6888, 0.6672, 0.7060, 0.6463, 0.7483, 0.7666,\n",
      "         0.6480, 0.5000, 0.4671, 0.4222, 0.6971, 0.6644, 0.7873, 0.6490, 0.7400,\n",
      "         0.5049, 0.7716, 0.7218, 0.7509, 0.8123, 0.6836, 0.6424, 0.7753, 0.7340,\n",
      "         0.8631, 0.7864, 0.5866, 0.6776, 0.4057],\n",
      "        [0.8266, 0.7334, 0.6796, 0.6438, 0.6385, 0.7109, 0.6432, 0.7635, 0.7682,\n",
      "         0.6778, 0.4719, 0.4259, 0.4273, 0.7119, 0.6239, 0.7951, 0.6275, 0.7131,\n",
      "         0.5361, 0.7774, 0.7207, 0.6893, 0.8337, 0.6753, 0.6173, 0.7698, 0.6877,\n",
      "         0.7911, 0.7722, 0.5667, 0.6578, 0.4501]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0202, 0.0172, 0.0165, 0.0162, 0.0159, 0.0182, 0.0168, 0.0187, 0.0199,\n",
      "        0.0173, 0.0118, 0.0105, 0.0102, 0.0179, 0.0154, 0.0198, 0.0155, 0.0180,\n",
      "        0.0126, 0.0205, 0.0184, 0.0169, 0.0202, 0.0158, 0.0163, 0.0201, 0.0186,\n",
      "        0.0205, 0.0198, 0.0141, 0.0166, 0.0104], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0212, 0.0215], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1473, -0.0496,  0.0000],\n",
      "        [ 0.1304, -0.0313,  0.0000],\n",
      "        [ 0.1064, -0.0149,  0.0000],\n",
      "        [ 0.1206, -0.0190,  0.0000],\n",
      "        [ 0.0993, -0.0300,  0.0000],\n",
      "        [ 0.1146, -0.0444,  0.0000],\n",
      "        [ 0.1337, -0.0390,  0.0000],\n",
      "        [ 0.1558, -0.0110,  0.0000],\n",
      "        [ 0.1243, -0.0309,  0.0000],\n",
      "        [ 0.1150, -0.0326,  0.0000],\n",
      "        [ 0.0606, -0.0203,  0.0000],\n",
      "        [ 0.0760, -0.0225,  0.0000],\n",
      "        [ 0.0912, -0.0129,  0.0000],\n",
      "        [ 0.1353, -0.0225,  0.0000],\n",
      "        [ 0.1227, -0.0241,  0.0000],\n",
      "        [ 0.1585, -0.0169,  0.0000],\n",
      "        [ 0.1156, -0.0274,  0.0000],\n",
      "        [ 0.1402, -0.0304,  0.0000],\n",
      "        [ 0.0844, -0.0158,  0.0000],\n",
      "        [ 0.1423, -0.0330,  0.0000],\n",
      "        [ 0.1203, -0.0377,  0.0000],\n",
      "        [ 0.0948, -0.0249,  0.0000],\n",
      "        [ 0.1626, -0.0185,  0.0000],\n",
      "        [ 0.1101, -0.0214,  0.0000],\n",
      "        [ 0.1192, -0.0167,  0.0000],\n",
      "        [ 0.1347, -0.0349,  0.0000],\n",
      "        [ 0.1194, -0.0277,  0.0000],\n",
      "        [ 0.1310, -0.0311,  0.0000],\n",
      "        [ 0.1287, -0.0262,  0.0000],\n",
      "        [ 0.1058, -0.0353,  0.0000],\n",
      "        [ 0.1249, -0.0260,  0.0000],\n",
      "        [ 0.0751, -0.0388,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.8575, 0.7640, 0.7329, 0.7182, 0.6963, 0.7373, 0.6748, 0.7796, 0.7996,\n",
      "         0.6761, 0.5229, 0.4848, 0.4399, 0.7266, 0.6927, 0.8206, 0.6766, 0.7721,\n",
      "         0.5261, 0.8049, 0.7531, 0.7830, 0.8464, 0.7123, 0.6688, 0.8087, 0.7659,\n",
      "         0.8991, 0.8198, 0.6104, 0.7054, 0.4231],\n",
      "        [0.8616, 0.7643, 0.7073, 0.6722, 0.6663, 0.7400, 0.6707, 0.7953, 0.8009,\n",
      "         0.7060, 0.4949, 0.4447, 0.4454, 0.7409, 0.6493, 0.8292, 0.6535, 0.7439,\n",
      "         0.5586, 0.8105, 0.7515, 0.7196, 0.8691, 0.7033, 0.6408, 0.8017, 0.7181,\n",
      "         0.8235, 0.8047, 0.5900, 0.6834, 0.4697]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0207, 0.0176, 0.0169, 0.0166, 0.0163, 0.0185, 0.0172, 0.0190, 0.0203,\n",
      "        0.0176, 0.0122, 0.0108, 0.0104, 0.0182, 0.0157, 0.0202, 0.0158, 0.0183,\n",
      "        0.0129, 0.0209, 0.0187, 0.0173, 0.0206, 0.0161, 0.0165, 0.0205, 0.0190,\n",
      "        0.0209, 0.0202, 0.0144, 0.0169, 0.0106], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0216, 0.0219], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0813, -0.0127,  0.0000],\n",
      "        [ 0.0458, -0.0091,  0.0000],\n",
      "        [ 0.0325, -0.0070,  0.0000],\n",
      "        [ 0.0587,  0.0167,  0.0000],\n",
      "        [ 0.0330, -0.0249,  0.0000],\n",
      "        [ 0.0595, -0.0233,  0.0000],\n",
      "        [ 0.0280,  0.0014,  0.0000],\n",
      "        [ 0.0540, -0.0182,  0.0000],\n",
      "        [ 0.0494, -0.0110,  0.0000],\n",
      "        [ 0.0612, -0.0242,  0.0000],\n",
      "        [ 0.0332, -0.0114,  0.0000],\n",
      "        [ 0.0382,  0.0031,  0.0000],\n",
      "        [ 0.0306,  0.0042,  0.0000],\n",
      "        [ 0.0691, -0.0145,  0.0000],\n",
      "        [ 0.0592, -0.0085,  0.0000],\n",
      "        [ 0.0413, -0.0140,  0.0000],\n",
      "        [ 0.0523, -0.0073,  0.0000],\n",
      "        [ 0.0644, -0.0108,  0.0000],\n",
      "        [ 0.0203, -0.0166,  0.0000],\n",
      "        [ 0.0409, -0.0041,  0.0000],\n",
      "        [ 0.0582, -0.0167,  0.0000],\n",
      "        [ 0.0532, -0.0105,  0.0000],\n",
      "        [ 0.0529, -0.0310,  0.0000],\n",
      "        [ 0.0383, -0.0105,  0.0000],\n",
      "        [ 0.0328, -0.0329,  0.0000],\n",
      "        [ 0.0500, -0.0216,  0.0000],\n",
      "        [ 0.0506, -0.0171,  0.0000],\n",
      "        [ 0.0508, -0.0122,  0.0000],\n",
      "        [ 0.0278,  0.0034,  0.0000],\n",
      "        [ 0.0558, -0.0197,  0.0000],\n",
      "        [ 0.0489, -0.0226,  0.0000],\n",
      "        [ 0.0448, -0.0118,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.8927, 0.7961, 0.7649, 0.7468, 0.7248, 0.7687, 0.7043, 0.8120, 0.8324,\n",
      "         0.7050, 0.5420, 0.5072, 0.4602, 0.7587, 0.7214, 0.8547, 0.7046, 0.8010,\n",
      "         0.5496, 0.8375, 0.7845, 0.8139, 0.8814, 0.7429, 0.7004, 0.8426, 0.7970,\n",
      "         0.9366, 0.8540, 0.6379, 0.7371, 0.4399],\n",
      "        [0.8971, 0.7963, 0.7384, 0.6991, 0.6936, 0.7723, 0.6997, 0.8283, 0.8341,\n",
      "         0.7358, 0.5128, 0.4652, 0.4659, 0.7736, 0.6771, 0.8637, 0.6809, 0.7723,\n",
      "         0.5834, 0.8438, 0.7832, 0.7484, 0.9050, 0.7337, 0.6718, 0.8357, 0.7474,\n",
      "         0.8586, 0.8386, 0.6167, 0.7144, 0.4881]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0210, 0.0179, 0.0173, 0.0168, 0.0166, 0.0189, 0.0176, 0.0194, 0.0206,\n",
      "        0.0179, 0.0123, 0.0111, 0.0107, 0.0187, 0.0161, 0.0205, 0.0161, 0.0185,\n",
      "        0.0132, 0.0213, 0.0191, 0.0175, 0.0209, 0.0165, 0.0170, 0.0209, 0.0193,\n",
      "        0.0213, 0.0206, 0.0148, 0.0174, 0.0108], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0221, 0.0224], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1672,  0.0198,  0.0000],\n",
      "        [ 0.1480,  0.0344,  0.0000],\n",
      "        [ 0.1277,  0.0140,  0.0000],\n",
      "        [ 0.1271,  0.0044,  0.0000],\n",
      "        [ 0.1350,  0.0138,  0.0000],\n",
      "        [ 0.1664,  0.0173,  0.0000],\n",
      "        [ 0.1680,  0.0246,  0.0000],\n",
      "        [ 0.1590,  0.0414,  0.0000],\n",
      "        [ 0.1771,  0.0197,  0.0000],\n",
      "        [ 0.1574,  0.0026,  0.0000],\n",
      "        [ 0.0914, -0.0087,  0.0000],\n",
      "        [ 0.0769,  0.0170,  0.0000],\n",
      "        [ 0.0824, -0.0032,  0.0000],\n",
      "        [ 0.1513,  0.0178,  0.0000],\n",
      "        [ 0.1174,  0.0335,  0.0000],\n",
      "        [ 0.1741,  0.0081,  0.0000],\n",
      "        [ 0.1276,  0.0210,  0.0000],\n",
      "        [ 0.1549,  0.0147,  0.0000],\n",
      "        [ 0.1200,  0.0239,  0.0000],\n",
      "        [ 0.1991,  0.0130,  0.0000],\n",
      "        [ 0.1469,  0.0217,  0.0000],\n",
      "        [ 0.1311,  0.0093,  0.0000],\n",
      "        [ 0.1623,  0.0361,  0.0000],\n",
      "        [ 0.1417,  0.0139,  0.0000],\n",
      "        [ 0.1518,  0.0289,  0.0000],\n",
      "        [ 0.1893,  0.0191,  0.0000],\n",
      "        [ 0.1521,  0.0339,  0.0000],\n",
      "        [ 0.1750,  0.0349,  0.0000],\n",
      "        [ 0.2010,  0.0090,  0.0000],\n",
      "        [ 0.1227,  0.0193,  0.0000],\n",
      "        [ 0.1460,  0.0055,  0.0000],\n",
      "        [ 0.1001, -0.0017,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.9315, 0.8291, 0.7960, 0.7792, 0.7567, 0.8017, 0.7345, 0.8478, 0.8692,\n",
      "         0.7365, 0.5663, 0.5241, 0.4767, 0.7901, 0.7524, 0.8909, 0.7356, 0.8397,\n",
      "         0.5710, 0.8748, 0.8185, 0.8493, 0.9192, 0.7737, 0.7280, 0.8792, 0.8322,\n",
      "         0.9763, 0.8910, 0.6624, 0.7669, 0.4594],\n",
      "        [0.9360, 0.8294, 0.7686, 0.7294, 0.7246, 0.8057, 0.7308, 0.8650, 0.8704,\n",
      "         0.7686, 0.5360, 0.4797, 0.4826, 0.8057, 0.7065, 0.9001, 0.7112, 0.8091,\n",
      "         0.6062, 0.8811, 0.8170, 0.7814, 0.9435, 0.7642, 0.6991, 0.8723, 0.7809,\n",
      "         0.8960, 0.8750, 0.6406, 0.7443, 0.5091]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0215, 0.0183, 0.0176, 0.0172, 0.0170, 0.0193, 0.0179, 0.0199, 0.0211,\n",
      "        0.0184, 0.0126, 0.0111, 0.0108, 0.0190, 0.0164, 0.0210, 0.0165, 0.0191,\n",
      "        0.0134, 0.0218, 0.0195, 0.0180, 0.0214, 0.0168, 0.0173, 0.0213, 0.0198,\n",
      "        0.0218, 0.0210, 0.0150, 0.0176, 0.0111], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0225, 0.0228], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1145,  0.0018,  0.0000],\n",
      "        [ 0.0990, -0.0211,  0.0000],\n",
      "        [ 0.0826, -0.0205,  0.0000],\n",
      "        [ 0.1019, -0.0054,  0.0000],\n",
      "        [ 0.0606, -0.0063,  0.0000],\n",
      "        [ 0.0977, -0.0085,  0.0000],\n",
      "        [ 0.0868, -0.0043,  0.0000],\n",
      "        [ 0.1035, -0.0025,  0.0000],\n",
      "        [ 0.1273, -0.0267,  0.0000],\n",
      "        [ 0.1004,  0.0234,  0.0000],\n",
      "        [ 0.0775, -0.0013,  0.0000],\n",
      "        [ 0.0412,  0.0166,  0.0000],\n",
      "        [ 0.0461, -0.0021,  0.0000],\n",
      "        [ 0.1142, -0.0090,  0.0000],\n",
      "        [ 0.0915,  0.0027,  0.0000],\n",
      "        [ 0.1046, -0.0090,  0.0000],\n",
      "        [ 0.1046, -0.0124,  0.0000],\n",
      "        [ 0.1285, -0.0010,  0.0000],\n",
      "        [ 0.0650,  0.0004,  0.0000],\n",
      "        [ 0.1229, -0.0100,  0.0000],\n",
      "        [ 0.1246,  0.0088,  0.0000],\n",
      "        [ 0.0817,  0.0066,  0.0000],\n",
      "        [ 0.0955, -0.0155,  0.0000],\n",
      "        [ 0.0899, -0.0221,  0.0000],\n",
      "        [ 0.0895, -0.0108,  0.0000],\n",
      "        [ 0.1247, -0.0035,  0.0000],\n",
      "        [ 0.0965, -0.0076,  0.0000],\n",
      "        [ 0.1111, -0.0127,  0.0000],\n",
      "        [ 0.0969, -0.0163,  0.0000],\n",
      "        [ 0.0825, -0.0012,  0.0000],\n",
      "        [ 0.1064,  0.0020,  0.0000],\n",
      "        [ 0.0591, -0.0121,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.9691, 0.8638, 0.8298, 0.8110, 0.7869, 0.8337, 0.7642, 0.8820, 0.9049,\n",
      "         0.7651, 0.5899, 0.5510, 0.4991, 0.8232, 0.7821, 0.9282, 0.7648, 0.8698,\n",
      "         0.5962, 0.9105, 0.8520, 0.8841, 0.9574, 0.8061, 0.7585, 0.9144, 0.8662,\n",
      "         1.0161, 0.9277, 0.6921, 0.7988, 0.4789],\n",
      "        [0.9741, 0.8641, 0.8013, 0.7598, 0.7540, 0.8379, 0.7603, 0.9001, 0.9065,\n",
      "         0.7986, 0.5586, 0.5046, 0.5049, 0.8398, 0.7351, 0.9381, 0.7396, 0.8393,\n",
      "         0.6327, 0.9171, 0.8508, 0.8140, 0.9828, 0.7962, 0.7290, 0.9075, 0.8131,\n",
      "         0.9329, 0.9113, 0.6692, 0.7752, 0.5303]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0219, 0.0187, 0.0180, 0.0175, 0.0173, 0.0196, 0.0183, 0.0202, 0.0215,\n",
      "        0.0186, 0.0129, 0.0115, 0.0111, 0.0194, 0.0167, 0.0214, 0.0168, 0.0193,\n",
      "        0.0138, 0.0221, 0.0199, 0.0183, 0.0218, 0.0171, 0.0177, 0.0217, 0.0201,\n",
      "        0.0222, 0.0214, 0.0154, 0.0180, 0.0113], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0230, 0.0233], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1607, -0.0123,  0.0000],\n",
      "        [ 0.1569,  0.0096,  0.0000],\n",
      "        [ 0.1240,  0.0206,  0.0000],\n",
      "        [ 0.1343,  0.0024,  0.0000],\n",
      "        [ 0.1212, -0.0247,  0.0000],\n",
      "        [ 0.1537,  0.0199,  0.0000],\n",
      "        [ 0.1496, -0.0242,  0.0000],\n",
      "        [ 0.1836, -0.0155,  0.0000],\n",
      "        [ 0.1774, -0.0164,  0.0000],\n",
      "        [ 0.1471, -0.0121,  0.0000],\n",
      "        [ 0.0793,  0.0095,  0.0000],\n",
      "        [ 0.0747, -0.0200,  0.0000],\n",
      "        [ 0.1007, -0.0056,  0.0000],\n",
      "        [ 0.1454, -0.0058,  0.0000],\n",
      "        [ 0.1243,  0.0055,  0.0000],\n",
      "        [ 0.1869, -0.0029,  0.0000],\n",
      "        [ 0.1329,  0.0043,  0.0000],\n",
      "        [ 0.1520,  0.0122,  0.0000],\n",
      "        [ 0.1291, -0.0035,  0.0000],\n",
      "        [ 0.1870, -0.0074,  0.0000],\n",
      "        [ 0.1509,  0.0103,  0.0000],\n",
      "        [ 0.1529,  0.0022,  0.0000],\n",
      "        [ 0.1694, -0.0080,  0.0000],\n",
      "        [ 0.1381,  0.0112,  0.0000],\n",
      "        [ 0.1360,  0.0125,  0.0000],\n",
      "        [ 0.1773,  0.0007,  0.0000],\n",
      "        [ 0.1694, -0.0018,  0.0000],\n",
      "        [ 0.1867,  0.0067,  0.0000],\n",
      "        [ 0.1824, -0.0012,  0.0000],\n",
      "        [ 0.1210,  0.0068,  0.0000],\n",
      "        [ 0.1249,  0.0236,  0.0000],\n",
      "        [ 0.0995, -0.0028,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.0110, 0.8997, 0.8635, 0.8464, 0.8222, 0.8698, 0.7983, 0.9207, 0.9445,\n",
      "         0.8003, 0.6162, 0.5668, 0.5181, 0.8578, 0.8168, 0.9674, 0.7982, 0.9108,\n",
      "         0.6199, 0.9506, 0.8889, 0.9212, 0.9974, 0.8392, 0.7894, 0.9545, 0.9034,\n",
      "         1.0594, 0.9670, 0.7191, 0.8300, 0.4994],\n",
      "        [1.0155, 0.9002, 0.8338, 0.7931, 0.7872, 0.8721, 0.7935, 0.9387, 0.9455,\n",
      "         0.8338, 0.5840, 0.5220, 0.5250, 0.8743, 0.7664, 0.9774, 0.7712, 0.8778,\n",
      "         0.6585, 0.9569, 0.8870, 0.8483, 1.0239, 0.8290, 0.7577, 0.9462, 0.8483,\n",
      "         0.9723, 0.9497, 0.6965, 0.8051, 0.5529]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0223, 0.0190, 0.0183, 0.0180, 0.0177, 0.0199, 0.0186, 0.0207, 0.0220,\n",
      "        0.0191, 0.0132, 0.0116, 0.0113, 0.0198, 0.0171, 0.0218, 0.0171, 0.0198,\n",
      "        0.0140, 0.0226, 0.0203, 0.0187, 0.0222, 0.0174, 0.0179, 0.0221, 0.0205,\n",
      "        0.0226, 0.0218, 0.0156, 0.0182, 0.0115], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0235, 0.0237], grad_fn=<MeanBackward1>)\n",
      "Epoch 6/10, Accuracy: 0.5063\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[0.0774, 0.0348, 0.0000],\n",
      "        [0.0397, 0.0469, 0.0000],\n",
      "        [0.0265, 0.0501, 0.0000],\n",
      "        [0.0472, 0.0308, 0.0000],\n",
      "        [0.0592, 0.0432, 0.0000],\n",
      "        [0.0431, 0.0420, 0.0000],\n",
      "        [0.0893, 0.0481, 0.0000],\n",
      "        [0.0691, 0.0499, 0.0000],\n",
      "        [0.0814, 0.0647, 0.0000],\n",
      "        [0.0495, 0.0665, 0.0000],\n",
      "        [0.0354, 0.0150, 0.0000],\n",
      "        [0.0401, 0.0159, 0.0000],\n",
      "        [0.0288, 0.0296, 0.0000],\n",
      "        [0.0633, 0.0539, 0.0000],\n",
      "        [0.0488, 0.0536, 0.0000],\n",
      "        [0.0776, 0.0535, 0.0000],\n",
      "        [0.0594, 0.0282, 0.0000],\n",
      "        [0.0589, 0.0363, 0.0000],\n",
      "        [0.0515, 0.0301, 0.0000],\n",
      "        [0.0704, 0.0664, 0.0000],\n",
      "        [0.0529, 0.0497, 0.0000],\n",
      "        [0.0224, 0.0478, 0.0000],\n",
      "        [0.0642, 0.0677, 0.0000],\n",
      "        [0.0673, 0.0704, 0.0000],\n",
      "        [0.0647, 0.0291, 0.0000],\n",
      "        [0.0580, 0.0484, 0.0000],\n",
      "        [0.0709, 0.0471, 0.0000],\n",
      "        [0.0664, 0.0504, 0.0000],\n",
      "        [0.0572, 0.0651, 0.0000],\n",
      "        [0.0372, 0.0104, 0.0000],\n",
      "        [0.0511, 0.0451, 0.0000],\n",
      "        [0.0394, 0.0306, 0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.0533, 0.9370, 0.9014, 0.8790, 0.8546, 0.9088, 0.8349, 0.9573, 0.9826,\n",
      "         0.8338, 0.6373, 0.5915, 0.5415, 0.8958, 0.8509, 1.0064, 0.8324, 0.9463,\n",
      "         0.6485, 0.9889, 0.9262, 0.9585, 1.0383, 0.8755, 0.8282, 0.9950, 0.9398,\n",
      "         1.1038, 1.0073, 0.7501, 0.8704, 0.5190],\n",
      "        [1.0585, 0.9373, 0.8711, 0.8231, 0.8193, 0.9131, 0.8309, 0.9773, 0.9842,\n",
      "         0.8693, 0.6033, 0.5421, 0.5478, 0.9135, 0.8004, 1.0170, 0.8057, 0.9135,\n",
      "         0.6879, 0.9959, 0.9249, 0.8829, 1.0657, 0.8653, 0.7965, 0.9874, 0.8831,\n",
      "         1.0146, 0.9900, 0.7258, 0.8451, 0.5740]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0228, 0.0194, 0.0188, 0.0182, 0.0180, 0.0205, 0.0192, 0.0210, 0.0223,\n",
      "        0.0194, 0.0133, 0.0119, 0.0116, 0.0202, 0.0175, 0.0222, 0.0176, 0.0201,\n",
      "        0.0144, 0.0230, 0.0207, 0.0190, 0.0226, 0.0179, 0.0185, 0.0226, 0.0209,\n",
      "        0.0231, 0.0223, 0.0160, 0.0188, 0.0117], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0240, 0.0242], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[0.1236, 0.0456, 0.0000],\n",
      "        [0.1059, 0.0245, 0.0000],\n",
      "        [0.1099, 0.0195, 0.0000],\n",
      "        [0.0836, 0.0206, 0.0000],\n",
      "        [0.0913, 0.0370, 0.0000],\n",
      "        [0.1001, 0.0370, 0.0000],\n",
      "        [0.1014, 0.0284, 0.0000],\n",
      "        [0.0934, 0.0338, 0.0000],\n",
      "        [0.1088, 0.0011, 0.0000],\n",
      "        [0.0935, 0.0162, 0.0000],\n",
      "        [0.0797, 0.0187, 0.0000],\n",
      "        [0.0258, 0.0170, 0.0000],\n",
      "        [0.0637, 0.0184, 0.0000],\n",
      "        [0.0954, 0.0095, 0.0000],\n",
      "        [0.0730, 0.0304, 0.0000],\n",
      "        [0.1109, 0.0303, 0.0000],\n",
      "        [0.0765, 0.0491, 0.0000],\n",
      "        [0.0807, 0.0449, 0.0000],\n",
      "        [0.0894, 0.0166, 0.0000],\n",
      "        [0.1249, 0.0209, 0.0000],\n",
      "        [0.0772, 0.0223, 0.0000],\n",
      "        [0.0986, 0.0426, 0.0000],\n",
      "        [0.1171, 0.0130, 0.0000],\n",
      "        [0.0969, 0.0423, 0.0000],\n",
      "        [0.0833, 0.0443, 0.0000],\n",
      "        [0.1166, 0.0293, 0.0000],\n",
      "        [0.0672, 0.0351, 0.0000],\n",
      "        [0.1024, 0.0502, 0.0000],\n",
      "        [0.1151, 0.0143, 0.0000],\n",
      "        [0.0626, 0.0334, 0.0000],\n",
      "        [0.0746, 0.0290, 0.0000],\n",
      "        [0.0688, 0.0139, 0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.0967, 0.9760, 0.9393, 0.9167, 0.8904, 0.9454, 0.8686, 0.9981, 1.0255,\n",
      "         0.8699, 0.6653, 0.6158, 0.5641, 0.9334, 0.8862, 1.0493, 0.8658, 0.9866,\n",
      "         0.6751, 1.0310, 0.9653, 0.9981, 1.0816, 0.9117, 0.8596, 1.0362, 0.9804,\n",
      "         1.1492, 1.0498, 0.7816, 0.9041, 0.5414],\n",
      "        [1.1018, 0.9763, 0.9075, 0.8593, 0.8536, 0.9497, 0.8643, 1.0190, 1.0270,\n",
      "         0.9063, 0.6306, 0.5653, 0.5704, 0.9512, 0.8333, 1.0602, 0.8379, 0.9526,\n",
      "         0.7155, 1.0383, 0.9637, 0.9201, 1.1102, 0.9007, 0.8267, 1.0282, 0.9218,\n",
      "         1.0565, 1.0317, 0.7562, 0.8781, 0.5988]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0232, 0.0198, 0.0192, 0.0186, 0.0184, 0.0208, 0.0195, 0.0215, 0.0228,\n",
      "        0.0199, 0.0136, 0.0122, 0.0118, 0.0207, 0.0178, 0.0226, 0.0178, 0.0205,\n",
      "        0.0147, 0.0234, 0.0211, 0.0194, 0.0231, 0.0182, 0.0188, 0.0230, 0.0213,\n",
      "        0.0235, 0.0227, 0.0163, 0.0191, 0.0120], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0244, 0.0247], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1794, -0.0607,  0.0000],\n",
      "        [ 0.1202, -0.0452,  0.0000],\n",
      "        [ 0.1571, -0.0291,  0.0000],\n",
      "        [ 0.1666, -0.0125,  0.0000],\n",
      "        [ 0.1218, -0.0454,  0.0000],\n",
      "        [ 0.1566, -0.0672,  0.0000],\n",
      "        [ 0.1416, -0.0174,  0.0000],\n",
      "        [ 0.1382, -0.0290,  0.0000],\n",
      "        [ 0.1623, -0.0354,  0.0000],\n",
      "        [ 0.1258, -0.0315,  0.0000],\n",
      "        [ 0.1217, -0.0412,  0.0000],\n",
      "        [ 0.0923, -0.0193,  0.0000],\n",
      "        [ 0.0731, -0.0049,  0.0000],\n",
      "        [ 0.1589, -0.0328,  0.0000],\n",
      "        [ 0.1296, -0.0246,  0.0000],\n",
      "        [ 0.1607, -0.0470,  0.0000],\n",
      "        [ 0.1389, -0.0307,  0.0000],\n",
      "        [ 0.1644, -0.0391,  0.0000],\n",
      "        [ 0.0715, -0.0325,  0.0000],\n",
      "        [ 0.1610, -0.0427,  0.0000],\n",
      "        [ 0.1370, -0.0306,  0.0000],\n",
      "        [ 0.1487, -0.0343,  0.0000],\n",
      "        [ 0.1514, -0.0579,  0.0000],\n",
      "        [ 0.1361, -0.0499,  0.0000],\n",
      "        [ 0.1228, -0.0451,  0.0000],\n",
      "        [ 0.1795, -0.0469,  0.0000],\n",
      "        [ 0.1658, -0.0344,  0.0000],\n",
      "        [ 0.1742, -0.0259,  0.0000],\n",
      "        [ 0.1526, -0.0392,  0.0000],\n",
      "        [ 0.0985, -0.0313,  0.0000],\n",
      "        [ 0.1270, -0.0475,  0.0000],\n",
      "        [ 0.1005, -0.0341,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.1420, 1.0166, 0.9767, 0.9562, 0.9274, 0.9837, 0.9009, 1.0398, 1.0667,\n",
      "         0.9043, 0.6953, 0.6460, 0.5878, 0.9701, 0.9208, 1.0940, 0.9006, 1.0260,\n",
      "         0.7024, 1.0744, 1.0049, 1.0403, 1.1275, 0.9483, 0.8930, 1.0775, 1.0202,\n",
      "         1.1952, 1.0926, 0.8142, 0.9394, 0.5654],\n",
      "        [1.1471, 1.0169, 0.9440, 0.8969, 0.8888, 0.9881, 0.8962, 1.0607, 1.0680,\n",
      "         0.9418, 0.6591, 0.5950, 0.5950, 0.9887, 0.8655, 1.1055, 0.8710, 0.9904,\n",
      "         0.7452, 1.0814, 1.0032, 0.9594, 1.1571, 0.9373, 0.8591, 1.0691, 0.9595,\n",
      "         1.0991, 1.0738, 0.7884, 0.9122, 0.6244]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0237, 0.0202, 0.0195, 0.0191, 0.0187, 0.0212, 0.0197, 0.0219, 0.0232,\n",
      "        0.0202, 0.0140, 0.0126, 0.0121, 0.0210, 0.0181, 0.0231, 0.0182, 0.0209,\n",
      "        0.0149, 0.0239, 0.0215, 0.0198, 0.0236, 0.0185, 0.0190, 0.0234, 0.0217,\n",
      "        0.0239, 0.0231, 0.0166, 0.0194, 0.0123], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0249, 0.0252], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 1.4213e-01,  1.2748e-03,  0.0000e+00],\n",
      "        [ 1.0462e-01, -3.1740e-03,  0.0000e+00],\n",
      "        [ 1.0278e-01, -2.5374e-03,  0.0000e+00],\n",
      "        [ 1.1286e-01,  6.0223e-03,  0.0000e+00],\n",
      "        [ 1.1424e-01,  1.6795e-02,  0.0000e+00],\n",
      "        [ 1.1062e-01, -1.9276e-02,  0.0000e+00],\n",
      "        [ 1.1096e-01,  1.0751e-02,  0.0000e+00],\n",
      "        [ 1.2836e-01,  6.1318e-03,  0.0000e+00],\n",
      "        [ 1.2083e-01,  1.9719e-02,  0.0000e+00],\n",
      "        [ 1.5941e-01,  1.9067e-02,  0.0000e+00],\n",
      "        [ 6.2021e-02,  5.9685e-03,  0.0000e+00],\n",
      "        [ 7.2009e-02,  2.5940e-03,  0.0000e+00],\n",
      "        [ 7.6935e-02,  2.6676e-03,  0.0000e+00],\n",
      "        [ 1.3684e-01, -9.9264e-03,  0.0000e+00],\n",
      "        [ 1.0263e-01,  1.9539e-02,  0.0000e+00],\n",
      "        [ 1.4180e-01,  1.5195e-05,  0.0000e+00],\n",
      "        [ 1.0077e-01,  1.0935e-02,  0.0000e+00],\n",
      "        [ 1.3951e-01,  4.2964e-04,  0.0000e+00],\n",
      "        [ 9.5941e-02,  4.9763e-03,  0.0000e+00],\n",
      "        [ 1.3078e-01,  2.4830e-03,  0.0000e+00],\n",
      "        [ 1.2863e-01,  4.8306e-03,  0.0000e+00],\n",
      "        [ 1.2205e-01,  1.3223e-02,  0.0000e+00],\n",
      "        [ 1.3424e-01, -6.5003e-03,  0.0000e+00],\n",
      "        [ 1.0866e-01,  7.6869e-03,  0.0000e+00],\n",
      "        [ 1.1584e-01, -7.2520e-03,  0.0000e+00],\n",
      "        [ 1.4660e-01,  5.7121e-04,  0.0000e+00],\n",
      "        [ 1.2358e-01,  1.2152e-02,  0.0000e+00],\n",
      "        [ 1.3560e-01,  3.6464e-02,  0.0000e+00],\n",
      "        [ 1.0776e-01, -8.5103e-03,  0.0000e+00],\n",
      "        [ 8.3741e-02, -1.0765e-02,  0.0000e+00],\n",
      "        [ 1.2789e-01, -8.1273e-03,  0.0000e+00],\n",
      "        [ 7.2220e-02,  6.4908e-03,  0.0000e+00]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.1898, 1.0586, 1.0178, 0.9948, 0.9656, 1.0270, 0.9414, 1.0831, 1.1121,\n",
      "         0.9434, 0.7240, 0.6703, 0.6122, 1.0127, 0.9601, 1.1387, 0.9392, 1.0690,\n",
      "         0.7325, 1.1197, 1.0473, 1.0827, 1.1739, 0.9884, 0.9339, 1.1239, 1.0632,\n",
      "         1.2453, 1.1388, 0.8481, 0.9819, 0.5885],\n",
      "        [1.1951, 1.0589, 0.9836, 0.9334, 0.9259, 1.0308, 0.9363, 1.1049, 1.1130,\n",
      "         0.9815, 0.6866, 0.6165, 0.6196, 1.0314, 0.9027, 1.1507, 0.9086, 1.0318,\n",
      "         0.7770, 1.1268, 1.0454, 0.9989, 1.2047, 0.9768, 0.8974, 1.1145, 1.0000,\n",
      "         1.1452, 1.1193, 0.8212, 0.9535, 0.6499]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0241, 0.0206, 0.0199, 0.0194, 0.0191, 0.0216, 0.0202, 0.0223, 0.0237,\n",
      "        0.0206, 0.0143, 0.0128, 0.0123, 0.0215, 0.0185, 0.0235, 0.0185, 0.0213,\n",
      "        0.0153, 0.0243, 0.0219, 0.0202, 0.0240, 0.0189, 0.0195, 0.0239, 0.0222,\n",
      "        0.0244, 0.0236, 0.0170, 0.0199, 0.0125], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0254, 0.0257], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 1.6396e-01,  1.7550e-02,  0.0000e+00],\n",
      "        [ 1.4454e-01,  2.6998e-02,  0.0000e+00],\n",
      "        [ 1.5459e-01,  1.1753e-02,  0.0000e+00],\n",
      "        [ 1.3882e-01,  5.8569e-03,  0.0000e+00],\n",
      "        [ 1.3805e-01,  1.5942e-04,  0.0000e+00],\n",
      "        [ 1.2633e-01,  1.3934e-02,  0.0000e+00],\n",
      "        [ 1.3045e-01,  2.2775e-02,  0.0000e+00],\n",
      "        [ 1.6439e-01,  4.2620e-03,  0.0000e+00],\n",
      "        [ 1.8339e-01,  1.3112e-02,  0.0000e+00],\n",
      "        [ 1.5046e-01,  2.1873e-02,  0.0000e+00],\n",
      "        [ 1.1809e-01, -3.9400e-03,  0.0000e+00],\n",
      "        [ 6.2412e-02, -1.8557e-02,  0.0000e+00],\n",
      "        [ 9.4318e-02,  1.4980e-02,  0.0000e+00],\n",
      "        [ 1.5169e-01,  9.5686e-03,  0.0000e+00],\n",
      "        [ 1.2186e-01,  1.0948e-02,  0.0000e+00],\n",
      "        [ 1.8516e-01,  2.9196e-02,  0.0000e+00],\n",
      "        [ 1.0782e-01,  9.3127e-03,  0.0000e+00],\n",
      "        [ 1.5245e-01,  1.1985e-02,  0.0000e+00],\n",
      "        [ 1.0558e-01,  1.1305e-03,  0.0000e+00],\n",
      "        [ 1.5557e-01,  3.2748e-02,  0.0000e+00],\n",
      "        [ 1.6156e-01,  2.7050e-03,  0.0000e+00],\n",
      "        [ 1.6756e-01, -2.4688e-03,  0.0000e+00],\n",
      "        [ 1.9020e-01,  1.8110e-02,  0.0000e+00],\n",
      "        [ 1.0613e-01,  9.7911e-03,  0.0000e+00],\n",
      "        [ 1.0999e-01,  2.6046e-02,  0.0000e+00],\n",
      "        [ 1.5967e-01,  3.8536e-02,  0.0000e+00],\n",
      "        [ 1.5576e-01, -8.5932e-03,  0.0000e+00],\n",
      "        [ 1.5041e-01,  1.4292e-02,  0.0000e+00],\n",
      "        [ 1.7365e-01,  2.5371e-02,  0.0000e+00],\n",
      "        [ 1.1012e-01,  1.6926e-02,  0.0000e+00],\n",
      "        [ 1.4526e-01,  4.8297e-03,  0.0000e+00],\n",
      "        [ 7.5250e-02,  2.7475e-02,  0.0000e+00]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.2394, 1.1025, 1.0599, 1.0368, 1.0067, 1.0675, 0.9802, 1.1283, 1.1585,\n",
      "         0.9834, 0.7537, 0.6954, 0.6376, 1.0542, 1.0004, 1.1862, 0.9787, 1.1148,\n",
      "         0.7628, 1.1664, 1.0913, 1.1275, 1.2224, 1.0287, 0.9702, 1.1695, 1.1078,\n",
      "         1.2975, 1.1858, 0.8831, 1.0212, 0.6141],\n",
      "        [1.2452, 1.1026, 1.0245, 0.9726, 0.9659, 1.0734, 0.9755, 1.1520, 1.1599,\n",
      "         1.0240, 0.7147, 0.6380, 0.6440, 1.0741, 0.9420, 1.1986, 0.9480, 1.0773,\n",
      "         0.8079, 1.1744, 1.0897, 1.0405, 1.2545, 1.0169, 0.9341, 1.1608, 1.0425,\n",
      "         1.1948, 1.1659, 0.8545, 0.9925, 0.6772]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0246, 0.0210, 0.0204, 0.0198, 0.0195, 0.0220, 0.0206, 0.0228, 0.0242,\n",
      "        0.0210, 0.0146, 0.0129, 0.0126, 0.0219, 0.0189, 0.0240, 0.0190, 0.0218,\n",
      "        0.0156, 0.0248, 0.0223, 0.0206, 0.0245, 0.0193, 0.0198, 0.0243, 0.0226,\n",
      "        0.0249, 0.0241, 0.0173, 0.0203, 0.0128], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0259, 0.0262], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1579, -0.0008,  0.0000],\n",
      "        [ 0.1212,  0.0118,  0.0000],\n",
      "        [ 0.1375,  0.0069,  0.0000],\n",
      "        [ 0.1499, -0.0011,  0.0000],\n",
      "        [ 0.1306, -0.0201,  0.0000],\n",
      "        [ 0.1430,  0.0057,  0.0000],\n",
      "        [ 0.1570,  0.0011,  0.0000],\n",
      "        [ 0.1643, -0.0123,  0.0000],\n",
      "        [ 0.1375, -0.0220,  0.0000],\n",
      "        [ 0.1565, -0.0248,  0.0000],\n",
      "        [ 0.0969,  0.0061,  0.0000],\n",
      "        [ 0.1089, -0.0116,  0.0000],\n",
      "        [ 0.0867, -0.0021,  0.0000],\n",
      "        [ 0.1512, -0.0184,  0.0000],\n",
      "        [ 0.1525, -0.0083,  0.0000],\n",
      "        [ 0.1628, -0.0153,  0.0000],\n",
      "        [ 0.1335, -0.0090,  0.0000],\n",
      "        [ 0.1562,  0.0025,  0.0000],\n",
      "        [ 0.0914,  0.0124,  0.0000],\n",
      "        [ 0.1820, -0.0042,  0.0000],\n",
      "        [ 0.1710, -0.0042,  0.0000],\n",
      "        [ 0.1658,  0.0035,  0.0000],\n",
      "        [ 0.1425, -0.0136,  0.0000],\n",
      "        [ 0.1341, -0.0193,  0.0000],\n",
      "        [ 0.1280, -0.0063,  0.0000],\n",
      "        [ 0.1708,  0.0076,  0.0000],\n",
      "        [ 0.1562, -0.0123,  0.0000],\n",
      "        [ 0.1623, -0.0051,  0.0000],\n",
      "        [ 0.1920,  0.0009,  0.0000],\n",
      "        [ 0.1096,  0.0028,  0.0000],\n",
      "        [ 0.1412, -0.0102,  0.0000],\n",
      "        [ 0.0599,  0.0015,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.2903, 1.1481, 1.1034, 1.0794, 1.0483, 1.1110, 1.0214, 1.1747, 1.2076,\n",
      "         1.0254, 0.7862, 0.7267, 0.6645, 1.0980, 1.0413, 1.2356, 1.0187, 1.1598,\n",
      "         0.7944, 1.2139, 1.1364, 1.1740, 1.2736, 1.0715, 1.0112, 1.2179, 1.1535,\n",
      "         1.3509, 1.2348, 0.9202, 1.0632, 0.6400],\n",
      "        [1.2958, 1.1482, 1.0670, 1.0125, 1.0052, 1.1162, 1.0162, 1.1984, 1.2084,\n",
      "         1.0663, 0.7456, 0.6695, 0.6725, 1.1185, 0.9799, 1.2485, 0.9859, 1.1189,\n",
      "         0.8423, 1.2214, 1.1343, 1.0837, 1.3068, 1.0594, 0.9731, 1.2081, 1.0854,\n",
      "         1.2438, 1.2137, 0.8914, 1.0332, 0.7053]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0251, 0.0214, 0.0207, 0.0202, 0.0199, 0.0224, 0.0210, 0.0232, 0.0247,\n",
      "        0.0214, 0.0149, 0.0134, 0.0129, 0.0223, 0.0193, 0.0245, 0.0193, 0.0221,\n",
      "        0.0159, 0.0252, 0.0228, 0.0210, 0.0250, 0.0197, 0.0203, 0.0247, 0.0230,\n",
      "        0.0254, 0.0245, 0.0177, 0.0207, 0.0131], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0265, 0.0267], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0677, -0.0173,  0.0000],\n",
      "        [ 0.0960, -0.0048,  0.0000],\n",
      "        [ 0.0513,  0.0056,  0.0000],\n",
      "        [ 0.0571, -0.0043,  0.0000],\n",
      "        [ 0.0817,  0.0282,  0.0000],\n",
      "        [ 0.0431, -0.0055,  0.0000],\n",
      "        [ 0.0417,  0.0027,  0.0000],\n",
      "        [ 0.0669, -0.0150,  0.0000],\n",
      "        [ 0.0948,  0.0089,  0.0000],\n",
      "        [ 0.0621, -0.0006,  0.0000],\n",
      "        [ 0.0243,  0.0143,  0.0000],\n",
      "        [ 0.0120, -0.0075,  0.0000],\n",
      "        [ 0.0214, -0.0364,  0.0000],\n",
      "        [ 0.0638, -0.0109,  0.0000],\n",
      "        [ 0.0395,  0.0012,  0.0000],\n",
      "        [ 0.0981, -0.0161,  0.0000],\n",
      "        [ 0.0462, -0.0209,  0.0000],\n",
      "        [ 0.0795, -0.0204,  0.0000],\n",
      "        [ 0.0474, -0.0068,  0.0000],\n",
      "        [ 0.0610, -0.0092,  0.0000],\n",
      "        [ 0.0690,  0.0126,  0.0000],\n",
      "        [ 0.0412,  0.0057,  0.0000],\n",
      "        [ 0.1060,  0.0164,  0.0000],\n",
      "        [ 0.0407,  0.0055,  0.0000],\n",
      "        [ 0.0927, -0.0078,  0.0000],\n",
      "        [ 0.0881,  0.0042,  0.0000],\n",
      "        [ 0.0696, -0.0024,  0.0000],\n",
      "        [ 0.0817, -0.0126,  0.0000],\n",
      "        [ 0.0681, -0.0006,  0.0000],\n",
      "        [ 0.0573, -0.0137,  0.0000],\n",
      "        [ 0.0573, -0.0003,  0.0000],\n",
      "        [ 0.0393, -0.0103,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.3439, 1.1955, 1.1499, 1.1234, 1.0890, 1.1590, 1.0643, 1.2231, 1.2556,\n",
      "         1.0674, 0.8174, 0.7575, 0.6925, 1.1441, 1.0845, 1.2860, 1.0616, 1.2062,\n",
      "         0.8296, 1.2648, 1.1834, 1.2225, 1.3257, 1.1162, 1.0564, 1.2685, 1.2008,\n",
      "         1.4068, 1.2862, 0.9598, 1.1085, 0.6654],\n",
      "        [1.3499, 1.1954, 1.1116, 1.0543, 1.0448, 1.1640, 1.0592, 1.2485, 1.2564,\n",
      "         1.1102, 0.7755, 0.6963, 0.6995, 1.1656, 1.0215, 1.2994, 1.0277, 1.1649,\n",
      "         0.8781, 1.2729, 1.1814, 1.1288, 1.3602, 1.1035, 1.0170, 1.2585, 1.1303,\n",
      "         1.2957, 1.2645, 0.9293, 1.0775, 0.7334]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0256, 0.0218, 0.0212, 0.0206, 0.0202, 0.0229, 0.0214, 0.0236, 0.0251,\n",
      "        0.0218, 0.0152, 0.0137, 0.0132, 0.0228, 0.0197, 0.0249, 0.0197, 0.0225,\n",
      "        0.0163, 0.0257, 0.0232, 0.0215, 0.0254, 0.0201, 0.0208, 0.0252, 0.0235,\n",
      "        0.0259, 0.0250, 0.0181, 0.0211, 0.0133], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0270, 0.0272], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1491, -0.0120,  0.0000],\n",
      "        [ 0.1417, -0.0306,  0.0000],\n",
      "        [ 0.1316, -0.0168,  0.0000],\n",
      "        [ 0.1084,  0.0021,  0.0000],\n",
      "        [ 0.1050, -0.0189,  0.0000],\n",
      "        [ 0.1441, -0.0369,  0.0000],\n",
      "        [ 0.1208, -0.0192,  0.0000],\n",
      "        [ 0.1205, -0.0243,  0.0000],\n",
      "        [ 0.1395, -0.0426,  0.0000],\n",
      "        [ 0.1253, -0.0126,  0.0000],\n",
      "        [ 0.0871, -0.0259,  0.0000],\n",
      "        [ 0.0514, -0.0035,  0.0000],\n",
      "        [ 0.0892, -0.0170,  0.0000],\n",
      "        [ 0.1383, -0.0079,  0.0000],\n",
      "        [ 0.1047, -0.0016,  0.0000],\n",
      "        [ 0.1444, -0.0353,  0.0000],\n",
      "        [ 0.1027, -0.0150,  0.0000],\n",
      "        [ 0.1498, -0.0250,  0.0000],\n",
      "        [ 0.0975, -0.0362,  0.0000],\n",
      "        [ 0.1539, -0.0499,  0.0000],\n",
      "        [ 0.1286, -0.0162,  0.0000],\n",
      "        [ 0.1181,  0.0063,  0.0000],\n",
      "        [ 0.1438, -0.0393,  0.0000],\n",
      "        [ 0.1142, -0.0095,  0.0000],\n",
      "        [ 0.1135, -0.0480,  0.0000],\n",
      "        [ 0.1526, -0.0379,  0.0000],\n",
      "        [ 0.1388, -0.0499,  0.0000],\n",
      "        [ 0.1281, -0.0219,  0.0000],\n",
      "        [ 0.1632, -0.0552,  0.0000],\n",
      "        [ 0.1079, -0.0443,  0.0000],\n",
      "        [ 0.1227, -0.0233,  0.0000],\n",
      "        [ 0.0883, -0.0247,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.3990, 1.2448, 1.1968, 1.1717, 1.1363, 1.2064, 1.1085, 1.2744, 1.3097,\n",
      "         1.1117, 0.8522, 0.7897, 0.7216, 1.1904, 1.1276, 1.3400, 1.1043, 1.2563,\n",
      "         0.8626, 1.3170, 1.2325, 1.2734, 1.3810, 1.1618, 1.0982, 1.3212, 1.2511,\n",
      "         1.4641, 1.3396, 0.9984, 1.1530, 0.6939],\n",
      "        [1.4051, 1.2445, 1.1576, 1.0993, 1.0906, 1.2131, 1.1041, 1.3005, 1.3103,\n",
      "         1.1564, 0.8076, 0.7260, 0.7295, 1.2131, 1.0629, 1.3537, 1.0697, 1.2134,\n",
      "         0.9138, 1.3251, 1.2307, 1.1761, 1.4164, 1.1490, 1.0590, 1.3113, 1.1779,\n",
      "         1.3492, 1.3173, 0.9670, 1.1220, 0.7634]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0261, 0.0223, 0.0216, 0.0211, 0.0207, 0.0233, 0.0218, 0.0242, 0.0256,\n",
      "        0.0222, 0.0155, 0.0140, 0.0135, 0.0232, 0.0200, 0.0255, 0.0200, 0.0229,\n",
      "        0.0166, 0.0262, 0.0237, 0.0219, 0.0260, 0.0205, 0.0211, 0.0257, 0.0239,\n",
      "        0.0264, 0.0255, 0.0184, 0.0215, 0.0136], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0275, 0.0277], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1319,  0.0172,  0.0000],\n",
      "        [ 0.0993,  0.0102,  0.0000],\n",
      "        [ 0.1136,  0.0240,  0.0000],\n",
      "        [ 0.1053,  0.0227,  0.0000],\n",
      "        [ 0.1239,  0.0154,  0.0000],\n",
      "        [ 0.1194,  0.0200,  0.0000],\n",
      "        [ 0.1300,  0.0269,  0.0000],\n",
      "        [ 0.1235,  0.0295,  0.0000],\n",
      "        [ 0.0981,  0.0428,  0.0000],\n",
      "        [ 0.0845,  0.0210,  0.0000],\n",
      "        [ 0.0805,  0.0279,  0.0000],\n",
      "        [ 0.0436,  0.0335,  0.0000],\n",
      "        [ 0.0557, -0.0051,  0.0000],\n",
      "        [ 0.1044,  0.0499,  0.0000],\n",
      "        [ 0.1028,  0.0329,  0.0000],\n",
      "        [ 0.1293,  0.0111,  0.0000],\n",
      "        [ 0.1039,  0.0130,  0.0000],\n",
      "        [ 0.1159,  0.0344,  0.0000],\n",
      "        [ 0.0760,  0.0097,  0.0000],\n",
      "        [ 0.1355,  0.0387,  0.0000],\n",
      "        [ 0.0978,  0.0494,  0.0000],\n",
      "        [ 0.1104,  0.0056,  0.0000],\n",
      "        [ 0.1275,  0.0416,  0.0000],\n",
      "        [ 0.1219,  0.0187,  0.0000],\n",
      "        [ 0.1151,  0.0186,  0.0000],\n",
      "        [ 0.1384,  0.0282,  0.0000],\n",
      "        [ 0.1333,  0.0291,  0.0000],\n",
      "        [ 0.1206,  0.0019,  0.0000],\n",
      "        [ 0.1390,  0.0271,  0.0000],\n",
      "        [ 0.0793,  0.0042,  0.0000],\n",
      "        [ 0.1118,  0.0306,  0.0000],\n",
      "        [ 0.0534, -0.0105,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.4575, 1.2958, 1.2468, 1.2191, 1.1831, 1.2571, 1.1563, 1.3262, 1.3639,\n",
      "         1.1601, 0.8872, 0.8217, 0.7512, 1.2401, 1.1754, 1.3951, 1.1508, 1.3090,\n",
      "         0.8982, 1.3712, 1.2841, 1.3252, 1.4379, 1.2102, 1.1442, 1.3766, 1.3023,\n",
      "         1.5259, 1.3949, 1.0395, 1.2010, 0.7231],\n",
      "        [1.4634, 1.2955, 1.2061, 1.1436, 1.1355, 1.2627, 1.1513, 1.3531, 1.3640,\n",
      "         1.2052, 0.8410, 0.7559, 0.7594, 1.2632, 1.1077, 1.4093, 1.1145, 1.2638,\n",
      "         0.9518, 1.3792, 1.2817, 1.2241, 1.4748, 1.1969, 1.1024, 1.3652, 1.2262,\n",
      "         1.4061, 1.3717, 1.0073, 1.1683, 0.7950]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0266, 0.0227, 0.0221, 0.0215, 0.0211, 0.0238, 0.0223, 0.0246, 0.0261,\n",
      "        0.0227, 0.0158, 0.0143, 0.0137, 0.0237, 0.0205, 0.0260, 0.0205, 0.0234,\n",
      "        0.0170, 0.0267, 0.0241, 0.0223, 0.0265, 0.0209, 0.0216, 0.0262, 0.0244,\n",
      "        0.0270, 0.0260, 0.0188, 0.0220, 0.0139], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0281, 0.0283], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1831, -0.0505,  0.0000],\n",
      "        [ 0.1328, -0.0597,  0.0000],\n",
      "        [ 0.1096, -0.0275,  0.0000],\n",
      "        [ 0.1563, -0.0209,  0.0000],\n",
      "        [ 0.1278, -0.0325,  0.0000],\n",
      "        [ 0.1107, -0.0500,  0.0000],\n",
      "        [ 0.1386, -0.0428,  0.0000],\n",
      "        [ 0.1627, -0.0429,  0.0000],\n",
      "        [ 0.1723, -0.0417,  0.0000],\n",
      "        [ 0.1444, -0.0182,  0.0000],\n",
      "        [ 0.0838, -0.0368,  0.0000],\n",
      "        [ 0.0905,  0.0046,  0.0000],\n",
      "        [ 0.1006, -0.0338,  0.0000],\n",
      "        [ 0.1159, -0.0299,  0.0000],\n",
      "        [ 0.1155, -0.0356,  0.0000],\n",
      "        [ 0.1752, -0.0681,  0.0000],\n",
      "        [ 0.1227, -0.0311,  0.0000],\n",
      "        [ 0.1528, -0.0353,  0.0000],\n",
      "        [ 0.1396, -0.0341,  0.0000],\n",
      "        [ 0.1380, -0.0709,  0.0000],\n",
      "        [ 0.1576, -0.0260,  0.0000],\n",
      "        [ 0.1460, -0.0396,  0.0000],\n",
      "        [ 0.1539, -0.0439,  0.0000],\n",
      "        [ 0.1004, -0.0424,  0.0000],\n",
      "        [ 0.1103, -0.0422,  0.0000],\n",
      "        [ 0.1359, -0.0613,  0.0000],\n",
      "        [ 0.1459, -0.0402,  0.0000],\n",
      "        [ 0.1900, -0.0291,  0.0000],\n",
      "        [ 0.1425, -0.0702,  0.0000],\n",
      "        [ 0.1449, -0.0318,  0.0000],\n",
      "        [ 0.1241, -0.0294,  0.0000],\n",
      "        [ 0.1045, -0.0378,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.5171, 1.3493, 1.2965, 1.2702, 1.2318, 1.3073, 1.2024, 1.3809, 1.4197,\n",
      "         1.2058, 0.9256, 0.8580, 0.7830, 1.2904, 1.2228, 1.4528, 1.1970, 1.3623,\n",
      "         0.9372, 1.4296, 1.3367, 1.3800, 1.4974, 1.2591, 1.1888, 1.4326, 1.3565,\n",
      "         1.5866, 1.4528, 1.0840, 1.2485, 0.7534],\n",
      "        [1.5230, 1.3488, 1.2537, 1.1920, 1.1822, 1.3131, 1.1968, 1.4091, 1.4194,\n",
      "         1.2527, 0.8786, 0.7909, 0.7912, 1.3140, 1.1524, 1.4676, 1.1588, 1.3160,\n",
      "         0.9921, 1.4379, 1.3343, 1.2752, 1.5360, 1.2451, 1.1452, 1.4211, 1.2774,\n",
      "         1.4623, 1.4285, 1.0500, 1.2140, 0.8282]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0271, 0.0232, 0.0225, 0.0220, 0.0215, 0.0242, 0.0227, 0.0251, 0.0266,\n",
      "        0.0231, 0.0162, 0.0147, 0.0140, 0.0241, 0.0209, 0.0265, 0.0208, 0.0239,\n",
      "        0.0174, 0.0273, 0.0246, 0.0228, 0.0270, 0.0213, 0.0219, 0.0267, 0.0249,\n",
      "        0.0274, 0.0265, 0.0192, 0.0223, 0.0142], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0286, 0.0288], grad_fn=<MeanBackward1>)\n",
      "Epoch 7/10, Accuracy: 0.4875\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1681, -0.0219,  0.0000],\n",
      "        [ 0.1218, -0.0272,  0.0000],\n",
      "        [ 0.1180, -0.0021,  0.0000],\n",
      "        [ 0.1520, -0.0051,  0.0000],\n",
      "        [ 0.1391, -0.0174,  0.0000],\n",
      "        [ 0.1202, -0.0320,  0.0000],\n",
      "        [ 0.1295,  0.0107,  0.0000],\n",
      "        [ 0.1415, -0.0132,  0.0000],\n",
      "        [ 0.1484, -0.0033,  0.0000],\n",
      "        [ 0.1064, -0.0028,  0.0000],\n",
      "        [ 0.0854, -0.0221,  0.0000],\n",
      "        [ 0.0885, -0.0143,  0.0000],\n",
      "        [ 0.1032, -0.0242,  0.0000],\n",
      "        [ 0.1334,  0.0049,  0.0000],\n",
      "        [ 0.0706, -0.0045,  0.0000],\n",
      "        [ 0.1661, -0.0220,  0.0000],\n",
      "        [ 0.1121, -0.0262,  0.0000],\n",
      "        [ 0.1412, -0.0123,  0.0000],\n",
      "        [ 0.1083,  0.0017,  0.0000],\n",
      "        [ 0.1392, -0.0196,  0.0000],\n",
      "        [ 0.1190, -0.0172,  0.0000],\n",
      "        [ 0.1208, -0.0097,  0.0000],\n",
      "        [ 0.1361, -0.0224,  0.0000],\n",
      "        [ 0.0983, -0.0146,  0.0000],\n",
      "        [ 0.1068, -0.0065,  0.0000],\n",
      "        [ 0.1236,  0.0032,  0.0000],\n",
      "        [ 0.1270, -0.0012,  0.0000],\n",
      "        [ 0.1395,  0.0003,  0.0000],\n",
      "        [ 0.1493, -0.0075,  0.0000],\n",
      "        [ 0.1301, -0.0430,  0.0000],\n",
      "        [ 0.1203, -0.0184,  0.0000],\n",
      "        [ 0.0694, -0.0140,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.5803, 1.4047, 1.3506, 1.3221, 1.2826, 1.3629, 1.2512, 1.4383, 1.4788,\n",
      "         1.2576, 0.9624, 0.8910, 0.8153, 1.3445, 1.2734, 1.5128, 1.2473, 1.4189,\n",
      "         0.9758, 1.4874, 1.3926, 1.4368, 1.5590, 1.3110, 1.2393, 1.4915, 1.4124,\n",
      "         1.6524, 1.5121, 1.1278, 1.3018, 0.7851],\n",
      "        [1.5859, 1.4040, 1.3062, 1.2400, 1.2309, 1.3687, 1.2456, 1.4676, 1.4777,\n",
      "         1.3051, 0.9135, 0.8210, 0.8241, 1.3686, 1.1997, 1.5280, 1.2078, 1.3700,\n",
      "         1.0327, 1.4960, 1.3896, 1.3280, 1.5988, 1.2964, 1.1942, 1.4787, 1.3303,\n",
      "         1.5231, 1.4869, 1.0931, 1.2664, 0.8625]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0277, 0.0236, 0.0230, 0.0224, 0.0220, 0.0247, 0.0231, 0.0256, 0.0271,\n",
      "        0.0236, 0.0165, 0.0149, 0.0143, 0.0246, 0.0213, 0.0270, 0.0213, 0.0243,\n",
      "        0.0177, 0.0278, 0.0251, 0.0232, 0.0275, 0.0217, 0.0224, 0.0272, 0.0254,\n",
      "        0.0280, 0.0271, 0.0196, 0.0228, 0.0145], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0292, 0.0294], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.2146,  0.0003,  0.0000],\n",
      "        [ 0.2003,  0.0160,  0.0000],\n",
      "        [ 0.1794, -0.0064,  0.0000],\n",
      "        [ 0.1722, -0.0122,  0.0000],\n",
      "        [ 0.1580, -0.0026,  0.0000],\n",
      "        [ 0.2148, -0.0101,  0.0000],\n",
      "        [ 0.1647, -0.0462,  0.0000],\n",
      "        [ 0.2224, -0.0179,  0.0000],\n",
      "        [ 0.1924,  0.0082,  0.0000],\n",
      "        [ 0.1973,  0.0184,  0.0000],\n",
      "        [ 0.1376, -0.0164,  0.0000],\n",
      "        [ 0.1344, -0.0151,  0.0000],\n",
      "        [ 0.1063,  0.0058,  0.0000],\n",
      "        [ 0.1908, -0.0016,  0.0000],\n",
      "        [ 0.2202,  0.0086,  0.0000],\n",
      "        [ 0.2138,  0.0150,  0.0000],\n",
      "        [ 0.1745, -0.0020,  0.0000],\n",
      "        [ 0.2114, -0.0054,  0.0000],\n",
      "        [ 0.1407, -0.0191,  0.0000],\n",
      "        [ 0.1906,  0.0054,  0.0000],\n",
      "        [ 0.2361,  0.0008,  0.0000],\n",
      "        [ 0.2114, -0.0003,  0.0000],\n",
      "        [ 0.2300,  0.0050,  0.0000],\n",
      "        [ 0.1823, -0.0283,  0.0000],\n",
      "        [ 0.1798, -0.0037,  0.0000],\n",
      "        [ 0.2087, -0.0060,  0.0000],\n",
      "        [ 0.2245, -0.0163,  0.0000],\n",
      "        [ 0.2416, -0.0169,  0.0000],\n",
      "        [ 0.2058, -0.0013,  0.0000],\n",
      "        [ 0.1631,  0.0065,  0.0000],\n",
      "        [ 0.1942,  0.0138,  0.0000],\n",
      "        [ 0.1351, -0.0149,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.6454, 1.4624, 1.4055, 1.3782, 1.3374, 1.4182, 1.3057, 1.4988, 1.5415,\n",
      "         1.3100, 1.0035, 0.9246, 0.8474, 1.4007, 1.3263, 1.5762, 1.2989, 1.4793,\n",
      "         1.0138, 1.5506, 1.4503, 1.4961, 1.6231, 1.3649, 1.2903, 1.5541, 1.4711,\n",
      "         1.7211, 1.5749, 1.1735, 1.3539, 0.8183],\n",
      "        [1.6516, 1.4616, 1.3595, 1.2937, 1.2841, 1.4244, 1.2992, 1.5288, 1.5402,\n",
      "         1.3592, 0.9524, 0.8522, 0.8560, 1.4253, 1.2499, 1.5919, 1.2579, 1.4282,\n",
      "         1.0728, 1.5591, 1.4469, 1.3830, 1.6645, 1.3501, 1.2431, 1.5404, 1.3852,\n",
      "         1.5865, 1.5485, 1.1370, 1.3170, 0.8980]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0282, 0.0241, 0.0235, 0.0229, 0.0225, 0.0252, 0.0237, 0.0261, 0.0277,\n",
      "        0.0240, 0.0169, 0.0152, 0.0146, 0.0251, 0.0217, 0.0276, 0.0217, 0.0249,\n",
      "        0.0180, 0.0283, 0.0256, 0.0237, 0.0281, 0.0222, 0.0228, 0.0278, 0.0259,\n",
      "        0.0286, 0.0276, 0.0200, 0.0233, 0.0148], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0298, 0.0299], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[0.1681, 0.0367, 0.0000],\n",
      "        [0.1467, 0.0250, 0.0000],\n",
      "        [0.0984, 0.0490, 0.0000],\n",
      "        [0.1557, 0.0423, 0.0000],\n",
      "        [0.1063, 0.0489, 0.0000],\n",
      "        [0.1371, 0.0335, 0.0000],\n",
      "        [0.0989, 0.0500, 0.0000],\n",
      "        [0.1258, 0.0209, 0.0000],\n",
      "        [0.1642, 0.0255, 0.0000],\n",
      "        [0.1287, 0.0414, 0.0000],\n",
      "        [0.0900, 0.0502, 0.0000],\n",
      "        [0.0703, 0.0320, 0.0000],\n",
      "        [0.0580, 0.0074, 0.0000],\n",
      "        [0.1248, 0.0473, 0.0000],\n",
      "        [0.0936, 0.0372, 0.0000],\n",
      "        [0.1517, 0.0196, 0.0000],\n",
      "        [0.1394, 0.0349, 0.0000],\n",
      "        [0.1522, 0.0393, 0.0000],\n",
      "        [0.0764, 0.0046, 0.0000],\n",
      "        [0.1313, 0.0276, 0.0000],\n",
      "        [0.1680, 0.0462, 0.0000],\n",
      "        [0.1397, 0.0239, 0.0000],\n",
      "        [0.1356, 0.0379, 0.0000],\n",
      "        [0.0982, 0.0471, 0.0000],\n",
      "        [0.0969, 0.0546, 0.0000],\n",
      "        [0.1526, 0.0470, 0.0000],\n",
      "        [0.1403, 0.0339, 0.0000],\n",
      "        [0.1632, 0.0411, 0.0000],\n",
      "        [0.1423, 0.0355, 0.0000],\n",
      "        [0.1186, 0.0290, 0.0000],\n",
      "        [0.1348, 0.0280, 0.0000],\n",
      "        [0.0937, 0.0120, 0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.7135, 1.5223, 1.4641, 1.4319, 1.3918, 1.4779, 1.3588, 1.5605, 1.6044,\n",
      "         1.3654, 1.0438, 0.9622, 0.8827, 1.4592, 1.3820, 1.6399, 1.3529, 1.5372,\n",
      "         1.0566, 1.6140, 1.5101, 1.5562, 1.6896, 1.4214, 1.3437, 1.6174, 1.5314,\n",
      "         1.7917, 1.6400, 1.2227, 1.4126, 0.8511],\n",
      "        [1.7193, 1.5211, 1.4156, 1.3442, 1.3363, 1.4838, 1.3519, 1.5927, 1.6031,\n",
      "         1.4160, 0.9914, 0.8867, 0.8911, 1.4844, 1.3029, 1.6562, 1.3101, 1.4858,\n",
      "         1.1171, 1.6229, 1.5069, 1.4396, 1.7326, 1.4054, 1.2946, 1.6034, 1.4429,\n",
      "         1.6521, 1.6126, 1.1841, 1.3743, 0.9342]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0288, 0.0246, 0.0239, 0.0233, 0.0229, 0.0257, 0.0241, 0.0267, 0.0282,\n",
      "        0.0246, 0.0172, 0.0155, 0.0149, 0.0256, 0.0222, 0.0281, 0.0222, 0.0253,\n",
      "        0.0184, 0.0289, 0.0261, 0.0242, 0.0286, 0.0226, 0.0233, 0.0283, 0.0264,\n",
      "        0.0291, 0.0282, 0.0204, 0.0238, 0.0151], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0303, 0.0305], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.2038, -0.0132,  0.0000],\n",
      "        [ 0.1625, -0.0254,  0.0000],\n",
      "        [ 0.1856, -0.0408,  0.0000],\n",
      "        [ 0.1648, -0.0398,  0.0000],\n",
      "        [ 0.1685, -0.0276,  0.0000],\n",
      "        [ 0.1748, -0.0204,  0.0000],\n",
      "        [ 0.1468, -0.0429,  0.0000],\n",
      "        [ 0.1914, -0.0172,  0.0000],\n",
      "        [ 0.1947, -0.0301,  0.0000],\n",
      "        [ 0.1674, -0.0126,  0.0000],\n",
      "        [ 0.1251, -0.0033,  0.0000],\n",
      "        [ 0.1338, -0.0241,  0.0000],\n",
      "        [ 0.1073, -0.0194,  0.0000],\n",
      "        [ 0.1801, -0.0406,  0.0000],\n",
      "        [ 0.1458, -0.0226,  0.0000],\n",
      "        [ 0.1671, -0.0218,  0.0000],\n",
      "        [ 0.1433, -0.0338,  0.0000],\n",
      "        [ 0.1675, -0.0319,  0.0000],\n",
      "        [ 0.1398,  0.0091,  0.0000],\n",
      "        [ 0.1855, -0.0335,  0.0000],\n",
      "        [ 0.2011, -0.0215,  0.0000],\n",
      "        [ 0.1741, -0.0153,  0.0000],\n",
      "        [ 0.2008, -0.0098,  0.0000],\n",
      "        [ 0.1269, -0.0455,  0.0000],\n",
      "        [ 0.1453, -0.0220,  0.0000],\n",
      "        [ 0.1697, -0.0243,  0.0000],\n",
      "        [ 0.1827, -0.0217,  0.0000],\n",
      "        [ 0.1971, -0.0400,  0.0000],\n",
      "        [ 0.1614, -0.0216,  0.0000],\n",
      "        [ 0.1663,  0.0021,  0.0000],\n",
      "        [ 0.1609, -0.0288,  0.0000],\n",
      "        [ 0.0813, -0.0092,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.7829, 1.5849, 1.5250, 1.4924, 1.4480, 1.5368, 1.4142, 1.6232, 1.6701,\n",
      "         1.4209, 1.0874, 1.0042, 0.9208, 1.5193, 1.4373, 1.7085, 1.4076, 1.6013,\n",
      "         1.1021, 1.6795, 1.5721, 1.6208, 1.7591, 1.4793, 1.3997, 1.6834, 1.5937,\n",
      "         1.8648, 1.7067, 1.2748, 1.4693, 0.8878],\n",
      "        [1.7889, 1.5834, 1.4745, 1.4011, 1.3903, 1.5429, 1.4074, 1.6562, 1.6682,\n",
      "         1.4733, 1.0329, 0.9255, 0.9295, 1.5453, 1.3551, 1.7253, 1.3631, 1.5470,\n",
      "         1.1650, 1.6885, 1.5684, 1.4994, 1.8037, 1.4630, 1.3483, 1.6683, 1.5014,\n",
      "         1.7194, 1.6782, 1.2345, 1.4292, 0.9736]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0293, 0.0251, 0.0244, 0.0238, 0.0233, 0.0261, 0.0246, 0.0272, 0.0288,\n",
      "        0.0250, 0.0176, 0.0159, 0.0152, 0.0261, 0.0226, 0.0287, 0.0226, 0.0258,\n",
      "        0.0189, 0.0294, 0.0266, 0.0247, 0.0292, 0.0230, 0.0237, 0.0288, 0.0269,\n",
      "        0.0297, 0.0287, 0.0209, 0.0242, 0.0154], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0309, 0.0311], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1520, -0.0773,  0.0000],\n",
      "        [ 0.1344, -0.0401,  0.0000],\n",
      "        [ 0.1263, -0.0231,  0.0000],\n",
      "        [ 0.1363, -0.0362,  0.0000],\n",
      "        [ 0.1268, -0.0486,  0.0000],\n",
      "        [ 0.1096, -0.0457,  0.0000],\n",
      "        [ 0.0974, -0.0412,  0.0000],\n",
      "        [ 0.1326, -0.0329,  0.0000],\n",
      "        [ 0.1708, -0.0366,  0.0000],\n",
      "        [ 0.1057, -0.0447,  0.0000],\n",
      "        [ 0.0855, -0.0317,  0.0000],\n",
      "        [ 0.0424, -0.0395,  0.0000],\n",
      "        [ 0.0761, -0.0218,  0.0000],\n",
      "        [ 0.1329, -0.0203,  0.0000],\n",
      "        [ 0.0975, -0.0476,  0.0000],\n",
      "        [ 0.1287, -0.0644,  0.0000],\n",
      "        [ 0.1211, -0.0482,  0.0000],\n",
      "        [ 0.1292, -0.0332,  0.0000],\n",
      "        [ 0.0913, -0.0314,  0.0000],\n",
      "        [ 0.1472, -0.0397,  0.0000],\n",
      "        [ 0.1144, -0.0286,  0.0000],\n",
      "        [ 0.1207, -0.0679,  0.0000],\n",
      "        [ 0.1491, -0.0457,  0.0000],\n",
      "        [ 0.1233, -0.0603,  0.0000],\n",
      "        [ 0.0882, -0.0262,  0.0000],\n",
      "        [ 0.1348, -0.0361,  0.0000],\n",
      "        [ 0.1297, -0.0479,  0.0000],\n",
      "        [ 0.1324, -0.0549,  0.0000],\n",
      "        [ 0.1043, -0.0529,  0.0000],\n",
      "        [ 0.1039, -0.0144,  0.0000],\n",
      "        [ 0.1164, -0.0402,  0.0000],\n",
      "        [ 0.0715, -0.0407,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.8569, 1.6500, 1.5870, 1.5538, 1.5069, 1.5991, 1.4726, 1.6898, 1.7380,\n",
      "         1.4802, 1.1319, 1.0459, 0.9601, 1.5808, 1.4964, 1.7781, 1.4648, 1.6653,\n",
      "         1.1476, 1.7471, 1.6367, 1.6867, 1.8311, 1.5405, 1.4552, 1.7515, 1.6594,\n",
      "         1.9409, 1.7769, 1.3271, 1.5285, 0.9245],\n",
      "        [1.8627, 1.6481, 1.5348, 1.4587, 1.4470, 1.6064, 1.4652, 1.7241, 1.7353,\n",
      "         1.5343, 1.0751, 0.9639, 0.9682, 1.6075, 1.4108, 1.7957, 1.4191, 1.6091,\n",
      "         1.2127, 1.7563, 1.6327, 1.5605, 1.8773, 1.5234, 1.4027, 1.7357, 1.5633,\n",
      "         1.7902, 1.7473, 1.2853, 1.4871, 1.0129]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0299, 0.0256, 0.0249, 0.0243, 0.0238, 0.0266, 0.0251, 0.0277, 0.0293,\n",
      "        0.0255, 0.0179, 0.0163, 0.0156, 0.0266, 0.0231, 0.0292, 0.0230, 0.0262,\n",
      "        0.0193, 0.0299, 0.0271, 0.0252, 0.0298, 0.0235, 0.0242, 0.0293, 0.0274,\n",
      "        0.0303, 0.0293, 0.0213, 0.0247, 0.0157], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0315, 0.0317], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[0.0817, 0.0456, 0.0000],\n",
      "        [0.0716, 0.0379, 0.0000],\n",
      "        [0.0401, 0.0401, 0.0000],\n",
      "        [0.0673, 0.0304, 0.0000],\n",
      "        [0.0628, 0.0574, 0.0000],\n",
      "        [0.0752, 0.0193, 0.0000],\n",
      "        [0.0425, 0.0520, 0.0000],\n",
      "        [0.1015, 0.0337, 0.0000],\n",
      "        [0.0861, 0.0472, 0.0000],\n",
      "        [0.0725, 0.0448, 0.0000],\n",
      "        [0.0455, 0.0494, 0.0000],\n",
      "        [0.0816, 0.0208, 0.0000],\n",
      "        [0.0391, 0.0167, 0.0000],\n",
      "        [0.0633, 0.0217, 0.0000],\n",
      "        [0.0533, 0.0109, 0.0000],\n",
      "        [0.0833, 0.0157, 0.0000],\n",
      "        [0.0877, 0.0440, 0.0000],\n",
      "        [0.0752, 0.0276, 0.0000],\n",
      "        [0.0655, 0.0310, 0.0000],\n",
      "        [0.0866, 0.0418, 0.0000],\n",
      "        [0.0802, 0.0239, 0.0000],\n",
      "        [0.0767, 0.0569, 0.0000],\n",
      "        [0.0900, 0.0422, 0.0000],\n",
      "        [0.0440, 0.0398, 0.0000],\n",
      "        [0.0611, 0.0229, 0.0000],\n",
      "        [0.0638, 0.0411, 0.0000],\n",
      "        [0.1080, 0.0091, 0.0000],\n",
      "        [0.0861, 0.0614, 0.0000],\n",
      "        [0.0840, 0.0324, 0.0000],\n",
      "        [0.0552, 0.0004, 0.0000],\n",
      "        [0.0809, 0.0288, 0.0000],\n",
      "        [0.0119, 0.0074, 0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.9333, 1.7173, 1.6529, 1.6154, 1.5696, 1.6682, 1.5357, 1.7576, 1.8104,\n",
      "         1.5422, 1.1762, 1.0877, 0.9994, 1.6481, 1.5591, 1.8500, 1.5256, 1.7337,\n",
      "         1.1963, 1.8188, 1.7046, 1.7552, 1.9057, 1.6040, 1.5201, 1.8252, 1.7267,\n",
      "         2.0205, 1.8504, 1.3802, 1.5953, 0.9616],\n",
      "        [1.9388, 1.7151, 1.5992, 1.5153, 1.5066, 1.6751, 1.5280, 1.7935, 1.8070,\n",
      "         1.5972, 1.1162, 1.0032, 1.0087, 1.6761, 1.4708, 1.8676, 1.4774, 1.6736,\n",
      "         1.2640, 1.8277, 1.6999, 1.6232, 1.9532, 1.5863, 1.4663, 1.8080, 1.6262,\n",
      "         1.8634, 1.8194, 1.3375, 1.5533, 1.0528]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0305, 0.0261, 0.0255, 0.0247, 0.0243, 0.0272, 0.0256, 0.0282, 0.0299,\n",
      "        0.0260, 0.0182, 0.0166, 0.0159, 0.0272, 0.0236, 0.0298, 0.0235, 0.0267,\n",
      "        0.0197, 0.0305, 0.0277, 0.0256, 0.0303, 0.0240, 0.0248, 0.0300, 0.0279,\n",
      "        0.0309, 0.0299, 0.0217, 0.0253, 0.0160], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0322, 0.0323], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 1.3978e-01,  1.6847e-02,  0.0000e+00],\n",
      "        [ 1.6675e-01,  1.9936e-02,  0.0000e+00],\n",
      "        [ 1.7978e-01,  3.6343e-03,  0.0000e+00],\n",
      "        [ 1.3899e-01,  1.8113e-02,  0.0000e+00],\n",
      "        [ 1.7034e-01, -1.9585e-02,  0.0000e+00],\n",
      "        [ 1.6089e-01,  1.9069e-02,  0.0000e+00],\n",
      "        [ 1.3535e-01,  1.1981e-02,  0.0000e+00],\n",
      "        [ 1.5745e-01,  1.1270e-03,  0.0000e+00],\n",
      "        [ 1.4998e-01,  1.3960e-04,  0.0000e+00],\n",
      "        [ 1.4963e-01,  4.6714e-03,  0.0000e+00],\n",
      "        [ 1.1144e-01, -7.7750e-03,  0.0000e+00],\n",
      "        [ 3.5691e-02,  2.7972e-03,  0.0000e+00],\n",
      "        [ 7.7487e-02,  9.0430e-04,  0.0000e+00],\n",
      "        [ 1.4282e-01, -3.0672e-03,  0.0000e+00],\n",
      "        [ 1.3833e-01,  3.5289e-02,  0.0000e+00],\n",
      "        [ 1.4151e-01, -7.9062e-03,  0.0000e+00],\n",
      "        [ 1.3525e-01,  5.0724e-03,  0.0000e+00],\n",
      "        [ 1.4817e-01, -2.7963e-03,  0.0000e+00],\n",
      "        [ 1.1642e-01,  1.7462e-02,  0.0000e+00],\n",
      "        [ 1.6557e-01, -1.4038e-03,  0.0000e+00],\n",
      "        [ 1.7700e-01,  1.9082e-02,  0.0000e+00],\n",
      "        [ 1.4961e-01,  1.0585e-02,  0.0000e+00],\n",
      "        [ 1.7913e-01, -1.2794e-02,  0.0000e+00],\n",
      "        [ 1.5227e-01, -2.3593e-02,  0.0000e+00],\n",
      "        [ 1.3511e-01, -1.0964e-02,  0.0000e+00],\n",
      "        [ 1.8316e-01,  1.1981e-02,  0.0000e+00],\n",
      "        [ 1.5682e-01,  7.4443e-03,  0.0000e+00],\n",
      "        [ 1.5676e-01,  2.7800e-02,  0.0000e+00],\n",
      "        [ 1.7013e-01,  7.4634e-03,  0.0000e+00],\n",
      "        [ 1.1820e-01,  2.0977e-02,  0.0000e+00],\n",
      "        [ 1.3387e-01, -5.1133e-03,  0.0000e+00],\n",
      "        [ 9.8840e-02,  3.4597e-02,  0.0000e+00]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.0125, 1.7877, 1.7207, 1.6840, 1.6342, 1.7348, 1.5989, 1.8318, 1.8862,\n",
      "         1.6058, 1.2256, 1.1300, 1.0397, 1.7154, 1.6213, 1.9271, 1.5887, 1.8064,\n",
      "         1.2442, 1.8944, 1.7743, 1.8277, 1.9838, 1.6699, 1.5818, 1.8991, 1.7987,\n",
      "         2.1031, 1.9257, 1.4375, 1.6582, 1.0024],\n",
      "        [2.0180, 1.7852, 1.6641, 1.5808, 1.5688, 1.7419, 1.5902, 1.8686, 1.8817,\n",
      "         1.6624, 1.1639, 1.0425, 1.0488, 1.7432, 1.5285, 1.9456, 1.5383, 1.7441,\n",
      "         1.3143, 1.9030, 1.7691, 1.6913, 2.0334, 1.6513, 1.5244, 1.8810, 1.6942,\n",
      "         1.9398, 1.8930, 1.3928, 1.6134, 1.0971]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0311, 0.0266, 0.0260, 0.0252, 0.0248, 0.0277, 0.0261, 0.0288, 0.0305,\n",
      "        0.0265, 0.0186, 0.0169, 0.0162, 0.0277, 0.0240, 0.0304, 0.0240, 0.0273,\n",
      "        0.0201, 0.0311, 0.0282, 0.0262, 0.0309, 0.0245, 0.0253, 0.0305, 0.0285,\n",
      "        0.0315, 0.0304, 0.0222, 0.0258, 0.0164], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0328, 0.0329], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1603,  0.0107,  0.0000],\n",
      "        [ 0.1250, -0.0035,  0.0000],\n",
      "        [ 0.1678, -0.0048,  0.0000],\n",
      "        [ 0.1610,  0.0047,  0.0000],\n",
      "        [ 0.1661,  0.0085,  0.0000],\n",
      "        [ 0.1670,  0.0172,  0.0000],\n",
      "        [ 0.1712,  0.0231,  0.0000],\n",
      "        [ 0.1348,  0.0166,  0.0000],\n",
      "        [ 0.1745,  0.0043,  0.0000],\n",
      "        [ 0.1457,  0.0181,  0.0000],\n",
      "        [ 0.1243,  0.0088,  0.0000],\n",
      "        [ 0.0914,  0.0118,  0.0000],\n",
      "        [ 0.0582,  0.0117,  0.0000],\n",
      "        [ 0.1606,  0.0186,  0.0000],\n",
      "        [ 0.1197,  0.0020,  0.0000],\n",
      "        [ 0.1578,  0.0124,  0.0000],\n",
      "        [ 0.1300,  0.0028,  0.0000],\n",
      "        [ 0.1433, -0.0054,  0.0000],\n",
      "        [ 0.1113,  0.0143,  0.0000],\n",
      "        [ 0.1918, -0.0011,  0.0000],\n",
      "        [ 0.1498,  0.0108,  0.0000],\n",
      "        [ 0.1464, -0.0135,  0.0000],\n",
      "        [ 0.1581,  0.0207,  0.0000],\n",
      "        [ 0.1654, -0.0098,  0.0000],\n",
      "        [ 0.1447,  0.0342,  0.0000],\n",
      "        [ 0.1917,  0.0124,  0.0000],\n",
      "        [ 0.1440,  0.0404,  0.0000],\n",
      "        [ 0.1918,  0.0181,  0.0000],\n",
      "        [ 0.1879,  0.0043,  0.0000],\n",
      "        [ 0.0831,  0.0100,  0.0000],\n",
      "        [ 0.1731, -0.0006,  0.0000],\n",
      "        [ 0.0829,  0.0260,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.0955, 1.8606, 1.7908, 1.7520, 1.7010, 1.8053, 1.6645, 1.9070, 1.9632,\n",
      "         1.6720, 1.2770, 1.1781, 1.0819, 1.7854, 1.6886, 2.0063, 1.6540, 1.8803,\n",
      "         1.2950, 1.9715, 1.8474, 1.9026, 2.0658, 1.7383, 1.6436, 1.9769, 1.8722,\n",
      "         2.1891, 2.0045, 1.4955, 1.7267, 1.0444],\n",
      "        [2.1006, 1.8577, 1.7326, 1.6434, 1.6331, 1.8125, 1.6563, 1.9452, 1.9578,\n",
      "         1.7304, 1.2120, 1.0873, 1.0925, 1.8146, 1.5927, 2.0246, 1.6015, 1.8154,\n",
      "         1.3687, 1.9793, 1.8419, 1.7604, 2.1166, 1.7193, 1.5855, 1.9578, 1.7636,\n",
      "         2.0190, 1.9706, 1.4497, 1.6817, 1.1413]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0318, 0.0271, 0.0265, 0.0257, 0.0253, 0.0283, 0.0267, 0.0294, 0.0311,\n",
      "        0.0271, 0.0190, 0.0173, 0.0165, 0.0283, 0.0246, 0.0310, 0.0244, 0.0279,\n",
      "        0.0205, 0.0317, 0.0288, 0.0267, 0.0316, 0.0250, 0.0257, 0.0311, 0.0291,\n",
      "        0.0321, 0.0310, 0.0226, 0.0263, 0.0167], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0334, 0.0335], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1603,  0.0159,  0.0000],\n",
      "        [ 0.2006,  0.0169,  0.0000],\n",
      "        [ 0.1967,  0.0225,  0.0000],\n",
      "        [ 0.1850,  0.0188,  0.0000],\n",
      "        [ 0.1547,  0.0282,  0.0000],\n",
      "        [ 0.2092, -0.0025,  0.0000],\n",
      "        [ 0.1903, -0.0025,  0.0000],\n",
      "        [ 0.1916,  0.0024,  0.0000],\n",
      "        [ 0.2334,  0.0125,  0.0000],\n",
      "        [ 0.1656,  0.0024,  0.0000],\n",
      "        [ 0.1026, -0.0025,  0.0000],\n",
      "        [ 0.1476,  0.0180,  0.0000],\n",
      "        [ 0.0689,  0.0255,  0.0000],\n",
      "        [ 0.2044,  0.0111,  0.0000],\n",
      "        [ 0.2001, -0.0039,  0.0000],\n",
      "        [ 0.2009, -0.0063,  0.0000],\n",
      "        [ 0.1521,  0.0211,  0.0000],\n",
      "        [ 0.1731,  0.0115,  0.0000],\n",
      "        [ 0.1185, -0.0112,  0.0000],\n",
      "        [ 0.2327,  0.0045,  0.0000],\n",
      "        [ 0.2302, -0.0052,  0.0000],\n",
      "        [ 0.1604,  0.0029,  0.0000],\n",
      "        [ 0.2162,  0.0216,  0.0000],\n",
      "        [ 0.1717,  0.0225,  0.0000],\n",
      "        [ 0.2122,  0.0025,  0.0000],\n",
      "        [ 0.2375, -0.0173,  0.0000],\n",
      "        [ 0.2180,  0.0103,  0.0000],\n",
      "        [ 0.2535,  0.0121,  0.0000],\n",
      "        [ 0.2325, -0.0397,  0.0000],\n",
      "        [ 0.1530,  0.0054,  0.0000],\n",
      "        [ 0.1837,  0.0133,  0.0000],\n",
      "        [ 0.1095, -0.0127,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.1817, 1.9368, 1.8631, 1.8253, 1.7718, 1.8802, 1.7344, 1.9857, 2.0438,\n",
      "         1.7421, 1.3312, 1.2259, 1.1257, 1.8586, 1.7577, 2.0881, 1.7212, 1.9578,\n",
      "         1.3471, 2.0528, 1.9231, 1.9813, 2.1501, 1.8085, 1.7133, 2.0588, 1.9485,\n",
      "         2.2790, 2.0875, 1.5567, 1.7959, 1.0871],\n",
      "        [2.1868, 1.9333, 1.8025, 1.7124, 1.7012, 1.8876, 1.7248, 2.0251, 2.0381,\n",
      "         1.8020, 1.2631, 1.1319, 1.1358, 1.8885, 1.6585, 2.1070, 1.6669, 1.8903,\n",
      "         1.4228, 2.0612, 1.9174, 1.8335, 2.2027, 1.7887, 1.6521, 2.0385, 1.8354,\n",
      "         2.1019, 2.0523, 1.5080, 1.7491, 1.1880]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0324, 0.0277, 0.0270, 0.0263, 0.0258, 0.0288, 0.0272, 0.0300, 0.0317,\n",
      "        0.0276, 0.0195, 0.0177, 0.0168, 0.0288, 0.0251, 0.0316, 0.0249, 0.0284,\n",
      "        0.0209, 0.0324, 0.0293, 0.0273, 0.0322, 0.0255, 0.0263, 0.0318, 0.0297,\n",
      "        0.0327, 0.0317, 0.0230, 0.0268, 0.0171], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0341, 0.0342], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1386, -0.0314,  0.0000],\n",
      "        [ 0.1098, -0.0142,  0.0000],\n",
      "        [ 0.0812,  0.0159,  0.0000],\n",
      "        [ 0.0801, -0.0104,  0.0000],\n",
      "        [ 0.0970,  0.0172,  0.0000],\n",
      "        [ 0.1002, -0.0177,  0.0000],\n",
      "        [ 0.1044,  0.0178,  0.0000],\n",
      "        [ 0.1209, -0.0073,  0.0000],\n",
      "        [ 0.1239,  0.0274,  0.0000],\n",
      "        [ 0.1183,  0.0293,  0.0000],\n",
      "        [ 0.0476,  0.0080,  0.0000],\n",
      "        [ 0.0367, -0.0071,  0.0000],\n",
      "        [ 0.0370, -0.0006,  0.0000],\n",
      "        [ 0.1078,  0.0104,  0.0000],\n",
      "        [ 0.0939, -0.0051,  0.0000],\n",
      "        [ 0.0818,  0.0071,  0.0000],\n",
      "        [ 0.1043, -0.0062,  0.0000],\n",
      "        [ 0.1171,  0.0088,  0.0000],\n",
      "        [ 0.1249, -0.0165,  0.0000],\n",
      "        [ 0.1141,  0.0364,  0.0000],\n",
      "        [ 0.1048,  0.0113,  0.0000],\n",
      "        [ 0.0839, -0.0159,  0.0000],\n",
      "        [ 0.1102,  0.0118,  0.0000],\n",
      "        [ 0.1266,  0.0111,  0.0000],\n",
      "        [ 0.0824,  0.0121,  0.0000],\n",
      "        [ 0.1236,  0.0215,  0.0000],\n",
      "        [ 0.0950,  0.0026,  0.0000],\n",
      "        [ 0.1319, -0.0125,  0.0000],\n",
      "        [ 0.0955,  0.0325,  0.0000],\n",
      "        [ 0.0726, -0.0157,  0.0000],\n",
      "        [ 0.0717, -0.0016,  0.0000],\n",
      "        [ 0.0872, -0.0221,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.2710, 2.0159, 1.9399, 1.8990, 1.8427, 1.9575, 1.8044, 2.0649, 2.1267,\n",
      "         1.8123, 1.3835, 1.2773, 1.1747, 1.9351, 1.8292, 2.1739, 1.7914, 2.0347,\n",
      "         1.4060, 2.1351, 2.0017, 2.0609, 2.2376, 1.8834, 1.7834, 2.1418, 2.0287,\n",
      "         2.3722, 2.1717, 1.6218, 1.8704, 1.1312],\n",
      "        [2.2758, 2.0119, 1.8757, 1.7820, 1.7694, 1.9641, 1.7941, 2.1066, 2.1202,\n",
      "         1.8736, 1.3148, 1.1787, 1.1834, 1.9655, 1.7254, 2.1937, 1.7350, 1.9647,\n",
      "         1.4840, 2.1440, 1.9953, 1.9076, 2.2928, 1.8624, 1.7181, 2.1197, 1.9107,\n",
      "         2.1877, 2.1350, 1.5707, 1.8202, 1.2360]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0331, 0.0282, 0.0276, 0.0268, 0.0263, 0.0294, 0.0277, 0.0306, 0.0323,\n",
      "        0.0281, 0.0198, 0.0180, 0.0172, 0.0294, 0.0256, 0.0322, 0.0254, 0.0289,\n",
      "        0.0214, 0.0329, 0.0299, 0.0278, 0.0328, 0.0260, 0.0268, 0.0323, 0.0302,\n",
      "        0.0334, 0.0323, 0.0235, 0.0274, 0.0174], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0347, 0.0348], grad_fn=<MeanBackward1>)\n",
      "Epoch 8/10, Accuracy: 0.4938\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.2084, -0.0087,  0.0000],\n",
      "        [ 0.1967,  0.0126,  0.0000],\n",
      "        [ 0.1898, -0.0050,  0.0000],\n",
      "        [ 0.1634, -0.0042,  0.0000],\n",
      "        [ 0.1876, -0.0174,  0.0000],\n",
      "        [ 0.1884,  0.0114,  0.0000],\n",
      "        [ 0.1867, -0.0013,  0.0000],\n",
      "        [ 0.2234,  0.0038,  0.0000],\n",
      "        [ 0.2229,  0.0057,  0.0000],\n",
      "        [ 0.2486, -0.0056,  0.0000],\n",
      "        [ 0.1154, -0.0045,  0.0000],\n",
      "        [ 0.1279, -0.0088,  0.0000],\n",
      "        [ 0.1633, -0.0019,  0.0000],\n",
      "        [ 0.1944,  0.0115,  0.0000],\n",
      "        [ 0.1922,  0.0132,  0.0000],\n",
      "        [ 0.2256, -0.0229,  0.0000],\n",
      "        [ 0.1979,  0.0039,  0.0000],\n",
      "        [ 0.2038,  0.0185,  0.0000],\n",
      "        [ 0.1425, -0.0036,  0.0000],\n",
      "        [ 0.2359, -0.0061,  0.0000],\n",
      "        [ 0.1988,  0.0268,  0.0000],\n",
      "        [ 0.2054,  0.0013,  0.0000],\n",
      "        [ 0.2263, -0.0083,  0.0000],\n",
      "        [ 0.2205,  0.0100,  0.0000],\n",
      "        [ 0.1834, -0.0236,  0.0000],\n",
      "        [ 0.1982, -0.0121,  0.0000],\n",
      "        [ 0.1833,  0.0127,  0.0000],\n",
      "        [ 0.2684, -0.0315,  0.0000],\n",
      "        [ 0.2131,  0.0089,  0.0000],\n",
      "        [ 0.1573,  0.0210,  0.0000],\n",
      "        [ 0.1907,  0.0103,  0.0000],\n",
      "        [ 0.1356, -0.0059,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.3640, 2.0983, 2.0186, 1.9793, 1.9208, 2.0361, 1.8783, 2.1508, 2.2158,\n",
      "         1.8880, 1.4424, 1.3270, 1.2223, 2.0136, 1.9041, 2.2625, 1.8651, 2.1202,\n",
      "         1.4610, 2.2236, 2.0838, 2.1456, 2.3294, 1.9598, 1.8559, 2.2305, 2.1121,\n",
      "         2.4700, 2.2609, 1.6874, 1.9450, 1.1793],\n",
      "        [2.3685, 2.0938, 1.9522, 1.8573, 1.8444, 2.0437, 1.8675, 2.1938, 2.2083,\n",
      "         1.9512, 1.3697, 1.2246, 1.2316, 2.0450, 1.7957, 2.2829, 1.8059, 2.0474,\n",
      "         1.5415, 2.2324, 2.0768, 1.9858, 2.3864, 1.9379, 1.7890, 2.2070, 1.9890,\n",
      "         2.2776, 2.2227, 1.6342, 1.8934, 1.2876]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0337, 0.0288, 0.0282, 0.0274, 0.0269, 0.0299, 0.0283, 0.0312, 0.0330,\n",
      "        0.0287, 0.0203, 0.0184, 0.0176, 0.0300, 0.0261, 0.0329, 0.0259, 0.0295,\n",
      "        0.0217, 0.0336, 0.0305, 0.0284, 0.0335, 0.0265, 0.0273, 0.0330, 0.0308,\n",
      "        0.0341, 0.0329, 0.0240, 0.0279, 0.0178], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0354, 0.0355], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.2192,  0.0243,  0.0000],\n",
      "        [ 0.1978,  0.0427,  0.0000],\n",
      "        [ 0.2078,  0.0174,  0.0000],\n",
      "        [ 0.1684,  0.0079,  0.0000],\n",
      "        [ 0.1807,  0.0182,  0.0000],\n",
      "        [ 0.2132,  0.0294,  0.0000],\n",
      "        [ 0.1986,  0.0245,  0.0000],\n",
      "        [ 0.2036,  0.0498,  0.0000],\n",
      "        [ 0.1923,  0.0358,  0.0000],\n",
      "        [ 0.1767,  0.0156,  0.0000],\n",
      "        [ 0.1482,  0.0147,  0.0000],\n",
      "        [ 0.1003,  0.0289,  0.0000],\n",
      "        [ 0.0972,  0.0127,  0.0000],\n",
      "        [ 0.1838,  0.0322,  0.0000],\n",
      "        [ 0.1940,  0.0223,  0.0000],\n",
      "        [ 0.1940,  0.0210,  0.0000],\n",
      "        [ 0.1657,  0.0234,  0.0000],\n",
      "        [ 0.1944,  0.0275,  0.0000],\n",
      "        [ 0.1602,  0.0372,  0.0000],\n",
      "        [ 0.2226,  0.0155,  0.0000],\n",
      "        [ 0.2068,  0.0221,  0.0000],\n",
      "        [ 0.2037,  0.0236,  0.0000],\n",
      "        [ 0.2120,  0.0538,  0.0000],\n",
      "        [ 0.2041,  0.0732,  0.0000],\n",
      "        [ 0.1842,  0.0123,  0.0000],\n",
      "        [ 0.2359,  0.0010,  0.0000],\n",
      "        [ 0.2138, -0.0039,  0.0000],\n",
      "        [ 0.2211,  0.0293,  0.0000],\n",
      "        [ 0.2170, -0.0028,  0.0000],\n",
      "        [ 0.1586,  0.0023,  0.0000],\n",
      "        [ 0.1705,  0.0227,  0.0000],\n",
      "        [ 0.1228,  0.0179,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.4609, 2.1840, 2.1022, 2.0584, 1.9994, 2.1207, 1.9573, 2.2385, 2.3071,\n",
      "         1.9668, 1.4997, 1.3804, 1.2708, 2.0968, 1.9827, 2.3551, 1.9426, 2.2073,\n",
      "         1.5213, 2.3150, 2.1694, 2.2332, 2.4245, 2.0395, 1.9337, 2.3220, 2.1982,\n",
      "         2.5706, 2.3540, 1.7558, 2.0260, 1.2279],\n",
      "        [2.4654, 2.1788, 2.0331, 1.9311, 1.9203, 2.1291, 1.9464, 2.2831, 2.2990,\n",
      "         2.0326, 1.4234, 1.2724, 1.2801, 2.1292, 1.8711, 2.3760, 1.8817, 2.1311,\n",
      "         1.6049, 2.3237, 2.1621, 2.0671, 2.4834, 2.0168, 1.8640, 2.2974, 2.0701,\n",
      "         2.3704, 2.3141, 1.7002, 1.9726, 1.3395]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0344, 0.0294, 0.0288, 0.0279, 0.0274, 0.0305, 0.0289, 0.0318, 0.0337,\n",
      "        0.0293, 0.0206, 0.0188, 0.0179, 0.0306, 0.0266, 0.0335, 0.0265, 0.0301,\n",
      "        0.0222, 0.0343, 0.0311, 0.0289, 0.0342, 0.0270, 0.0279, 0.0336, 0.0314,\n",
      "        0.0347, 0.0336, 0.0245, 0.0284, 0.0181], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0361, 0.0362], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.2011, -0.0571,  0.0000],\n",
      "        [ 0.1967, -0.0445,  0.0000],\n",
      "        [ 0.1856, -0.0446,  0.0000],\n",
      "        [ 0.1737, -0.0272,  0.0000],\n",
      "        [ 0.1469, -0.0452,  0.0000],\n",
      "        [ 0.1828, -0.0550,  0.0000],\n",
      "        [ 0.1786, -0.0555,  0.0000],\n",
      "        [ 0.2254, -0.0798,  0.0000],\n",
      "        [ 0.1947, -0.0343,  0.0000],\n",
      "        [ 0.1883, -0.0343,  0.0000],\n",
      "        [ 0.1402, -0.0530,  0.0000],\n",
      "        [ 0.1181, -0.0598,  0.0000],\n",
      "        [ 0.1166, -0.0514,  0.0000],\n",
      "        [ 0.1823, -0.0310,  0.0000],\n",
      "        [ 0.1735, -0.0437,  0.0000],\n",
      "        [ 0.2451, -0.0713,  0.0000],\n",
      "        [ 0.1430, -0.0454,  0.0000],\n",
      "        [ 0.1900, -0.0784,  0.0000],\n",
      "        [ 0.1656, -0.0569,  0.0000],\n",
      "        [ 0.2183, -0.0575,  0.0000],\n",
      "        [ 0.2116, -0.0431,  0.0000],\n",
      "        [ 0.1642, -0.0518,  0.0000],\n",
      "        [ 0.2639, -0.0641,  0.0000],\n",
      "        [ 0.1547, -0.0710,  0.0000],\n",
      "        [ 0.1521, -0.0521,  0.0000],\n",
      "        [ 0.2051, -0.0442,  0.0000],\n",
      "        [ 0.1898, -0.0351,  0.0000],\n",
      "        [ 0.1801, -0.0659,  0.0000],\n",
      "        [ 0.2331, -0.0473,  0.0000],\n",
      "        [ 0.1110, -0.0548,  0.0000],\n",
      "        [ 0.1927, -0.0367,  0.0000],\n",
      "        [ 0.1210, -0.0358,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.5608, 2.2732, 2.1868, 2.1439, 2.0799, 2.2052, 2.0360, 2.3276, 2.3998,\n",
      "         2.0445, 1.5621, 1.4411, 1.3255, 2.1816, 2.0618, 2.4510, 2.0200, 2.2954,\n",
      "         1.5859, 2.4080, 2.2572, 2.3249, 2.5227, 2.1227, 2.0093, 2.4144, 2.2869,\n",
      "         2.6738, 2.4487, 1.8286, 2.1073, 1.2785],\n",
      "        [2.5649, 2.2675, 2.1147, 2.0116, 1.9971, 2.2132, 2.0231, 2.3747, 2.3906,\n",
      "         2.1122, 1.4846, 1.3295, 1.3345, 2.2144, 1.9451, 2.4724, 1.9557, 2.2162,\n",
      "         1.6716, 2.4165, 2.2492, 2.1522, 2.5840, 2.0988, 1.9366, 2.3887, 2.1536,\n",
      "         2.4658, 2.4067, 1.7702, 2.0511, 1.3949]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0350, 0.0299, 0.0293, 0.0285, 0.0280, 0.0311, 0.0294, 0.0324, 0.0343,\n",
      "        0.0298, 0.0211, 0.0192, 0.0183, 0.0312, 0.0271, 0.0342, 0.0269, 0.0307,\n",
      "        0.0227, 0.0349, 0.0317, 0.0295, 0.0348, 0.0276, 0.0284, 0.0343, 0.0321,\n",
      "        0.0354, 0.0342, 0.0250, 0.0290, 0.0185], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0368, 0.0368], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1098,  0.0381,  0.0000],\n",
      "        [ 0.1062,  0.0229,  0.0000],\n",
      "        [ 0.0991,  0.0490,  0.0000],\n",
      "        [ 0.0844,  0.0118,  0.0000],\n",
      "        [ 0.0736,  0.0511,  0.0000],\n",
      "        [ 0.1438,  0.0615,  0.0000],\n",
      "        [ 0.0848,  0.0468,  0.0000],\n",
      "        [ 0.1379,  0.0345,  0.0000],\n",
      "        [ 0.1333,  0.0331,  0.0000],\n",
      "        [ 0.1383,  0.0321,  0.0000],\n",
      "        [ 0.0744,  0.0181,  0.0000],\n",
      "        [ 0.0504,  0.0214,  0.0000],\n",
      "        [ 0.0643, -0.0107,  0.0000],\n",
      "        [ 0.1274,  0.0234,  0.0000],\n",
      "        [ 0.1071,  0.0472,  0.0000],\n",
      "        [ 0.1215, -0.0048,  0.0000],\n",
      "        [ 0.1203,  0.0390,  0.0000],\n",
      "        [ 0.1003,  0.0269,  0.0000],\n",
      "        [ 0.0844,  0.0308,  0.0000],\n",
      "        [ 0.1525,  0.0423,  0.0000],\n",
      "        [ 0.1161,  0.0362,  0.0000],\n",
      "        [ 0.1349,  0.0410,  0.0000],\n",
      "        [ 0.1284,  0.0260,  0.0000],\n",
      "        [ 0.1337,  0.0296,  0.0000],\n",
      "        [ 0.0944,  0.0304,  0.0000],\n",
      "        [ 0.1307,  0.0480,  0.0000],\n",
      "        [ 0.1291,  0.0534,  0.0000],\n",
      "        [ 0.1351,  0.0611,  0.0000],\n",
      "        [ 0.1127,  0.0323,  0.0000],\n",
      "        [ 0.0498,  0.0240,  0.0000],\n",
      "        [ 0.1582,  0.0293,  0.0000],\n",
      "        [ 0.0685,  0.0213,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.6660, 2.3657, 2.2770, 2.2294, 2.1650, 2.2961, 2.1202, 2.4225, 2.4989,\n",
      "         2.1307, 1.6238, 1.4980, 1.3800, 2.2728, 2.1468, 2.5507, 2.1030, 2.3895,\n",
      "         1.6503, 2.5053, 2.3501, 2.4177, 2.6257, 2.2107, 2.0947, 2.5138, 2.3800,\n",
      "         2.7834, 2.5495, 1.9033, 2.1975, 1.3306],\n",
      "        [2.6696, 2.3593, 2.2016, 2.0911, 2.0788, 2.3044, 2.1068, 2.4707, 2.4881,\n",
      "         2.1996, 1.5425, 1.3818, 1.3895, 2.3063, 2.0250, 2.5728, 2.0362, 2.3060,\n",
      "         1.7399, 2.5138, 2.3412, 2.2380, 2.6892, 2.1855, 2.0195, 2.4861, 2.2403,\n",
      "         2.5667, 2.5056, 1.8429, 2.1390, 1.4503]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0358, 0.0305, 0.0299, 0.0290, 0.0285, 0.0317, 0.0300, 0.0331, 0.0350,\n",
      "        0.0304, 0.0215, 0.0196, 0.0187, 0.0319, 0.0277, 0.0349, 0.0275, 0.0313,\n",
      "        0.0232, 0.0356, 0.0324, 0.0301, 0.0355, 0.0281, 0.0290, 0.0349, 0.0327,\n",
      "        0.0361, 0.0349, 0.0255, 0.0297, 0.0189], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0375, 0.0375], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.2653,  0.0013,  0.0000],\n",
      "        [ 0.1983, -0.0253,  0.0000],\n",
      "        [ 0.2366, -0.0093,  0.0000],\n",
      "        [ 0.1819,  0.0460,  0.0000],\n",
      "        [ 0.1816, -0.0322,  0.0000],\n",
      "        [ 0.2043, -0.0358,  0.0000],\n",
      "        [ 0.2148, -0.0014,  0.0000],\n",
      "        [ 0.2338,  0.0245,  0.0000],\n",
      "        [ 0.2033, -0.0004,  0.0000],\n",
      "        [ 0.1961, -0.0023,  0.0000],\n",
      "        [ 0.1705, -0.0074,  0.0000],\n",
      "        [ 0.1510, -0.0261,  0.0000],\n",
      "        [ 0.1583,  0.0393,  0.0000],\n",
      "        [ 0.2096,  0.0279,  0.0000],\n",
      "        [ 0.2293, -0.0031,  0.0000],\n",
      "        [ 0.2165,  0.0147,  0.0000],\n",
      "        [ 0.1812,  0.0126,  0.0000],\n",
      "        [ 0.2122,  0.0263,  0.0000],\n",
      "        [ 0.1558, -0.0268,  0.0000],\n",
      "        [ 0.2486,  0.0072,  0.0000],\n",
      "        [ 0.1715, -0.0081,  0.0000],\n",
      "        [ 0.2006,  0.0055,  0.0000],\n",
      "        [ 0.2788, -0.0133,  0.0000],\n",
      "        [ 0.2184, -0.0137,  0.0000],\n",
      "        [ 0.1749, -0.0652,  0.0000],\n",
      "        [ 0.2114, -0.0110,  0.0000],\n",
      "        [ 0.1981, -0.0036,  0.0000],\n",
      "        [ 0.2338, -0.0396,  0.0000],\n",
      "        [ 0.2200, -0.0030,  0.0000],\n",
      "        [ 0.1446, -0.0250,  0.0000],\n",
      "        [ 0.1715,  0.0135,  0.0000],\n",
      "        [ 0.1346, -0.0114,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.7742, 2.4621, 2.3702, 2.3236, 2.2554, 2.3910, 2.2083, 2.5221, 2.6012,\n",
      "         2.2187, 1.6912, 1.5575, 1.4376, 2.3647, 2.2344, 2.6563, 2.1889, 2.4860,\n",
      "         1.7166, 2.6079, 2.4462, 2.5182, 2.7325, 2.3002, 2.1810, 2.6164, 2.4776,\n",
      "         2.8978, 2.6531, 1.9810, 2.2827, 1.3861],\n",
      "        [2.7775, 2.4551, 2.2922, 2.1793, 2.1657, 2.3990, 2.1940, 2.5715, 2.5900,\n",
      "         2.2901, 1.6060, 1.4371, 1.4474, 2.3992, 2.1082, 2.6784, 2.1194, 2.3994,\n",
      "         1.8101, 2.6159, 2.4369, 2.3309, 2.7982, 2.2743, 2.1030, 2.5869, 2.3326,\n",
      "         2.6719, 2.6074, 1.9176, 2.2224, 1.5100]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0364, 0.0311, 0.0306, 0.0297, 0.0291, 0.0324, 0.0306, 0.0337, 0.0357,\n",
      "        0.0310, 0.0219, 0.0200, 0.0191, 0.0325, 0.0282, 0.0356, 0.0280, 0.0319,\n",
      "        0.0236, 0.0363, 0.0330, 0.0307, 0.0362, 0.0287, 0.0296, 0.0356, 0.0333,\n",
      "        0.0369, 0.0356, 0.0260, 0.0302, 0.0193], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0383, 0.0383], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1978, -0.0243,  0.0000],\n",
      "        [ 0.1405,  0.0198,  0.0000],\n",
      "        [ 0.1703, -0.0117,  0.0000],\n",
      "        [ 0.1702, -0.0354,  0.0000],\n",
      "        [ 0.1557, -0.0322,  0.0000],\n",
      "        [ 0.1657,  0.0286,  0.0000],\n",
      "        [ 0.1427, -0.0111,  0.0000],\n",
      "        [ 0.1658, -0.0173,  0.0000],\n",
      "        [ 0.1703, -0.0346,  0.0000],\n",
      "        [ 0.1230, -0.0338,  0.0000],\n",
      "        [ 0.1219, -0.0139,  0.0000],\n",
      "        [ 0.1293, -0.0084,  0.0000],\n",
      "        [ 0.0696, -0.0169,  0.0000],\n",
      "        [ 0.1453, -0.0274,  0.0000],\n",
      "        [ 0.1363, -0.0018,  0.0000],\n",
      "        [ 0.1746, -0.0030,  0.0000],\n",
      "        [ 0.1024, -0.0287,  0.0000],\n",
      "        [ 0.1760, -0.0257,  0.0000],\n",
      "        [ 0.1567,  0.0086,  0.0000],\n",
      "        [ 0.1484, -0.0017,  0.0000],\n",
      "        [ 0.1889, -0.0178,  0.0000],\n",
      "        [ 0.1399, -0.0132,  0.0000],\n",
      "        [ 0.1945, -0.0183,  0.0000],\n",
      "        [ 0.1007,  0.0011,  0.0000],\n",
      "        [ 0.1131,  0.0136,  0.0000],\n",
      "        [ 0.1569,  0.0074,  0.0000],\n",
      "        [ 0.1463, -0.0148,  0.0000],\n",
      "        [ 0.1535,  0.0055,  0.0000],\n",
      "        [ 0.1697, -0.0121,  0.0000],\n",
      "        [ 0.1774, -0.0099,  0.0000],\n",
      "        [ 0.1634, -0.0113,  0.0000],\n",
      "        [ 0.0973,  0.0184,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.8879, 2.5627, 2.4667, 2.4152, 2.3462, 2.4852, 2.2970, 2.6261, 2.7076,\n",
      "         2.3091, 1.7601, 1.6219, 1.4944, 2.4623, 2.3258, 2.7636, 2.2798, 2.5858,\n",
      "         1.7894, 2.7151, 2.5453, 2.6207, 2.8439, 2.3932, 2.2682, 2.7217, 2.5786,\n",
      "         3.0147, 2.7610, 2.0641, 2.3780, 1.4431],\n",
      "        [2.8908, 2.5549, 2.3851, 2.2640, 2.2521, 2.4939, 2.2820, 2.6774, 2.6946,\n",
      "         2.3826, 1.6719, 1.4976, 1.5046, 2.4974, 2.1937, 2.7865, 2.2074, 2.4950,\n",
      "         1.8858, 2.7229, 2.5351, 2.4257, 2.9120, 2.3659, 2.1854, 2.6908, 2.4272,\n",
      "         2.7794, 2.7126, 1.9976, 2.3144, 1.5717]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0372, 0.0318, 0.0312, 0.0302, 0.0297, 0.0329, 0.0312, 0.0344, 0.0364,\n",
      "        0.0316, 0.0224, 0.0205, 0.0194, 0.0332, 0.0288, 0.0363, 0.0286, 0.0325,\n",
      "        0.0242, 0.0370, 0.0336, 0.0313, 0.0369, 0.0292, 0.0301, 0.0363, 0.0340,\n",
      "        0.0375, 0.0363, 0.0266, 0.0308, 0.0197], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0390, 0.0390], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.2303, -0.0419,  0.0000],\n",
      "        [ 0.1825, -0.0361,  0.0000],\n",
      "        [ 0.1581, -0.0157,  0.0000],\n",
      "        [ 0.1935, -0.0459,  0.0000],\n",
      "        [ 0.1530,  0.0100,  0.0000],\n",
      "        [ 0.1908, -0.0303,  0.0000],\n",
      "        [ 0.2045, -0.0012,  0.0000],\n",
      "        [ 0.1673, -0.0464,  0.0000],\n",
      "        [ 0.2036, -0.0545,  0.0000],\n",
      "        [ 0.1910, -0.0538,  0.0000],\n",
      "        [ 0.1248, -0.0305,  0.0000],\n",
      "        [ 0.1195, -0.0142,  0.0000],\n",
      "        [ 0.1178, -0.0662,  0.0000],\n",
      "        [ 0.1653, -0.0606,  0.0000],\n",
      "        [ 0.1551, -0.0288,  0.0000],\n",
      "        [ 0.2385, -0.0594,  0.0000],\n",
      "        [ 0.1570, -0.0413,  0.0000],\n",
      "        [ 0.1940, -0.0684,  0.0000],\n",
      "        [ 0.1565, -0.0139,  0.0000],\n",
      "        [ 0.2304, -0.0403,  0.0000],\n",
      "        [ 0.1924, -0.0242,  0.0000],\n",
      "        [ 0.1446, -0.0155,  0.0000],\n",
      "        [ 0.1841, -0.0414,  0.0000],\n",
      "        [ 0.1373, -0.0213,  0.0000],\n",
      "        [ 0.2017, -0.0268,  0.0000],\n",
      "        [ 0.2379, -0.0345,  0.0000],\n",
      "        [ 0.1696, -0.0176,  0.0000],\n",
      "        [ 0.2433, -0.0255,  0.0000],\n",
      "        [ 0.2171, -0.0245,  0.0000],\n",
      "        [ 0.1828, -0.0597,  0.0000],\n",
      "        [ 0.1904, -0.0320,  0.0000],\n",
      "        [ 0.1595, -0.0577,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[3.0061, 2.6670, 2.5657, 2.5149, 2.4405, 2.5878, 2.3896, 2.7331, 2.8182,\n",
      "         2.4024, 1.8340, 1.6907, 1.5564, 2.5610, 2.4195, 2.8761, 2.3714, 2.6930,\n",
      "         1.8617, 2.8243, 2.6490, 2.7281, 2.9609, 2.4909, 2.3601, 2.8325, 2.6837,\n",
      "         3.1372, 2.8732, 2.1476, 2.4742, 1.5017],\n",
      "        [3.0082, 2.6585, 2.4805, 2.3576, 2.3423, 2.5956, 2.3741, 2.7867, 2.8036,\n",
      "         2.4783, 1.7418, 1.5612, 1.5670, 2.5977, 2.2827, 2.8995, 2.2951, 2.5981,\n",
      "         1.9620, 2.8315, 2.6379, 2.5252, 3.0314, 2.4623, 2.2746, 2.7998, 2.5258,\n",
      "         2.8921, 2.8228, 2.0785, 2.4080, 1.6346]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0379, 0.0324, 0.0318, 0.0309, 0.0303, 0.0336, 0.0318, 0.0351, 0.0371,\n",
      "        0.0323, 0.0229, 0.0209, 0.0198, 0.0338, 0.0294, 0.0370, 0.0292, 0.0332,\n",
      "        0.0246, 0.0377, 0.0343, 0.0320, 0.0377, 0.0298, 0.0307, 0.0370, 0.0347,\n",
      "        0.0383, 0.0370, 0.0271, 0.0314, 0.0201], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0398, 0.0397], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0939,  0.0012,  0.0000],\n",
      "        [ 0.1055, -0.0101,  0.0000],\n",
      "        [ 0.1350, -0.0059,  0.0000],\n",
      "        [ 0.1208, -0.0102,  0.0000],\n",
      "        [ 0.0573, -0.0459,  0.0000],\n",
      "        [ 0.1298,  0.0201,  0.0000],\n",
      "        [ 0.1086,  0.0173,  0.0000],\n",
      "        [ 0.1211,  0.0243,  0.0000],\n",
      "        [ 0.1583, -0.0162,  0.0000],\n",
      "        [ 0.1189,  0.0298,  0.0000],\n",
      "        [ 0.0766, -0.0022,  0.0000],\n",
      "        [ 0.0631,  0.0387,  0.0000],\n",
      "        [ 0.0793,  0.0234,  0.0000],\n",
      "        [ 0.1379,  0.0203,  0.0000],\n",
      "        [ 0.1237, -0.0067,  0.0000],\n",
      "        [ 0.1030, -0.0027,  0.0000],\n",
      "        [ 0.0532, -0.0151,  0.0000],\n",
      "        [ 0.1011,  0.0206,  0.0000],\n",
      "        [ 0.0816,  0.0348,  0.0000],\n",
      "        [ 0.1535,  0.0042,  0.0000],\n",
      "        [ 0.1365,  0.0030,  0.0000],\n",
      "        [ 0.1196, -0.0178,  0.0000],\n",
      "        [ 0.1374,  0.0052,  0.0000],\n",
      "        [ 0.0723, -0.0156,  0.0000],\n",
      "        [ 0.0620,  0.0265,  0.0000],\n",
      "        [ 0.1406,  0.0069,  0.0000],\n",
      "        [ 0.1276,  0.0058,  0.0000],\n",
      "        [ 0.0986,  0.0152,  0.0000],\n",
      "        [ 0.1299, -0.0088,  0.0000],\n",
      "        [ 0.1027,  0.0094,  0.0000],\n",
      "        [ 0.1084,  0.0156,  0.0000],\n",
      "        [ 0.0994,  0.0204,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[3.1286, 2.7757, 2.6730, 2.6160, 2.5424, 2.6923, 2.4897, 2.8421, 2.9320,\n",
      "         2.5003, 1.9068, 1.7621, 1.6231, 2.6666, 2.5185, 2.9937, 2.4686, 2.8002,\n",
      "         1.9393, 2.9383, 2.7570, 2.8374, 3.0803, 2.5932, 2.4563, 2.9475, 2.7916,\n",
      "         3.2649, 2.9907, 2.2367, 2.5749, 1.5628],\n",
      "        [3.1305, 2.7662, 2.5839, 2.4522, 2.4409, 2.7013, 2.4731, 2.8975, 2.9167,\n",
      "         2.5789, 1.8110, 1.6259, 1.6328, 2.7041, 2.3761, 3.0175, 2.3897, 2.7019,\n",
      "         2.0424, 2.9459, 2.7455, 2.6266, 3.1535, 2.5632, 2.3678, 2.9130, 2.6267,\n",
      "         3.0095, 2.9382, 2.1643, 2.5065, 1.7006]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0387, 0.0330, 0.0325, 0.0314, 0.0309, 0.0343, 0.0325, 0.0358, 0.0378,\n",
      "        0.0329, 0.0233, 0.0214, 0.0203, 0.0345, 0.0300, 0.0377, 0.0298, 0.0338,\n",
      "        0.0252, 0.0384, 0.0350, 0.0326, 0.0384, 0.0304, 0.0313, 0.0377, 0.0353,\n",
      "        0.0391, 0.0378, 0.0277, 0.0321, 0.0205], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0405, 0.0405], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1671,  0.0139,  0.0000],\n",
      "        [ 0.1136, -0.0008,  0.0000],\n",
      "        [ 0.1321, -0.0374,  0.0000],\n",
      "        [ 0.1327, -0.0097,  0.0000],\n",
      "        [ 0.2009,  0.0140,  0.0000],\n",
      "        [ 0.0941, -0.0051,  0.0000],\n",
      "        [ 0.1371,  0.0217,  0.0000],\n",
      "        [ 0.0944, -0.0162,  0.0000],\n",
      "        [ 0.1638,  0.0451,  0.0000],\n",
      "        [ 0.1251, -0.0376,  0.0000],\n",
      "        [ 0.0835, -0.0219,  0.0000],\n",
      "        [ 0.0369,  0.0121,  0.0000],\n",
      "        [ 0.0629, -0.0309,  0.0000],\n",
      "        [ 0.1200, -0.0259,  0.0000],\n",
      "        [ 0.0941, -0.0202,  0.0000],\n",
      "        [ 0.1335,  0.0115,  0.0000],\n",
      "        [ 0.1224,  0.0036,  0.0000],\n",
      "        [ 0.0967,  0.0041,  0.0000],\n",
      "        [ 0.0624,  0.0029,  0.0000],\n",
      "        [ 0.1296,  0.0199,  0.0000],\n",
      "        [ 0.1074,  0.0013,  0.0000],\n",
      "        [ 0.1103, -0.0415,  0.0000],\n",
      "        [ 0.1286, -0.0007,  0.0000],\n",
      "        [ 0.1023, -0.0083,  0.0000],\n",
      "        [ 0.1225, -0.0103,  0.0000],\n",
      "        [ 0.1411, -0.0056,  0.0000],\n",
      "        [ 0.1388, -0.0045,  0.0000],\n",
      "        [ 0.1499, -0.0143,  0.0000],\n",
      "        [ 0.1246,  0.0399,  0.0000],\n",
      "        [ 0.0913,  0.0157,  0.0000],\n",
      "        [ 0.1093, -0.0179,  0.0000],\n",
      "        [ 0.0855,  0.0132,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[3.2562, 2.8887, 2.7818, 2.7232, 2.6425, 2.8031, 2.5925, 2.9599, 3.0514,\n",
      "         2.6045, 1.9826, 1.8297, 1.6873, 2.7768, 2.6228, 3.1157, 2.5693, 2.9158,\n",
      "         2.0180, 3.0588, 2.8695, 2.9534, 3.2058, 2.6989, 2.5609, 3.0686, 2.9061,\n",
      "         3.3991, 3.1121, 2.3275, 2.6816, 1.6282],\n",
      "        [3.2574, 2.8784, 2.6887, 2.5522, 2.5359, 2.8120, 2.5742, 3.0181, 3.0340,\n",
      "         2.6852, 1.8832, 1.6887, 1.6967, 2.8147, 2.4749, 3.1404, 2.4870, 2.8131,\n",
      "         2.1245, 3.0663, 2.8568, 2.7337, 3.2820, 2.6674, 2.4665, 3.0317, 2.7342,\n",
      "         3.1328, 3.0572, 2.2519, 2.6091, 1.7707]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0394, 0.0337, 0.0331, 0.0321, 0.0315, 0.0350, 0.0331, 0.0365, 0.0386,\n",
      "        0.0336, 0.0238, 0.0218, 0.0207, 0.0352, 0.0306, 0.0385, 0.0303, 0.0345,\n",
      "        0.0256, 0.0392, 0.0357, 0.0332, 0.0392, 0.0311, 0.0320, 0.0385, 0.0361,\n",
      "        0.0399, 0.0385, 0.0282, 0.0327, 0.0209], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0413, 0.0413], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.2966,  0.0243,  0.0000],\n",
      "        [ 0.2619,  0.0663,  0.0000],\n",
      "        [ 0.2892,  0.0540,  0.0000],\n",
      "        [ 0.2674,  0.0523,  0.0000],\n",
      "        [ 0.2327,  0.0199,  0.0000],\n",
      "        [ 0.2262,  0.0293,  0.0000],\n",
      "        [ 0.2221,  0.0229,  0.0000],\n",
      "        [ 0.3119,  0.0521,  0.0000],\n",
      "        [ 0.2884,  0.0196,  0.0000],\n",
      "        [ 0.1732,  0.0539,  0.0000],\n",
      "        [ 0.1988, -0.0272,  0.0000],\n",
      "        [ 0.1240,  0.0359,  0.0000],\n",
      "        [ 0.1399,  0.0512,  0.0000],\n",
      "        [ 0.2439,  0.0361,  0.0000],\n",
      "        [ 0.2225,  0.0543,  0.0000],\n",
      "        [ 0.2497,  0.0525,  0.0000],\n",
      "        [ 0.2135,  0.0372,  0.0000],\n",
      "        [ 0.2203,  0.0586,  0.0000],\n",
      "        [ 0.2350,  0.0125,  0.0000],\n",
      "        [ 0.2516,  0.0299,  0.0000],\n",
      "        [ 0.2322,  0.0476,  0.0000],\n",
      "        [ 0.3019,  0.0517,  0.0000],\n",
      "        [ 0.3318,  0.0601,  0.0000],\n",
      "        [ 0.1882,  0.0580,  0.0000],\n",
      "        [ 0.1976,  0.0261,  0.0000],\n",
      "        [ 0.2625,  0.0216,  0.0000],\n",
      "        [ 0.2973,  0.0432,  0.0000],\n",
      "        [ 0.2984,  0.0647,  0.0000],\n",
      "        [ 0.2321,  0.0499,  0.0000],\n",
      "        [ 0.1906,  0.0332,  0.0000],\n",
      "        [ 0.2227,  0.0376,  0.0000],\n",
      "        [ 0.0940,  0.0180,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[3.3898, 3.0064, 2.8948, 2.8347, 2.7549, 2.9182, 2.6989, 3.0791, 3.1778,\n",
      "         2.7109, 2.0648, 1.8997, 1.7551, 2.8895, 2.7292, 3.2433, 2.6750, 3.0365,\n",
      "         2.0990, 3.1844, 2.9870, 3.0737, 3.3360, 2.8082, 2.6623, 3.1938, 3.0246,\n",
      "         3.5370, 3.2400, 2.4199, 2.7902, 1.6968],\n",
      "        [3.3903, 2.9952, 2.7984, 2.6560, 2.6437, 2.9265, 2.6790, 3.1378, 3.1590,\n",
      "         2.7943, 1.9604, 1.7550, 1.7660, 2.9284, 2.5743, 3.2681, 2.5885, 2.9278,\n",
      "         2.2117, 3.1910, 2.9732, 2.8442, 3.4144, 2.7753, 2.5655, 3.1548, 2.8449,\n",
      "         3.2592, 3.1823, 2.3421, 2.7155, 1.8439]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0403, 0.0344, 0.0338, 0.0328, 0.0322, 0.0357, 0.0338, 0.0372, 0.0394,\n",
      "        0.0342, 0.0242, 0.0222, 0.0211, 0.0359, 0.0312, 0.0393, 0.0310, 0.0351,\n",
      "        0.0262, 0.0400, 0.0364, 0.0339, 0.0400, 0.0317, 0.0326, 0.0393, 0.0368,\n",
      "        0.0406, 0.0393, 0.0287, 0.0334, 0.0214], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0421, 0.0420], grad_fn=<MeanBackward1>)\n",
      "Epoch 9/10, Accuracy: 0.5188\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.2581,  0.0541,  0.0000],\n",
      "        [ 0.1875,  0.0723,  0.0000],\n",
      "        [ 0.2001,  0.0168,  0.0000],\n",
      "        [ 0.2183,  0.0370,  0.0000],\n",
      "        [ 0.1793,  0.0462,  0.0000],\n",
      "        [ 0.2255,  0.0243,  0.0000],\n",
      "        [ 0.2208,  0.0290,  0.0000],\n",
      "        [ 0.2462,  0.0142,  0.0000],\n",
      "        [ 0.2111,  0.0421,  0.0000],\n",
      "        [ 0.1988,  0.0532,  0.0000],\n",
      "        [ 0.1556,  0.0318,  0.0000],\n",
      "        [ 0.1939,  0.0104,  0.0000],\n",
      "        [ 0.1335,  0.0561,  0.0000],\n",
      "        [ 0.2381,  0.0483,  0.0000],\n",
      "        [ 0.2197,  0.0669,  0.0000],\n",
      "        [ 0.2341,  0.0293,  0.0000],\n",
      "        [ 0.1860,  0.0617,  0.0000],\n",
      "        [ 0.2338,  0.0447,  0.0000],\n",
      "        [ 0.1584, -0.0516,  0.0000],\n",
      "        [ 0.2073,  0.0526,  0.0000],\n",
      "        [ 0.2407,  0.0566,  0.0000],\n",
      "        [ 0.2224,  0.0507,  0.0000],\n",
      "        [ 0.2228,  0.0170,  0.0000],\n",
      "        [ 0.1747,  0.0349,  0.0000],\n",
      "        [ 0.1891,  0.0090,  0.0000],\n",
      "        [ 0.2223,  0.0343,  0.0000],\n",
      "        [ 0.2356,  0.0291,  0.0000],\n",
      "        [ 0.2698,  0.0369,  0.0000],\n",
      "        [ 0.2008,  0.0559,  0.0000],\n",
      "        [ 0.1825,  0.0321,  0.0000],\n",
      "        [ 0.2198,  0.0120,  0.0000],\n",
      "        [ 0.1279,  0.0311,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[3.5274, 3.1288, 3.0113, 2.9516, 2.8673, 3.0362, 2.8084, 3.2065, 3.3083,\n",
      "         2.8212, 2.1510, 1.9788, 1.8272, 3.0072, 2.8396, 3.3748, 2.7840, 3.1570,\n",
      "         2.1829, 3.3132, 3.1080, 3.1999, 3.4724, 2.9226, 2.7711, 3.3232, 3.1480,\n",
      "         3.6813, 3.3711, 2.5196, 2.9048, 1.7655],\n",
      "        [3.5275, 3.1168, 2.9106, 2.7651, 2.7517, 3.0444, 2.7871, 3.2676, 3.2880,\n",
      "         2.9071, 2.0429, 1.8265, 1.8385, 3.0470, 2.6783, 3.4001, 2.6934, 3.0446,\n",
      "         2.2988, 3.3197, 3.0935, 2.9610, 3.5537, 2.8885, 2.6687, 3.2818, 2.9606,\n",
      "         3.3915, 3.3109, 2.4377, 2.8266, 1.9184]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0410, 0.0351, 0.0345, 0.0334, 0.0328, 0.0364, 0.0345, 0.0380, 0.0402,\n",
      "        0.0349, 0.0248, 0.0227, 0.0215, 0.0366, 0.0318, 0.0400, 0.0316, 0.0358,\n",
      "        0.0267, 0.0408, 0.0371, 0.0346, 0.0408, 0.0323, 0.0333, 0.0400, 0.0375,\n",
      "        0.0415, 0.0401, 0.0293, 0.0341, 0.0218], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0429, 0.0428], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1184,  0.0112,  0.0000],\n",
      "        [ 0.1396,  0.0352,  0.0000],\n",
      "        [ 0.1477,  0.0370,  0.0000],\n",
      "        [ 0.1148,  0.0058,  0.0000],\n",
      "        [ 0.1225, -0.0014,  0.0000],\n",
      "        [ 0.1239,  0.0337,  0.0000],\n",
      "        [ 0.0761,  0.0101,  0.0000],\n",
      "        [ 0.1325,  0.0509,  0.0000],\n",
      "        [ 0.1256,  0.0284,  0.0000],\n",
      "        [ 0.1186,  0.0445,  0.0000],\n",
      "        [ 0.0814,  0.0149,  0.0000],\n",
      "        [ 0.0064,  0.0050,  0.0000],\n",
      "        [ 0.0692,  0.0486,  0.0000],\n",
      "        [ 0.1012,  0.0252,  0.0000],\n",
      "        [ 0.0870,  0.0253,  0.0000],\n",
      "        [ 0.1506,  0.0318,  0.0000],\n",
      "        [ 0.1384,  0.0451,  0.0000],\n",
      "        [ 0.1288,  0.0181,  0.0000],\n",
      "        [ 0.0833,  0.0223,  0.0000],\n",
      "        [ 0.1504,  0.0497,  0.0000],\n",
      "        [ 0.1273,  0.0270,  0.0000],\n",
      "        [ 0.1003,  0.0239,  0.0000],\n",
      "        [ 0.1542,  0.0309,  0.0000],\n",
      "        [ 0.0542,  0.0417,  0.0000],\n",
      "        [ 0.1337,  0.0036,  0.0000],\n",
      "        [ 0.1700,  0.0118,  0.0000],\n",
      "        [ 0.1148,  0.0244,  0.0000],\n",
      "        [ 0.1484,  0.0481,  0.0000],\n",
      "        [ 0.1301,  0.0186,  0.0000],\n",
      "        [ 0.0974,  0.0067,  0.0000],\n",
      "        [ 0.1522,  0.0354,  0.0000],\n",
      "        [ 0.0673,  0.0077,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[3.6718, 3.2561, 3.1352, 3.0694, 2.9835, 3.1597, 2.9233, 3.3351, 3.4418,\n",
      "         2.9362, 2.2375, 2.0587, 1.9047, 3.1298, 2.9555, 3.5117, 2.8963, 3.2852,\n",
      "         2.2746, 3.4462, 3.2345, 3.3298, 3.6134, 3.0421, 2.8867, 3.4585, 3.2760,\n",
      "         3.8308, 3.5089, 2.6235, 3.0234, 1.8365],\n",
      "        [3.6712, 3.2431, 3.0304, 2.8753, 2.8627, 3.1677, 2.9007, 3.3989, 3.4194,\n",
      "         3.0245, 2.1241, 1.9006, 1.9146, 3.1704, 2.7871, 3.5378, 2.8019, 3.1675,\n",
      "         2.3944, 3.4523, 3.2187, 3.0811, 3.6974, 3.0060, 2.7800, 3.4144, 3.0801,\n",
      "         3.5284, 3.4457, 2.5378, 2.9428, 1.9957]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0419, 0.0358, 0.0352, 0.0341, 0.0335, 0.0371, 0.0352, 0.0387, 0.0410,\n",
      "        0.0356, 0.0252, 0.0231, 0.0220, 0.0373, 0.0325, 0.0408, 0.0322, 0.0365,\n",
      "        0.0273, 0.0416, 0.0378, 0.0353, 0.0416, 0.0329, 0.0340, 0.0408, 0.0382,\n",
      "        0.0423, 0.0409, 0.0300, 0.0348, 0.0222], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0438, 0.0437], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.3719, -0.0048,  0.0000],\n",
      "        [ 0.2944, -0.0332,  0.0000],\n",
      "        [ 0.2764, -0.0214,  0.0000],\n",
      "        [ 0.2999, -0.0128,  0.0000],\n",
      "        [ 0.2377,  0.0107,  0.0000],\n",
      "        [ 0.2815, -0.0299,  0.0000],\n",
      "        [ 0.3095,  0.0073,  0.0000],\n",
      "        [ 0.3156, -0.0059,  0.0000],\n",
      "        [ 0.3202, -0.0676,  0.0000],\n",
      "        [ 0.3009, -0.0472,  0.0000],\n",
      "        [ 0.2182, -0.0084,  0.0000],\n",
      "        [ 0.2115,  0.0094,  0.0000],\n",
      "        [ 0.1868, -0.0014,  0.0000],\n",
      "        [ 0.3003, -0.0366,  0.0000],\n",
      "        [ 0.2866, -0.0318,  0.0000],\n",
      "        [ 0.3314, -0.0293,  0.0000],\n",
      "        [ 0.2198,  0.0061,  0.0000],\n",
      "        [ 0.3160, -0.0515,  0.0000],\n",
      "        [ 0.2721, -0.0336,  0.0000],\n",
      "        [ 0.2992, -0.0532,  0.0000],\n",
      "        [ 0.3340, -0.0742,  0.0000],\n",
      "        [ 0.2993,  0.0148,  0.0000],\n",
      "        [ 0.3585, -0.0334,  0.0000],\n",
      "        [ 0.2510,  0.0104,  0.0000],\n",
      "        [ 0.2204, -0.0251,  0.0000],\n",
      "        [ 0.3016, -0.0423,  0.0000],\n",
      "        [ 0.2897, -0.0367,  0.0000],\n",
      "        [ 0.3042,  0.0219,  0.0000],\n",
      "        [ 0.3161, -0.0519,  0.0000],\n",
      "        [ 0.2442, -0.0546,  0.0000],\n",
      "        [ 0.3068, -0.0562,  0.0000],\n",
      "        [ 0.2000, -0.0253,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[3.8207, 3.3886, 3.2609, 3.1970, 3.1054, 3.2870, 3.0403, 3.4712, 3.5832,\n",
      "         3.0562, 2.3309, 2.1455, 1.9794, 3.2567, 3.0762, 3.6554, 3.0151, 3.4202,\n",
      "         2.3677, 3.5879, 3.3664, 3.4660, 3.7605, 3.1654, 2.9996, 3.5983, 3.4099,\n",
      "         3.9860, 3.6515, 2.7287, 3.1456, 1.9139],\n",
      "        [3.8192, 3.3746, 3.1506, 2.9949, 2.9794, 3.2955, 3.0165, 3.5377, 3.5596,\n",
      "         3.1480, 2.2150, 1.9814, 1.9907, 3.2985, 2.9016, 3.6821, 2.9164, 3.2977,\n",
      "         2.4922, 3.5937, 3.3499, 3.2075, 3.8484, 3.1275, 2.8884, 3.5523, 3.2062,\n",
      "         3.6712, 3.5854, 2.6393, 3.0604, 2.0781]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0427, 0.0365, 0.0359, 0.0348, 0.0342, 0.0378, 0.0358, 0.0395, 0.0418,\n",
      "        0.0363, 0.0259, 0.0237, 0.0224, 0.0381, 0.0331, 0.0417, 0.0328, 0.0372,\n",
      "        0.0278, 0.0424, 0.0386, 0.0360, 0.0424, 0.0336, 0.0345, 0.0416, 0.0390,\n",
      "        0.0431, 0.0417, 0.0305, 0.0354, 0.0227], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0446, 0.0445], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 3.1165e-01,  5.7152e-03,  0.0000e+00],\n",
      "        [ 2.4792e-01, -1.7751e-02,  0.0000e+00],\n",
      "        [ 2.3596e-01,  2.3369e-02,  0.0000e+00],\n",
      "        [ 2.2390e-01, -6.5917e-03,  0.0000e+00],\n",
      "        [ 1.9190e-01, -9.2156e-03,  0.0000e+00],\n",
      "        [ 2.6669e-01, -3.1099e-04,  0.0000e+00],\n",
      "        [ 2.7966e-01, -3.6687e-02,  0.0000e+00],\n",
      "        [ 2.4708e-01, -1.6511e-02,  0.0000e+00],\n",
      "        [ 2.9490e-01, -2.9885e-04,  0.0000e+00],\n",
      "        [ 2.0363e-01,  9.7098e-03,  0.0000e+00],\n",
      "        [ 1.5856e-01, -1.0373e-02,  0.0000e+00],\n",
      "        [ 1.7789e-01, -2.8456e-02,  0.0000e+00],\n",
      "        [ 1.5048e-01, -1.1572e-02,  0.0000e+00],\n",
      "        [ 2.6968e-01, -7.5672e-03,  0.0000e+00],\n",
      "        [ 2.2686e-01, -2.4187e-02,  0.0000e+00],\n",
      "        [ 2.7765e-01, -1.8884e-02,  0.0000e+00],\n",
      "        [ 2.2593e-01, -2.3346e-02,  0.0000e+00],\n",
      "        [ 2.3820e-01, -2.7354e-02,  0.0000e+00],\n",
      "        [ 1.4696e-01,  4.2658e-02,  0.0000e+00],\n",
      "        [ 3.1509e-01, -1.8514e-02,  0.0000e+00],\n",
      "        [ 2.2239e-01,  8.7450e-03,  0.0000e+00],\n",
      "        [ 2.2461e-01, -1.3657e-02,  0.0000e+00],\n",
      "        [ 2.5536e-01,  1.4192e-04,  0.0000e+00],\n",
      "        [ 2.6649e-01, -1.8085e-02,  0.0000e+00],\n",
      "        [ 2.2951e-01, -3.5845e-02,  0.0000e+00],\n",
      "        [ 2.7103e-01, -2.8045e-02,  0.0000e+00],\n",
      "        [ 2.6347e-01, -2.8080e-02,  0.0000e+00],\n",
      "        [ 3.1892e-01, -4.4854e-02,  0.0000e+00],\n",
      "        [ 3.2040e-01, -2.1173e-02,  0.0000e+00],\n",
      "        [ 1.8917e-01,  2.3412e-03,  0.0000e+00],\n",
      "        [ 2.0822e-01,  9.9597e-04,  0.0000e+00],\n",
      "        [ 1.5287e-01,  5.8384e-03,  0.0000e+00]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[3.9765, 3.5267, 3.3936, 3.3289, 3.2323, 3.4201, 3.1656, 3.6133, 3.7278,\n",
      "         3.1793, 2.4271, 2.2322, 2.0614, 3.3883, 3.2009, 3.8042, 3.1373, 3.5600,\n",
      "         2.4633, 3.7318, 3.5028, 3.6071, 3.9142, 3.2952, 3.1225, 3.7446, 3.5476,\n",
      "         4.1490, 3.7995, 2.8404, 3.2709, 1.9923],\n",
      "        [3.9746, 3.5114, 3.2791, 3.1179, 3.1013, 3.4295, 3.1410, 3.6822, 3.7026,\n",
      "         3.2745, 2.3045, 2.0591, 2.0717, 3.4319, 3.0197, 3.8313, 3.0351, 3.4325,\n",
      "         2.5918, 3.7379, 3.4855, 3.3378, 4.0048, 3.2558, 3.0075, 3.6962, 3.3352,\n",
      "         3.8210, 3.7308, 2.7464, 3.1827, 2.1625]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0436, 0.0372, 0.0366, 0.0355, 0.0349, 0.0385, 0.0366, 0.0403, 0.0426,\n",
      "        0.0370, 0.0264, 0.0241, 0.0229, 0.0388, 0.0338, 0.0425, 0.0335, 0.0380,\n",
      "        0.0284, 0.0432, 0.0393, 0.0367, 0.0433, 0.0343, 0.0353, 0.0425, 0.0398,\n",
      "        0.0440, 0.0426, 0.0311, 0.0361, 0.0232], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0455, 0.0453], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1864, -0.0596,  0.0000],\n",
      "        [ 0.1547, -0.0465,  0.0000],\n",
      "        [ 0.1363, -0.0487,  0.0000],\n",
      "        [ 0.1374, -0.0777,  0.0000],\n",
      "        [ 0.1569, -0.0378,  0.0000],\n",
      "        [ 0.1121, -0.0206,  0.0000],\n",
      "        [ 0.1516, -0.0628,  0.0000],\n",
      "        [ 0.2007, -0.0776,  0.0000],\n",
      "        [ 0.1660, -0.0612,  0.0000],\n",
      "        [ 0.1377, -0.0808,  0.0000],\n",
      "        [ 0.1337, -0.0148,  0.0000],\n",
      "        [ 0.1045, -0.0201,  0.0000],\n",
      "        [ 0.1180, -0.0448,  0.0000],\n",
      "        [ 0.1738, -0.0666,  0.0000],\n",
      "        [ 0.1571, -0.0455,  0.0000],\n",
      "        [ 0.1953, -0.0665,  0.0000],\n",
      "        [ 0.1098, -0.0112,  0.0000],\n",
      "        [ 0.1747, -0.0559,  0.0000],\n",
      "        [ 0.1217, -0.0962,  0.0000],\n",
      "        [ 0.1418, -0.0312,  0.0000],\n",
      "        [ 0.1430, -0.0501,  0.0000],\n",
      "        [ 0.1572, -0.0753,  0.0000],\n",
      "        [ 0.2217, -0.0605,  0.0000],\n",
      "        [ 0.1558, -0.0173,  0.0000],\n",
      "        [ 0.1038, -0.0446,  0.0000],\n",
      "        [ 0.1329, -0.0764,  0.0000],\n",
      "        [ 0.1797, -0.0641,  0.0000],\n",
      "        [ 0.1143, -0.0751,  0.0000],\n",
      "        [ 0.1880, -0.0605,  0.0000],\n",
      "        [ 0.0944, -0.0606,  0.0000],\n",
      "        [ 0.1267, -0.0256,  0.0000],\n",
      "        [ 0.0866, -0.0441,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[4.1384, 3.6701, 3.5322, 3.4634, 3.3622, 3.5576, 3.2958, 3.7585, 3.8794,\n",
      "         3.3101, 2.5230, 2.3274, 2.1476, 3.5272, 3.3305, 3.9584, 3.2642, 3.7014,\n",
      "         2.5660, 3.8834, 3.6449, 3.7536, 4.0719, 3.4287, 3.2499, 3.8970, 3.6911,\n",
      "         4.3177, 3.9537, 2.9572, 3.4036, 2.0732],\n",
      "        [4.1359, 3.6538, 3.4128, 3.2432, 3.2256, 3.5663, 3.2692, 3.8299, 3.8525,\n",
      "         3.4079, 2.3962, 2.1474, 2.1575, 3.5713, 3.1414, 3.9863, 3.1574, 3.5679,\n",
      "         2.6988, 3.8892, 3.6263, 3.4726, 4.1662, 3.3874, 3.1282, 3.8453, 3.4691,\n",
      "         3.9752, 3.8818, 2.8592, 3.3109, 2.2502]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0444, 0.0380, 0.0374, 0.0362, 0.0355, 0.0392, 0.0373, 0.0411, 0.0435,\n",
      "        0.0377, 0.0269, 0.0247, 0.0234, 0.0396, 0.0345, 0.0433, 0.0341, 0.0387,\n",
      "        0.0290, 0.0441, 0.0401, 0.0375, 0.0441, 0.0350, 0.0360, 0.0433, 0.0405,\n",
      "        0.0448, 0.0434, 0.0318, 0.0368, 0.0236], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0464, 0.0462], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.2700, -0.1027,  0.0000],\n",
      "        [ 0.2680, -0.0849,  0.0000],\n",
      "        [ 0.2401, -0.0997,  0.0000],\n",
      "        [ 0.2339, -0.1296,  0.0000],\n",
      "        [ 0.1998, -0.0874,  0.0000],\n",
      "        [ 0.2431, -0.0681,  0.0000],\n",
      "        [ 0.1954, -0.0952,  0.0000],\n",
      "        [ 0.2361, -0.0864,  0.0000],\n",
      "        [ 0.2398, -0.0942,  0.0000],\n",
      "        [ 0.2570, -0.1156,  0.0000],\n",
      "        [ 0.1547, -0.0428,  0.0000],\n",
      "        [ 0.1641, -0.0483,  0.0000],\n",
      "        [ 0.1686, -0.0813,  0.0000],\n",
      "        [ 0.2449, -0.0978,  0.0000],\n",
      "        [ 0.2374, -0.0593,  0.0000],\n",
      "        [ 0.2534, -0.0681,  0.0000],\n",
      "        [ 0.2239, -0.0709,  0.0000],\n",
      "        [ 0.2455, -0.0825,  0.0000],\n",
      "        [ 0.1611, -0.0812,  0.0000],\n",
      "        [ 0.2803, -0.0676,  0.0000],\n",
      "        [ 0.2526, -0.0760,  0.0000],\n",
      "        [ 0.2367, -0.1536,  0.0000],\n",
      "        [ 0.2716, -0.0622,  0.0000],\n",
      "        [ 0.2095, -0.0798,  0.0000],\n",
      "        [ 0.2040, -0.0405,  0.0000],\n",
      "        [ 0.2673, -0.0996,  0.0000],\n",
      "        [ 0.2417, -0.0809,  0.0000],\n",
      "        [ 0.2829, -0.1231,  0.0000],\n",
      "        [ 0.2738, -0.0568,  0.0000],\n",
      "        [ 0.1799, -0.0739,  0.0000],\n",
      "        [ 0.2071, -0.0793,  0.0000],\n",
      "        [ 0.1576, -0.0681,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[4.3072, 3.8194, 3.6754, 3.6048, 3.5008, 3.7029, 3.4265, 3.9127, 4.0379,\n",
      "         3.4448, 2.6295, 2.4218, 2.2352, 3.6693, 3.4651, 4.1206, 3.3978, 3.8521,\n",
      "         2.6686, 4.0404, 3.7931, 3.9064, 4.2392, 3.5681, 3.3802, 4.0547, 3.8422,\n",
      "         4.4935, 4.1140, 3.0777, 3.5413, 2.1583],\n",
      "        [4.3039, 3.8021, 3.5508, 3.3752, 3.3582, 3.7105, 3.3992, 3.9862, 4.0087,\n",
      "         3.5460, 2.4957, 2.2352, 2.2457, 3.7148, 3.2671, 4.1486, 3.2861, 3.7123,\n",
      "         2.8075, 4.0453, 3.7729, 3.6136, 4.3365, 3.5248, 3.2538, 3.9999, 3.6103,\n",
      "         4.1361, 4.0382, 2.9756, 3.4455, 2.3423]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0453, 0.0387, 0.0381, 0.0370, 0.0363, 0.0400, 0.0380, 0.0419, 0.0443,\n",
      "        0.0385, 0.0275, 0.0253, 0.0239, 0.0404, 0.0351, 0.0442, 0.0348, 0.0395,\n",
      "        0.0296, 0.0449, 0.0409, 0.0382, 0.0450, 0.0357, 0.0367, 0.0441, 0.0414,\n",
      "        0.0457, 0.0443, 0.0324, 0.0375, 0.0241], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0473, 0.0471], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.2477, -0.0570,  0.0000],\n",
      "        [ 0.1626, -0.0862,  0.0000],\n",
      "        [ 0.1871, -0.0907,  0.0000],\n",
      "        [ 0.1674, -0.0775,  0.0000],\n",
      "        [ 0.1467, -0.0317,  0.0000],\n",
      "        [ 0.2062, -0.0602,  0.0000],\n",
      "        [ 0.1897, -0.0486,  0.0000],\n",
      "        [ 0.1673, -0.0870,  0.0000],\n",
      "        [ 0.2058, -0.1580,  0.0000],\n",
      "        [ 0.1386, -0.0853,  0.0000],\n",
      "        [ 0.1727, -0.0378,  0.0000],\n",
      "        [ 0.1312, -0.0514,  0.0000],\n",
      "        [ 0.1199, -0.0558,  0.0000],\n",
      "        [ 0.1857, -0.1107,  0.0000],\n",
      "        [ 0.1014, -0.0612,  0.0000],\n",
      "        [ 0.1873, -0.0999,  0.0000],\n",
      "        [ 0.1836, -0.0310,  0.0000],\n",
      "        [ 0.2067, -0.0792,  0.0000],\n",
      "        [ 0.1254, -0.0784,  0.0000],\n",
      "        [ 0.2127, -0.1091,  0.0000],\n",
      "        [ 0.1258, -0.0779,  0.0000],\n",
      "        [ 0.1728, -0.0194,  0.0000],\n",
      "        [ 0.1552, -0.1491,  0.0000],\n",
      "        [ 0.2115, -0.0530,  0.0000],\n",
      "        [ 0.1663, -0.0578,  0.0000],\n",
      "        [ 0.2037, -0.0787,  0.0000],\n",
      "        [ 0.1344, -0.1062,  0.0000],\n",
      "        [ 0.2427, -0.0527,  0.0000],\n",
      "        [ 0.1793, -0.0891,  0.0000],\n",
      "        [ 0.1585, -0.0370,  0.0000],\n",
      "        [ 0.1441, -0.0803,  0.0000],\n",
      "        [ 0.1302, -0.0715,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[4.4821, 3.9747, 3.8262, 3.7518, 3.6419, 3.8528, 3.5660, 4.0723, 4.2027,\n",
      "         3.5845, 2.7339, 2.5183, 2.3265, 3.8196, 3.6074, 4.2877, 3.5357, 4.0078,\n",
      "         2.7784, 4.2042, 3.9475, 4.0656, 4.4108, 3.7142, 3.5187, 4.2181, 3.9991,\n",
      "         4.6751, 4.2818, 3.2037, 3.6866, 2.2464],\n",
      "        [4.4775, 3.9563, 3.6955, 3.5128, 3.4926, 3.8609, 3.5365, 4.1487, 4.1713,\n",
      "         3.6892, 2.5965, 2.3261, 2.3379, 3.8664, 3.4009, 4.3169, 3.4186, 3.8626,\n",
      "         2.9220, 4.2091, 3.9261, 3.7612, 4.5123, 3.6688, 3.3872, 4.1611, 3.7576,\n",
      "         4.3031, 4.2027, 3.0972, 3.5854, 2.4373]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0462, 0.0395, 0.0389, 0.0377, 0.0370, 0.0408, 0.0388, 0.0428, 0.0452,\n",
      "        0.0393, 0.0280, 0.0258, 0.0244, 0.0412, 0.0359, 0.0451, 0.0355, 0.0402,\n",
      "        0.0302, 0.0458, 0.0417, 0.0390, 0.0459, 0.0364, 0.0374, 0.0450, 0.0422,\n",
      "        0.0466, 0.0452, 0.0331, 0.0383, 0.0246], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0482, 0.0480], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[0.2074, 0.1967, 0.0000],\n",
      "        [0.1750, 0.1717, 0.0000],\n",
      "        [0.2164, 0.1429, 0.0000],\n",
      "        [0.1507, 0.1542, 0.0000],\n",
      "        [0.1662, 0.1412, 0.0000],\n",
      "        [0.1894, 0.1628, 0.0000],\n",
      "        [0.2301, 0.1864, 0.0000],\n",
      "        [0.2040, 0.1757, 0.0000],\n",
      "        [0.1775, 0.1666, 0.0000],\n",
      "        [0.1849, 0.1711, 0.0000],\n",
      "        [0.1287, 0.1014, 0.0000],\n",
      "        [0.1107, 0.1318, 0.0000],\n",
      "        [0.1017, 0.0669, 0.0000],\n",
      "        [0.2058, 0.1803, 0.0000],\n",
      "        [0.1807, 0.1670, 0.0000],\n",
      "        [0.2064, 0.1869, 0.0000],\n",
      "        [0.0923, 0.1437, 0.0000],\n",
      "        [0.1547, 0.1734, 0.0000],\n",
      "        [0.1695, 0.1217, 0.0000],\n",
      "        [0.2244, 0.1625, 0.0000],\n",
      "        [0.1708, 0.1844, 0.0000],\n",
      "        [0.1499, 0.1597, 0.0000],\n",
      "        [0.2620, 0.1562, 0.0000],\n",
      "        [0.1836, 0.1413, 0.0000],\n",
      "        [0.1777, 0.2088, 0.0000],\n",
      "        [0.2257, 0.2185, 0.0000],\n",
      "        [0.1638, 0.1753, 0.0000],\n",
      "        [0.1735, 0.2613, 0.0000],\n",
      "        [0.2074, 0.1807, 0.0000],\n",
      "        [0.1168, 0.1292, 0.0000],\n",
      "        [0.1678, 0.1372, 0.0000],\n",
      "        [0.1168, 0.1001, 0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[4.6662, 4.1362, 3.9840, 3.9026, 3.7932, 4.0133, 3.7171, 4.2364, 4.3740,\n",
      "         3.7320, 2.8414, 2.6160, 2.4184, 3.9769, 3.7563, 4.4612, 3.6837, 4.1742,\n",
      "         2.8915, 4.3754, 4.1082, 4.2306, 4.5885, 3.8660, 3.6661, 4.3902, 4.1612,\n",
      "         4.8658, 4.4568, 3.3322, 3.8398, 2.3364],\n",
      "        [4.6610, 4.1165, 3.8486, 3.6531, 3.6385, 4.0220, 3.6855, 4.3160, 4.3407,\n",
      "         3.8405, 2.6981, 2.4118, 2.4297, 4.0247, 3.5415, 4.4910, 3.5622, 4.0220,\n",
      "         3.0405, 4.3796, 4.0857, 3.9132, 4.6938, 3.8186, 3.5285, 4.3303, 3.9094,\n",
      "         4.4784, 4.3742, 3.2206, 3.7352, 2.5348]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0472, 0.0403, 0.0397, 0.0384, 0.0378, 0.0417, 0.0396, 0.0436, 0.0462,\n",
      "        0.0401, 0.0285, 0.0261, 0.0248, 0.0421, 0.0366, 0.0460, 0.0363, 0.0411,\n",
      "        0.0308, 0.0468, 0.0426, 0.0398, 0.0468, 0.0371, 0.0382, 0.0459, 0.0430,\n",
      "        0.0476, 0.0461, 0.0337, 0.0392, 0.0251], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0492, 0.0489], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[0.2622, 0.0964, 0.0000],\n",
      "        [0.2146, 0.0854, 0.0000],\n",
      "        [0.1989, 0.0430, 0.0000],\n",
      "        [0.2289, 0.0392, 0.0000],\n",
      "        [0.2542, 0.0518, 0.0000],\n",
      "        [0.1832, 0.0633, 0.0000],\n",
      "        [0.2707, 0.0670, 0.0000],\n",
      "        [0.2979, 0.0558, 0.0000],\n",
      "        [0.2835, 0.0829, 0.0000],\n",
      "        [0.1899, 0.0205, 0.0000],\n",
      "        [0.0974, 0.0549, 0.0000],\n",
      "        [0.1288, 0.0311, 0.0000],\n",
      "        [0.1258, 0.0341, 0.0000],\n",
      "        [0.2243, 0.0629, 0.0000],\n",
      "        [0.2229, 0.0602, 0.0000],\n",
      "        [0.2843, 0.0375, 0.0000],\n",
      "        [0.2393, 0.0666, 0.0000],\n",
      "        [0.2465, 0.0771, 0.0000],\n",
      "        [0.1632, 0.0599, 0.0000],\n",
      "        [0.2529, 0.0706, 0.0000],\n",
      "        [0.2360, 0.0549, 0.0000],\n",
      "        [0.2136, 0.0270, 0.0000],\n",
      "        [0.2751, 0.0591, 0.0000],\n",
      "        [0.2471, 0.0375, 0.0000],\n",
      "        [0.2025, 0.0747, 0.0000],\n",
      "        [0.2307, 0.0691, 0.0000],\n",
      "        [0.2709, 0.0758, 0.0000],\n",
      "        [0.2870, 0.0695, 0.0000],\n",
      "        [0.2952, 0.0484, 0.0000],\n",
      "        [0.1766, 0.0877, 0.0000],\n",
      "        [0.2161, 0.0308, 0.0000],\n",
      "        [0.1215, 0.0411, 0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[4.8553, 4.3046, 4.1436, 4.0626, 3.9469, 4.1745, 3.8658, 4.4087, 4.5513,\n",
      "         3.8852, 2.9636, 2.7220, 2.5180, 4.1380, 3.9089, 4.6422, 3.8314, 4.3428,\n",
      "         3.0085, 4.5534, 4.2754, 4.4039, 4.7761, 4.0227, 3.8119, 4.5696, 4.3300,\n",
      "         5.0651, 4.6378, 3.4683, 3.9929, 2.4348],\n",
      "        [4.8491, 4.2836, 4.0023, 3.8022, 3.7850, 4.1829, 3.8317, 4.4908, 4.5155,\n",
      "         3.9966, 2.8143, 2.5106, 2.5288, 4.1870, 3.6847, 4.6730, 3.7044, 4.1834,\n",
      "         3.1638, 4.5575, 4.2511, 4.0730, 4.8853, 3.9731, 3.6673, 4.5058, 4.0669,\n",
      "         4.6604, 4.5515, 3.3525, 3.8834, 2.6404]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0481, 0.0411, 0.0405, 0.0392, 0.0385, 0.0425, 0.0404, 0.0445, 0.0471,\n",
      "        0.0409, 0.0292, 0.0267, 0.0253, 0.0429, 0.0374, 0.0469, 0.0370, 0.0419,\n",
      "        0.0314, 0.0477, 0.0434, 0.0406, 0.0478, 0.0379, 0.0389, 0.0468, 0.0439,\n",
      "        0.0486, 0.0470, 0.0344, 0.0399, 0.0256], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0501, 0.0499], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.2322, -0.0661,  0.0000],\n",
      "        [ 0.2247, -0.0789,  0.0000],\n",
      "        [ 0.2520, -0.0543,  0.0000],\n",
      "        [ 0.2033, -0.0325,  0.0000],\n",
      "        [ 0.1808, -0.0251,  0.0000],\n",
      "        [ 0.2665, -0.0488,  0.0000],\n",
      "        [ 0.2187,  0.0077,  0.0000],\n",
      "        [ 0.2207, -0.0596,  0.0000],\n",
      "        [ 0.2637, -0.0510,  0.0000],\n",
      "        [ 0.1805,  0.0097,  0.0000],\n",
      "        [ 0.1142, -0.0346,  0.0000],\n",
      "        [ 0.1184,  0.0087,  0.0000],\n",
      "        [ 0.1077, -0.0526,  0.0000],\n",
      "        [ 0.2515, -0.0182,  0.0000],\n",
      "        [ 0.2287,  0.0132,  0.0000],\n",
      "        [ 0.2217, -0.0815,  0.0000],\n",
      "        [ 0.1998,  0.0058,  0.0000],\n",
      "        [ 0.1711, -0.0315,  0.0000],\n",
      "        [ 0.1523, -0.0898,  0.0000],\n",
      "        [ 0.2847, -0.0239,  0.0000],\n",
      "        [ 0.2209, -0.0155,  0.0000],\n",
      "        [ 0.1874, -0.0391,  0.0000],\n",
      "        [ 0.2414, -0.0957,  0.0000],\n",
      "        [ 0.2037,  0.0100,  0.0000],\n",
      "        [ 0.2308, -0.0454,  0.0000],\n",
      "        [ 0.2681, -0.0246,  0.0000],\n",
      "        [ 0.2212, -0.0413,  0.0000],\n",
      "        [ 0.2750, -0.0173,  0.0000],\n",
      "        [ 0.2727, -0.0658,  0.0000],\n",
      "        [ 0.1948, -0.0942,  0.0000],\n",
      "        [ 0.1820, -0.0291,  0.0000],\n",
      "        [ 0.1497, -0.0443,  0.0000]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[5.0532, 4.4796, 4.3129, 4.2296, 4.1061, 4.3435, 4.0194, 4.5879, 4.7361,\n",
      "         4.0398, 3.0837, 2.8413, 2.6222, 4.3043, 4.0648, 4.8317, 3.9849, 4.5196,\n",
      "         3.1314, 4.7361, 4.4481, 4.5830, 4.9705, 4.1857, 3.9678, 4.7540, 4.5062,\n",
      "         5.2695, 4.8255, 3.6095, 4.1550, 2.5330],\n",
      "        [5.0463, 4.4573, 4.1659, 3.9580, 3.9371, 4.3509, 3.9841, 4.6729, 4.6980,\n",
      "         4.1549, 2.9266, 2.6230, 2.6339, 4.3554, 3.8314, 4.8626, 3.8518, 4.3540,\n",
      "         3.2923, 4.7396, 4.4225, 4.2383, 5.0832, 4.1338, 3.8181, 4.6871, 4.2318,\n",
      "         4.8476, 4.7350, 3.4889, 4.0418, 2.7469]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0491, 0.0419, 0.0413, 0.0400, 0.0393, 0.0433, 0.0411, 0.0454, 0.0480,\n",
      "        0.0416, 0.0298, 0.0274, 0.0258, 0.0437, 0.0381, 0.0478, 0.0377, 0.0428,\n",
      "        0.0320, 0.0486, 0.0443, 0.0414, 0.0487, 0.0386, 0.0397, 0.0477, 0.0448,\n",
      "        0.0495, 0.0479, 0.0351, 0.0407, 0.0261], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0511, 0.0508], grad_fn=<MeanBackward1>)\n",
      "Epoch 10/10, Accuracy: 0.5375\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.1519,  0.0420,  0.0000],\n",
      "        [ 0.1386,  0.0359,  0.0000],\n",
      "        [ 0.1153, -0.0128,  0.0000],\n",
      "        [ 0.1468,  0.0412,  0.0000],\n",
      "        [ 0.1464, -0.0243,  0.0000],\n",
      "        [ 0.1232,  0.0463,  0.0000],\n",
      "        [ 0.0943, -0.0071,  0.0000],\n",
      "        [ 0.1780,  0.0497,  0.0000],\n",
      "        [ 0.1283,  0.0153,  0.0000],\n",
      "        [ 0.0939, -0.0178,  0.0000],\n",
      "        [ 0.0751,  0.0131,  0.0000],\n",
      "        [ 0.0953,  0.0199,  0.0000],\n",
      "        [ 0.1048,  0.0201,  0.0000],\n",
      "        [ 0.1022, -0.0102,  0.0000],\n",
      "        [ 0.1123,  0.0016,  0.0000],\n",
      "        [ 0.1758,  0.0156,  0.0000],\n",
      "        [ 0.2116,  0.0582,  0.0000],\n",
      "        [ 0.1259,  0.0021,  0.0000],\n",
      "        [ 0.0606,  0.0444,  0.0000],\n",
      "        [ 0.1553,  0.0201,  0.0000],\n",
      "        [ 0.1189,  0.0375,  0.0000],\n",
      "        [ 0.1464,  0.0237,  0.0000],\n",
      "        [ 0.1487, -0.0141,  0.0000],\n",
      "        [ 0.1522, -0.0455,  0.0000],\n",
      "        [ 0.1115, -0.0102,  0.0000],\n",
      "        [ 0.1056,  0.0187,  0.0000],\n",
      "        [ 0.1604,  0.0558,  0.0000],\n",
      "        [ 0.2107,  0.0338,  0.0000],\n",
      "        [ 0.1180, -0.0426,  0.0000],\n",
      "        [ 0.0699,  0.0355,  0.0000],\n",
      "        [ 0.1403,  0.0151,  0.0000],\n",
      "        [ 0.0415,  0.0347,  0.0000]])\n",
      "Layer 1: tensor([[5.2581, 4.6620, 4.4880, 4.4009, 4.2752, 4.5179, 4.1866, 4.7732, 4.9297,\n",
      "         4.2062, 3.2074, 2.9537, 2.7313, 4.4809, 4.2320, 5.0274, 4.1468, 4.7007,\n",
      "         3.2596, 4.9291, 4.6287, 4.7682, 5.1724, 4.3575, 4.1296, 4.9470, 4.6880,\n",
      "         5.4835, 5.0222, 3.7575, 4.3249, 2.6378],\n",
      "        [5.2504, 4.6381, 4.3352, 4.1174, 4.0990, 4.5276, 4.1495, 4.8612, 4.8895,\n",
      "         4.3265, 3.0430, 2.7256, 2.7430, 4.5331, 3.9894, 5.0592, 4.0083, 4.5280,\n",
      "         3.4271, 4.9324, 4.6019, 4.4082, 5.2893, 4.3032, 3.9742, 4.8773, 4.4017,\n",
      "         5.0441, 4.9279, 3.6311, 4.2070, 2.8593]])\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0500, 0.0427, 0.0422, 0.0408, 0.0401, 0.0442, 0.0420, 0.0463, 0.0490,\n",
      "        0.0425, 0.0303, 0.0279, 0.0264, 0.0446, 0.0389, 0.0488, 0.0384, 0.0435,\n",
      "        0.0327, 0.0496, 0.0451, 0.0422, 0.0497, 0.0394, 0.0406, 0.0487, 0.0456,\n",
      "        0.0505, 0.0489, 0.0359, 0.0415, 0.0267])\n",
      "Layer 1: tensor([0.0521, 0.0518])\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.2012, -0.0240,  0.0000],\n",
      "        [ 0.1445, -0.0471,  0.0000],\n",
      "        [ 0.1000, -0.0289,  0.0000],\n",
      "        [ 0.1132,  0.0012,  0.0000],\n",
      "        [ 0.1670, -0.0484,  0.0000],\n",
      "        [ 0.1597, -0.0329,  0.0000],\n",
      "        [ 0.1840,  0.0410,  0.0000],\n",
      "        [ 0.1385,  0.0527,  0.0000],\n",
      "        [ 0.1748, -0.0221,  0.0000],\n",
      "        [ 0.1546, -0.0066,  0.0000],\n",
      "        [ 0.0722, -0.0267,  0.0000],\n",
      "        [ 0.0659,  0.0336,  0.0000],\n",
      "        [ 0.1055,  0.0025,  0.0000],\n",
      "        [ 0.1245,  0.0289,  0.0000],\n",
      "        [ 0.1458,  0.0356,  0.0000],\n",
      "        [ 0.1310, -0.0195,  0.0000],\n",
      "        [ 0.1614,  0.0022,  0.0000],\n",
      "        [ 0.1107, -0.0041,  0.0000],\n",
      "        [ 0.0949, -0.0120,  0.0000],\n",
      "        [ 0.2342, -0.0106,  0.0000],\n",
      "        [ 0.1507,  0.0053,  0.0000],\n",
      "        [ 0.0784, -0.0295,  0.0000],\n",
      "        [ 0.1306, -0.0244,  0.0000],\n",
      "        [ 0.1294, -0.0053,  0.0000],\n",
      "        [ 0.1084, -0.0104,  0.0000],\n",
      "        [ 0.1591, -0.0228,  0.0000],\n",
      "        [ 0.1035, -0.0187,  0.0000],\n",
      "        [ 0.1611,  0.0213,  0.0000],\n",
      "        [ 0.2134, -0.0436,  0.0000],\n",
      "        [ 0.1768, -0.0127,  0.0000],\n",
      "        [ 0.1027, -0.0161,  0.0000],\n",
      "        [ 0.1420, -0.0334,  0.0000]])\n",
      "Layer 1: tensor([[5.4723, 4.8514, 4.6697, 4.5796, 4.4491, 4.7043, 4.3562, 4.9681, 5.1289,\n",
      "         4.3758, 3.3374, 3.0758, 2.8440, 4.6613, 4.4031, 5.2322, 4.3176, 4.8931,\n",
      "         3.3933, 5.1274, 4.8166, 4.9634, 5.3829, 4.5344, 4.2989, 5.1474, 4.8799,\n",
      "         5.7069, 5.2260, 3.9124, 4.5010, 2.7421],\n",
      "        [5.4638, 4.8263, 4.5099, 4.2836, 4.2656, 4.7126, 4.3177, 5.0595, 5.0865,\n",
      "         4.5011, 3.1672, 2.8363, 2.8553, 4.7154, 4.1502, 5.2648, 4.1734, 4.7127,\n",
      "         3.5663, 5.1304, 4.7885, 4.5893, 5.5045, 4.4774, 4.1362, 5.0741, 4.5814,\n",
      "         5.2490, 5.1274, 3.7795, 4.3780, 2.9733]])\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0511, 0.0436, 0.0430, 0.0416, 0.0409, 0.0451, 0.0429, 0.0472, 0.0499,\n",
      "        0.0433, 0.0309, 0.0285, 0.0270, 0.0455, 0.0396, 0.0498, 0.0392, 0.0444,\n",
      "        0.0334, 0.0506, 0.0460, 0.0431, 0.0507, 0.0402, 0.0414, 0.0497, 0.0466,\n",
      "        0.0515, 0.0499, 0.0366, 0.0424, 0.0272])\n",
      "Layer 1: tensor([0.0531, 0.0528])\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0340,  0.0122,  0.0000],\n",
      "        [ 0.0318,  0.0105,  0.0000],\n",
      "        [ 0.0067, -0.0036,  0.0000],\n",
      "        [ 0.0389,  0.0185,  0.0000],\n",
      "        [ 0.0237,  0.0015,  0.0000],\n",
      "        [ 0.0334,  0.0091,  0.0000],\n",
      "        [ 0.0329,  0.0094,  0.0000],\n",
      "        [ 0.0348,  0.0119,  0.0000],\n",
      "        [ 0.0407,  0.0074,  0.0000],\n",
      "        [ 0.0339,  0.0102,  0.0000],\n",
      "        [ 0.0286,  0.0058,  0.0000],\n",
      "        [ 0.0111,  0.0010,  0.0000],\n",
      "        [ 0.0152, -0.0005,  0.0000],\n",
      "        [ 0.0400,  0.0080,  0.0000],\n",
      "        [ 0.0281,  0.0056,  0.0000],\n",
      "        [ 0.0450,  0.0074,  0.0000],\n",
      "        [ 0.0290,  0.0079,  0.0000],\n",
      "        [ 0.0370,  0.0060,  0.0000],\n",
      "        [ 0.0233,  0.0020,  0.0000],\n",
      "        [ 0.0526,  0.0166,  0.0000],\n",
      "        [ 0.0308,  0.0047,  0.0000],\n",
      "        [ 0.0427, -0.0014,  0.0000],\n",
      "        [ 0.0284,  0.0002,  0.0000],\n",
      "        [ 0.0237, -0.0034,  0.0000],\n",
      "        [ 0.0213,  0.0079,  0.0000],\n",
      "        [ 0.0576,  0.0095,  0.0000],\n",
      "        [ 0.0297,  0.0131,  0.0000],\n",
      "        [ 0.0388,  0.0086,  0.0000],\n",
      "        [ 0.0418,  0.0098,  0.0000],\n",
      "        [ 0.0244, -0.0068,  0.0000],\n",
      "        [ 0.0264,  0.0072,  0.0000],\n",
      "        [ 0.0224,  0.0032,  0.0000]])\n",
      "Layer 1: tensor([[0.1036, 0.1020, 0.0780, 0.1125, 0.0952, 0.1110, 0.0874, 0.1025, 0.0810,\n",
      "         0.0994, 0.1081, 0.0752, 0.0813, 0.1107, 0.0812, 0.0958, 0.0916, 0.1118,\n",
      "         0.0901, 0.1315, 0.0950, 0.1092, 0.0673, 0.0623, 0.1017, 0.1005, 0.0888,\n",
      "         0.1034, 0.1100, 0.0879, 0.1099, 0.0958],\n",
      "        [0.1085, 0.1035, 0.0732, 0.1209, 0.0936, 0.1117, 0.0939, 0.1094, 0.0887,\n",
      "         0.1079, 0.1237, 0.0824, 0.0842, 0.1141, 0.0866, 0.1003, 0.0969, 0.1201,\n",
      "         0.0978, 0.1435, 0.1015, 0.1137, 0.0736, 0.0677, 0.1031, 0.1184, 0.0935,\n",
      "         0.1212, 0.1222, 0.0937, 0.1106, 0.1006]])\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0070, 0.0064, 0.0040, 0.0064, 0.0057, 0.0081, 0.0058, 0.0068, 0.0062,\n",
      "        0.0071, 0.0061, 0.0030, 0.0046, 0.0070, 0.0053, 0.0065, 0.0063, 0.0081,\n",
      "        0.0047, 0.0094, 0.0068, 0.0070, 0.0056, 0.0046, 0.0064, 0.0081, 0.0062,\n",
      "        0.0074, 0.0077, 0.0052, 0.0065, 0.0053])\n",
      "Layer 1: tensor([0.0126, 0.0133])\n",
      "Test Accuracy: 0.5450\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from model import EnergyBasedModel as EBM\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_3d_circle_data(center, radius, normal_vector, num_points=100):\n",
    "    \"\"\"\n",
    "    Generate points on a 3D circle with given center, radius, and normal vector.\n",
    "    \n",
    "    Parameters:\n",
    "    - center: 3D coordinates of circle center\n",
    "    - radius: radius of the circle\n",
    "    - normal_vector: normal vector to the circle plane\n",
    "    - num_points: number of points to generate\n",
    "    \n",
    "    Returns:\n",
    "    - points on the circle\n",
    "    \"\"\"\n",
    "    # Normalize the normal vector\n",
    "    normal = np.array(normal_vector)\n",
    "    normal = normal / np.linalg.norm(normal)\n",
    "    \n",
    "    # Find two orthogonal vectors in the circle plane\n",
    "    if np.allclose(normal, [1, 0, 0]):\n",
    "        v1 = np.array([0, 1, 0])\n",
    "    else:\n",
    "        v1 = np.cross(normal, [1, 0, 0])\n",
    "        v1 = v1 / np.linalg.norm(v1)\n",
    "    \n",
    "    v2 = np.cross(normal, v1)\n",
    "    v2 = v2 / np.linalg.norm(v2)\n",
    "    \n",
    "    # Generate circle points\n",
    "    theta = np.linspace(0, 2 * np.pi, num_points)\n",
    "    circle_points = center + radius * (np.outer(np.cos(theta), v1) + np.outer(np.sin(theta), v2))\n",
    "    \n",
    "    return circle_points\n",
    "\n",
    "# Create the dataset\n",
    "def create_circles_dataset(num_points=100):\n",
    "    # Circle 1: centered at the origin, on the xy-plane\n",
    "    center1 = np.array([0, 0, 0])\n",
    "    radius1 = 1.0\n",
    "    normal1 = np.array([0, 0, 1])  # Normal to xy-plane\n",
    "    \n",
    "    # Circle 2: centered at (1,0,0), also on a plane parallel to xy-plane\n",
    "    center2 = np.array([1, 0, 0])\n",
    "    radius2 = 1.0\n",
    "    normal2 = np.array([0, 0, 1])  # Same normal (parallel planes)\n",
    "    \n",
    "    # Generate points\n",
    "    circle1_points = generate_3d_circle_data(center1, radius1, normal1, num_points)\n",
    "    circle2_points = generate_3d_circle_data(center2, radius2, normal2, num_points)\n",
    "    \n",
    "    # Combine into a dataset with labels\n",
    "    X = np.vstack([circle1_points, circle2_points])\n",
    "    y = np.array([0] * num_points + [1] * num_points)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Generate the dataset\n",
    "X, y = create_circles_dataset(num_points=200)\n",
    "\n",
    "# Visualize\n",
    "def visualize_circles(X, y):\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Plot points for each circle\n",
    "    colors = ['blue', 'red']\n",
    "    for i, color in enumerate(colors):\n",
    "        mask = (y == i)\n",
    "        ax.scatter(X[mask, 0], X[mask, 1], X[mask, 2], c=color, s=10, label=f'Circle {i+1}')\n",
    "    \n",
    "    # Add circle centers\n",
    "    centers = [np.array([0, 0, 0]), np.array([1, 0, 0])]\n",
    "    ax.scatter([c[0] for c in centers], [c[1] for c in centers], [c[2] for c in centers], \n",
    "               c='black', s=100, marker='x', label='Centers')\n",
    "    \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title('Two 3D Circles')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the dataset\n",
    "visualize_circles(X, y)\n",
    "\n",
    "# Now you can use this dataset (X, y) for training your model.\n",
    "# Test, train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "import torch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "# Create a DataLoader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# Define the model \n",
    "model_config = {\n",
    "    'input_size': 3,  # 3D input\n",
    "    'hidden_sizes': [32, 2],  # Hidden layer sizes\n",
    "    'beta': 0.1,  # Temperature parameter\n",
    "    'dt': 0.01,   # Step size\n",
    "    'n_steps': 10  # Number of steps\n",
    "}\n",
    "\n",
    "model = EBM(\n",
    "    input_size=model_config['input_size'],\n",
    "    hidden_sizes=model_config['hidden_sizes'],\n",
    "    beta=model_config['beta'],\n",
    "    dt=model_config['dt'],\n",
    "    optimizer=None,  # Optimizer will be set separately\n",
    "    n_steps=model_config['n_steps']\n",
    ")\n",
    "\n",
    "# Define the optimizer\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Set the optimizer in the model\n",
    "model.optimizer = optimizer\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    targets = []\n",
    "    preds = []\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_X)\n",
    "        preds.append(output)\n",
    "        targets.append(batch_y)\n",
    "    accuracy = (torch.cat(preds).argmax(dim=1) == torch.cat(targets)).float().mean()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Accuracy: {accuracy.item():.4f}\")\n",
    "\n",
    "for batch_X, batch_y in test_loader:\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_X)\n",
    "        preds.append(output)\n",
    "        targets.append(batch_y)\n",
    "accuracy = (torch.cat(preds).argmax(dim=1) == torch.cat(targets)).float().mean()\n",
    "print(f\"Test Accuracy: {accuracy.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7462, 0.5635],\n",
       "        [1.0044, 0.5266],\n",
       "        [0.5852, 0.6654],\n",
       "        [0.1369, 0.3500],\n",
       "        [0.3875, 0.5967],\n",
       "        [0.3503, 0.1660],\n",
       "        [0.3257, 0.9605],\n",
       "        [0.5277, 0.1067],\n",
       "        [0.7359, 0.7476],\n",
       "        [0.6065, 1.0038],\n",
       "        [0.4815, 1.0045],\n",
       "        [0.9189, 0.3106],\n",
       "        [0.3412, 0.5391],\n",
       "        [0.5793, 0.8001],\n",
       "        [0.8517, 0.5397],\n",
       "        [0.3919, 0.8106]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
