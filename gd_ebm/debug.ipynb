{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights Gradients:\n",
      "Layer 0: tensor([[-4.0060e-03,  2.3958e-02,  4.0294e-03],\n",
      "        [ 1.9626e-03,  2.5969e-02, -2.8885e-03],\n",
      "        [-4.1703e-04,  4.7406e-02,  5.7480e-03],\n",
      "        [-3.3843e-03,  1.6685e-02, -2.3014e-03],\n",
      "        [-2.7765e-03,  2.3217e-02, -4.4851e-03],\n",
      "        [-3.1357e-03,  2.3314e-02, -4.9952e-04],\n",
      "        [-3.5864e-03,  6.4022e-03,  3.8359e-03],\n",
      "        [-1.3142e-03,  4.3679e-02, -3.6748e-04],\n",
      "        [-3.1691e-03,  1.8501e-02, -5.5160e-03],\n",
      "        [-1.5712e-03,  1.3470e-02, -1.9104e-03],\n",
      "        [-2.1787e-04,  2.2191e-02,  2.4716e-03],\n",
      "        [-1.5098e-03,  2.2268e-02,  2.1091e-03],\n",
      "        [ 1.6197e-05,  3.2930e-02,  1.6083e-03],\n",
      "        [ 1.9306e-03,  4.0845e-02,  3.1541e-03],\n",
      "        [-2.3515e-03,  2.6749e-02, -9.7466e-04],\n",
      "        [-3.4732e-03,  4.7147e-02, -5.3569e-03],\n",
      "        [-8.7757e-04,  4.0728e-02,  6.7479e-03],\n",
      "        [-9.5380e-04,  4.2798e-02,  3.1548e-03],\n",
      "        [-9.2534e-04,  4.9759e-02, -4.3193e-04],\n",
      "        [-4.0387e-03,  1.7009e-02,  3.9703e-04],\n",
      "        [-3.5707e-04,  2.9750e-02,  2.0970e-03],\n",
      "        [-1.6682e-05,  3.6361e-02,  5.4083e-03],\n",
      "        [-2.5181e-03,  3.3616e-02,  2.3775e-03],\n",
      "        [ 1.0726e-04,  3.1701e-02,  3.1986e-03],\n",
      "        [-2.3724e-03,  3.6755e-02, -4.8404e-03],\n",
      "        [-1.5129e-03,  2.9442e-02,  2.9950e-03],\n",
      "        [ 1.7248e-05,  2.3678e-02, -4.5613e-03],\n",
      "        [-5.8374e-03,  3.1087e-02,  1.9994e-03],\n",
      "        [-2.2654e-03,  4.0519e-02, -1.6569e-03],\n",
      "        [-5.6414e-03,  3.0470e-02, -1.8800e-03],\n",
      "        [-6.5837e-04,  3.6214e-02,  2.2943e-03],\n",
      "        [-4.0763e-03,  2.2592e-02, -5.2868e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0490, 0.0507, 0.0757, 0.0378, 0.0460, 0.0478, 0.0395, 0.0681, 0.0518,\n",
      "         0.0442, 0.0431, 0.0508, 0.0606, 0.0548, 0.0644, 0.0671, 0.0751, 0.0634,\n",
      "         0.0802, 0.0452, 0.0594, 0.0579, 0.0665, 0.0646, 0.0732, 0.0595, 0.0528,\n",
      "         0.0652, 0.0626, 0.0603, 0.0646, 0.0573],\n",
      "        [0.0418, 0.0398, 0.0598, 0.0305, 0.0409, 0.0436, 0.0345, 0.0593, 0.0389,\n",
      "         0.0319, 0.0466, 0.0397, 0.0450, 0.0485, 0.0498, 0.0593, 0.0579, 0.0499,\n",
      "         0.0700, 0.0370, 0.0490, 0.0511, 0.0470, 0.0530, 0.0488, 0.0465, 0.0429,\n",
      "         0.0530, 0.0480, 0.0452, 0.0481, 0.0384]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0045, 0.0042, 0.0076, 0.0023, 0.0043, 0.0040, 0.0024, 0.0078, 0.0035,\n",
      "        0.0028, 0.0042, 0.0047, 0.0051, 0.0059, 0.0050, 0.0067, 0.0075, 0.0070,\n",
      "        0.0081, 0.0035, 0.0058, 0.0067, 0.0058, 0.0057, 0.0062, 0.0052, 0.0049,\n",
      "        0.0054, 0.0062, 0.0048, 0.0058, 0.0040], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0064, 0.0041], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0023,  0.0290, -0.0059],\n",
      "        [ 0.0021,  0.0221, -0.0066],\n",
      "        [ 0.0008,  0.0491, -0.0093],\n",
      "        [ 0.0019,  0.0078,  0.0013],\n",
      "        [ 0.0012,  0.0290, -0.0095],\n",
      "        [-0.0007,  0.0198, -0.0052],\n",
      "        [-0.0008,  0.0170, -0.0049],\n",
      "        [ 0.0047,  0.0455, -0.0131],\n",
      "        [ 0.0019,  0.0176, -0.0071],\n",
      "        [-0.0038,  0.0196, -0.0101],\n",
      "        [-0.0035,  0.0244, -0.0061],\n",
      "        [-0.0014,  0.0319, -0.0098],\n",
      "        [ 0.0032,  0.0312, -0.0079],\n",
      "        [-0.0002,  0.0332, -0.0089],\n",
      "        [ 0.0040,  0.0276, -0.0110],\n",
      "        [ 0.0041,  0.0406, -0.0126],\n",
      "        [ 0.0029,  0.0489, -0.0130],\n",
      "        [ 0.0043,  0.0437, -0.0089],\n",
      "        [ 0.0020,  0.0579, -0.0156],\n",
      "        [-0.0041,  0.0216, -0.0032],\n",
      "        [ 0.0010,  0.0368, -0.0021],\n",
      "        [ 0.0047,  0.0463, -0.0062],\n",
      "        [ 0.0056,  0.0485, -0.0107],\n",
      "        [ 0.0010,  0.0272, -0.0084],\n",
      "        [ 0.0031,  0.0345, -0.0072],\n",
      "        [ 0.0035,  0.0389, -0.0098],\n",
      "        [-0.0021,  0.0337, -0.0110],\n",
      "        [ 0.0052,  0.0371, -0.0107],\n",
      "        [ 0.0072,  0.0352, -0.0099],\n",
      "        [ 0.0038,  0.0335, -0.0082],\n",
      "        [ 0.0013,  0.0376, -0.0063],\n",
      "        [ 0.0043,  0.0217, -0.0077]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0508, 0.0537, 0.0793, 0.0392, 0.0481, 0.0507, 0.0410, 0.0723, 0.0547,\n",
      "         0.0470, 0.0446, 0.0531, 0.0627, 0.0576, 0.0668, 0.0710, 0.0784, 0.0657,\n",
      "         0.0842, 0.0463, 0.0620, 0.0606, 0.0695, 0.0669, 0.0765, 0.0633, 0.0541,\n",
      "         0.0684, 0.0657, 0.0631, 0.0675, 0.0593],\n",
      "        [0.0431, 0.0422, 0.0623, 0.0317, 0.0425, 0.0462, 0.0359, 0.0624, 0.0413,\n",
      "         0.0342, 0.0481, 0.0414, 0.0461, 0.0505, 0.0514, 0.0625, 0.0601, 0.0512,\n",
      "         0.0730, 0.0378, 0.0509, 0.0531, 0.0489, 0.0546, 0.0509, 0.0495, 0.0435,\n",
      "         0.0555, 0.0502, 0.0472, 0.0499, 0.0396]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0046, 0.0044, 0.0077, 0.0024, 0.0044, 0.0042, 0.0025, 0.0080, 0.0037,\n",
      "        0.0030, 0.0043, 0.0048, 0.0051, 0.0060, 0.0050, 0.0069, 0.0076, 0.0070,\n",
      "        0.0082, 0.0035, 0.0059, 0.0068, 0.0059, 0.0057, 0.0064, 0.0054, 0.0048,\n",
      "        0.0055, 0.0063, 0.0049, 0.0058, 0.0040], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0065, 0.0043], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-9.7690e-04,  1.7130e-02, -7.4249e-04],\n",
      "        [-3.2588e-03,  1.7142e-03, -6.4968e-03],\n",
      "        [-4.6176e-03,  2.8431e-02, -4.5444e-03],\n",
      "        [-4.8286e-03,  1.6342e-02,  2.5697e-03],\n",
      "        [ 1.0857e-03,  2.1409e-02, -3.4412e-03],\n",
      "        [-7.6030e-03,  4.6042e-03, -8.0786e-03],\n",
      "        [-2.2350e-03,  5.4551e-04, -2.3380e-03],\n",
      "        [-5.1611e-05,  2.6236e-02, -3.9275e-03],\n",
      "        [-1.3931e-03,  1.5073e-02, -2.1416e-03],\n",
      "        [-1.1458e-04,  1.0452e-02, -2.8062e-03],\n",
      "        [-1.8289e-03,  6.5755e-03, -1.9384e-03],\n",
      "        [-5.4710e-03,  1.7160e-02, -6.3256e-03],\n",
      "        [-1.3898e-03,  1.6578e-02, -2.8834e-03],\n",
      "        [ 2.1180e-03,  2.2705e-02, -3.3767e-03],\n",
      "        [-6.8754e-03,  2.2732e-02,  1.9240e-03],\n",
      "        [-3.5135e-03,  2.2447e-02, -2.0114e-03],\n",
      "        [ 4.5070e-04,  3.0757e-02, -4.1046e-03],\n",
      "        [-4.6201e-04,  3.1965e-02, -2.2137e-03],\n",
      "        [-3.1573e-03,  2.6061e-02, -2.9643e-03],\n",
      "        [ 8.4747e-04,  9.2936e-03, -3.2615e-03],\n",
      "        [-3.9932e-03,  1.3845e-02, -2.4866e-03],\n",
      "        [ 4.9923e-04,  2.3424e-02, -2.4988e-03],\n",
      "        [-5.2376e-03,  1.6520e-02, -2.6182e-03],\n",
      "        [-5.5370e-03,  1.9261e-02, -4.2053e-03],\n",
      "        [-5.1537e-03,  1.9533e-02, -5.9615e-05],\n",
      "        [-1.9416e-03,  1.9250e-02, -6.5464e-03],\n",
      "        [-9.3111e-04,  1.6186e-02, -1.7147e-03],\n",
      "        [-4.1181e-03,  1.5256e-02,  6.1078e-04],\n",
      "        [-2.3400e-03,  2.1872e-02, -3.6915e-03],\n",
      "        [ 3.2163e-04,  9.6510e-03,  2.6655e-03],\n",
      "        [-9.9900e-04,  1.6590e-02, -1.6497e-03],\n",
      "        [-3.8270e-04,  1.9976e-02, -3.0774e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0539, 0.0556, 0.0830, 0.0416, 0.0507, 0.0526, 0.0438, 0.0744, 0.0574,\n",
      "         0.0488, 0.0482, 0.0560, 0.0664, 0.0600, 0.0707, 0.0733, 0.0822, 0.0693,\n",
      "         0.0873, 0.0498, 0.0655, 0.0631, 0.0721, 0.0712, 0.0804, 0.0650, 0.0584,\n",
      "         0.0715, 0.0689, 0.0662, 0.0708, 0.0629],\n",
      "        [0.0453, 0.0435, 0.0647, 0.0332, 0.0445, 0.0476, 0.0383, 0.0640, 0.0435,\n",
      "         0.0360, 0.0515, 0.0435, 0.0486, 0.0522, 0.0541, 0.0637, 0.0628, 0.0539,\n",
      "         0.0751, 0.0404, 0.0537, 0.0551, 0.0495, 0.0579, 0.0535, 0.0503, 0.0468,\n",
      "         0.0578, 0.0525, 0.0494, 0.0521, 0.0419]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0047, 0.0044, 0.0078, 0.0025, 0.0045, 0.0042, 0.0027, 0.0080, 0.0039,\n",
      "        0.0031, 0.0045, 0.0049, 0.0053, 0.0061, 0.0052, 0.0068, 0.0078, 0.0071,\n",
      "        0.0082, 0.0037, 0.0061, 0.0069, 0.0059, 0.0060, 0.0065, 0.0053, 0.0051,\n",
      "        0.0056, 0.0065, 0.0050, 0.0059, 0.0042], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0067, 0.0044], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0015,  0.0283,  0.0051],\n",
      "        [ 0.0081,  0.0277,  0.0069],\n",
      "        [ 0.0036,  0.0551, -0.0015],\n",
      "        [ 0.0002,  0.0127, -0.0009],\n",
      "        [-0.0015,  0.0341,  0.0013],\n",
      "        [ 0.0069,  0.0222, -0.0010],\n",
      "        [-0.0002,  0.0106,  0.0045],\n",
      "        [ 0.0116,  0.0488, -0.0031],\n",
      "        [ 0.0055,  0.0204, -0.0049],\n",
      "        [ 0.0011,  0.0047, -0.0038],\n",
      "        [-0.0026,  0.0244,  0.0036],\n",
      "        [ 0.0005,  0.0280, -0.0004],\n",
      "        [ 0.0093,  0.0347,  0.0002],\n",
      "        [ 0.0073,  0.0419, -0.0037],\n",
      "        [-0.0026,  0.0349,  0.0028],\n",
      "        [ 0.0049,  0.0522, -0.0031],\n",
      "        [ 0.0059,  0.0506,  0.0010],\n",
      "        [ 0.0077,  0.0558, -0.0007],\n",
      "        [ 0.0075,  0.0516,  0.0001],\n",
      "        [-0.0006,  0.0261, -0.0015],\n",
      "        [ 0.0066,  0.0374,  0.0019],\n",
      "        [ 0.0093,  0.0467, -0.0003],\n",
      "        [ 0.0064,  0.0440,  0.0024],\n",
      "        [ 0.0067,  0.0287, -0.0016],\n",
      "        [ 0.0112,  0.0362, -0.0033],\n",
      "        [ 0.0001,  0.0478, -0.0022],\n",
      "        [ 0.0029,  0.0349, -0.0009],\n",
      "        [ 0.0016,  0.0364,  0.0005],\n",
      "        [ 0.0103,  0.0475, -0.0011],\n",
      "        [ 0.0060,  0.0284, -0.0059],\n",
      "        [ 0.0055,  0.0387,  0.0022],\n",
      "        [ 0.0064,  0.0278,  0.0011]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0562, 0.0586, 0.0876, 0.0423, 0.0528, 0.0550, 0.0448, 0.0798, 0.0592,\n",
      "         0.0509, 0.0495, 0.0585, 0.0694, 0.0633, 0.0734, 0.0775, 0.0869, 0.0736,\n",
      "         0.0927, 0.0509, 0.0689, 0.0676, 0.0761, 0.0739, 0.0841, 0.0687, 0.0600,\n",
      "         0.0750, 0.0726, 0.0691, 0.0744, 0.0648],\n",
      "        [0.0474, 0.0457, 0.0681, 0.0345, 0.0465, 0.0500, 0.0395, 0.0677, 0.0450,\n",
      "         0.0371, 0.0531, 0.0454, 0.0508, 0.0550, 0.0564, 0.0674, 0.0659, 0.0565,\n",
      "         0.0793, 0.0418, 0.0560, 0.0580, 0.0529, 0.0602, 0.0559, 0.0533, 0.0485,\n",
      "         0.0605, 0.0550, 0.0515, 0.0547, 0.0435]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0048, 0.0045, 0.0081, 0.0024, 0.0046, 0.0043, 0.0026, 0.0083, 0.0038,\n",
      "        0.0031, 0.0045, 0.0050, 0.0054, 0.0063, 0.0052, 0.0071, 0.0080, 0.0074,\n",
      "        0.0086, 0.0037, 0.0062, 0.0072, 0.0061, 0.0060, 0.0066, 0.0055, 0.0051,\n",
      "        0.0057, 0.0066, 0.0051, 0.0061, 0.0042], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0069, 0.0045], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-3.2006e-03,  2.0955e-02, -2.0346e-04],\n",
      "        [-2.1696e-03,  9.1492e-03,  8.6533e-03],\n",
      "        [-5.1740e-03,  4.3007e-02, -1.3469e-03],\n",
      "        [-2.1587e-03,  1.4653e-02, -3.8228e-03],\n",
      "        [ 2.3349e-03,  2.4643e-02,  4.2518e-04],\n",
      "        [-5.6098e-03,  1.6884e-02,  3.1484e-03],\n",
      "        [-3.1368e-03,  9.4059e-03,  2.2503e-03],\n",
      "        [-2.6770e-03,  4.3385e-02, -4.5327e-03],\n",
      "        [-1.6817e-04,  1.4608e-02, -1.8167e-03],\n",
      "        [ 3.8116e-03,  1.3049e-02, -4.4865e-03],\n",
      "        [-5.1356e-03,  2.2823e-02,  4.2787e-03],\n",
      "        [-2.2151e-03,  3.0490e-02,  3.0059e-03],\n",
      "        [-3.0356e-03,  2.2455e-02, -6.6393e-04],\n",
      "        [ 2.1810e-03,  3.4569e-02, -2.5608e-03],\n",
      "        [-3.9486e-03,  2.1544e-02, -2.6637e-03],\n",
      "        [ 8.5064e-04,  3.1168e-02, -2.0793e-03],\n",
      "        [-1.0663e-03,  4.2853e-02, -6.4468e-05],\n",
      "        [-6.9561e-04,  3.7543e-02,  1.2768e-03],\n",
      "        [ 5.1884e-04,  3.6351e-02, -2.6364e-03],\n",
      "        [-7.9150e-04,  1.7005e-02,  2.0728e-03],\n",
      "        [-6.0507e-06,  2.0975e-02,  2.5787e-03],\n",
      "        [ 3.6785e-03,  3.0512e-02,  2.5463e-03],\n",
      "        [-4.1049e-03,  2.8287e-02, -4.3533e-04],\n",
      "        [-9.1789e-04,  2.8584e-02,  1.8070e-03],\n",
      "        [-1.3036e-03,  2.9993e-02, -1.6785e-03],\n",
      "        [ 5.7560e-04,  3.0749e-02,  3.4932e-03],\n",
      "        [ 8.4649e-05,  2.5018e-02, -1.4194e-03],\n",
      "        [-4.1973e-03,  2.6619e-02,  8.2845e-04],\n",
      "        [ 1.5229e-03,  2.8500e-02,  3.6810e-03],\n",
      "        [ 2.1255e-03,  2.7155e-02, -7.4565e-03],\n",
      "        [ 1.0813e-03,  2.3635e-02,  1.8472e-03],\n",
      "        [-1.3569e-03,  1.5813e-02, -7.8105e-04]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0592, 0.0613, 0.0916, 0.0449, 0.0556, 0.0578, 0.0475, 0.0829, 0.0625,\n",
      "         0.0534, 0.0526, 0.0614, 0.0726, 0.0662, 0.0771, 0.0811, 0.0906, 0.0765,\n",
      "         0.0964, 0.0540, 0.0722, 0.0700, 0.0794, 0.0777, 0.0882, 0.0719, 0.0636,\n",
      "         0.0785, 0.0760, 0.0725, 0.0778, 0.0683],\n",
      "        [0.0496, 0.0477, 0.0711, 0.0362, 0.0486, 0.0523, 0.0414, 0.0705, 0.0472,\n",
      "         0.0389, 0.0557, 0.0476, 0.0531, 0.0574, 0.0590, 0.0703, 0.0687, 0.0590,\n",
      "         0.0825, 0.0438, 0.0586, 0.0604, 0.0551, 0.0630, 0.0585, 0.0556, 0.0509,\n",
      "         0.0632, 0.0575, 0.0539, 0.0571, 0.0456]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0049, 0.0046, 0.0082, 0.0025, 0.0047, 0.0044, 0.0027, 0.0084, 0.0040,\n",
      "        0.0032, 0.0047, 0.0051, 0.0055, 0.0064, 0.0054, 0.0072, 0.0081, 0.0075,\n",
      "        0.0087, 0.0039, 0.0063, 0.0072, 0.0062, 0.0062, 0.0068, 0.0056, 0.0053,\n",
      "        0.0058, 0.0067, 0.0053, 0.0062, 0.0044], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0071, 0.0047], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 3.1031e-03,  2.9380e-02,  6.0966e-03],\n",
      "        [ 5.1174e-03,  1.8995e-02,  6.9644e-03],\n",
      "        [ 4.8922e-03,  4.8124e-02,  5.0736e-03],\n",
      "        [ 1.5537e-03,  1.5614e-02, -7.0161e-04],\n",
      "        [ 1.1687e-03,  1.8015e-02,  1.7453e-03],\n",
      "        [ 5.9298e-03,  2.3179e-02,  5.5439e-03],\n",
      "        [-3.7469e-03,  9.4441e-03,  3.5371e-03],\n",
      "        [ 4.3576e-03,  5.3860e-02,  8.5852e-03],\n",
      "        [ 4.9145e-03,  1.7722e-02,  4.8736e-03],\n",
      "        [ 3.5129e-03,  1.5157e-02,  4.9230e-03],\n",
      "        [ 1.3739e-04,  2.1905e-02,  7.1203e-03],\n",
      "        [-1.7294e-04,  3.3838e-02,  3.9171e-03],\n",
      "        [ 2.4557e-03,  3.1527e-02, -1.0296e-05],\n",
      "        [ 5.8706e-03,  4.5812e-02,  8.2762e-03],\n",
      "        [-3.4291e-04,  2.5112e-02,  3.3171e-03],\n",
      "        [ 4.6611e-03,  4.0419e-02,  2.0766e-03],\n",
      "        [ 3.2855e-03,  4.9593e-02,  8.8801e-03],\n",
      "        [ 3.6184e-03,  5.5431e-02,  4.9267e-03],\n",
      "        [ 6.2137e-03,  5.0643e-02,  7.8490e-03],\n",
      "        [-4.6143e-03,  2.1026e-02,  3.2900e-03],\n",
      "        [ 5.2864e-03,  3.1402e-02,  6.7931e-03],\n",
      "        [ 6.9046e-03,  4.4939e-02,  1.0647e-02],\n",
      "        [ 9.7593e-05,  4.4766e-02,  7.5238e-03],\n",
      "        [ 5.0706e-03,  3.4393e-02,  4.9564e-03],\n",
      "        [ 1.4896e-03,  3.8526e-02,  8.0079e-03],\n",
      "        [ 1.9791e-03,  2.9841e-02,  1.6780e-03],\n",
      "        [-4.4046e-03,  2.4881e-02,  4.9041e-03],\n",
      "        [ 2.4067e-03,  3.2536e-02,  4.3674e-03],\n",
      "        [ 7.9729e-03,  4.5243e-02,  6.0635e-03],\n",
      "        [ 1.7772e-03,  2.3290e-02,  7.1111e-03],\n",
      "        [ 3.3495e-03,  3.3447e-02,  5.6951e-03],\n",
      "        [-2.9842e-04,  2.0628e-02,  7.9483e-04]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0623, 0.0640, 0.0968, 0.0464, 0.0583, 0.0601, 0.0489, 0.0878, 0.0644,\n",
      "         0.0551, 0.0548, 0.0644, 0.0766, 0.0699, 0.0809, 0.0855, 0.0957, 0.0815,\n",
      "         0.1021, 0.0563, 0.0761, 0.0747, 0.0840, 0.0815, 0.0924, 0.0751, 0.0667,\n",
      "         0.0822, 0.0800, 0.0757, 0.0819, 0.0712],\n",
      "        [0.0517, 0.0500, 0.0746, 0.0371, 0.0505, 0.0545, 0.0427, 0.0748, 0.0489,\n",
      "         0.0407, 0.0577, 0.0497, 0.0554, 0.0602, 0.0613, 0.0738, 0.0723, 0.0623,\n",
      "         0.0869, 0.0450, 0.0614, 0.0640, 0.0576, 0.0655, 0.0611, 0.0584, 0.0524,\n",
      "         0.0661, 0.0603, 0.0562, 0.0598, 0.0470]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0050, 0.0047, 0.0084, 0.0025, 0.0048, 0.0044, 0.0027, 0.0086, 0.0040,\n",
      "        0.0032, 0.0047, 0.0052, 0.0057, 0.0065, 0.0055, 0.0073, 0.0083, 0.0077,\n",
      "        0.0089, 0.0039, 0.0065, 0.0075, 0.0064, 0.0063, 0.0069, 0.0057, 0.0054,\n",
      "        0.0060, 0.0069, 0.0054, 0.0064, 0.0044], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0073, 0.0048], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-3.8983e-03,  3.2714e-02, -2.2698e-04],\n",
      "        [-2.9265e-04,  2.6050e-02, -4.2845e-03],\n",
      "        [-5.4378e-03,  5.2457e-02, -5.8054e-03],\n",
      "        [-6.4390e-04,  1.2483e-02, -1.3283e-03],\n",
      "        [ 1.7370e-03,  2.6540e-02, -2.9110e-03],\n",
      "        [ 5.7392e-04,  2.6111e-02, -6.9660e-03],\n",
      "        [-2.6105e-03,  2.6991e-03, -5.3112e-04],\n",
      "        [-3.1181e-03,  4.9939e-02, -6.2892e-03],\n",
      "        [ 1.3461e-03,  2.0414e-02, -4.8206e-03],\n",
      "        [ 9.6855e-04,  1.4736e-02,  1.8203e-03],\n",
      "        [-4.6581e-03,  2.7341e-02, -2.8131e-03],\n",
      "        [-3.1458e-03,  2.6442e-02, -1.4301e-03],\n",
      "        [-1.5424e-03,  2.9630e-02, -2.6274e-03],\n",
      "        [-2.6581e-03,  3.9223e-02, -3.1800e-03],\n",
      "        [-1.7256e-03,  3.1884e-02,  1.0827e-03],\n",
      "        [ 2.2072e-04,  5.4780e-02, -2.2106e-03],\n",
      "        [-5.4209e-03,  4.9961e-02, -1.4105e-03],\n",
      "        [-5.1388e-03,  4.2007e-02, -1.1718e-03],\n",
      "        [-4.4269e-04,  5.4496e-02, -3.6823e-03],\n",
      "        [ 9.0482e-04,  2.0109e-02, -3.1013e-03],\n",
      "        [-1.8964e-03,  4.4953e-02, -6.2749e-03],\n",
      "        [-4.2180e-03,  4.5039e-02, -5.8069e-03],\n",
      "        [-7.4079e-03,  3.9246e-02,  9.8959e-06],\n",
      "        [-2.7916e-03,  3.5528e-02, -3.7825e-03],\n",
      "        [-4.1763e-04,  3.6354e-02, -3.7326e-03],\n",
      "        [-1.5939e-03,  4.3428e-02, -3.2956e-03],\n",
      "        [ 1.5744e-03,  3.1993e-02, -1.9777e-03],\n",
      "        [-3.1481e-03,  3.8891e-02, -2.8586e-03],\n",
      "        [-2.7022e-03,  4.4889e-02, -3.1402e-03],\n",
      "        [-1.9150e-03,  3.8622e-02, -2.1375e-03],\n",
      "        [-1.9870e-03,  4.3200e-02, -3.0258e-03],\n",
      "        [ 8.7954e-04,  1.7916e-02, -1.5698e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0657, 0.0668, 0.1019, 0.0488, 0.0614, 0.0628, 0.0512, 0.0921, 0.0670,\n",
      "         0.0569, 0.0577, 0.0675, 0.0807, 0.0737, 0.0850, 0.0898, 0.1005, 0.0857,\n",
      "         0.1072, 0.0595, 0.0799, 0.0784, 0.0887, 0.0857, 0.0968, 0.0786, 0.0707,\n",
      "         0.0860, 0.0839, 0.0793, 0.0861, 0.0749],\n",
      "        [0.0542, 0.0522, 0.0783, 0.0391, 0.0530, 0.0570, 0.0444, 0.0781, 0.0510,\n",
      "         0.0420, 0.0602, 0.0519, 0.0581, 0.0633, 0.0642, 0.0775, 0.0755, 0.0650,\n",
      "         0.0909, 0.0474, 0.0642, 0.0668, 0.0612, 0.0685, 0.0639, 0.0614, 0.0551,\n",
      "         0.0690, 0.0631, 0.0588, 0.0626, 0.0494]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0051, 0.0048, 0.0086, 0.0027, 0.0050, 0.0046, 0.0028, 0.0088, 0.0041,\n",
      "        0.0033, 0.0049, 0.0053, 0.0058, 0.0067, 0.0056, 0.0075, 0.0085, 0.0078,\n",
      "        0.0091, 0.0040, 0.0066, 0.0075, 0.0065, 0.0064, 0.0071, 0.0059, 0.0055,\n",
      "        0.0061, 0.0070, 0.0055, 0.0065, 0.0046], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0075, 0.0050], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0096,  0.0185, -0.0022],\n",
      "        [ 0.0099,  0.0182,  0.0069],\n",
      "        [ 0.0067,  0.0367,  0.0015],\n",
      "        [-0.0006,  0.0078, -0.0065],\n",
      "        [ 0.0065,  0.0100,  0.0001],\n",
      "        [ 0.0061,  0.0202,  0.0040],\n",
      "        [ 0.0064,  0.0040,  0.0026],\n",
      "        [ 0.0148,  0.0421, -0.0057],\n",
      "        [ 0.0029,  0.0138,  0.0002],\n",
      "        [ 0.0048,  0.0085, -0.0096],\n",
      "        [ 0.0099,  0.0137,  0.0003],\n",
      "        [ 0.0094,  0.0152, -0.0031],\n",
      "        [ 0.0056,  0.0156,  0.0008],\n",
      "        [ 0.0078,  0.0383, -0.0008],\n",
      "        [ 0.0064,  0.0227,  0.0020],\n",
      "        [ 0.0089,  0.0343, -0.0013],\n",
      "        [ 0.0120,  0.0378, -0.0003],\n",
      "        [ 0.0114,  0.0324,  0.0042],\n",
      "        [ 0.0106,  0.0424,  0.0007],\n",
      "        [ 0.0056,  0.0179,  0.0001],\n",
      "        [ 0.0095,  0.0227,  0.0039],\n",
      "        [ 0.0102,  0.0382,  0.0061],\n",
      "        [ 0.0112,  0.0243, -0.0005],\n",
      "        [ 0.0090,  0.0179,  0.0001],\n",
      "        [ 0.0055,  0.0334, -0.0031],\n",
      "        [ 0.0106,  0.0310, -0.0026],\n",
      "        [ 0.0091,  0.0226, -0.0015],\n",
      "        [ 0.0088,  0.0230, -0.0028],\n",
      "        [ 0.0100,  0.0251,  0.0012],\n",
      "        [ 0.0031,  0.0201, -0.0080],\n",
      "        [ 0.0061,  0.0221,  0.0020],\n",
      "        [ 0.0070,  0.0110, -0.0013]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0681, 0.0705, 0.1060, 0.0503, 0.0639, 0.0664, 0.0538, 0.0967, 0.0713,\n",
      "         0.0612, 0.0604, 0.0707, 0.0833, 0.0765, 0.0881, 0.0937, 0.1047, 0.0888,\n",
      "         0.1115, 0.0612, 0.0836, 0.0817, 0.0913, 0.0890, 0.1014, 0.0827, 0.0727,\n",
      "         0.0901, 0.0880, 0.0830, 0.0896, 0.0775],\n",
      "        [0.0564, 0.0547, 0.0816, 0.0401, 0.0551, 0.0596, 0.0465, 0.0819, 0.0535,\n",
      "         0.0447, 0.0629, 0.0543, 0.0603, 0.0656, 0.0667, 0.0806, 0.0790, 0.0681,\n",
      "         0.0947, 0.0489, 0.0673, 0.0700, 0.0630, 0.0714, 0.0670, 0.0639, 0.0571,\n",
      "         0.0722, 0.0661, 0.0614, 0.0653, 0.0510]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0052, 0.0049, 0.0087, 0.0026, 0.0050, 0.0047, 0.0029, 0.0089, 0.0043,\n",
      "        0.0035, 0.0050, 0.0054, 0.0058, 0.0067, 0.0057, 0.0076, 0.0086, 0.0079,\n",
      "        0.0092, 0.0040, 0.0067, 0.0077, 0.0065, 0.0066, 0.0072, 0.0060, 0.0055,\n",
      "        0.0062, 0.0072, 0.0056, 0.0066, 0.0046], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0077, 0.0051], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-1.6031e-03,  2.4909e-02,  8.0464e-03],\n",
      "        [ 2.0377e-03,  3.0991e-02,  5.2412e-03],\n",
      "        [ 3.1941e-03,  4.6842e-02,  7.6467e-03],\n",
      "        [ 3.9111e-04,  1.6997e-02, -2.4196e-03],\n",
      "        [ 1.5919e-03,  2.8001e-02,  1.3419e-03],\n",
      "        [-1.0040e-03,  2.5534e-02,  5.0386e-03],\n",
      "        [-5.0444e-03,  8.0523e-03,  7.3150e-03],\n",
      "        [ 6.1673e-03,  6.1161e-02,  3.7788e-03],\n",
      "        [ 1.8607e-03,  1.3588e-02, -1.9189e-03],\n",
      "        [-6.1192e-04,  1.0495e-02,  3.2446e-03],\n",
      "        [-1.0232e-04,  2.0439e-02,  8.9832e-03],\n",
      "        [-8.6985e-04,  2.9745e-02,  2.3322e-03],\n",
      "        [ 3.7493e-03,  3.9299e-02,  7.6430e-03],\n",
      "        [ 6.8679e-03,  4.5027e-02,  5.7523e-04],\n",
      "        [-5.0091e-04,  3.0307e-02,  4.1305e-03],\n",
      "        [-1.1982e-03,  4.7767e-02,  9.5050e-05],\n",
      "        [ 5.7617e-03,  4.9988e-02,  4.5883e-03],\n",
      "        [ 4.5848e-03,  4.2160e-02,  1.9157e-03],\n",
      "        [ 1.6267e-03,  6.0317e-02,  7.3564e-03],\n",
      "        [ 5.3451e-04,  2.1871e-02,  2.5659e-03],\n",
      "        [-1.0483e-04,  3.3389e-02,  6.9329e-03],\n",
      "        [ 2.6989e-03,  4.3836e-02,  3.1244e-03],\n",
      "        [-8.1180e-04,  3.4142e-02,  1.1257e-02],\n",
      "        [ 3.0950e-03,  4.0517e-02,  4.4498e-03],\n",
      "        [ 7.1238e-03,  4.6517e-02,  3.8804e-03],\n",
      "        [ 2.5776e-03,  2.5891e-02,  5.7527e-03],\n",
      "        [ 3.3750e-03,  2.8626e-02,  7.2398e-03],\n",
      "        [-1.7683e-04,  3.7183e-02,  3.2519e-03],\n",
      "        [ 4.0597e-03,  4.2343e-02, -2.6511e-04],\n",
      "        [ 1.3816e-03,  2.7765e-02,  2.1087e-03],\n",
      "        [ 2.3464e-03,  4.3598e-02,  8.2499e-03],\n",
      "        [ 5.3397e-03,  2.8251e-02,  4.0403e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0721, 0.0734, 0.1123, 0.0524, 0.0672, 0.0689, 0.0554, 0.1022, 0.0729,\n",
      "         0.0623, 0.0630, 0.0741, 0.0882, 0.0811, 0.0928, 0.0990, 0.1109, 0.0950,\n",
      "         0.1181, 0.0644, 0.0881, 0.0872, 0.0973, 0.0937, 0.1062, 0.0865, 0.0770,\n",
      "         0.0943, 0.0926, 0.0867, 0.0945, 0.0812],\n",
      "        [0.0594, 0.0568, 0.0857, 0.0425, 0.0579, 0.0621, 0.0486, 0.0852, 0.0555,\n",
      "         0.0459, 0.0661, 0.0569, 0.0636, 0.0690, 0.0702, 0.0843, 0.0827, 0.0716,\n",
      "         0.0990, 0.0519, 0.0705, 0.0732, 0.0664, 0.0751, 0.0701, 0.0667, 0.0607,\n",
      "         0.0753, 0.0692, 0.0642, 0.0685, 0.0540]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0054, 0.0050, 0.0089, 0.0027, 0.0051, 0.0048, 0.0029, 0.0091, 0.0042,\n",
      "        0.0034, 0.0051, 0.0055, 0.0060, 0.0069, 0.0059, 0.0078, 0.0088, 0.0082,\n",
      "        0.0094, 0.0042, 0.0069, 0.0079, 0.0068, 0.0067, 0.0074, 0.0061, 0.0057,\n",
      "        0.0064, 0.0073, 0.0057, 0.0068, 0.0047], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0079, 0.0053], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0020,  0.0339,  0.0067],\n",
      "        [-0.0021,  0.0304,  0.0036],\n",
      "        [-0.0052,  0.0472,  0.0071],\n",
      "        [-0.0013,  0.0088,  0.0034],\n",
      "        [-0.0036,  0.0265,  0.0093],\n",
      "        [-0.0055,  0.0228,  0.0059],\n",
      "        [-0.0071,  0.0150,  0.0004],\n",
      "        [-0.0062,  0.0490,  0.0107],\n",
      "        [ 0.0005,  0.0192,  0.0041],\n",
      "        [-0.0017,  0.0234,  0.0091],\n",
      "        [-0.0056,  0.0222,  0.0047],\n",
      "        [-0.0114,  0.0293,  0.0064],\n",
      "        [-0.0087,  0.0294,  0.0046],\n",
      "        [-0.0054,  0.0374,  0.0079],\n",
      "        [-0.0012,  0.0253,  0.0043],\n",
      "        [-0.0038,  0.0337,  0.0065],\n",
      "        [-0.0026,  0.0518,  0.0104],\n",
      "        [-0.0055,  0.0394,  0.0058],\n",
      "        [-0.0074,  0.0536,  0.0090],\n",
      "        [-0.0085,  0.0245,  0.0074],\n",
      "        [-0.0059,  0.0358,  0.0062],\n",
      "        [-0.0023,  0.0470,  0.0072],\n",
      "        [-0.0080,  0.0321, -0.0005],\n",
      "        [-0.0124,  0.0332,  0.0093],\n",
      "        [-0.0032,  0.0422,  0.0084],\n",
      "        [-0.0074,  0.0242,  0.0011],\n",
      "        [-0.0123,  0.0262,  0.0047],\n",
      "        [-0.0036,  0.0304,  0.0031],\n",
      "        [-0.0029,  0.0348,  0.0035],\n",
      "        [-0.0014,  0.0278,  0.0076],\n",
      "        [-0.0017,  0.0396,  0.0065],\n",
      "        [-0.0069,  0.0224,  0.0060]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0758, 0.0768, 0.1179, 0.0550, 0.0706, 0.0721, 0.0580, 0.1072, 0.0762,\n",
      "         0.0650, 0.0663, 0.0777, 0.0925, 0.0852, 0.0973, 0.1040, 0.1161, 0.0996,\n",
      "         0.1238, 0.0676, 0.0924, 0.0914, 0.1021, 0.0982, 0.1112, 0.0905, 0.0809,\n",
      "         0.0986, 0.0971, 0.0908, 0.0991, 0.0850],\n",
      "        [0.0622, 0.0593, 0.0897, 0.0444, 0.0605, 0.0648, 0.0509, 0.0891, 0.0580,\n",
      "         0.0480, 0.0692, 0.0596, 0.0666, 0.0721, 0.0735, 0.0882, 0.0865, 0.0750,\n",
      "         0.1034, 0.0543, 0.0738, 0.0764, 0.0695, 0.0785, 0.0734, 0.0695, 0.0635,\n",
      "         0.0787, 0.0724, 0.0672, 0.0717, 0.0565]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0055, 0.0051, 0.0091, 0.0029, 0.0053, 0.0049, 0.0030, 0.0093, 0.0043,\n",
      "        0.0035, 0.0052, 0.0057, 0.0062, 0.0071, 0.0061, 0.0080, 0.0090, 0.0084,\n",
      "        0.0096, 0.0044, 0.0071, 0.0080, 0.0070, 0.0069, 0.0075, 0.0062, 0.0060,\n",
      "        0.0065, 0.0075, 0.0058, 0.0069, 0.0049], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0081, 0.0054], grad_fn=<MeanBackward1>)\n",
      "Epoch 1/10, Accuracy: 0.5188\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 1.1899e-03,  3.9619e-02, -1.2578e-03],\n",
      "        [ 3.2411e-03,  4.0911e-02, -4.1290e-03],\n",
      "        [ 2.1287e-04,  7.5637e-02, -1.8491e-03],\n",
      "        [-5.0333e-03,  2.6751e-02, -7.8392e-03],\n",
      "        [-2.6788e-03,  3.7152e-02,  1.9493e-03],\n",
      "        [ 1.6020e-03,  4.7030e-02, -2.7432e-03],\n",
      "        [ 5.3316e-04,  1.9153e-02, -2.0249e-03],\n",
      "        [ 4.1912e-04,  8.3612e-02, -1.1542e-02],\n",
      "        [ 1.0261e-03,  3.5779e-02,  1.0741e-03],\n",
      "        [ 1.7212e-03,  3.1143e-02,  5.7104e-03],\n",
      "        [ 1.2971e-05,  3.5523e-02,  3.9083e-03],\n",
      "        [-1.7140e-03,  5.0653e-02, -1.8666e-03],\n",
      "        [ 1.6122e-03,  4.9093e-02, -4.2767e-03],\n",
      "        [-3.7592e-03,  5.8876e-02, -6.5132e-03],\n",
      "        [-6.0332e-04,  4.6101e-02, -2.7009e-03],\n",
      "        [-1.0115e-03,  6.7441e-02, -4.7796e-03],\n",
      "        [ 1.1363e-03,  7.1601e-02, -6.9449e-03],\n",
      "        [-1.0294e-03,  6.4710e-02, -5.9379e-03],\n",
      "        [ 1.1140e-03,  8.4283e-02, -5.6142e-03],\n",
      "        [-2.6172e-03,  3.4049e-02,  2.6123e-03],\n",
      "        [ 1.3949e-03,  4.1343e-02, -7.7494e-05],\n",
      "        [ 1.4493e-03,  6.2047e-02, -4.8185e-03],\n",
      "        [ 5.2570e-03,  5.4467e-02, -4.1528e-03],\n",
      "        [-1.9545e-03,  5.0391e-02, -2.2575e-03],\n",
      "        [ 3.0297e-03,  6.5627e-02, -9.7862e-03],\n",
      "        [ 7.6490e-04,  5.1040e-02, -4.1304e-03],\n",
      "        [ 5.6058e-04,  2.9411e-02,  5.5892e-03],\n",
      "        [-8.6004e-04,  6.1785e-02, -4.0881e-03],\n",
      "        [ 8.7443e-04,  6.3659e-02, -7.1762e-03],\n",
      "        [ 6.0366e-05,  4.3230e-02,  2.2423e-03],\n",
      "        [ 3.1294e-03,  5.2473e-02, -3.4885e-04],\n",
      "        [-3.1173e-03,  3.8189e-02, -3.0030e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0791, 0.0808, 0.1236, 0.0570, 0.0739, 0.0759, 0.0602, 0.1132, 0.0799,\n",
      "         0.0681, 0.0688, 0.0813, 0.0965, 0.0896, 0.1013, 0.1096, 0.1217, 0.1040,\n",
      "         0.1302, 0.0699, 0.0966, 0.0961, 0.1073, 0.1022, 0.1164, 0.0956, 0.0838,\n",
      "         0.1033, 0.1019, 0.0949, 0.1037, 0.0884],\n",
      "        [0.0653, 0.0622, 0.0945, 0.0463, 0.0634, 0.0678, 0.0524, 0.0939, 0.0598,\n",
      "         0.0491, 0.0716, 0.0622, 0.0699, 0.0762, 0.0768, 0.0933, 0.0909, 0.0789,\n",
      "         0.1091, 0.0565, 0.0771, 0.0807, 0.0743, 0.0818, 0.0767, 0.0734, 0.0662,\n",
      "         0.0823, 0.0759, 0.0701, 0.0753, 0.0590]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0056, 0.0053, 0.0093, 0.0029, 0.0054, 0.0050, 0.0030, 0.0095, 0.0045,\n",
      "        0.0036, 0.0052, 0.0058, 0.0063, 0.0073, 0.0061, 0.0082, 0.0092, 0.0085,\n",
      "        0.0099, 0.0044, 0.0072, 0.0082, 0.0072, 0.0070, 0.0077, 0.0065, 0.0059,\n",
      "        0.0066, 0.0076, 0.0060, 0.0071, 0.0050], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0083, 0.0056], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0096,  0.0181,  0.0030],\n",
      "        [-0.0068,  0.0215, -0.0014],\n",
      "        [-0.0202,  0.0335,  0.0065],\n",
      "        [-0.0065,  0.0085,  0.0070],\n",
      "        [-0.0082,  0.0123,  0.0077],\n",
      "        [-0.0099,  0.0173,  0.0003],\n",
      "        [-0.0073,  0.0077,  0.0002],\n",
      "        [-0.0158,  0.0344,  0.0069],\n",
      "        [-0.0024,  0.0079,  0.0061],\n",
      "        [-0.0033,  0.0106,  0.0064],\n",
      "        [-0.0070,  0.0121,  0.0026],\n",
      "        [-0.0112,  0.0226,  0.0107],\n",
      "        [-0.0114,  0.0274,  0.0023],\n",
      "        [-0.0134,  0.0226,  0.0016],\n",
      "        [-0.0119,  0.0135,  0.0103],\n",
      "        [-0.0140,  0.0278,  0.0051],\n",
      "        [-0.0171,  0.0264,  0.0096],\n",
      "        [-0.0171,  0.0251,  0.0086],\n",
      "        [-0.0156,  0.0384,  0.0060],\n",
      "        [-0.0115,  0.0167,  0.0048],\n",
      "        [-0.0140,  0.0207,  0.0026],\n",
      "        [-0.0173,  0.0219,  0.0069],\n",
      "        [-0.0103,  0.0282,  0.0005],\n",
      "        [-0.0152,  0.0217,  0.0090],\n",
      "        [-0.0127,  0.0333,  0.0104],\n",
      "        [-0.0153,  0.0178,  0.0026],\n",
      "        [-0.0091,  0.0149,  0.0077],\n",
      "        [-0.0059,  0.0259,  0.0045],\n",
      "        [-0.0131,  0.0253,  0.0069],\n",
      "        [-0.0089,  0.0163,  0.0020],\n",
      "        [-0.0080,  0.0315,  0.0009],\n",
      "        [-0.0068,  0.0193,  0.0038]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0836, 0.0840, 0.1297, 0.0601, 0.0777, 0.0789, 0.0636, 0.1177, 0.0832,\n",
      "         0.0706, 0.0734, 0.0854, 0.1018, 0.0938, 0.1067, 0.1140, 0.1276, 0.1095,\n",
      "         0.1357, 0.0745, 0.1018, 0.1005, 0.1119, 0.1080, 0.1220, 0.0989, 0.0897,\n",
      "         0.1080, 0.1068, 0.0994, 0.1088, 0.0933],\n",
      "        [0.0681, 0.0647, 0.0980, 0.0487, 0.0662, 0.0708, 0.0558, 0.0969, 0.0637,\n",
      "         0.0525, 0.0760, 0.0652, 0.0728, 0.0787, 0.0803, 0.0960, 0.0943, 0.0817,\n",
      "         0.1124, 0.0596, 0.0807, 0.0831, 0.0756, 0.0859, 0.0804, 0.0759, 0.0699,\n",
      "         0.0859, 0.0792, 0.0735, 0.0783, 0.0620]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0058, 0.0053, 0.0095, 0.0031, 0.0055, 0.0051, 0.0033, 0.0095, 0.0046,\n",
      "        0.0037, 0.0056, 0.0059, 0.0065, 0.0074, 0.0064, 0.0082, 0.0093, 0.0086,\n",
      "        0.0099, 0.0046, 0.0074, 0.0082, 0.0072, 0.0073, 0.0079, 0.0064, 0.0063,\n",
      "        0.0068, 0.0078, 0.0061, 0.0072, 0.0052], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0085, 0.0058], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0110,  0.0351,  0.0077],\n",
      "        [ 0.0036,  0.0146,  0.0061],\n",
      "        [ 0.0150,  0.0439,  0.0143],\n",
      "        [ 0.0067,  0.0127, -0.0018],\n",
      "        [ 0.0010,  0.0290,  0.0086],\n",
      "        [ 0.0059,  0.0131, -0.0005],\n",
      "        [-0.0008,  0.0133, -0.0009],\n",
      "        [ 0.0135,  0.0478,  0.0089],\n",
      "        [ 0.0011,  0.0229,  0.0046],\n",
      "        [ 0.0030,  0.0153,  0.0072],\n",
      "        [ 0.0027,  0.0186,  0.0088],\n",
      "        [ 0.0086,  0.0312,  0.0051],\n",
      "        [ 0.0039,  0.0319,  0.0130],\n",
      "        [ 0.0069,  0.0323,  0.0086],\n",
      "        [ 0.0088,  0.0400,  0.0109],\n",
      "        [ 0.0085,  0.0408,  0.0154],\n",
      "        [ 0.0142,  0.0509,  0.0130],\n",
      "        [ 0.0102,  0.0456,  0.0147],\n",
      "        [ 0.0117,  0.0513,  0.0191],\n",
      "        [ 0.0013,  0.0291,  0.0050],\n",
      "        [ 0.0104,  0.0392,  0.0103],\n",
      "        [ 0.0116,  0.0369,  0.0147],\n",
      "        [ 0.0077,  0.0376,  0.0119],\n",
      "        [ 0.0081,  0.0383,  0.0098],\n",
      "        [ 0.0122,  0.0480,  0.0087],\n",
      "        [ 0.0103,  0.0288,  0.0090],\n",
      "        [-0.0035,  0.0436,  0.0171],\n",
      "        [ 0.0115,  0.0339,  0.0101],\n",
      "        [ 0.0140,  0.0387,  0.0134],\n",
      "        [ 0.0038,  0.0299,  0.0100],\n",
      "        [ 0.0119,  0.0389,  0.0138],\n",
      "        [-0.0010,  0.0247,  0.0064]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0873, 0.0881, 0.1362, 0.0610, 0.0808, 0.0821, 0.0653, 0.1254, 0.0863,\n",
      "         0.0742, 0.0759, 0.0894, 0.1063, 0.0984, 0.1110, 0.1198, 0.1346, 0.1162,\n",
      "         0.1434, 0.0763, 0.1071, 0.1073, 0.1170, 0.1126, 0.1277, 0.1038, 0.0923,\n",
      "         0.1131, 0.1125, 0.1037, 0.1141, 0.0959],\n",
      "        [0.0712, 0.0676, 0.1031, 0.0493, 0.0687, 0.0733, 0.0572, 0.1029, 0.0654,\n",
      "         0.0545, 0.0786, 0.0682, 0.0764, 0.0826, 0.0836, 0.1006, 0.0998, 0.0872,\n",
      "         0.1187, 0.0612, 0.0850, 0.0889, 0.0795, 0.0897, 0.0842, 0.0793, 0.0722,\n",
      "         0.0899, 0.0834, 0.0765, 0.0823, 0.0637]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0058, 0.0054, 0.0097, 0.0029, 0.0056, 0.0052, 0.0032, 0.0099, 0.0047,\n",
      "        0.0038, 0.0055, 0.0060, 0.0066, 0.0075, 0.0064, 0.0084, 0.0096, 0.0089,\n",
      "        0.0102, 0.0046, 0.0075, 0.0086, 0.0073, 0.0073, 0.0080, 0.0066, 0.0062,\n",
      "        0.0069, 0.0080, 0.0062, 0.0074, 0.0051], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0088, 0.0059], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-1.6151e-03,  2.6617e-02,  1.3260e-04],\n",
      "        [-1.0974e-02,  2.5911e-02,  2.0646e-03],\n",
      "        [-7.8195e-03,  4.4732e-02,  6.5468e-03],\n",
      "        [-1.3226e-03,  2.2361e-02,  1.2238e-02],\n",
      "        [-7.2911e-04,  2.2454e-02, -1.4670e-03],\n",
      "        [-6.4253e-03,  2.4894e-02,  6.0445e-03],\n",
      "        [-5.2320e-03,  7.9609e-03, -5.9422e-03],\n",
      "        [-2.9844e-03,  4.0615e-02,  1.0236e-02],\n",
      "        [-6.0886e-03,  2.0490e-02,  3.4474e-03],\n",
      "        [-2.4713e-04,  8.4126e-03,  2.7609e-03],\n",
      "        [ 1.4905e-03,  1.8797e-02,  4.8769e-03],\n",
      "        [-4.2862e-03,  2.7466e-02,  9.9053e-03],\n",
      "        [-6.9296e-03,  2.0931e-02, -6.5141e-05],\n",
      "        [-7.3840e-03,  3.2385e-02,  8.8122e-03],\n",
      "        [-9.6501e-03,  2.3793e-02,  2.7277e-03],\n",
      "        [-3.1276e-03,  2.9617e-02,  4.2480e-03],\n",
      "        [-8.7981e-03,  3.5712e-02,  5.9933e-04],\n",
      "        [-9.1006e-03,  4.1994e-02,  5.5636e-03],\n",
      "        [-1.1269e-02,  3.8108e-02,  6.5006e-03],\n",
      "        [-2.5139e-03,  2.0502e-02,  1.4955e-03],\n",
      "        [-6.5478e-03,  4.0916e-02,  2.9531e-03],\n",
      "        [-9.5341e-03,  3.8815e-02,  1.3090e-03],\n",
      "        [-8.9770e-03,  4.1830e-02,  2.1346e-03],\n",
      "        [-6.9690e-03,  2.3080e-02,  4.3402e-03],\n",
      "        [-1.5900e-02,  3.9763e-02,  1.0445e-02],\n",
      "        [-3.4791e-04,  3.4113e-02,  5.1511e-04],\n",
      "        [-5.9965e-03,  2.5345e-02,  4.8704e-03],\n",
      "        [-2.9267e-03,  2.3634e-02,  7.1084e-03],\n",
      "        [-7.8454e-03,  3.3401e-02,  6.5728e-03],\n",
      "        [ 3.0353e-05,  2.0171e-02,  2.2291e-03],\n",
      "        [-7.1243e-03,  2.9264e-02, -1.1922e-03],\n",
      "        [-3.6121e-03,  2.4810e-02, -5.2046e-04]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0919, 0.0921, 0.1426, 0.0654, 0.0854, 0.0867, 0.0694, 0.1297, 0.0908,\n",
      "         0.0771, 0.0807, 0.0937, 0.1115, 0.1031, 0.1167, 0.1253, 0.1402, 0.1207,\n",
      "         0.1490, 0.0813, 0.1119, 0.1107, 0.1225, 0.1183, 0.1337, 0.1084, 0.0982,\n",
      "         0.1182, 0.1175, 0.1088, 0.1193, 0.1017],\n",
      "        [0.0744, 0.0707, 0.1072, 0.0523, 0.0720, 0.0771, 0.0606, 0.1065, 0.0694,\n",
      "         0.0576, 0.0830, 0.0714, 0.0796, 0.0858, 0.0874, 0.1045, 0.1036, 0.0901,\n",
      "         0.1228, 0.0646, 0.0887, 0.0916, 0.0818, 0.0939, 0.0882, 0.0826, 0.0762,\n",
      "         0.0938, 0.0870, 0.0801, 0.0856, 0.0672]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0060, 0.0055, 0.0098, 0.0032, 0.0058, 0.0053, 0.0034, 0.0099, 0.0048,\n",
      "        0.0039, 0.0058, 0.0062, 0.0067, 0.0076, 0.0066, 0.0086, 0.0097, 0.0089,\n",
      "        0.0103, 0.0048, 0.0077, 0.0086, 0.0074, 0.0075, 0.0082, 0.0067, 0.0065,\n",
      "        0.0070, 0.0081, 0.0064, 0.0075, 0.0054], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0090, 0.0061], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 4.5612e-03,  4.0607e-02,  2.6438e-03],\n",
      "        [ 4.1368e-03,  2.5500e-02, -8.6366e-04],\n",
      "        [ 9.0588e-03,  7.2285e-02, -3.3504e-04],\n",
      "        [ 3.6368e-03,  2.4799e-02, -5.1057e-03],\n",
      "        [-8.5908e-04,  3.7978e-02, -1.9694e-04],\n",
      "        [ 4.3946e-03,  2.9275e-02,  2.2001e-03],\n",
      "        [-2.0094e-03,  1.3638e-02, -4.5948e-03],\n",
      "        [ 6.2046e-03,  6.3275e-02,  2.3309e-03],\n",
      "        [ 8.2534e-03,  3.3190e-02, -5.2003e-03],\n",
      "        [ 2.7523e-03,  1.0252e-02, -2.4821e-03],\n",
      "        [ 4.8852e-03,  2.0421e-02, -9.5181e-04],\n",
      "        [ 5.0327e-03,  3.2291e-02, -9.7728e-03],\n",
      "        [ 5.6106e-03,  4.5581e-02,  6.5212e-03],\n",
      "        [ 6.1157e-03,  5.8276e-02,  3.6947e-03],\n",
      "        [ 9.1142e-04,  5.7492e-02,  1.8547e-03],\n",
      "        [ 5.3274e-03,  6.1910e-02,  2.5130e-03],\n",
      "        [ 4.9417e-03,  7.2772e-02,  1.1523e-03],\n",
      "        [ 6.4051e-03,  6.9420e-02, -6.9412e-04],\n",
      "        [ 9.2446e-03,  6.4780e-02,  3.3342e-03],\n",
      "        [-1.1152e-05,  3.3313e-02,  1.1050e-03],\n",
      "        [ 9.2802e-03,  4.8704e-02, -1.7861e-03],\n",
      "        [ 6.8470e-03,  5.5223e-02, -2.5426e-04],\n",
      "        [ 1.2166e-03,  5.5207e-02, -4.6442e-03],\n",
      "        [ 7.5415e-03,  4.9495e-02,  3.9091e-03],\n",
      "        [ 8.8213e-03,  5.5907e-02, -3.8024e-03],\n",
      "        [ 4.3627e-03,  5.4368e-02, -2.6793e-03],\n",
      "        [ 1.9876e-03,  4.3747e-02, -1.3141e-03],\n",
      "        [ 7.7090e-03,  4.2294e-02, -1.6095e-03],\n",
      "        [ 9.2816e-03,  6.3756e-02,  3.9895e-04],\n",
      "        [-1.5675e-03,  4.6122e-02,  2.6203e-04],\n",
      "        [ 1.1737e-02,  4.6254e-02,  3.5007e-03],\n",
      "        [ 1.6142e-03,  3.8164e-02,  5.1544e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.0960, 0.0969, 0.1500, 0.0671, 0.0891, 0.0907, 0.0711, 0.1382, 0.0941,\n",
      "         0.0802, 0.0830, 0.0980, 0.1164, 0.1086, 0.1215, 0.1325, 0.1475, 0.1273,\n",
      "         0.1577, 0.0837, 0.1174, 0.1177, 0.1294, 0.1230, 0.1398, 0.1144, 0.1014,\n",
      "         0.1239, 0.1235, 0.1135, 0.1253, 0.1051],\n",
      "        [0.0779, 0.0740, 0.1131, 0.0538, 0.0752, 0.0803, 0.0619, 0.1132, 0.0712,\n",
      "         0.0593, 0.0854, 0.0746, 0.0834, 0.0906, 0.0911, 0.1105, 0.1092, 0.0953,\n",
      "         0.1301, 0.0666, 0.0929, 0.0974, 0.0875, 0.0976, 0.0922, 0.0872, 0.0789,\n",
      "         0.0982, 0.0914, 0.0836, 0.0901, 0.0694]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0061, 0.0057, 0.0101, 0.0031, 0.0059, 0.0055, 0.0033, 0.0103, 0.0049,\n",
      "        0.0039, 0.0057, 0.0063, 0.0068, 0.0079, 0.0067, 0.0088, 0.0099, 0.0092,\n",
      "        0.0106, 0.0048, 0.0078, 0.0089, 0.0077, 0.0076, 0.0084, 0.0070, 0.0065,\n",
      "        0.0072, 0.0083, 0.0065, 0.0077, 0.0054], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0092, 0.0063], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 2.0909e-03,  2.1977e-02, -3.2542e-03],\n",
      "        [ 5.7721e-03,  2.1654e-02, -7.8085e-03],\n",
      "        [-7.6015e-04,  2.0838e-02, -2.8477e-03],\n",
      "        [-1.6962e-03,  9.1437e-03,  1.5089e-04],\n",
      "        [-1.0937e-03,  2.1681e-02, -3.7279e-03],\n",
      "        [-7.5393e-05,  2.2374e-02, -6.2198e-03],\n",
      "        [ 2.3650e-04,  6.2906e-03, -7.2796e-03],\n",
      "        [-1.8444e-03,  2.7372e-02, -4.5771e-03],\n",
      "        [-6.3876e-03,  1.9405e-02, -3.1126e-03],\n",
      "        [ 4.7564e-03,  1.2198e-02, -4.8417e-03],\n",
      "        [ 5.6158e-03,  1.8590e-02, -6.3970e-03],\n",
      "        [ 6.9087e-03,  5.8703e-03, -4.0483e-03],\n",
      "        [-1.5448e-03,  1.3264e-02,  1.0119e-03],\n",
      "        [-3.9328e-03,  3.0845e-02, -6.2340e-03],\n",
      "        [-3.2824e-03,  1.3967e-02, -1.1100e-03],\n",
      "        [ 1.3953e-03,  3.0033e-02,  2.7620e-03],\n",
      "        [-5.0432e-04,  2.1588e-02, -5.5555e-03],\n",
      "        [-3.6484e-03,  1.9324e-02, -2.9542e-03],\n",
      "        [ 5.6472e-03,  3.0397e-02, -2.2043e-03],\n",
      "        [-1.7756e-03,  1.1749e-02, -1.9724e-03],\n",
      "        [ 1.4627e-03,  2.7091e-02, -4.1572e-03],\n",
      "        [-4.3409e-04,  2.3773e-02, -3.5742e-03],\n",
      "        [-5.7335e-04,  1.8100e-02, -1.0900e-02],\n",
      "        [-1.4945e-04,  1.5206e-02, -2.4221e-04],\n",
      "        [ 2.6917e-03,  2.0281e-02, -3.0597e-03],\n",
      "        [-2.1777e-04,  9.5355e-03, -5.6522e-03],\n",
      "        [-1.5861e-03,  1.9478e-02, -7.6882e-03],\n",
      "        [ 1.6299e-03,  1.6651e-02,  1.8376e-03],\n",
      "        [-1.7815e-03,  2.4378e-02,  1.0701e-03],\n",
      "        [-6.0967e-03,  2.8364e-02, -2.8003e-03],\n",
      "        [ 5.8017e-03,  2.6537e-02,  4.1084e-04],\n",
      "        [-8.4853e-03,  1.1917e-02, -3.6439e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1005, 0.1009, 0.1565, 0.0705, 0.0933, 0.0948, 0.0757, 0.1431, 0.0995,\n",
      "         0.0849, 0.0887, 0.1028, 0.1218, 0.1128, 0.1273, 0.1371, 0.1539, 0.1326,\n",
      "         0.1631, 0.0883, 0.1231, 0.1219, 0.1334, 0.1294, 0.1465, 0.1188, 0.1074,\n",
      "         0.1294, 0.1293, 0.1189, 0.1306, 0.1103],\n",
      "        [0.0814, 0.0772, 0.1178, 0.0567, 0.0787, 0.0841, 0.0656, 0.1173, 0.0754,\n",
      "         0.0625, 0.0902, 0.0782, 0.0870, 0.0941, 0.0954, 0.1148, 0.1137, 0.0990,\n",
      "         0.1347, 0.0701, 0.0971, 0.1006, 0.0905, 0.1023, 0.0965, 0.0908, 0.0830,\n",
      "         0.1025, 0.0954, 0.0875, 0.0938, 0.0729]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0062, 0.0058, 0.0102, 0.0033, 0.0060, 0.0056, 0.0036, 0.0103, 0.0052,\n",
      "        0.0042, 0.0060, 0.0064, 0.0069, 0.0079, 0.0068, 0.0089, 0.0100, 0.0092,\n",
      "        0.0106, 0.0049, 0.0079, 0.0089, 0.0077, 0.0078, 0.0085, 0.0070, 0.0067,\n",
      "        0.0074, 0.0084, 0.0066, 0.0078, 0.0056], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0095, 0.0065], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-2.1742e-03,  3.7269e-02,  1.9149e-04],\n",
      "        [-6.6566e-04,  4.6449e-02, -1.4752e-02],\n",
      "        [-7.8317e-04,  6.9622e-02, -2.1856e-02],\n",
      "        [-2.9793e-03,  2.3397e-02, -7.7900e-04],\n",
      "        [-5.0779e-03,  5.3071e-02, -1.0387e-02],\n",
      "        [-6.1903e-05,  3.7318e-02, -1.9465e-02],\n",
      "        [-1.1145e-03,  1.9893e-02, -1.0696e-02],\n",
      "        [ 5.7608e-04,  8.0229e-02, -1.3918e-02],\n",
      "        [-4.7718e-04,  3.5768e-02, -1.5057e-02],\n",
      "        [ 1.0609e-03,  2.4713e-02,  3.9565e-03],\n",
      "        [-6.6810e-03,  4.5898e-02, -4.1507e-03],\n",
      "        [-5.8949e-04,  4.7846e-02, -1.8906e-03],\n",
      "        [ 4.5191e-04,  5.8101e-02, -9.8965e-03],\n",
      "        [-3.0533e-03,  5.5181e-02, -1.2900e-02],\n",
      "        [-1.5890e-03,  5.0280e-02, -1.2223e-02],\n",
      "        [-1.6662e-03,  6.9896e-02, -1.9320e-02],\n",
      "        [-3.7284e-03,  7.5317e-02, -1.2948e-02],\n",
      "        [-4.3441e-03,  6.5784e-02, -1.2775e-02],\n",
      "        [ 4.3741e-03,  8.0843e-02, -1.3700e-02],\n",
      "        [ 2.0666e-03,  3.5005e-02, -7.5894e-03],\n",
      "        [ 6.9752e-03,  4.6483e-02, -1.1916e-02],\n",
      "        [ 1.3176e-03,  5.7409e-02, -1.8742e-02],\n",
      "        [-1.7510e-03,  5.1581e-02, -1.3239e-02],\n",
      "        [-1.7478e-04,  5.8076e-02, -6.7728e-03],\n",
      "        [ 6.2782e-03,  6.7672e-02, -9.5902e-03],\n",
      "        [ 1.9567e-04,  4.9239e-02, -1.8605e-02],\n",
      "        [-1.2181e-03,  4.6019e-02, -5.1442e-03],\n",
      "        [ 2.1657e-03,  5.8185e-02, -1.4019e-02],\n",
      "        [-3.6377e-03,  5.8852e-02, -1.8591e-02],\n",
      "        [ 1.4536e-03,  4.5703e-02, -1.8813e-02],\n",
      "        [ 3.4721e-03,  5.8340e-02, -1.2142e-02],\n",
      "        [-5.8522e-03,  4.9704e-02, -1.1010e-02]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1050, 0.1063, 0.1646, 0.0729, 0.0976, 0.0996, 0.0777, 0.1519, 0.1033,\n",
      "         0.0883, 0.0911, 0.1074, 0.1268, 0.1192, 0.1325, 0.1453, 0.1615, 0.1391,\n",
      "         0.1723, 0.0910, 0.1287, 0.1290, 0.1412, 0.1342, 0.1531, 0.1259, 0.1106,\n",
      "         0.1356, 0.1357, 0.1242, 0.1370, 0.1144],\n",
      "        [0.0849, 0.0813, 0.1239, 0.0591, 0.0823, 0.0884, 0.0675, 0.1240, 0.0781,\n",
      "         0.0647, 0.0929, 0.0816, 0.0907, 0.0995, 0.0993, 0.1216, 0.1189, 0.1034,\n",
      "         0.1419, 0.0726, 0.1012, 0.1058, 0.0967, 0.1061, 0.1008, 0.0965, 0.0858,\n",
      "         0.1073, 0.0999, 0.0914, 0.0984, 0.0759]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0063, 0.0060, 0.0105, 0.0033, 0.0061, 0.0058, 0.0035, 0.0107, 0.0051,\n",
      "        0.0041, 0.0060, 0.0065, 0.0071, 0.0082, 0.0069, 0.0093, 0.0103, 0.0094,\n",
      "        0.0110, 0.0050, 0.0081, 0.0092, 0.0081, 0.0079, 0.0087, 0.0074, 0.0067,\n",
      "        0.0075, 0.0086, 0.0068, 0.0080, 0.0056], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0097, 0.0067], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0031,  0.0326, -0.0209],\n",
      "        [ 0.0040,  0.0350, -0.0136],\n",
      "        [ 0.0012,  0.0689, -0.0289],\n",
      "        [-0.0042,  0.0225, -0.0118],\n",
      "        [-0.0041,  0.0340, -0.0154],\n",
      "        [-0.0040,  0.0377, -0.0161],\n",
      "        [-0.0038,  0.0170, -0.0099],\n",
      "        [ 0.0021,  0.0624, -0.0272],\n",
      "        [-0.0029,  0.0330, -0.0142],\n",
      "        [ 0.0057,  0.0150, -0.0093],\n",
      "        [-0.0073,  0.0200, -0.0128],\n",
      "        [-0.0027,  0.0323, -0.0131],\n",
      "        [ 0.0020,  0.0461, -0.0155],\n",
      "        [-0.0049,  0.0562, -0.0226],\n",
      "        [ 0.0019,  0.0425, -0.0179],\n",
      "        [ 0.0028,  0.0538, -0.0231],\n",
      "        [-0.0015,  0.0584, -0.0288],\n",
      "        [ 0.0006,  0.0555, -0.0199],\n",
      "        [ 0.0084,  0.0777, -0.0292],\n",
      "        [-0.0027,  0.0270, -0.0109],\n",
      "        [ 0.0025,  0.0540, -0.0237],\n",
      "        [ 0.0044,  0.0584, -0.0238],\n",
      "        [ 0.0050,  0.0524, -0.0183],\n",
      "        [-0.0073,  0.0398, -0.0178],\n",
      "        [ 0.0069,  0.0581, -0.0203],\n",
      "        [ 0.0028,  0.0419, -0.0229],\n",
      "        [-0.0021,  0.0415, -0.0079],\n",
      "        [ 0.0048,  0.0448, -0.0226],\n",
      "        [ 0.0018,  0.0501, -0.0192],\n",
      "        [ 0.0012,  0.0389, -0.0179],\n",
      "        [ 0.0040,  0.0555, -0.0252],\n",
      "        [-0.0046,  0.0381, -0.0159]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1097, 0.1118, 0.1723, 0.0757, 0.1021, 0.1048, 0.0808, 0.1600, 0.1081,\n",
      "         0.0924, 0.0948, 0.1123, 0.1322, 0.1249, 0.1381, 0.1530, 0.1690, 0.1452,\n",
      "         0.1806, 0.0945, 0.1347, 0.1351, 0.1481, 0.1398, 0.1600, 0.1326, 0.1148,\n",
      "         0.1419, 0.1421, 0.1298, 0.1433, 0.1190],\n",
      "        [0.0886, 0.0854, 0.1292, 0.0620, 0.0860, 0.0931, 0.0708, 0.1294, 0.0825,\n",
      "         0.0682, 0.0970, 0.0853, 0.0941, 0.1036, 0.1035, 0.1274, 0.1238, 0.1069,\n",
      "         0.1477, 0.0757, 0.1056, 0.1096, 0.1006, 0.1104, 0.1054, 0.1014, 0.0890,\n",
      "         0.1122, 0.1044, 0.0957, 0.1025, 0.0793]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0064, 0.0062, 0.0106, 0.0034, 0.0063, 0.0060, 0.0036, 0.0109, 0.0054,\n",
      "        0.0043, 0.0061, 0.0067, 0.0071, 0.0083, 0.0070, 0.0095, 0.0104, 0.0095,\n",
      "        0.0111, 0.0050, 0.0082, 0.0092, 0.0082, 0.0080, 0.0089, 0.0076, 0.0068,\n",
      "        0.0077, 0.0088, 0.0069, 0.0081, 0.0057], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0099, 0.0068], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 1.5447e-02,  4.3362e-02,  8.5943e-03],\n",
      "        [ 2.0236e-02,  1.9185e-02, -4.5400e-03],\n",
      "        [ 2.2696e-02,  6.1095e-02,  1.8759e-03],\n",
      "        [ 5.3888e-03,  2.1466e-02,  4.7624e-03],\n",
      "        [ 9.2519e-03,  4.2518e-02, -1.3636e-03],\n",
      "        [ 1.5834e-02,  2.0618e-02, -1.4007e-03],\n",
      "        [ 2.8271e-03,  2.1062e-02,  1.4083e-04],\n",
      "        [ 2.2790e-02,  4.5669e-02,  5.5739e-03],\n",
      "        [ 1.3798e-02,  3.4537e-02, -3.4117e-03],\n",
      "        [ 1.3750e-02,  1.6121e-02, -3.1643e-03],\n",
      "        [ 1.2198e-02,  2.9800e-02, -8.0627e-05],\n",
      "        [ 1.3578e-02,  2.8354e-02,  7.7569e-04],\n",
      "        [ 1.6476e-02,  3.4814e-02,  7.7985e-04],\n",
      "        [ 1.9015e-02,  4.4027e-02,  3.9293e-03],\n",
      "        [ 8.2479e-03,  4.5945e-02,  4.5713e-03],\n",
      "        [ 1.7892e-02,  4.5732e-02, -2.9494e-03],\n",
      "        [ 2.2197e-02,  6.5218e-02,  3.7461e-03],\n",
      "        [ 1.9108e-02,  5.3044e-02,  1.9471e-03],\n",
      "        [ 2.8076e-02,  4.9952e-02,  6.2668e-04],\n",
      "        [ 8.9995e-03,  2.3947e-02,  3.7291e-03],\n",
      "        [ 2.3712e-02,  4.0394e-02,  2.0118e-03],\n",
      "        [ 2.2524e-02,  4.8335e-02, -1.3099e-03],\n",
      "        [ 1.5364e-02,  4.3154e-02,  9.7656e-04],\n",
      "        [ 1.8627e-02,  3.8202e-02,  3.1832e-03],\n",
      "        [ 2.2335e-02,  3.2196e-02,  4.5597e-03],\n",
      "        [ 1.8986e-02,  4.1330e-02,  2.9300e-03],\n",
      "        [ 1.3273e-02,  2.4739e-02,  4.6956e-03],\n",
      "        [ 1.3017e-02,  3.7559e-02, -7.4443e-04],\n",
      "        [ 1.8718e-02,  4.5535e-02,  1.3490e-03],\n",
      "        [ 9.4183e-03,  3.2243e-02, -4.0404e-03],\n",
      "        [ 1.9106e-02,  5.1082e-02,  9.2616e-04],\n",
      "        [ 1.0652e-02,  3.8265e-02,  7.7109e-04]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1153, 0.1161, 0.1805, 0.0785, 0.1068, 0.1086, 0.0845, 0.1676, 0.1124,\n",
      "         0.0962, 0.1003, 0.1178, 0.1393, 0.1307, 0.1448, 0.1592, 0.1775, 0.1537,\n",
      "         0.1893, 0.0992, 0.1418, 0.1425, 0.1542, 0.1473, 0.1677, 0.1373, 0.1214,\n",
      "         0.1483, 0.1492, 0.1356, 0.1502, 0.1244],\n",
      "        [0.0926, 0.0886, 0.1350, 0.0636, 0.0895, 0.0962, 0.0738, 0.1356, 0.0858,\n",
      "         0.0717, 0.1020, 0.0894, 0.0990, 0.1079, 0.1082, 0.1318, 0.1301, 0.1135,\n",
      "         0.1544, 0.0788, 0.1112, 0.1159, 0.1037, 0.1161, 0.1105, 0.1047, 0.0937,\n",
      "         0.1172, 0.1096, 0.0998, 0.1074, 0.0824]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0065, 0.0062, 0.0108, 0.0034, 0.0063, 0.0060, 0.0037, 0.0111, 0.0055,\n",
      "        0.0045, 0.0063, 0.0068, 0.0073, 0.0084, 0.0072, 0.0095, 0.0107, 0.0098,\n",
      "        0.0114, 0.0051, 0.0085, 0.0095, 0.0082, 0.0082, 0.0091, 0.0076, 0.0070,\n",
      "        0.0078, 0.0090, 0.0071, 0.0083, 0.0058], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0102, 0.0070], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0009,  0.0403,  0.0118],\n",
      "        [-0.0071,  0.0286,  0.0117],\n",
      "        [-0.0015,  0.0482,  0.0221],\n",
      "        [ 0.0034,  0.0021, -0.0005],\n",
      "        [ 0.0046,  0.0307,  0.0096],\n",
      "        [-0.0066,  0.0218,  0.0155],\n",
      "        [ 0.0032,  0.0213,  0.0121],\n",
      "        [-0.0021,  0.0511,  0.0212],\n",
      "        [ 0.0001,  0.0063,  0.0102],\n",
      "        [ 0.0062,  0.0099,  0.0071],\n",
      "        [-0.0069,  0.0243,  0.0160],\n",
      "        [-0.0051,  0.0308,  0.0106],\n",
      "        [ 0.0031,  0.0341,  0.0165],\n",
      "        [-0.0052,  0.0388,  0.0217],\n",
      "        [ 0.0111,  0.0323,  0.0108],\n",
      "        [ 0.0059,  0.0438,  0.0169],\n",
      "        [ 0.0014,  0.0556,  0.0184],\n",
      "        [ 0.0030,  0.0444,  0.0225],\n",
      "        [ 0.0004,  0.0528,  0.0248],\n",
      "        [-0.0028,  0.0299,  0.0116],\n",
      "        [-0.0066,  0.0337,  0.0186],\n",
      "        [-0.0003,  0.0480,  0.0235],\n",
      "        [-0.0002,  0.0339,  0.0178],\n",
      "        [-0.0025,  0.0421,  0.0167],\n",
      "        [-0.0076,  0.0257,  0.0108],\n",
      "        [ 0.0013,  0.0386,  0.0079],\n",
      "        [-0.0038,  0.0278,  0.0195],\n",
      "        [-0.0037,  0.0341,  0.0099],\n",
      "        [ 0.0013,  0.0421,  0.0157],\n",
      "        [-0.0003,  0.0198,  0.0125],\n",
      "        [-0.0055,  0.0373,  0.0154],\n",
      "        [ 0.0044,  0.0213,  0.0104]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1213, 0.1208, 0.1892, 0.0822, 0.1121, 0.1129, 0.0888, 0.1746, 0.1168,\n",
      "         0.1001, 0.1061, 0.1236, 0.1463, 0.1366, 0.1523, 0.1656, 0.1861, 0.1617,\n",
      "         0.1974, 0.1046, 0.1490, 0.1492, 0.1608, 0.1551, 0.1756, 0.1422, 0.1285,\n",
      "         0.1550, 0.1564, 0.1419, 0.1574, 0.1306],\n",
      "        [0.0982, 0.0919, 0.1423, 0.0667, 0.0941, 0.0997, 0.0768, 0.1415, 0.0878,\n",
      "         0.0725, 0.1069, 0.0937, 0.1052, 0.1138, 0.1143, 0.1381, 0.1372, 0.1206,\n",
      "         0.1623, 0.0837, 0.1169, 0.1221, 0.1105, 0.1225, 0.1158, 0.1083, 0.0998,\n",
      "         0.1223, 0.1149, 0.1043, 0.1132, 0.0871]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0068, 0.0063, 0.0111, 0.0036, 0.0065, 0.0060, 0.0038, 0.0112, 0.0055,\n",
      "        0.0044, 0.0065, 0.0070, 0.0076, 0.0086, 0.0075, 0.0096, 0.0109, 0.0101,\n",
      "        0.0116, 0.0054, 0.0087, 0.0097, 0.0084, 0.0086, 0.0093, 0.0075, 0.0074,\n",
      "        0.0080, 0.0092, 0.0072, 0.0085, 0.0061], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0104, 0.0072], grad_fn=<MeanBackward1>)\n",
      "Epoch 2/10, Accuracy: 0.4938\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0023,  0.0169, -0.0065],\n",
      "        [-0.0011,  0.0215, -0.0086],\n",
      "        [-0.0037,  0.0431, -0.0088],\n",
      "        [-0.0059,  0.0049, -0.0029],\n",
      "        [ 0.0007,  0.0215, -0.0060],\n",
      "        [-0.0043,  0.0203, -0.0065],\n",
      "        [-0.0054,  0.0075, -0.0050],\n",
      "        [ 0.0003,  0.0436, -0.0065],\n",
      "        [-0.0010,  0.0290, -0.0053],\n",
      "        [-0.0003,  0.0021, -0.0013],\n",
      "        [-0.0084,  0.0076, -0.0027],\n",
      "        [ 0.0017,  0.0182,  0.0009],\n",
      "        [-0.0053,  0.0398, -0.0052],\n",
      "        [-0.0110,  0.0364, -0.0090],\n",
      "        [-0.0019,  0.0287, -0.0093],\n",
      "        [-0.0014,  0.0455, -0.0112],\n",
      "        [-0.0021,  0.0471, -0.0086],\n",
      "        [-0.0010,  0.0482, -0.0051],\n",
      "        [-0.0083,  0.0505, -0.0067],\n",
      "        [ 0.0063,  0.0148, -0.0024],\n",
      "        [-0.0047,  0.0264, -0.0045],\n",
      "        [-0.0058,  0.0441, -0.0061],\n",
      "        [-0.0128,  0.0367, -0.0072],\n",
      "        [-0.0056,  0.0337, -0.0070],\n",
      "        [ 0.0019,  0.0350, -0.0061],\n",
      "        [ 0.0011,  0.0334, -0.0070],\n",
      "        [-0.0103,  0.0222, -0.0024],\n",
      "        [ 0.0032,  0.0337, -0.0056],\n",
      "        [-0.0046,  0.0476, -0.0107],\n",
      "        [-0.0057,  0.0238, -0.0091],\n",
      "        [-0.0021,  0.0324, -0.0101],\n",
      "        [ 0.0028,  0.0367, -0.0066]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1268, 0.1270, 0.1984, 0.0864, 0.1176, 0.1192, 0.0926, 0.1830, 0.1228,\n",
      "         0.1045, 0.1104, 0.1292, 0.1523, 0.1436, 0.1588, 0.1746, 0.1942, 0.1679,\n",
      "         0.2068, 0.1094, 0.1554, 0.1556, 0.1691, 0.1615, 0.1835, 0.1503, 0.1338,\n",
      "         0.1621, 0.1635, 0.1484, 0.1646, 0.1367],\n",
      "        [0.1021, 0.0966, 0.1483, 0.0702, 0.0983, 0.1052, 0.0807, 0.1476, 0.0934,\n",
      "         0.0771, 0.1117, 0.0979, 0.1088, 0.1183, 0.1188, 0.1442, 0.1423, 0.1241,\n",
      "         0.1686, 0.0874, 0.1216, 0.1262, 0.1144, 0.1274, 0.1211, 0.1142, 0.1036,\n",
      "         0.1279, 0.1199, 0.1092, 0.1177, 0.0911]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0069, 0.0065, 0.0112, 0.0037, 0.0067, 0.0063, 0.0039, 0.0114, 0.0058,\n",
      "        0.0046, 0.0066, 0.0071, 0.0077, 0.0088, 0.0076, 0.0099, 0.0110, 0.0101,\n",
      "        0.0117, 0.0055, 0.0088, 0.0098, 0.0085, 0.0086, 0.0095, 0.0079, 0.0074,\n",
      "        0.0082, 0.0093, 0.0074, 0.0086, 0.0062], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0107, 0.0074], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 3.2098e-03,  2.1761e-02,  1.5375e-03],\n",
      "        [-3.1135e-03,  5.5648e-03, -9.3704e-04],\n",
      "        [-3.4362e-03,  4.0076e-02, -5.2793e-03],\n",
      "        [-6.3161e-03,  2.7823e-02,  9.1700e-04],\n",
      "        [ 3.7707e-03,  9.9314e-03,  5.0374e-04],\n",
      "        [-5.6387e-03,  2.6653e-02, -4.8450e-05],\n",
      "        [ 4.1305e-03,  1.5338e-02,  3.2193e-03],\n",
      "        [ 3.3845e-03,  3.8393e-02,  2.3308e-03],\n",
      "        [-8.6471e-04,  2.1239e-02, -1.3803e-03],\n",
      "        [ 4.8849e-03,  1.5975e-02,  3.2609e-03],\n",
      "        [-1.2736e-03,  2.1591e-02,  4.6672e-03],\n",
      "        [-3.0500e-03,  2.8750e-02, -3.1981e-03],\n",
      "        [ 7.3120e-03,  1.6287e-02, -1.3696e-03],\n",
      "        [ 3.9515e-04,  2.6574e-02,  3.9950e-03],\n",
      "        [ 2.1376e-03,  2.2880e-02, -3.0219e-03],\n",
      "        [ 6.0800e-03,  3.4736e-02, -5.8086e-03],\n",
      "        [ 2.8991e-03,  2.6255e-02, -5.1549e-04],\n",
      "        [ 6.9485e-03,  3.4233e-02, -2.1247e-03],\n",
      "        [ 1.1446e-04,  3.6002e-02, -8.1248e-04],\n",
      "        [ 3.9210e-03,  1.2436e-02, -1.8831e-03],\n",
      "        [-1.1393e-03,  2.0707e-02, -9.4931e-05],\n",
      "        [-1.4970e-03,  2.2751e-02,  2.4980e-03],\n",
      "        [ 4.8196e-03,  3.4590e-02, -1.6973e-03],\n",
      "        [-9.4722e-04,  1.5694e-02,  3.0689e-03],\n",
      "        [-1.7611e-03,  2.7102e-02, -4.3123e-03],\n",
      "        [ 6.2003e-03,  2.0163e-02, -2.6821e-03],\n",
      "        [ 1.3303e-03,  1.5868e-02,  1.4424e-03],\n",
      "        [ 3.9012e-03,  2.7969e-02, -6.4376e-03],\n",
      "        [ 3.9534e-04,  2.7356e-02, -6.5419e-03],\n",
      "        [ 4.7105e-03,  2.6265e-02, -4.3504e-06],\n",
      "        [ 4.2587e-03,  1.4048e-02, -6.9627e-03],\n",
      "        [ 6.4373e-03,  1.3806e-02, -1.2353e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1323, 0.1330, 0.2068, 0.0896, 0.1227, 0.1248, 0.0971, 0.1917, 0.1291,\n",
      "         0.1106, 0.1159, 0.1352, 0.1589, 0.1496, 0.1655, 0.1818, 0.2029, 0.1757,\n",
      "         0.2157, 0.1137, 0.1628, 0.1629, 0.1750, 0.1685, 0.1920, 0.1570, 0.1396,\n",
      "         0.1695, 0.1713, 0.1551, 0.1718, 0.1421],\n",
      "        [0.1068, 0.1009, 0.1553, 0.0727, 0.1026, 0.1095, 0.0840, 0.1547, 0.0969,\n",
      "         0.0804, 0.1167, 0.1024, 0.1141, 0.1240, 0.1242, 0.1508, 0.1495, 0.1310,\n",
      "         0.1766, 0.0909, 0.1276, 0.1330, 0.1198, 0.1332, 0.1268, 0.1193, 0.1085,\n",
      "         0.1336, 0.1258, 0.1141, 0.1234, 0.0948]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0070, 0.0066, 0.0114, 0.0038, 0.0068, 0.0064, 0.0041, 0.0115, 0.0059,\n",
      "        0.0048, 0.0068, 0.0073, 0.0078, 0.0089, 0.0077, 0.0100, 0.0113, 0.0103,\n",
      "        0.0119, 0.0056, 0.0090, 0.0099, 0.0086, 0.0088, 0.0097, 0.0080, 0.0076,\n",
      "        0.0083, 0.0095, 0.0075, 0.0088, 0.0063], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0110, 0.0076], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 7.5934e-03,  3.3904e-02,  9.3311e-03],\n",
      "        [ 1.7295e-02,  3.6767e-02,  2.2926e-03],\n",
      "        [ 1.0416e-02,  5.5638e-02,  1.1178e-02],\n",
      "        [ 5.6975e-03,  1.7284e-02,  5.8497e-03],\n",
      "        [ 5.2380e-03,  3.6206e-02,  1.0515e-02],\n",
      "        [ 1.2231e-02,  2.9106e-02, -6.0974e-03],\n",
      "        [-3.3710e-03,  1.3037e-02,  4.1279e-03],\n",
      "        [ 9.9603e-03,  6.4852e-02,  9.8025e-03],\n",
      "        [ 9.6161e-03,  2.0694e-02,  8.0800e-04],\n",
      "        [ 1.0151e-02,  2.4031e-02,  2.2253e-03],\n",
      "        [ 1.1249e-02,  2.9819e-02,  8.5929e-03],\n",
      "        [ 1.0110e-02,  3.5435e-02,  6.8738e-03],\n",
      "        [ 4.3127e-03,  4.2481e-02,  1.1899e-02],\n",
      "        [ 4.0762e-03,  5.2378e-02,  1.1675e-02],\n",
      "        [ 5.0758e-03,  3.7846e-02,  1.1016e-02],\n",
      "        [ 1.0684e-02,  6.0819e-02,  1.0981e-02],\n",
      "        [ 9.0300e-03,  6.4376e-02,  2.1963e-02],\n",
      "        [ 4.4503e-03,  5.4956e-02,  1.6199e-02],\n",
      "        [ 1.4647e-02,  6.4615e-02,  1.4004e-02],\n",
      "        [ 2.3309e-03,  2.1630e-02,  8.2662e-03],\n",
      "        [ 1.4597e-02,  3.7162e-02,  9.0439e-03],\n",
      "        [ 1.0358e-02,  5.3149e-02,  1.6210e-02],\n",
      "        [ 6.1933e-03,  4.6137e-02,  7.0905e-03],\n",
      "        [ 1.3249e-02,  4.6142e-02,  1.4911e-02],\n",
      "        [ 1.7034e-02,  5.3762e-02,  1.4109e-02],\n",
      "        [ 5.8533e-03,  5.4976e-02,  8.6960e-03],\n",
      "        [ 8.9236e-03,  2.9325e-02,  1.1622e-02],\n",
      "        [ 4.7546e-03,  4.6483e-02,  4.2465e-03],\n",
      "        [ 1.4386e-02,  5.4454e-02,  1.1485e-02],\n",
      "        [ 3.5608e-03,  4.5470e-02,  4.8247e-03],\n",
      "        [ 1.0491e-02,  4.3383e-02,  1.5394e-02],\n",
      "        [ 5.3140e-05,  2.8930e-02,  6.8695e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1396, 0.1383, 0.2180, 0.0932, 0.1288, 0.1291, 0.1004, 0.2016, 0.1324,\n",
      "         0.1131, 0.1215, 0.1416, 0.1677, 0.1578, 0.1738, 0.1909, 0.2137, 0.1863,\n",
      "         0.2271, 0.1193, 0.1712, 0.1723, 0.1852, 0.1773, 0.2009, 0.1634, 0.1475,\n",
      "         0.1772, 0.1797, 0.1620, 0.1806, 0.1486],\n",
      "        [0.1119, 0.1052, 0.1629, 0.0756, 0.1072, 0.1138, 0.0871, 0.1624, 0.1004,\n",
      "         0.0835, 0.1218, 0.1072, 0.1195, 0.1299, 0.1298, 0.1578, 0.1566, 0.1377,\n",
      "         0.1849, 0.0948, 0.1337, 0.1396, 0.1259, 0.1394, 0.1327, 0.1245, 0.1135,\n",
      "         0.1397, 0.1317, 0.1191, 0.1293, 0.0988]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0072, 0.0067, 0.0117, 0.0038, 0.0069, 0.0064, 0.0040, 0.0119, 0.0059,\n",
      "        0.0047, 0.0069, 0.0074, 0.0081, 0.0092, 0.0079, 0.0103, 0.0116, 0.0107,\n",
      "        0.0123, 0.0057, 0.0092, 0.0103, 0.0089, 0.0090, 0.0099, 0.0081, 0.0077,\n",
      "        0.0085, 0.0098, 0.0077, 0.0090, 0.0064], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0112, 0.0078], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0003,  0.0282, -0.0030],\n",
      "        [ 0.0017,  0.0334, -0.0054],\n",
      "        [ 0.0030,  0.0625,  0.0046],\n",
      "        [ 0.0038,  0.0108,  0.0017],\n",
      "        [-0.0021,  0.0412, -0.0029],\n",
      "        [-0.0022,  0.0320, -0.0009],\n",
      "        [-0.0015,  0.0101, -0.0088],\n",
      "        [ 0.0093,  0.0530, -0.0009],\n",
      "        [ 0.0060,  0.0404,  0.0075],\n",
      "        [-0.0052,  0.0212, -0.0018],\n",
      "        [ 0.0005,  0.0297, -0.0046],\n",
      "        [ 0.0013,  0.0415,  0.0003],\n",
      "        [ 0.0096,  0.0356,  0.0005],\n",
      "        [ 0.0011,  0.0450, -0.0040],\n",
      "        [ 0.0021,  0.0312,  0.0039],\n",
      "        [ 0.0059,  0.0523,  0.0010],\n",
      "        [ 0.0029,  0.0539,  0.0024],\n",
      "        [ 0.0108,  0.0555,  0.0069],\n",
      "        [ 0.0049,  0.0511, -0.0003],\n",
      "        [-0.0045,  0.0347, -0.0033],\n",
      "        [ 0.0033,  0.0381, -0.0024],\n",
      "        [ 0.0041,  0.0427,  0.0041],\n",
      "        [ 0.0050,  0.0443,  0.0002],\n",
      "        [ 0.0052,  0.0351, -0.0024],\n",
      "        [ 0.0049,  0.0476,  0.0058],\n",
      "        [ 0.0019,  0.0368,  0.0056],\n",
      "        [-0.0011,  0.0362, -0.0011],\n",
      "        [ 0.0102,  0.0485,  0.0057],\n",
      "        [ 0.0084,  0.0535,  0.0094],\n",
      "        [-0.0004,  0.0486, -0.0005],\n",
      "        [ 0.0006,  0.0486, -0.0025],\n",
      "        [ 0.0075,  0.0378,  0.0018]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1458, 0.1450, 0.2279, 0.0969, 0.1346, 0.1356, 0.1045, 0.2117, 0.1389,\n",
      "         0.1187, 0.1267, 0.1481, 0.1750, 0.1653, 0.1811, 0.2004, 0.2237, 0.1945,\n",
      "         0.2380, 0.1242, 0.1791, 0.1808, 0.1936, 0.1850, 0.2100, 0.1718, 0.1534,\n",
      "         0.1853, 0.1882, 0.1693, 0.1888, 0.1549],\n",
      "        [0.1164, 0.1104, 0.1695, 0.0788, 0.1117, 0.1197, 0.0914, 0.1697, 0.1064,\n",
      "         0.0889, 0.1273, 0.1121, 0.1241, 0.1352, 0.1350, 0.1646, 0.1632, 0.1428,\n",
      "         0.1926, 0.0985, 0.1396, 0.1452, 0.1303, 0.1451, 0.1389, 0.1308, 0.1179,\n",
      "         0.1460, 0.1377, 0.1246, 0.1346, 0.1029]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0073, 0.0069, 0.0119, 0.0039, 0.0071, 0.0067, 0.0042, 0.0121, 0.0061,\n",
      "        0.0049, 0.0071, 0.0076, 0.0082, 0.0094, 0.0081, 0.0105, 0.0118, 0.0108,\n",
      "        0.0125, 0.0058, 0.0094, 0.0104, 0.0091, 0.0092, 0.0101, 0.0084, 0.0079,\n",
      "        0.0087, 0.0099, 0.0079, 0.0092, 0.0066], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0115, 0.0081], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0133,  0.0585,  0.0055],\n",
      "        [ 0.0062,  0.0673, -0.0005],\n",
      "        [ 0.0179,  0.1108,  0.0019],\n",
      "        [ 0.0105,  0.0265, -0.0037],\n",
      "        [ 0.0106,  0.0710, -0.0005],\n",
      "        [ 0.0109,  0.0532, -0.0104],\n",
      "        [ 0.0103,  0.0313, -0.0074],\n",
      "        [ 0.0189,  0.1032, -0.0029],\n",
      "        [ 0.0116,  0.0528,  0.0063],\n",
      "        [ 0.0087,  0.0287,  0.0079],\n",
      "        [ 0.0069,  0.0671,  0.0038],\n",
      "        [ 0.0080,  0.0657, -0.0009],\n",
      "        [ 0.0143,  0.0715,  0.0011],\n",
      "        [ 0.0130,  0.0863,  0.0045],\n",
      "        [ 0.0140,  0.0753,  0.0006],\n",
      "        [ 0.0160,  0.1059,  0.0001],\n",
      "        [ 0.0172,  0.1084,  0.0070],\n",
      "        [ 0.0162,  0.1055,  0.0012],\n",
      "        [ 0.0183,  0.1090,  0.0067],\n",
      "        [ 0.0089,  0.0496, -0.0041],\n",
      "        [ 0.0159,  0.0787,  0.0006],\n",
      "        [ 0.0129,  0.1015,  0.0016],\n",
      "        [ 0.0126,  0.0859,  0.0015],\n",
      "        [ 0.0115,  0.0842,  0.0011],\n",
      "        [ 0.0163,  0.0819,  0.0072],\n",
      "        [ 0.0107,  0.0802, -0.0046],\n",
      "        [ 0.0085,  0.0683,  0.0035],\n",
      "        [ 0.0113,  0.0800,  0.0042],\n",
      "        [ 0.0102,  0.1015,  0.0016],\n",
      "        [ 0.0156,  0.0732,  0.0065],\n",
      "        [ 0.0116,  0.0832,  0.0096],\n",
      "        [ 0.0107,  0.0568, -0.0023]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1530, 0.1517, 0.2397, 0.1003, 0.1409, 0.1413, 0.1078, 0.2235, 0.1433,\n",
      "         0.1226, 0.1315, 0.1549, 0.1835, 0.1742, 0.1894, 0.2109, 0.2351, 0.2056,\n",
      "         0.2508, 0.1291, 0.1878, 0.1912, 0.2044, 0.1931, 0.2195, 0.1799, 0.1599,\n",
      "         0.1938, 0.1974, 0.1768, 0.1981, 0.1611],\n",
      "        [0.1222, 0.1156, 0.1789, 0.0817, 0.1171, 0.1247, 0.0937, 0.1795, 0.1091,\n",
      "         0.0907, 0.1316, 0.1171, 0.1305, 0.1430, 0.1412, 0.1739, 0.1719, 0.1511,\n",
      "         0.2035, 0.1025, 0.1462, 0.1538, 0.1394, 0.1514, 0.1451, 0.1376, 0.1229,\n",
      "         0.1527, 0.1445, 0.1301, 0.1416, 0.1072]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0075, 0.0071, 0.0123, 0.0039, 0.0073, 0.0068, 0.0041, 0.0125, 0.0061,\n",
      "        0.0049, 0.0071, 0.0077, 0.0084, 0.0097, 0.0082, 0.0109, 0.0121, 0.0111,\n",
      "        0.0129, 0.0059, 0.0096, 0.0108, 0.0095, 0.0093, 0.0103, 0.0086, 0.0080,\n",
      "        0.0089, 0.0102, 0.0080, 0.0094, 0.0067], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0118, 0.0083], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0114,  0.0394, -0.0020],\n",
      "        [ 0.0147,  0.0290, -0.0077],\n",
      "        [ 0.0078,  0.0684, -0.0129],\n",
      "        [ 0.0032,  0.0278, -0.0045],\n",
      "        [ 0.0111,  0.0445, -0.0082],\n",
      "        [ 0.0088,  0.0352, -0.0095],\n",
      "        [ 0.0093,  0.0133, -0.0017],\n",
      "        [ 0.0244,  0.0854, -0.0153],\n",
      "        [ 0.0015,  0.0436, -0.0167],\n",
      "        [ 0.0046,  0.0345, -0.0131],\n",
      "        [ 0.0078,  0.0300, -0.0137],\n",
      "        [ 0.0088,  0.0412, -0.0085],\n",
      "        [ 0.0124,  0.0502, -0.0079],\n",
      "        [ 0.0069,  0.0804, -0.0159],\n",
      "        [ 0.0125,  0.0424, -0.0066],\n",
      "        [ 0.0178,  0.0608, -0.0112],\n",
      "        [ 0.0094,  0.0787, -0.0060],\n",
      "        [ 0.0092,  0.0772, -0.0103],\n",
      "        [ 0.0200,  0.0766, -0.0186],\n",
      "        [ 0.0110,  0.0355, -0.0008],\n",
      "        [ 0.0110,  0.0506, -0.0035],\n",
      "        [ 0.0107,  0.0695, -0.0099],\n",
      "        [ 0.0077,  0.0494, -0.0143],\n",
      "        [ 0.0116,  0.0565, -0.0034],\n",
      "        [ 0.0157,  0.0587, -0.0102],\n",
      "        [ 0.0126,  0.0481, -0.0112],\n",
      "        [ 0.0066,  0.0510, -0.0191],\n",
      "        [ 0.0177,  0.0420, -0.0120],\n",
      "        [ 0.0115,  0.0588, -0.0107],\n",
      "        [ 0.0079,  0.0524, -0.0091],\n",
      "        [ 0.0101,  0.0424, -0.0055],\n",
      "        [ 0.0084,  0.0513, -0.0083]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1597, 0.1586, 0.2499, 0.1052, 0.1475, 0.1484, 0.1136, 0.2322, 0.1510,\n",
      "         0.1292, 0.1386, 0.1621, 0.1913, 0.1812, 0.1978, 0.2201, 0.2447, 0.2135,\n",
      "         0.2606, 0.1354, 0.1962, 0.1984, 0.2122, 0.2020, 0.2296, 0.1880, 0.1681,\n",
      "         0.2025, 0.2064, 0.1849, 0.2067, 0.1686],\n",
      "        [0.1274, 0.1209, 0.1864, 0.0853, 0.1222, 0.1307, 0.0986, 0.1866, 0.1152,\n",
      "         0.0959, 0.1380, 0.1226, 0.1358, 0.1484, 0.1474, 0.1810, 0.1791, 0.1571,\n",
      "         0.2113, 0.1070, 0.1527, 0.1599, 0.1442, 0.1581, 0.1519, 0.1435, 0.1284,\n",
      "         0.1595, 0.1511, 0.1360, 0.1477, 0.1119]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0076, 0.0073, 0.0124, 0.0040, 0.0074, 0.0070, 0.0043, 0.0126, 0.0064,\n",
      "        0.0051, 0.0073, 0.0079, 0.0085, 0.0097, 0.0084, 0.0110, 0.0122, 0.0112,\n",
      "        0.0130, 0.0060, 0.0097, 0.0108, 0.0095, 0.0095, 0.0105, 0.0088, 0.0081,\n",
      "        0.0091, 0.0103, 0.0082, 0.0096, 0.0068], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0121, 0.0085], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0044,  0.0559, -0.0001],\n",
      "        [ 0.0089,  0.0471,  0.0014],\n",
      "        [ 0.0100,  0.0864,  0.0045],\n",
      "        [ 0.0054,  0.0244,  0.0048],\n",
      "        [ 0.0119,  0.0383, -0.0023],\n",
      "        [ 0.0084,  0.0496, -0.0040],\n",
      "        [ 0.0063,  0.0228, -0.0006],\n",
      "        [ 0.0155,  0.0773, -0.0005],\n",
      "        [ 0.0080,  0.0462,  0.0014],\n",
      "        [ 0.0012,  0.0267, -0.0007],\n",
      "        [ 0.0113,  0.0368,  0.0019],\n",
      "        [ 0.0048,  0.0514,  0.0008],\n",
      "        [ 0.0125,  0.0509, -0.0036],\n",
      "        [ 0.0136,  0.0637,  0.0048],\n",
      "        [ 0.0085,  0.0617,  0.0040],\n",
      "        [ 0.0155,  0.0711,  0.0018],\n",
      "        [ 0.0127,  0.0728,  0.0075],\n",
      "        [ 0.0117,  0.0747,  0.0036],\n",
      "        [ 0.0127,  0.0862, -0.0025],\n",
      "        [ 0.0055,  0.0406, -0.0019],\n",
      "        [ 0.0102,  0.0633, -0.0052],\n",
      "        [ 0.0107,  0.0706,  0.0008],\n",
      "        [ 0.0079,  0.0788, -0.0023],\n",
      "        [ 0.0145,  0.0580, -0.0024],\n",
      "        [ 0.0085,  0.0616,  0.0072],\n",
      "        [ 0.0076,  0.0686, -0.0015],\n",
      "        [ 0.0112,  0.0613, -0.0057],\n",
      "        [ 0.0097,  0.0650,  0.0004],\n",
      "        [ 0.0117,  0.0801,  0.0023],\n",
      "        [ 0.0121,  0.0395,  0.0029],\n",
      "        [ 0.0110,  0.0635,  0.0014],\n",
      "        [ 0.0130,  0.0504, -0.0024]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1675, 0.1657, 0.2619, 0.1094, 0.1545, 0.1547, 0.1180, 0.2443, 0.1569,\n",
      "         0.1339, 0.1450, 0.1697, 0.2006, 0.1904, 0.2068, 0.2307, 0.2568, 0.2246,\n",
      "         0.2735, 0.1415, 0.2058, 0.2090, 0.2222, 0.2115, 0.2400, 0.1964, 0.1762,\n",
      "         0.2116, 0.2161, 0.1931, 0.2165, 0.1761],\n",
      "        [0.1334, 0.1263, 0.1951, 0.0892, 0.1279, 0.1364, 0.1026, 0.1956, 0.1198,\n",
      "         0.0997, 0.1442, 0.1283, 0.1424, 0.1559, 0.1541, 0.1896, 0.1876, 0.1648,\n",
      "         0.2211, 0.1119, 0.1600, 0.1675, 0.1509, 0.1656, 0.1590, 0.1501, 0.1347,\n",
      "         0.1667, 0.1581, 0.1422, 0.1546, 0.1172]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0078, 0.0074, 0.0127, 0.0041, 0.0076, 0.0071, 0.0044, 0.0129, 0.0065,\n",
      "        0.0052, 0.0075, 0.0081, 0.0087, 0.0100, 0.0086, 0.0112, 0.0125, 0.0115,\n",
      "        0.0133, 0.0062, 0.0099, 0.0111, 0.0097, 0.0098, 0.0107, 0.0089, 0.0084,\n",
      "        0.0093, 0.0106, 0.0084, 0.0098, 0.0070], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0123, 0.0087], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0042,  0.0487, -0.0039],\n",
      "        [-0.0010,  0.0459, -0.0029],\n",
      "        [-0.0097,  0.0604,  0.0058],\n",
      "        [-0.0070,  0.0126,  0.0056],\n",
      "        [-0.0134,  0.0422,  0.0037],\n",
      "        [-0.0008,  0.0441, -0.0036],\n",
      "        [-0.0030,  0.0377, -0.0007],\n",
      "        [-0.0132,  0.0709, -0.0015],\n",
      "        [-0.0081,  0.0306, -0.0007],\n",
      "        [-0.0085,  0.0269,  0.0040],\n",
      "        [-0.0045,  0.0340,  0.0002],\n",
      "        [-0.0083,  0.0431, -0.0013],\n",
      "        [-0.0083,  0.0413,  0.0051],\n",
      "        [-0.0110,  0.0489, -0.0012],\n",
      "        [-0.0090,  0.0575,  0.0069],\n",
      "        [-0.0126,  0.0683,  0.0068],\n",
      "        [-0.0079,  0.0712,  0.0022],\n",
      "        [-0.0111,  0.0624,  0.0053],\n",
      "        [-0.0145,  0.0803,  0.0056],\n",
      "        [-0.0158,  0.0388, -0.0010],\n",
      "        [-0.0147,  0.0562, -0.0064],\n",
      "        [-0.0104,  0.0678,  0.0044],\n",
      "        [-0.0083,  0.0533,  0.0019],\n",
      "        [-0.0089,  0.0504, -0.0053],\n",
      "        [-0.0168,  0.0537,  0.0024],\n",
      "        [-0.0026,  0.0558, -0.0064],\n",
      "        [-0.0223,  0.0384, -0.0003],\n",
      "        [-0.0093,  0.0456, -0.0002],\n",
      "        [-0.0058,  0.0494,  0.0036],\n",
      "        [-0.0217,  0.0319,  0.0047],\n",
      "        [-0.0106,  0.0461,  0.0026],\n",
      "        [-0.0120,  0.0327,  0.0003]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1760, 0.1726, 0.2740, 0.1157, 0.1621, 0.1617, 0.1247, 0.2535, 0.1641,\n",
      "         0.1394, 0.1533, 0.1777, 0.2100, 0.1991, 0.2170, 0.2402, 0.2679, 0.2341,\n",
      "         0.2844, 0.1494, 0.2153, 0.2167, 0.2322, 0.2223, 0.2510, 0.2040, 0.1858,\n",
      "         0.2210, 0.2259, 0.2020, 0.2262, 0.1851],\n",
      "        [0.1404, 0.1315, 0.2045, 0.0941, 0.1341, 0.1424, 0.1080, 0.2033, 0.1249,\n",
      "         0.1032, 0.1514, 0.1343, 0.1495, 0.1633, 0.1618, 0.1979, 0.1960, 0.1724,\n",
      "         0.2305, 0.1182, 0.1673, 0.1743, 0.1592, 0.1738, 0.1665, 0.1563, 0.1421,\n",
      "         0.1741, 0.1654, 0.1488, 0.1619, 0.1236]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0080, 0.0075, 0.0129, 0.0044, 0.0078, 0.0073, 0.0046, 0.0129, 0.0066,\n",
      "        0.0053, 0.0077, 0.0083, 0.0089, 0.0102, 0.0088, 0.0114, 0.0127, 0.0116,\n",
      "        0.0134, 0.0064, 0.0101, 0.0112, 0.0100, 0.0101, 0.0109, 0.0090, 0.0087,\n",
      "        0.0094, 0.0107, 0.0086, 0.0100, 0.0073], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0126, 0.0090], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0065,  0.0254,  0.0085],\n",
      "        [-0.0103,  0.0220,  0.0132],\n",
      "        [-0.0101,  0.0262,  0.0133],\n",
      "        [-0.0039, -0.0003,  0.0022],\n",
      "        [-0.0054,  0.0274,  0.0034],\n",
      "        [-0.0122,  0.0121,  0.0098],\n",
      "        [-0.0138,  0.0045,  0.0091],\n",
      "        [-0.0075,  0.0228,  0.0053],\n",
      "        [ 0.0023,  0.0053,  0.0009],\n",
      "        [-0.0022,  0.0149, -0.0029],\n",
      "        [-0.0080,  0.0248,  0.0065],\n",
      "        [-0.0030,  0.0145,  0.0047],\n",
      "        [-0.0180,  0.0267,  0.0075],\n",
      "        [ 0.0003,  0.0132,  0.0032],\n",
      "        [-0.0123,  0.0189,  0.0036],\n",
      "        [-0.0141,  0.0287,  0.0076],\n",
      "        [-0.0062,  0.0287,  0.0108],\n",
      "        [-0.0073,  0.0192,  0.0056],\n",
      "        [-0.0134,  0.0310,  0.0081],\n",
      "        [-0.0013,  0.0212,  0.0078],\n",
      "        [-0.0030,  0.0220,  0.0113],\n",
      "        [-0.0045,  0.0190,  0.0128],\n",
      "        [-0.0177,  0.0119,  0.0018],\n",
      "        [-0.0087,  0.0280,  0.0100],\n",
      "        [-0.0040,  0.0164,  0.0085],\n",
      "        [-0.0081,  0.0244,  0.0076],\n",
      "        [-0.0086,  0.0254, -0.0039],\n",
      "        [-0.0026,  0.0096,  0.0057],\n",
      "        [-0.0085,  0.0098,  0.0098],\n",
      "        [-0.0033,  0.0032,  0.0016],\n",
      "        [-0.0031,  0.0279,  0.0127],\n",
      "        [-0.0100,  0.0149, -0.0006]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1834, 0.1804, 0.2852, 0.1205, 0.1692, 0.1692, 0.1312, 0.2642, 0.1728,\n",
      "         0.1473, 0.1619, 0.1859, 0.2186, 0.2069, 0.2262, 0.2492, 0.2793, 0.2442,\n",
      "         0.2954, 0.1565, 0.2251, 0.2255, 0.2393, 0.2323, 0.2625, 0.2128, 0.1949,\n",
      "         0.2307, 0.2362, 0.2111, 0.2356, 0.1930],\n",
      "        [0.1467, 0.1370, 0.2131, 0.0981, 0.1401, 0.1484, 0.1131, 0.2119, 0.1309,\n",
      "         0.1084, 0.1593, 0.1407, 0.1563, 0.1699, 0.1693, 0.2052, 0.2048, 0.1808,\n",
      "         0.2397, 0.1242, 0.1753, 0.1820, 0.1645, 0.1821, 0.1744, 0.1622, 0.1498,\n",
      "         0.1817, 0.1731, 0.1555, 0.1689, 0.1293]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0082, 0.0076, 0.0131, 0.0045, 0.0079, 0.0074, 0.0048, 0.0131, 0.0069,\n",
      "        0.0055, 0.0080, 0.0085, 0.0091, 0.0103, 0.0090, 0.0114, 0.0129, 0.0118,\n",
      "        0.0135, 0.0066, 0.0103, 0.0113, 0.0099, 0.0103, 0.0112, 0.0092, 0.0089,\n",
      "        0.0096, 0.0110, 0.0088, 0.0101, 0.0074], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0129, 0.0092], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0195,  0.0481, -0.0018],\n",
      "        [-0.0139,  0.0536, -0.0246],\n",
      "        [-0.0250,  0.0927, -0.0110],\n",
      "        [-0.0099,  0.0297,  0.0050],\n",
      "        [-0.0125,  0.0736, -0.0029],\n",
      "        [-0.0157,  0.0395, -0.0135],\n",
      "        [-0.0058,  0.0384, -0.0065],\n",
      "        [-0.0219,  0.0892, -0.0159],\n",
      "        [-0.0155,  0.0467,  0.0029],\n",
      "        [-0.0167,  0.0355, -0.0051],\n",
      "        [-0.0107,  0.0663, -0.0136],\n",
      "        [-0.0128,  0.0715, -0.0071],\n",
      "        [-0.0160,  0.0705, -0.0151],\n",
      "        [-0.0255,  0.0660, -0.0119],\n",
      "        [-0.0212,  0.0682,  0.0035],\n",
      "        [-0.0268,  0.0778, -0.0152],\n",
      "        [-0.0235,  0.0935, -0.0045],\n",
      "        [-0.0249,  0.0861, -0.0030],\n",
      "        [-0.0280,  0.0982, -0.0234],\n",
      "        [-0.0133,  0.0445, -0.0073],\n",
      "        [-0.0206,  0.0730, -0.0154],\n",
      "        [-0.0219,  0.0758, -0.0158],\n",
      "        [-0.0216,  0.0862, -0.0145],\n",
      "        [-0.0188,  0.0736, -0.0141],\n",
      "        [-0.0213,  0.0733, -0.0117],\n",
      "        [-0.0190,  0.0561, -0.0135],\n",
      "        [-0.0176,  0.0848, -0.0211],\n",
      "        [-0.0152,  0.0696, -0.0038],\n",
      "        [-0.0249,  0.0651, -0.0122],\n",
      "        [-0.0168,  0.0659, -0.0094],\n",
      "        [-0.0208,  0.0736, -0.0111],\n",
      "        [-0.0134,  0.0615,  0.0008]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.1929, 0.1885, 0.3005, 0.1260, 0.1778, 0.1770, 0.1349, 0.2786, 0.1784,\n",
      "         0.1505, 0.1675, 0.1943, 0.2299, 0.2192, 0.2367, 0.2646, 0.2933, 0.2566,\n",
      "         0.3122, 0.1633, 0.2356, 0.2385, 0.2552, 0.2427, 0.2740, 0.2243, 0.2038,\n",
      "         0.2413, 0.2474, 0.2205, 0.2477, 0.2020],\n",
      "        [0.1533, 0.1438, 0.2239, 0.1030, 0.1468, 0.1558, 0.1172, 0.2226, 0.1365,\n",
      "         0.1123, 0.1651, 0.1469, 0.1634, 0.1788, 0.1765, 0.2169, 0.2140, 0.1882,\n",
      "         0.2519, 0.1293, 0.1828, 0.1905, 0.1745, 0.1896, 0.1822, 0.1718, 0.1558,\n",
      "         0.1901, 0.1810, 0.1627, 0.1770, 0.1350]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0084, 0.0078, 0.0135, 0.0046, 0.0081, 0.0076, 0.0048, 0.0135, 0.0069,\n",
      "        0.0054, 0.0081, 0.0086, 0.0093, 0.0107, 0.0092, 0.0120, 0.0132, 0.0120,\n",
      "        0.0140, 0.0067, 0.0105, 0.0116, 0.0104, 0.0105, 0.0114, 0.0095, 0.0091,\n",
      "        0.0098, 0.0112, 0.0089, 0.0104, 0.0076], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0132, 0.0095], grad_fn=<MeanBackward1>)\n",
      "Epoch 3/10, Accuracy: 0.4938\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-2.5303e-03,  4.1925e-02,  5.1329e-03],\n",
      "        [ 4.3588e-03,  3.8405e-02,  4.4130e-04],\n",
      "        [ 1.4142e-03,  7.7611e-02,  7.5335e-03],\n",
      "        [ 5.9658e-04,  2.8860e-02, -4.4661e-03],\n",
      "        [-2.3109e-04,  4.3271e-02,  7.9560e-03],\n",
      "        [-4.3324e-03,  4.0228e-02,  2.2370e-04],\n",
      "        [-7.8802e-05,  2.4827e-02,  1.2262e-02],\n",
      "        [ 1.1102e-03,  8.0728e-02,  5.4192e-03],\n",
      "        [ 4.1821e-03,  2.3696e-02,  4.4136e-03],\n",
      "        [-4.8713e-05,  2.8521e-02, -6.6924e-05],\n",
      "        [ 4.5662e-03,  4.4746e-02,  3.7555e-03],\n",
      "        [-6.0629e-03,  6.5894e-02,  9.5762e-03],\n",
      "        [ 4.9139e-03,  4.3797e-02,  7.4467e-03],\n",
      "        [-5.0319e-03,  5.3056e-02,  2.0291e-04],\n",
      "        [ 4.2251e-04,  5.0135e-02,  8.1157e-03],\n",
      "        [ 2.3506e-03,  6.6887e-02,  5.9613e-03],\n",
      "        [ 2.7243e-03,  8.0152e-02,  8.0279e-03],\n",
      "        [-2.6472e-03,  6.7857e-02,  5.2930e-03],\n",
      "        [-1.2068e-04,  7.5083e-02,  1.1983e-02],\n",
      "        [-6.7185e-03,  4.1810e-02,  4.2444e-03],\n",
      "        [-3.1554e-03,  5.1245e-02,  6.8996e-03],\n",
      "        [ 3.8080e-03,  6.5439e-02,  9.6863e-03],\n",
      "        [-3.4660e-03,  6.5679e-02,  1.4957e-02],\n",
      "        [ 1.5781e-03,  5.7447e-02,  6.6381e-03],\n",
      "        [ 7.8299e-03,  6.9150e-02, -1.7379e-03],\n",
      "        [-4.8680e-03,  7.3238e-02,  5.2408e-03],\n",
      "        [-2.3457e-03,  4.4995e-02,  1.4484e-02],\n",
      "        [-9.3050e-05,  6.0650e-02,  1.0506e-02],\n",
      "        [ 4.8786e-03,  6.6242e-02,  9.6318e-03],\n",
      "        [ 4.6929e-03,  4.9465e-02,  8.4965e-03],\n",
      "        [ 5.3887e-03,  5.0314e-02,  7.4569e-03],\n",
      "        [-5.0429e-03,  3.9263e-02,  6.4557e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2014, 0.1971, 0.3137, 0.1297, 0.1853, 0.1843, 0.1404, 0.2924, 0.1857,\n",
      "         0.1581, 0.1750, 0.2032, 0.2397, 0.2286, 0.2469, 0.2754, 0.3071, 0.2696,\n",
      "         0.3263, 0.1692, 0.2468, 0.2504, 0.2650, 0.2532, 0.2865, 0.2337, 0.2117,\n",
      "         0.2521, 0.2591, 0.2301, 0.2587, 0.2093],\n",
      "        [0.1602, 0.1500, 0.2338, 0.1067, 0.1531, 0.1623, 0.1224, 0.2327, 0.1422,\n",
      "         0.1179, 0.1728, 0.1537, 0.1709, 0.1865, 0.1845, 0.2258, 0.2243, 0.1978,\n",
      "         0.2629, 0.1347, 0.1915, 0.1996, 0.1813, 0.1983, 0.1908, 0.1786, 0.1627,\n",
      "         0.1986, 0.1895, 0.1699, 0.1852, 0.1406]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0085, 0.0080, 0.0137, 0.0046, 0.0083, 0.0077, 0.0049, 0.0138, 0.0071,\n",
      "        0.0056, 0.0082, 0.0088, 0.0095, 0.0108, 0.0094, 0.0121, 0.0135, 0.0123,\n",
      "        0.0143, 0.0068, 0.0108, 0.0119, 0.0105, 0.0107, 0.0116, 0.0097, 0.0092,\n",
      "        0.0100, 0.0114, 0.0091, 0.0106, 0.0077], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0135, 0.0097], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0048,  0.0331, -0.0026],\n",
      "        [-0.0072,  0.0185, -0.0041],\n",
      "        [ 0.0063,  0.0442,  0.0050],\n",
      "        [ 0.0092,  0.0197,  0.0029],\n",
      "        [-0.0029,  0.0369,  0.0005],\n",
      "        [-0.0002,  0.0245,  0.0085],\n",
      "        [-0.0011,  0.0173,  0.0012],\n",
      "        [ 0.0062,  0.0515,  0.0098],\n",
      "        [-0.0007,  0.0284,  0.0104],\n",
      "        [ 0.0046,  0.0160, -0.0142],\n",
      "        [ 0.0011,  0.0208,  0.0017],\n",
      "        [ 0.0109,  0.0273, -0.0085],\n",
      "        [-0.0047,  0.0321,  0.0013],\n",
      "        [ 0.0069,  0.0283,  0.0073],\n",
      "        [ 0.0028,  0.0509,  0.0052],\n",
      "        [ 0.0051,  0.0474,  0.0106],\n",
      "        [ 0.0045,  0.0441,  0.0018],\n",
      "        [ 0.0055,  0.0425,  0.0086],\n",
      "        [ 0.0014,  0.0610, -0.0024],\n",
      "        [-0.0022,  0.0174,  0.0022],\n",
      "        [-0.0007,  0.0307,  0.0083],\n",
      "        [ 0.0002,  0.0466,  0.0094],\n",
      "        [ 0.0011,  0.0404,  0.0048],\n",
      "        [ 0.0050,  0.0373,  0.0021],\n",
      "        [ 0.0014,  0.0285, -0.0008],\n",
      "        [ 0.0048,  0.0257, -0.0003],\n",
      "        [-0.0032,  0.0264,  0.0026],\n",
      "        [ 0.0046,  0.0450,  0.0033],\n",
      "        [ 0.0049,  0.0440,  0.0062],\n",
      "        [ 0.0009,  0.0263,  0.0152],\n",
      "        [-0.0032,  0.0299, -0.0006],\n",
      "        [-0.0046,  0.0365,  0.0053]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2101, 0.2062, 0.3273, 0.1355, 0.1935, 0.1934, 0.1472, 0.3051, 0.1955,\n",
      "         0.1662, 0.1834, 0.2125, 0.2495, 0.2383, 0.2573, 0.2873, 0.3204, 0.2807,\n",
      "         0.3397, 0.1767, 0.2579, 0.2610, 0.2755, 0.2645, 0.2993, 0.2444, 0.2209,\n",
      "         0.2633, 0.2708, 0.2403, 0.2698, 0.2184],\n",
      "        [0.1676, 0.1569, 0.2448, 0.1108, 0.1597, 0.1695, 0.1273, 0.2438, 0.1487,\n",
      "         0.1229, 0.1802, 0.1608, 0.1785, 0.1952, 0.1925, 0.2361, 0.2349, 0.2071,\n",
      "         0.2749, 0.1402, 0.2005, 0.2094, 0.1894, 0.2071, 0.1996, 0.1867, 0.1695,\n",
      "         0.2075, 0.1985, 0.1774, 0.1937, 0.1464]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0087, 0.0082, 0.0139, 0.0047, 0.0084, 0.0079, 0.0051, 0.0140, 0.0073,\n",
      "        0.0058, 0.0084, 0.0090, 0.0096, 0.0110, 0.0095, 0.0123, 0.0137, 0.0125,\n",
      "        0.0144, 0.0070, 0.0110, 0.0120, 0.0106, 0.0109, 0.0119, 0.0098, 0.0094,\n",
      "        0.0102, 0.0116, 0.0093, 0.0108, 0.0079], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0138, 0.0100], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 5.7115e-03,  4.9392e-02,  2.7788e-03],\n",
      "        [-4.8313e-03,  5.2596e-02,  1.0335e-02],\n",
      "        [-3.5577e-03,  8.1330e-02,  3.4037e-03],\n",
      "        [-2.6526e-03,  7.5084e-03, -6.5199e-03],\n",
      "        [ 1.6356e-03,  4.5442e-02,  3.7867e-03],\n",
      "        [-1.2530e-03,  4.2073e-02,  1.7503e-03],\n",
      "        [-1.9461e-05,  3.8869e-02,  8.8253e-03],\n",
      "        [ 6.8526e-03,  8.1109e-02,  4.8986e-04],\n",
      "        [ 5.5061e-03,  4.0877e-02, -5.4320e-03],\n",
      "        [ 1.1450e-02,  2.4501e-02, -9.8631e-03],\n",
      "        [-3.2341e-03,  4.7919e-02, -6.5635e-04],\n",
      "        [-2.2501e-03,  4.7348e-02, -1.5719e-03],\n",
      "        [-4.0062e-03,  6.2802e-02,  8.7743e-03],\n",
      "        [ 8.5484e-03,  6.5417e-02,  5.3906e-03],\n",
      "        [ 5.7017e-03,  5.5590e-02,  1.8861e-03],\n",
      "        [-7.9550e-04,  6.2291e-02,  1.5409e-03],\n",
      "        [ 5.6521e-03,  8.9876e-02,  6.1739e-03],\n",
      "        [-3.5881e-03,  7.5923e-02,  7.3350e-03],\n",
      "        [ 1.5922e-04,  8.6787e-02,  4.6576e-03],\n",
      "        [ 2.4840e-03,  3.6295e-02,  1.3221e-03],\n",
      "        [-9.4816e-03,  6.8528e-02,  1.1591e-03],\n",
      "        [-1.2492e-03,  8.0715e-02,  8.7108e-03],\n",
      "        [-3.6028e-03,  6.5124e-02,  7.4391e-03],\n",
      "        [ 3.8722e-03,  6.9320e-02,  8.4514e-04],\n",
      "        [-2.5163e-03,  6.3911e-02, -5.9283e-03],\n",
      "        [ 3.1791e-03,  6.1689e-02,  1.2958e-02],\n",
      "        [ 7.2891e-03,  5.4303e-02, -3.6071e-03],\n",
      "        [-1.3415e-04,  5.1520e-02,  4.7158e-03],\n",
      "        [ 2.7392e-03,  5.3515e-02,  5.1761e-03],\n",
      "        [ 2.2663e-03,  4.0022e-02, -9.2759e-03],\n",
      "        [-4.6543e-03,  6.5415e-02,  6.4365e-03],\n",
      "        [ 5.8020e-03,  4.8956e-02,  9.0720e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2202, 0.2157, 0.3430, 0.1408, 0.2026, 0.2018, 0.1527, 0.3199, 0.2024,\n",
      "         0.1719, 0.1912, 0.2221, 0.2610, 0.2502, 0.2690, 0.3019, 0.3354, 0.2945,\n",
      "         0.3562, 0.1846, 0.2698, 0.2737, 0.2896, 0.2762, 0.3127, 0.2559, 0.2318,\n",
      "         0.2751, 0.2834, 0.2509, 0.2824, 0.2282],\n",
      "        [0.1753, 0.1641, 0.2557, 0.1158, 0.1672, 0.1770, 0.1331, 0.2546, 0.1551,\n",
      "         0.1279, 0.1883, 0.1682, 0.1866, 0.2040, 0.2014, 0.2467, 0.2452, 0.2164,\n",
      "         0.2869, 0.1469, 0.2097, 0.2183, 0.1986, 0.2166, 0.2088, 0.1956, 0.1781,\n",
      "         0.2168, 0.2076, 0.1855, 0.2024, 0.1536]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0089, 0.0084, 0.0142, 0.0048, 0.0086, 0.0081, 0.0051, 0.0143, 0.0074,\n",
      "        0.0059, 0.0086, 0.0092, 0.0098, 0.0113, 0.0098, 0.0126, 0.0140, 0.0128,\n",
      "        0.0148, 0.0071, 0.0112, 0.0123, 0.0109, 0.0111, 0.0121, 0.0101, 0.0096,\n",
      "        0.0105, 0.0119, 0.0095, 0.0110, 0.0081], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0142, 0.0102], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0065,  0.0663,  0.0010],\n",
      "        [ 0.0167,  0.0436,  0.0082],\n",
      "        [ 0.0123,  0.0895,  0.0038],\n",
      "        [ 0.0056,  0.0065, -0.0091],\n",
      "        [ 0.0082,  0.0665,  0.0082],\n",
      "        [ 0.0106,  0.0372,  0.0042],\n",
      "        [ 0.0037,  0.0353,  0.0033],\n",
      "        [ 0.0196,  0.0665, -0.0030],\n",
      "        [ 0.0061,  0.0407, -0.0062],\n",
      "        [ 0.0114,  0.0334,  0.0014],\n",
      "        [ 0.0057,  0.0513,  0.0083],\n",
      "        [ 0.0054,  0.0559,  0.0029],\n",
      "        [ 0.0158,  0.0545,  0.0008],\n",
      "        [ 0.0127,  0.0594, -0.0029],\n",
      "        [ 0.0083,  0.0642, -0.0037],\n",
      "        [ 0.0148,  0.0727,  0.0021],\n",
      "        [ 0.0100,  0.0893,  0.0044],\n",
      "        [ 0.0146,  0.0777, -0.0011],\n",
      "        [ 0.0172,  0.0835, -0.0106],\n",
      "        [ 0.0095,  0.0520,  0.0081],\n",
      "        [ 0.0117,  0.0691, -0.0049],\n",
      "        [ 0.0117,  0.0771, -0.0047],\n",
      "        [ 0.0138,  0.0715, -0.0014],\n",
      "        [ 0.0048,  0.0666,  0.0050],\n",
      "        [ 0.0144,  0.0446, -0.0101],\n",
      "        [ 0.0163,  0.0728,  0.0054],\n",
      "        [ 0.0157,  0.0610, -0.0014],\n",
      "        [ 0.0101,  0.0591, -0.0014],\n",
      "        [ 0.0098,  0.0729,  0.0016],\n",
      "        [ 0.0105,  0.0463,  0.0087],\n",
      "        [ 0.0062,  0.0755, -0.0006],\n",
      "        [ 0.0132,  0.0506,  0.0065]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2296, 0.2256, 0.3582, 0.1460, 0.2114, 0.2111, 0.1589, 0.3359, 0.2115,\n",
      "         0.1804, 0.1994, 0.2320, 0.2727, 0.2616, 0.2803, 0.3154, 0.3506, 0.3081,\n",
      "         0.3727, 0.1916, 0.2822, 0.2872, 0.3022, 0.2879, 0.3266, 0.2679, 0.2408,\n",
      "         0.2874, 0.2964, 0.2620, 0.2948, 0.2370],\n",
      "        [0.1828, 0.1715, 0.2674, 0.1202, 0.1744, 0.1849, 0.1384, 0.2671, 0.1619,\n",
      "         0.1346, 0.1963, 0.1758, 0.1950, 0.2132, 0.2100, 0.2578, 0.2566, 0.2267,\n",
      "         0.3002, 0.1526, 0.2193, 0.2290, 0.2072, 0.2256, 0.2184, 0.2043, 0.1852,\n",
      "         0.2265, 0.2172, 0.1938, 0.2116, 0.1598]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0090, 0.0085, 0.0144, 0.0049, 0.0088, 0.0083, 0.0052, 0.0146, 0.0076,\n",
      "        0.0061, 0.0087, 0.0093, 0.0100, 0.0115, 0.0099, 0.0128, 0.0142, 0.0130,\n",
      "        0.0151, 0.0072, 0.0114, 0.0126, 0.0111, 0.0113, 0.0123, 0.0103, 0.0097,\n",
      "        0.0107, 0.0121, 0.0097, 0.0112, 0.0082], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0145, 0.0105], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0072,  0.0515, -0.0154],\n",
      "        [-0.0089,  0.0544, -0.0260],\n",
      "        [-0.0046,  0.0616, -0.0200],\n",
      "        [ 0.0071,  0.0125,  0.0005],\n",
      "        [-0.0020,  0.0364, -0.0141],\n",
      "        [ 0.0005,  0.0461, -0.0230],\n",
      "        [-0.0029,  0.0421, -0.0185],\n",
      "        [ 0.0032,  0.0670, -0.0278],\n",
      "        [ 0.0034,  0.0157, -0.0188],\n",
      "        [-0.0041,  0.0246, -0.0098],\n",
      "        [-0.0004,  0.0311, -0.0164],\n",
      "        [ 0.0078,  0.0496, -0.0131],\n",
      "        [-0.0068,  0.0404, -0.0147],\n",
      "        [ 0.0056,  0.0384, -0.0271],\n",
      "        [-0.0054,  0.0409, -0.0077],\n",
      "        [ 0.0002,  0.0486, -0.0143],\n",
      "        [-0.0058,  0.0647, -0.0209],\n",
      "        [ 0.0071,  0.0483, -0.0187],\n",
      "        [ 0.0029,  0.0734, -0.0226],\n",
      "        [-0.0023,  0.0479, -0.0224],\n",
      "        [-0.0026,  0.0637, -0.0231],\n",
      "        [ 0.0012,  0.0600, -0.0226],\n",
      "        [-0.0042,  0.0507, -0.0201],\n",
      "        [-0.0021,  0.0457, -0.0203],\n",
      "        [ 0.0043,  0.0664, -0.0201],\n",
      "        [-0.0052,  0.0534, -0.0134],\n",
      "        [ 0.0017,  0.0317, -0.0211],\n",
      "        [ 0.0019,  0.0502, -0.0092],\n",
      "        [ 0.0062,  0.0386, -0.0143],\n",
      "        [-0.0069,  0.0283, -0.0129],\n",
      "        [-0.0044,  0.0571, -0.0161],\n",
      "        [ 0.0003,  0.0307, -0.0174]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2404, 0.2354, 0.3745, 0.1542, 0.2218, 0.2210, 0.1667, 0.3496, 0.2210,\n",
      "         0.1877, 0.2093, 0.2426, 0.2848, 0.2740, 0.2930, 0.3300, 0.3657, 0.3208,\n",
      "         0.3883, 0.2017, 0.2945, 0.2987, 0.3161, 0.3014, 0.3411, 0.2801, 0.2529,\n",
      "         0.3000, 0.3095, 0.2737, 0.3079, 0.2489],\n",
      "        [0.1911, 0.1793, 0.2796, 0.1260, 0.1825, 0.1933, 0.1447, 0.2788, 0.1691,\n",
      "         0.1404, 0.2051, 0.1838, 0.2034, 0.2232, 0.2191, 0.2701, 0.2681, 0.2368,\n",
      "         0.3132, 0.1597, 0.2290, 0.2389, 0.2173, 0.2357, 0.2284, 0.2145, 0.1937,\n",
      "         0.2367, 0.2271, 0.2026, 0.2211, 0.1670]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0092, 0.0087, 0.0147, 0.0051, 0.0090, 0.0085, 0.0054, 0.0148, 0.0078,\n",
      "        0.0063, 0.0089, 0.0095, 0.0102, 0.0117, 0.0101, 0.0131, 0.0144, 0.0131,\n",
      "        0.0153, 0.0074, 0.0116, 0.0127, 0.0113, 0.0115, 0.0126, 0.0106, 0.0099,\n",
      "        0.0109, 0.0123, 0.0099, 0.0114, 0.0084], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0148, 0.0107], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 2.0510e-04,  5.3105e-02,  2.0753e-02],\n",
      "        [ 2.5346e-03,  4.6729e-02,  1.0724e-02],\n",
      "        [ 2.5338e-04,  8.2413e-02,  1.9434e-02],\n",
      "        [ 6.2695e-03,  1.2632e-02,  8.7732e-03],\n",
      "        [-3.7568e-03,  4.8632e-02,  1.3540e-02],\n",
      "        [-5.3327e-03,  4.1450e-02,  1.2884e-02],\n",
      "        [-1.7533e-03,  1.9891e-02,  1.2259e-02],\n",
      "        [ 1.5885e-03,  7.0511e-02,  1.2937e-02],\n",
      "        [-3.9410e-03,  3.8821e-02,  1.2400e-02],\n",
      "        [ 3.0798e-03,  5.2208e-02,  1.0202e-02],\n",
      "        [-2.7382e-03,  6.4631e-02,  5.7383e-03],\n",
      "        [ 6.7079e-04,  5.8316e-02,  1.2285e-02],\n",
      "        [ 4.0135e-03,  5.5300e-02,  6.1545e-03],\n",
      "        [-7.8566e-05,  5.0261e-02,  1.1058e-02],\n",
      "        [-7.8755e-07,  3.7363e-02,  1.2892e-02],\n",
      "        [-7.9099e-04,  6.7368e-02,  6.6202e-03],\n",
      "        [ 8.5053e-03,  6.9742e-02,  1.8498e-02],\n",
      "        [ 2.4680e-03,  6.0267e-02,  1.4330e-02],\n",
      "        [-2.5385e-03,  7.6082e-02,  1.9294e-02],\n",
      "        [-8.9408e-03,  4.4519e-02,  6.6725e-03],\n",
      "        [-6.1711e-03,  5.8408e-02,  1.8810e-02],\n",
      "        [-3.0064e-03,  5.5576e-02,  1.9392e-02],\n",
      "        [-1.0898e-03,  5.7208e-02,  1.1787e-02],\n",
      "        [ 3.4435e-03,  5.9180e-02,  9.3720e-03],\n",
      "        [ 6.9341e-03,  5.6964e-02,  1.2065e-02],\n",
      "        [-1.7008e-03,  4.0942e-02,  4.5460e-04],\n",
      "        [-1.5206e-02,  6.2264e-02,  8.5868e-03],\n",
      "        [-2.4635e-03,  5.2653e-02,  9.1965e-03],\n",
      "        [ 1.3052e-03,  5.6347e-02,  1.1530e-02],\n",
      "        [-5.9640e-04,  5.6289e-02,  7.4507e-03],\n",
      "        [-3.8044e-04,  7.1935e-02,  1.4467e-02],\n",
      "        [ 1.8920e-03,  3.6299e-02,  1.1030e-02]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2513, 0.2454, 0.3912, 0.1590, 0.2312, 0.2297, 0.1729, 0.3664, 0.2298,\n",
      "         0.1962, 0.2193, 0.2536, 0.2979, 0.2862, 0.3060, 0.3439, 0.3830, 0.3375,\n",
      "         0.4064, 0.2094, 0.3087, 0.3143, 0.3290, 0.3151, 0.3564, 0.2910, 0.2637,\n",
      "         0.3133, 0.3240, 0.2856, 0.3218, 0.2585],\n",
      "        [0.2003, 0.1867, 0.2923, 0.1317, 0.1908, 0.2014, 0.1511, 0.2909, 0.1765,\n",
      "         0.1459, 0.2153, 0.1924, 0.2138, 0.2332, 0.2298, 0.2808, 0.2807, 0.2486,\n",
      "         0.3271, 0.1676, 0.2397, 0.2502, 0.2270, 0.2475, 0.2391, 0.2225, 0.2038,\n",
      "         0.2471, 0.2377, 0.2117, 0.2312, 0.1753]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0094, 0.0089, 0.0150, 0.0052, 0.0092, 0.0086, 0.0055, 0.0151, 0.0079,\n",
      "        0.0063, 0.0092, 0.0098, 0.0105, 0.0119, 0.0104, 0.0133, 0.0148, 0.0136,\n",
      "        0.0156, 0.0076, 0.0119, 0.0131, 0.0116, 0.0119, 0.0129, 0.0107, 0.0102,\n",
      "        0.0111, 0.0126, 0.0101, 0.0117, 0.0086], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0151, 0.0110], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0146,  0.0562, -0.0039],\n",
      "        [ 0.0113,  0.0567, -0.0092],\n",
      "        [ 0.0128,  0.1027, -0.0229],\n",
      "        [ 0.0005,  0.0295,  0.0013],\n",
      "        [-0.0050,  0.0660, -0.0148],\n",
      "        [ 0.0058,  0.0667, -0.0043],\n",
      "        [ 0.0019,  0.0409, -0.0104],\n",
      "        [ 0.0116,  0.1050, -0.0269],\n",
      "        [ 0.0039,  0.0648, -0.0061],\n",
      "        [-0.0004,  0.0362,  0.0002],\n",
      "        [ 0.0042,  0.0606, -0.0123],\n",
      "        [ 0.0043,  0.0560, -0.0166],\n",
      "        [ 0.0053,  0.0741, -0.0167],\n",
      "        [ 0.0132,  0.0934, -0.0182],\n",
      "        [ 0.0032,  0.0624, -0.0074],\n",
      "        [ 0.0096,  0.0938, -0.0163],\n",
      "        [ 0.0120,  0.0995, -0.0185],\n",
      "        [ 0.0115,  0.0888, -0.0186],\n",
      "        [ 0.0089,  0.1082, -0.0248],\n",
      "        [ 0.0039,  0.0490, -0.0197],\n",
      "        [ 0.0170,  0.0890, -0.0202],\n",
      "        [ 0.0134,  0.0996, -0.0236],\n",
      "        [ 0.0129,  0.0733, -0.0148],\n",
      "        [ 0.0094,  0.0875, -0.0194],\n",
      "        [ 0.0154,  0.0790, -0.0182],\n",
      "        [ 0.0099,  0.0676, -0.0124],\n",
      "        [ 0.0086,  0.0779, -0.0261],\n",
      "        [ 0.0066,  0.0668, -0.0133],\n",
      "        [ 0.0173,  0.0865, -0.0143],\n",
      "        [ 0.0038,  0.0809, -0.0207],\n",
      "        [ 0.0182,  0.0825, -0.0151],\n",
      "        [-0.0036,  0.0597, -0.0113]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2622, 0.2574, 0.4091, 0.1653, 0.2415, 0.2415, 0.1796, 0.3845, 0.2406,\n",
      "         0.2047, 0.2272, 0.2647, 0.3098, 0.2996, 0.3182, 0.3612, 0.3999, 0.3516,\n",
      "         0.4251, 0.2175, 0.3219, 0.3284, 0.3450, 0.3277, 0.3718, 0.3066, 0.2742,\n",
      "         0.3274, 0.3386, 0.2981, 0.3361, 0.2686],\n",
      "        [0.2090, 0.1960, 0.3059, 0.1372, 0.1992, 0.2112, 0.1570, 0.3049, 0.1847,\n",
      "         0.1525, 0.2234, 0.2010, 0.2224, 0.2438, 0.2392, 0.2949, 0.2931, 0.2590,\n",
      "         0.3422, 0.1742, 0.2503, 0.2612, 0.2386, 0.2574, 0.2498, 0.2347, 0.2121,\n",
      "         0.2583, 0.2485, 0.2212, 0.2418, 0.1822]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0096, 0.0091, 0.0153, 0.0053, 0.0094, 0.0089, 0.0055, 0.0154, 0.0082,\n",
      "        0.0065, 0.0092, 0.0099, 0.0106, 0.0122, 0.0105, 0.0137, 0.0150, 0.0137,\n",
      "        0.0160, 0.0077, 0.0121, 0.0133, 0.0119, 0.0120, 0.0131, 0.0111, 0.0103,\n",
      "        0.0114, 0.0129, 0.0103, 0.0119, 0.0087], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0155, 0.0113], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-3.2934e-03,  6.4770e-02,  4.5767e-03],\n",
      "        [ 4.9580e-03,  4.8656e-02, -3.2092e-03],\n",
      "        [ 9.7946e-03,  9.0194e-02,  1.6125e-03],\n",
      "        [-3.4454e-03,  5.2400e-02,  1.0445e-02],\n",
      "        [-4.4493e-03,  5.0976e-02,  5.0836e-04],\n",
      "        [-3.0073e-03,  4.9843e-02,  4.2339e-04],\n",
      "        [ 3.7445e-03,  2.3525e-02, -3.1916e-03],\n",
      "        [-1.3170e-03,  9.6869e-02,  7.6895e-03],\n",
      "        [-1.2754e-02,  4.2637e-02, -3.6727e-04],\n",
      "        [ 1.5818e-02,  5.5202e-02, -8.0919e-04],\n",
      "        [ 3.0384e-03,  5.6519e-02, -3.3390e-03],\n",
      "        [ 1.3560e-02,  5.2599e-02, -3.5916e-03],\n",
      "        [ 9.9199e-03,  4.9122e-02,  1.2272e-02],\n",
      "        [-1.3869e-02,  7.8242e-02, -3.5771e-03],\n",
      "        [ 6.0612e-04,  8.7237e-02,  6.8695e-03],\n",
      "        [ 7.3105e-03,  8.6551e-02,  1.1364e-02],\n",
      "        [ 6.8049e-03,  9.7558e-02,  2.8561e-03],\n",
      "        [-1.3937e-05,  8.0695e-02,  4.2108e-03],\n",
      "        [ 3.1523e-03,  8.9605e-02,  3.4583e-03],\n",
      "        [-6.9162e-03,  3.4198e-02, -9.8025e-04],\n",
      "        [-9.3556e-03,  5.1315e-02,  1.1756e-03],\n",
      "        [-8.7901e-04,  7.1402e-02,  4.0024e-04],\n",
      "        [ 1.2116e-02,  6.8975e-02,  3.7672e-03],\n",
      "        [ 7.9346e-03,  6.8230e-02,  6.1705e-03],\n",
      "        [ 3.1813e-03,  8.6316e-02, -1.1657e-03],\n",
      "        [ 1.4634e-03,  6.3680e-02,  2.6625e-03],\n",
      "        [-8.8078e-03,  4.4608e-02, -2.7282e-03],\n",
      "        [ 4.6174e-04,  6.2375e-02,  2.4180e-03],\n",
      "        [ 4.0576e-03,  7.0024e-02,  5.1735e-03],\n",
      "        [ 5.2278e-03,  6.1618e-02,  1.5853e-03],\n",
      "        [ 2.3849e-03,  5.7777e-02, -1.6796e-03],\n",
      "        [-1.0542e-02,  4.5205e-02,  1.0078e-02]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2744, 0.2678, 0.4274, 0.1722, 0.2525, 0.2510, 0.1876, 0.4012, 0.2501,\n",
      "         0.2129, 0.2388, 0.2769, 0.3244, 0.3127, 0.3328, 0.3760, 0.4181, 0.3686,\n",
      "         0.4440, 0.2277, 0.3371, 0.3442, 0.3598, 0.3432, 0.3885, 0.3183, 0.2876,\n",
      "         0.3416, 0.3540, 0.3112, 0.3514, 0.2806],\n",
      "        [0.2190, 0.2039, 0.3203, 0.1431, 0.2085, 0.2195, 0.1636, 0.3187, 0.1914,\n",
      "         0.1579, 0.2339, 0.2103, 0.2334, 0.2555, 0.2506, 0.3078, 0.3070, 0.2722,\n",
      "         0.3578, 0.1825, 0.2622, 0.2745, 0.2496, 0.2698, 0.2614, 0.2439, 0.2224,\n",
      "         0.2697, 0.2601, 0.2311, 0.2534, 0.1907]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0098, 0.0093, 0.0156, 0.0054, 0.0096, 0.0090, 0.0057, 0.0157, 0.0083,\n",
      "        0.0066, 0.0095, 0.0102, 0.0109, 0.0124, 0.0108, 0.0139, 0.0154, 0.0140,\n",
      "        0.0162, 0.0079, 0.0123, 0.0136, 0.0121, 0.0123, 0.0134, 0.0112, 0.0106,\n",
      "        0.0116, 0.0131, 0.0106, 0.0122, 0.0089], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0158, 0.0116], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0173,  0.0576, -0.0020],\n",
      "        [-0.0067,  0.0571, -0.0071],\n",
      "        [-0.0205,  0.1084, -0.0097],\n",
      "        [-0.0105,  0.0567, -0.0080],\n",
      "        [-0.0109,  0.0742, -0.0110],\n",
      "        [-0.0177,  0.0524, -0.0093],\n",
      "        [-0.0026,  0.0439, -0.0033],\n",
      "        [-0.0149,  0.1054, -0.0066],\n",
      "        [-0.0161,  0.0425, -0.0122],\n",
      "        [-0.0096,  0.0406,  0.0023],\n",
      "        [-0.0117,  0.0590, -0.0047],\n",
      "        [-0.0066,  0.0864, -0.0037],\n",
      "        [-0.0034,  0.0697,  0.0017],\n",
      "        [-0.0211,  0.0752, -0.0136],\n",
      "        [-0.0156,  0.0685, -0.0103],\n",
      "        [-0.0139,  0.0997, -0.0083],\n",
      "        [-0.0133,  0.1105, -0.0134],\n",
      "        [-0.0105,  0.1010, -0.0123],\n",
      "        [-0.0140,  0.1221, -0.0084],\n",
      "        [-0.0090,  0.0525, -0.0060],\n",
      "        [-0.0171,  0.0885, -0.0113],\n",
      "        [-0.0077,  0.1107, -0.0176],\n",
      "        [-0.0141,  0.0970, -0.0019],\n",
      "        [-0.0067,  0.0735, -0.0064],\n",
      "        [-0.0164,  0.0956, -0.0080],\n",
      "        [-0.0164,  0.0688, -0.0135],\n",
      "        [-0.0153,  0.0673, -0.0018],\n",
      "        [-0.0160,  0.0804, -0.0038],\n",
      "        [-0.0144,  0.0930, -0.0127],\n",
      "        [-0.0207,  0.0763, -0.0032],\n",
      "        [-0.0183,  0.0872, -0.0055],\n",
      "        [-0.0109,  0.0592, -0.0057]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2876, 0.2796, 0.4471, 0.1810, 0.2648, 0.2622, 0.1961, 0.4189, 0.2597,\n",
      "         0.2202, 0.2500, 0.2894, 0.3395, 0.3285, 0.3484, 0.3937, 0.4367, 0.3852,\n",
      "         0.4636, 0.2393, 0.3521, 0.3588, 0.3767, 0.3591, 0.4055, 0.3326, 0.3017,\n",
      "         0.3565, 0.3697, 0.3250, 0.3670, 0.2945],\n",
      "        [0.2287, 0.2134, 0.3343, 0.1495, 0.2179, 0.2298, 0.1709, 0.3330, 0.2003,\n",
      "         0.1654, 0.2441, 0.2198, 0.2435, 0.2669, 0.2616, 0.3220, 0.3205, 0.2837,\n",
      "         0.3732, 0.1906, 0.2737, 0.2856, 0.2605, 0.2814, 0.2733, 0.2554, 0.2322,\n",
      "         0.2816, 0.2719, 0.2415, 0.2644, 0.1995]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0100, 0.0095, 0.0159, 0.0056, 0.0098, 0.0092, 0.0059, 0.0159, 0.0085,\n",
      "        0.0067, 0.0097, 0.0104, 0.0111, 0.0127, 0.0111, 0.0142, 0.0157, 0.0143,\n",
      "        0.0165, 0.0081, 0.0126, 0.0137, 0.0124, 0.0126, 0.0136, 0.0115, 0.0108,\n",
      "        0.0119, 0.0134, 0.0108, 0.0124, 0.0092], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0161, 0.0119], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-1.2836e-03,  2.6706e-02,  8.7901e-03],\n",
      "        [ 8.5164e-06,  3.9508e-02,  6.8552e-03],\n",
      "        [ 9.0631e-03,  2.6622e-02,  1.6754e-02],\n",
      "        [ 4.8932e-03,  9.7612e-03,  1.0860e-02],\n",
      "        [-1.4243e-03,  3.4730e-02,  1.1129e-02],\n",
      "        [-1.1860e-03,  1.7203e-02,  1.2266e-02],\n",
      "        [ 5.7458e-04,  2.1298e-02,  4.5556e-03],\n",
      "        [ 7.4648e-03,  5.1068e-02,  9.7637e-03],\n",
      "        [-8.7698e-03,  5.5254e-03,  1.0823e-02],\n",
      "        [ 6.0936e-03,  9.0568e-03,  1.9661e-03],\n",
      "        [ 8.1070e-04, -4.9758e-04,  9.5923e-03],\n",
      "        [ 1.1077e-02,  2.9245e-02,  1.1163e-02],\n",
      "        [ 1.4090e-03,  3.0222e-02,  1.9065e-03],\n",
      "        [ 8.8962e-04,  3.1649e-02,  1.6943e-02],\n",
      "        [ 1.2033e-03,  2.3739e-02,  6.4589e-03],\n",
      "        [ 5.9361e-03,  3.6038e-02,  1.6315e-02],\n",
      "        [ 1.2115e-02,  4.8537e-02,  1.5641e-02],\n",
      "        [ 1.2792e-02,  4.1236e-02,  1.7489e-02],\n",
      "        [ 3.9398e-03,  5.4439e-02,  1.0368e-02],\n",
      "        [-6.5649e-03,  2.5174e-02,  7.3676e-03],\n",
      "        [-6.5792e-03,  4.0988e-02,  1.8288e-02],\n",
      "        [ 8.0842e-03,  5.0329e-02,  1.8930e-02],\n",
      "        [ 1.4398e-02,  3.7521e-02,  1.2781e-02],\n",
      "        [-8.0559e-03,  2.6907e-02,  1.1691e-02],\n",
      "        [-2.1364e-03,  5.6123e-02,  1.0160e-02],\n",
      "        [ 1.5775e-02,  4.7649e-02,  9.4777e-03],\n",
      "        [-1.3281e-02,  3.0408e-02,  8.4078e-03],\n",
      "        [ 1.1403e-02,  2.7794e-02,  1.5241e-03],\n",
      "        [ 6.1178e-03,  3.9589e-02,  1.8924e-02],\n",
      "        [ 2.8147e-03,  2.9986e-02,  1.3816e-02],\n",
      "        [-4.1445e-03,  2.7841e-02,  1.2672e-02],\n",
      "        [ 3.5912e-03,  3.2737e-02,  6.7873e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.2993, 0.2917, 0.4658, 0.1875, 0.2756, 0.2737, 0.2054, 0.4367, 0.2726,\n",
      "         0.2324, 0.2617, 0.3023, 0.3533, 0.3412, 0.3625, 0.4089, 0.4552, 0.4015,\n",
      "         0.4819, 0.2484, 0.3678, 0.3739, 0.3898, 0.3743, 0.4235, 0.3461, 0.3140,\n",
      "         0.3719, 0.3862, 0.3391, 0.3823, 0.3058],\n",
      "        [0.2384, 0.2227, 0.3483, 0.1558, 0.2271, 0.2400, 0.1797, 0.3462, 0.2112,\n",
      "         0.1749, 0.2555, 0.2299, 0.2537, 0.2774, 0.2728, 0.3340, 0.3341, 0.2956,\n",
      "         0.3877, 0.1987, 0.2861, 0.2970, 0.2694, 0.2940, 0.2860, 0.2651, 0.2421,\n",
      "         0.2939, 0.2841, 0.2523, 0.2756, 0.2082]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0102, 0.0096, 0.0162, 0.0057, 0.0100, 0.0094, 0.0061, 0.0161, 0.0087,\n",
      "        0.0070, 0.0100, 0.0106, 0.0113, 0.0129, 0.0113, 0.0143, 0.0159, 0.0145,\n",
      "        0.0167, 0.0083, 0.0128, 0.0140, 0.0124, 0.0128, 0.0139, 0.0115, 0.0110,\n",
      "        0.0121, 0.0136, 0.0110, 0.0126, 0.0094], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0165, 0.0122], grad_fn=<MeanBackward1>)\n",
      "Epoch 4/10, Accuracy: 0.5063\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-3.4907e-03,  5.2582e-02, -4.6929e-03],\n",
      "        [ 3.2306e-03,  4.4081e-02, -1.4649e-03],\n",
      "        [-3.5525e-03,  9.3493e-02, -2.8421e-02],\n",
      "        [-3.4537e-03,  4.3135e-02, -1.0167e-02],\n",
      "        [ 6.5171e-04,  5.4794e-02, -5.7483e-03],\n",
      "        [-3.3976e-03,  3.9584e-02, -1.5252e-03],\n",
      "        [ 7.0979e-03,  2.0481e-02,  3.0457e-04],\n",
      "        [-8.1748e-03,  8.1383e-02, -1.6310e-02],\n",
      "        [-1.2463e-02,  5.1817e-02, -8.1804e-03],\n",
      "        [-9.0407e-03,  4.6640e-02, -6.9423e-03],\n",
      "        [ 6.9625e-04,  6.3272e-02, -1.3078e-02],\n",
      "        [-1.1653e-03,  6.2778e-02, -1.8788e-02],\n",
      "        [-3.8709e-04,  6.6230e-02, -2.0092e-02],\n",
      "        [-1.6523e-02,  5.7135e-02, -1.1932e-02],\n",
      "        [ 9.3328e-04,  5.8741e-02, -9.0702e-03],\n",
      "        [-7.9262e-03,  8.4384e-02, -1.5035e-02],\n",
      "        [ 6.5881e-04,  7.3944e-02, -2.4663e-02],\n",
      "        [-2.0577e-03,  6.7841e-02, -2.1681e-02],\n",
      "        [-1.1790e-02,  9.7196e-02, -1.3407e-02],\n",
      "        [-6.1838e-03,  2.7108e-02, -5.8900e-03],\n",
      "        [-4.4509e-03,  5.8524e-02,  3.7095e-03],\n",
      "        [-4.7828e-03,  5.5908e-02, -9.8775e-03],\n",
      "        [-1.2265e-03,  6.5112e-02, -2.0035e-02],\n",
      "        [-2.3086e-03,  6.4473e-02, -1.3549e-02],\n",
      "        [-1.2341e-02,  7.9352e-02, -1.8369e-02],\n",
      "        [-3.8056e-05,  5.3785e-02, -2.7050e-02],\n",
      "        [-1.6552e-02,  5.7602e-02, -6.4282e-03],\n",
      "        [-6.0934e-03,  7.7645e-02, -1.9173e-02],\n",
      "        [-9.5299e-03,  7.2783e-02, -2.3571e-02],\n",
      "        [-1.1740e-02,  7.0137e-02, -6.3441e-03],\n",
      "        [-8.3847e-03,  7.3729e-02, -1.6682e-02],\n",
      "        [ 1.3202e-04,  4.4711e-02, -1.6162e-02]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.3128, 0.3054, 0.4866, 0.1965, 0.2886, 0.2870, 0.2133, 0.4571, 0.2847,\n",
      "         0.2419, 0.2732, 0.3156, 0.3686, 0.3576, 0.3785, 0.4290, 0.4754, 0.4192,\n",
      "         0.5040, 0.2593, 0.3834, 0.3910, 0.4092, 0.3905, 0.4418, 0.3631, 0.3275,\n",
      "         0.3883, 0.4033, 0.3540, 0.3992, 0.3195],\n",
      "        [0.2496, 0.2331, 0.3653, 0.1623, 0.2377, 0.2508, 0.1857, 0.3637, 0.2188,\n",
      "         0.1805, 0.2662, 0.2402, 0.2660, 0.2917, 0.2850, 0.3508, 0.3506, 0.3109,\n",
      "         0.4066, 0.2073, 0.2987, 0.3125, 0.2849, 0.3070, 0.2989, 0.2783, 0.2529,\n",
      "         0.3071, 0.2974, 0.2636, 0.2888, 0.2175]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0104, 0.0099, 0.0165, 0.0059, 0.0102, 0.0097, 0.0062, 0.0165, 0.0090,\n",
      "        0.0071, 0.0102, 0.0108, 0.0115, 0.0132, 0.0115, 0.0147, 0.0162, 0.0148,\n",
      "        0.0171, 0.0084, 0.0130, 0.0142, 0.0128, 0.0131, 0.0142, 0.0119, 0.0112,\n",
      "        0.0123, 0.0139, 0.0113, 0.0129, 0.0096], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0169, 0.0125], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0136,  0.0648,  0.0080],\n",
      "        [ 0.0031,  0.0712,  0.0299],\n",
      "        [ 0.0226,  0.0949,  0.0204],\n",
      "        [ 0.0092,  0.0251, -0.0075],\n",
      "        [ 0.0048,  0.0587,  0.0221],\n",
      "        [ 0.0122,  0.0642,  0.0147],\n",
      "        [ 0.0024,  0.0384,  0.0079],\n",
      "        [ 0.0377,  0.0904,  0.0239],\n",
      "        [ 0.0044,  0.0489,  0.0091],\n",
      "        [ 0.0211,  0.0464,  0.0136],\n",
      "        [-0.0021,  0.0643,  0.0129],\n",
      "        [ 0.0263,  0.0607,  0.0169],\n",
      "        [ 0.0187,  0.0794,  0.0214],\n",
      "        [ 0.0178,  0.0756,  0.0140],\n",
      "        [ 0.0102,  0.0614,  0.0147],\n",
      "        [ 0.0184,  0.0916,  0.0225],\n",
      "        [ 0.0182,  0.0937,  0.0218],\n",
      "        [ 0.0254,  0.0884,  0.0206],\n",
      "        [ 0.0298,  0.1077,  0.0284],\n",
      "        [ 0.0174,  0.0505,  0.0185],\n",
      "        [ 0.0155,  0.0788,  0.0180],\n",
      "        [ 0.0178,  0.0871,  0.0257],\n",
      "        [ 0.0193,  0.0731,  0.0195],\n",
      "        [ 0.0143,  0.0844,  0.0232],\n",
      "        [ 0.0290,  0.0853,  0.0188],\n",
      "        [ 0.0247,  0.0610,  0.0193],\n",
      "        [ 0.0124,  0.0689,  0.0287],\n",
      "        [ 0.0273,  0.0617,  0.0160],\n",
      "        [ 0.0154,  0.0816,  0.0227],\n",
      "        [ 0.0149,  0.0487,  0.0191],\n",
      "        [ 0.0083,  0.0888,  0.0147],\n",
      "        [ 0.0137,  0.0569,  0.0214]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.3274, 0.3184, 0.5087, 0.2022, 0.3006, 0.2978, 0.2211, 0.4785, 0.2949,\n",
      "         0.2513, 0.2846, 0.3297, 0.3853, 0.3739, 0.3947, 0.4477, 0.4979, 0.4402,\n",
      "         0.5273, 0.2702, 0.4019, 0.4112, 0.4264, 0.4078, 0.4613, 0.3782, 0.3419,\n",
      "         0.4053, 0.4218, 0.3690, 0.4172, 0.3319],\n",
      "        [0.2611, 0.2434, 0.3815, 0.1679, 0.2478, 0.2608, 0.1930, 0.3806, 0.2274,\n",
      "         0.1883, 0.2775, 0.2511, 0.2779, 0.3045, 0.2975, 0.3660, 0.3669, 0.3259,\n",
      "         0.4251, 0.2160, 0.3131, 0.3276, 0.2969, 0.3207, 0.3126, 0.2907, 0.2641,\n",
      "         0.3208, 0.3113, 0.2751, 0.3020, 0.2263]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0107, 0.0101, 0.0168, 0.0058, 0.0104, 0.0098, 0.0062, 0.0169, 0.0090,\n",
      "        0.0072, 0.0104, 0.0110, 0.0118, 0.0135, 0.0117, 0.0150, 0.0166, 0.0152,\n",
      "        0.0175, 0.0086, 0.0134, 0.0147, 0.0130, 0.0134, 0.0145, 0.0121, 0.0115,\n",
      "        0.0126, 0.0142, 0.0115, 0.0132, 0.0097], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0172, 0.0128], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0042,  0.0121, -0.0057],\n",
      "        [ 0.0011,  0.0102,  0.0018],\n",
      "        [ 0.0098,  0.0404, -0.0048],\n",
      "        [ 0.0038,  0.0416, -0.0004],\n",
      "        [ 0.0068,  0.0152,  0.0017],\n",
      "        [-0.0077,  0.0212, -0.0037],\n",
      "        [-0.0033,  0.0093, -0.0038],\n",
      "        [ 0.0118,  0.0482, -0.0043],\n",
      "        [-0.0104,  0.0089,  0.0046],\n",
      "        [ 0.0050,  0.0048, -0.0112],\n",
      "        [ 0.0076,  0.0101, -0.0017],\n",
      "        [ 0.0121,  0.0274,  0.0023],\n",
      "        [ 0.0120,  0.0307, -0.0075],\n",
      "        [-0.0059,  0.0307, -0.0033],\n",
      "        [-0.0026,  0.0292, -0.0007],\n",
      "        [ 0.0097,  0.0383, -0.0094],\n",
      "        [ 0.0076,  0.0414, -0.0083],\n",
      "        [ 0.0044,  0.0445, -0.0006],\n",
      "        [ 0.0046,  0.0314, -0.0104],\n",
      "        [-0.0009,  0.0199, -0.0006],\n",
      "        [-0.0019,  0.0197, -0.0027],\n",
      "        [ 0.0021,  0.0397, -0.0083],\n",
      "        [ 0.0106,  0.0263, -0.0035],\n",
      "        [ 0.0040,  0.0385, -0.0062],\n",
      "        [ 0.0026,  0.0411, -0.0010],\n",
      "        [ 0.0110,  0.0178,  0.0015],\n",
      "        [-0.0028,  0.0151,  0.0016],\n",
      "        [ 0.0210,  0.0082,  0.0072],\n",
      "        [ 0.0118,  0.0322, -0.0015],\n",
      "        [ 0.0089,  0.0147, -0.0050],\n",
      "        [ 0.0165,  0.0093, -0.0065],\n",
      "        [ 0.0104,  0.0173,  0.0032]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.3406, 0.3324, 0.5290, 0.2122, 0.3140, 0.3123, 0.2328, 0.4975, 0.3107,\n",
      "         0.2645, 0.2989, 0.3442, 0.4004, 0.3888, 0.4108, 0.4654, 0.5175, 0.4560,\n",
      "         0.5481, 0.2819, 0.4189, 0.4262, 0.4422, 0.4254, 0.4814, 0.3950, 0.3568,\n",
      "         0.4227, 0.4397, 0.3853, 0.4345, 0.3465],\n",
      "        [0.2723, 0.2542, 0.3974, 0.1769, 0.2592, 0.2729, 0.2030, 0.3953, 0.2395,\n",
      "         0.1979, 0.2908, 0.2625, 0.2896, 0.3170, 0.3105, 0.3809, 0.3817, 0.3381,\n",
      "         0.4424, 0.2264, 0.3267, 0.3399, 0.3081, 0.3354, 0.3268, 0.3033, 0.2769,\n",
      "         0.3347, 0.3248, 0.2876, 0.3150, 0.2373]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0108, 0.0103, 0.0170, 0.0061, 0.0106, 0.0101, 0.0065, 0.0170, 0.0094,\n",
      "        0.0075, 0.0107, 0.0113, 0.0120, 0.0136, 0.0119, 0.0152, 0.0168, 0.0152,\n",
      "        0.0177, 0.0088, 0.0136, 0.0147, 0.0131, 0.0136, 0.0148, 0.0124, 0.0117,\n",
      "        0.0128, 0.0145, 0.0117, 0.0134, 0.0100], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0176, 0.0131], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0046,  0.0705, -0.0023],\n",
      "        [ 0.0051,  0.0499,  0.0008],\n",
      "        [ 0.0141,  0.1047,  0.0046],\n",
      "        [ 0.0068,  0.0411, -0.0013],\n",
      "        [ 0.0073,  0.0554, -0.0045],\n",
      "        [ 0.0015,  0.0482,  0.0047],\n",
      "        [ 0.0011,  0.0455, -0.0031],\n",
      "        [ 0.0216,  0.1131, -0.0018],\n",
      "        [ 0.0003,  0.0546,  0.0058],\n",
      "        [ 0.0038,  0.0368, -0.0122],\n",
      "        [ 0.0087,  0.0456, -0.0030],\n",
      "        [ 0.0191,  0.0601,  0.0065],\n",
      "        [ 0.0139,  0.0814, -0.0024],\n",
      "        [ 0.0202,  0.0634, -0.0065],\n",
      "        [ 0.0035,  0.0707,  0.0003],\n",
      "        [ 0.0114,  0.0972, -0.0002],\n",
      "        [ 0.0143,  0.1035, -0.0040],\n",
      "        [ 0.0196,  0.1004,  0.0058],\n",
      "        [ 0.0186,  0.1054,  0.0018],\n",
      "        [ 0.0161,  0.0511,  0.0018],\n",
      "        [ 0.0141,  0.0790,  0.0028],\n",
      "        [ 0.0097,  0.0954,  0.0039],\n",
      "        [ 0.0144,  0.1016, -0.0022],\n",
      "        [ 0.0137,  0.0632, -0.0034],\n",
      "        [ 0.0261,  0.0992,  0.0100],\n",
      "        [ 0.0251,  0.0820,  0.0051],\n",
      "        [ 0.0209,  0.0580,  0.0033],\n",
      "        [ 0.0203,  0.0909,  0.0076],\n",
      "        [ 0.0146,  0.0935,  0.0139],\n",
      "        [ 0.0120,  0.0881, -0.0113],\n",
      "        [ 0.0156,  0.0765,  0.0033],\n",
      "        [ 0.0088,  0.0714,  0.0004]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.3569, 0.3473, 0.5543, 0.2208, 0.3285, 0.3258, 0.2402, 0.5223, 0.3212,\n",
      "         0.2725, 0.3098, 0.3593, 0.4192, 0.4094, 0.4290, 0.4894, 0.5418, 0.4780,\n",
      "         0.5753, 0.2942, 0.4375, 0.4480, 0.4655, 0.4438, 0.5021, 0.4138, 0.3730,\n",
      "         0.4413, 0.4595, 0.4019, 0.4546, 0.3612],\n",
      "        [0.2842, 0.2658, 0.4163, 0.1830, 0.2705, 0.2851, 0.2101, 0.4151, 0.2487,\n",
      "         0.2056, 0.3018, 0.2742, 0.3030, 0.3326, 0.3240, 0.3996, 0.4001, 0.3549,\n",
      "         0.4636, 0.2353, 0.3414, 0.3570, 0.3237, 0.3495, 0.3415, 0.3178, 0.2883,\n",
      "         0.3497, 0.3399, 0.3002, 0.3296, 0.2467]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0111, 0.0105, 0.0175, 0.0062, 0.0108, 0.0103, 0.0065, 0.0175, 0.0095,\n",
      "        0.0076, 0.0108, 0.0115, 0.0123, 0.0140, 0.0122, 0.0156, 0.0172, 0.0156,\n",
      "        0.0182, 0.0090, 0.0139, 0.0152, 0.0135, 0.0139, 0.0151, 0.0127, 0.0119,\n",
      "        0.0131, 0.0148, 0.0120, 0.0137, 0.0102], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0180, 0.0134], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-6.8401e-03,  7.5517e-02,  9.6906e-03],\n",
      "        [-8.6913e-03,  8.7448e-02,  7.9099e-03],\n",
      "        [-9.8459e-05,  1.0462e-01,  1.3108e-02],\n",
      "        [ 1.4878e-02,  2.9476e-02, -1.8669e-03],\n",
      "        [-5.5967e-03,  7.8818e-02,  7.0794e-03],\n",
      "        [-9.7002e-04,  5.0151e-02,  9.5435e-03],\n",
      "        [-5.4282e-03,  2.7857e-02, -2.3231e-03],\n",
      "        [ 8.8568e-03,  9.5690e-02, -7.3129e-03],\n",
      "        [ 9.7031e-03,  4.9200e-02,  6.7819e-03],\n",
      "        [-1.4239e-02,  5.3357e-02,  3.8146e-03],\n",
      "        [ 1.0134e-03,  8.1727e-02,  2.3647e-02],\n",
      "        [-4.2336e-03,  8.2340e-02,  2.0142e-03],\n",
      "        [ 5.7146e-03,  8.7642e-02,  7.4991e-04],\n",
      "        [ 2.0201e-03,  7.9971e-02,  2.5227e-03],\n",
      "        [ 9.4082e-05,  5.8905e-02,  3.7652e-03],\n",
      "        [ 6.0808e-03,  9.1990e-02,  5.4201e-03],\n",
      "        [ 1.2326e-03,  1.1773e-01,  7.7657e-03],\n",
      "        [ 2.8793e-03,  9.9446e-02, -1.9125e-03],\n",
      "        [-1.3475e-03,  1.2317e-01,  4.7683e-03],\n",
      "        [-5.6043e-03,  4.7278e-02, -2.7764e-03],\n",
      "        [ 2.6362e-03,  1.0028e-01,  1.9344e-02],\n",
      "        [ 1.6677e-03,  9.4380e-02,  1.0108e-03],\n",
      "        [-1.3060e-03,  9.3627e-02,  2.1913e-03],\n",
      "        [ 9.0748e-03,  9.1201e-02,  7.0845e-03],\n",
      "        [ 1.2148e-02,  9.5512e-02,  5.9142e-03],\n",
      "        [-1.8763e-03,  8.9305e-02, -8.4225e-03],\n",
      "        [ 3.9542e-03,  7.8750e-02,  5.1420e-03],\n",
      "        [-1.4778e-03,  7.7364e-02,  1.8610e-03],\n",
      "        [ 8.5406e-03,  8.1901e-02, -1.4535e-03],\n",
      "        [ 4.8429e-03,  5.7376e-02,  1.3058e-02],\n",
      "        [-3.1554e-03,  1.0575e-01,  2.5422e-02],\n",
      "        [ 1.1199e-03,  7.0120e-02, -1.6336e-02]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.3726, 0.3615, 0.5780, 0.2315, 0.3433, 0.3398, 0.2516, 0.5439, 0.3349,\n",
      "         0.2848, 0.3259, 0.3754, 0.4380, 0.4264, 0.4485, 0.5096, 0.5645, 0.4999,\n",
      "         0.5981, 0.3078, 0.4565, 0.4663, 0.4844, 0.4644, 0.5240, 0.4295, 0.3909,\n",
      "         0.4602, 0.4797, 0.4195, 0.4735, 0.3780],\n",
      "        [0.2976, 0.2771, 0.4349, 0.1921, 0.2829, 0.2974, 0.2194, 0.4332, 0.2594,\n",
      "         0.2143, 0.3161, 0.2867, 0.3170, 0.3477, 0.3390, 0.4170, 0.4177, 0.3715,\n",
      "         0.4828, 0.2467, 0.3565, 0.3727, 0.3387, 0.3658, 0.3571, 0.3306, 0.3029,\n",
      "         0.3650, 0.3553, 0.3137, 0.3439, 0.2590]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0113, 0.0107, 0.0178, 0.0064, 0.0111, 0.0105, 0.0067, 0.0178, 0.0097,\n",
      "        0.0077, 0.0111, 0.0117, 0.0125, 0.0143, 0.0125, 0.0159, 0.0175, 0.0160,\n",
      "        0.0185, 0.0092, 0.0141, 0.0154, 0.0138, 0.0142, 0.0154, 0.0129, 0.0123,\n",
      "        0.0134, 0.0151, 0.0122, 0.0140, 0.0105], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0183, 0.0137], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-6.8672e-03,  6.0302e-02,  8.9076e-03],\n",
      "        [ 1.1837e-03,  3.6838e-02,  7.8521e-03],\n",
      "        [-9.8533e-03,  7.7836e-02,  9.8808e-03],\n",
      "        [-6.1266e-03,  8.2735e-03, -4.5543e-03],\n",
      "        [ 7.9843e-03,  5.7865e-02,  4.5245e-03],\n",
      "        [-5.4073e-03,  2.5618e-02, -1.0550e-03],\n",
      "        [-6.4959e-03,  2.7900e-02,  1.6522e-03],\n",
      "        [-1.7252e-03,  8.1579e-02,  8.7976e-04],\n",
      "        [-2.3988e-03,  3.8562e-02,  2.3443e-04],\n",
      "        [-2.2718e-03,  3.6494e-02,  8.2532e-03],\n",
      "        [-1.5455e-02,  5.1191e-02,  2.5638e-03],\n",
      "        [-2.4234e-03,  4.6774e-02,  5.6476e-03],\n",
      "        [ 2.2746e-03,  4.8376e-02,  1.1205e-02],\n",
      "        [-1.6193e-03,  7.8065e-02,  4.3858e-03],\n",
      "        [-1.1470e-03,  4.8727e-02,  2.1857e-02],\n",
      "        [-2.0910e-03,  7.5731e-02,  7.4523e-03],\n",
      "        [-2.3811e-03,  8.5979e-02,  1.6433e-02],\n",
      "        [-7.7581e-04,  6.9047e-02,  1.5483e-02],\n",
      "        [ 5.3224e-03,  6.8553e-02,  8.6941e-03],\n",
      "        [ 4.6631e-03,  6.4225e-02,  3.5220e-03],\n",
      "        [ 2.7276e-03,  5.3377e-02,  2.2299e-03],\n",
      "        [-5.4661e-04,  6.5607e-02,  8.7632e-03],\n",
      "        [-6.2561e-03,  6.4459e-02,  1.3356e-02],\n",
      "        [-2.2251e-03,  6.3688e-02,  1.1437e-02],\n",
      "        [ 6.2201e-03,  5.3931e-02,  3.5107e-03],\n",
      "        [ 3.8533e-05,  7.8745e-02,  2.1420e-02],\n",
      "        [ 9.9619e-03,  7.7894e-02,  8.3153e-03],\n",
      "        [-9.8265e-04,  5.6669e-02,  5.4774e-03],\n",
      "        [ 2.0817e-03,  7.2828e-02,  9.9879e-03],\n",
      "        [ 2.2755e-03,  7.6347e-02, -1.1958e-02],\n",
      "        [-1.4431e-03,  6.3604e-02,  9.0519e-03],\n",
      "        [ 7.4546e-03,  5.1249e-02,  9.8103e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.3891, 0.3768, 0.6028, 0.2400, 0.3584, 0.3538, 0.2625, 0.5677, 0.3496,\n",
      "         0.2970, 0.3407, 0.3920, 0.4570, 0.4444, 0.4674, 0.5309, 0.5892, 0.5213,\n",
      "         0.6249, 0.3217, 0.4773, 0.4874, 0.5046, 0.4845, 0.5468, 0.4483, 0.4091,\n",
      "         0.4799, 0.5007, 0.4375, 0.4944, 0.3938],\n",
      "        [0.3107, 0.2892, 0.4539, 0.2002, 0.2957, 0.3098, 0.2295, 0.4513, 0.2708,\n",
      "         0.2239, 0.3304, 0.2997, 0.3308, 0.3624, 0.3539, 0.4345, 0.4358, 0.3869,\n",
      "         0.5041, 0.2585, 0.3729, 0.3886, 0.3533, 0.3821, 0.3733, 0.3460, 0.3173,\n",
      "         0.3810, 0.3711, 0.3276, 0.3597, 0.2707]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0115, 0.0110, 0.0181, 0.0065, 0.0113, 0.0107, 0.0069, 0.0181, 0.0100,\n",
      "        0.0079, 0.0113, 0.0120, 0.0128, 0.0145, 0.0127, 0.0162, 0.0178, 0.0162,\n",
      "        0.0188, 0.0094, 0.0144, 0.0157, 0.0140, 0.0145, 0.0157, 0.0132, 0.0126,\n",
      "        0.0137, 0.0153, 0.0125, 0.0143, 0.0107], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0187, 0.0140], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0041,  0.0733, -0.0092],\n",
      "        [-0.0010,  0.0623, -0.0133],\n",
      "        [-0.0041,  0.1039, -0.0136],\n",
      "        [-0.0014,  0.0320,  0.0103],\n",
      "        [-0.0062,  0.0545, -0.0169],\n",
      "        [-0.0002,  0.0561, -0.0147],\n",
      "        [-0.0016,  0.0388, -0.0062],\n",
      "        [-0.0107,  0.0883, -0.0086],\n",
      "        [-0.0026,  0.0316, -0.0170],\n",
      "        [-0.0022,  0.0522,  0.0005],\n",
      "        [-0.0090,  0.0457, -0.0081],\n",
      "        [-0.0050,  0.0544,  0.0010],\n",
      "        [-0.0062,  0.0900, -0.0035],\n",
      "        [-0.0149,  0.0823, -0.0260],\n",
      "        [ 0.0062,  0.0706, -0.0130],\n",
      "        [ 0.0014,  0.0935, -0.0140],\n",
      "        [-0.0030,  0.1080, -0.0136],\n",
      "        [ 0.0024,  0.0920, -0.0093],\n",
      "        [ 0.0009,  0.1121, -0.0177],\n",
      "        [-0.0115,  0.0416, -0.0097],\n",
      "        [ 0.0002,  0.0791, -0.0184],\n",
      "        [ 0.0031,  0.0946, -0.0138],\n",
      "        [ 0.0068,  0.1026, -0.0128],\n",
      "        [-0.0099,  0.0878, -0.0081],\n",
      "        [-0.0045,  0.0676, -0.0056],\n",
      "        [ 0.0099,  0.0906, -0.0170],\n",
      "        [-0.0127,  0.0664, -0.0226],\n",
      "        [ 0.0006,  0.0582, -0.0136],\n",
      "        [ 0.0033,  0.0872, -0.0139],\n",
      "        [-0.0154,  0.0573, -0.0188],\n",
      "        [-0.0032,  0.0855, -0.0225],\n",
      "        [ 0.0013,  0.0634, -0.0156]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.4060, 0.3940, 0.6292, 0.2509, 0.3743, 0.3704, 0.2730, 0.5941, 0.3639,\n",
      "         0.3093, 0.3542, 0.4089, 0.4752, 0.4652, 0.4875, 0.5559, 0.6144, 0.5429,\n",
      "         0.6516, 0.3345, 0.4975, 0.5080, 0.5272, 0.5044, 0.5701, 0.4687, 0.4257,\n",
      "         0.5008, 0.5226, 0.4564, 0.5159, 0.4104],\n",
      "        [0.3245, 0.3025, 0.4741, 0.2086, 0.3087, 0.3240, 0.2384, 0.4729, 0.2822,\n",
      "         0.2333, 0.3438, 0.3130, 0.3448, 0.3791, 0.3694, 0.4548, 0.4554, 0.4044,\n",
      "         0.5264, 0.2681, 0.3892, 0.4064, 0.3692, 0.3982, 0.3899, 0.3616, 0.3297,\n",
      "         0.3978, 0.3879, 0.3420, 0.3758, 0.2822]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0118, 0.0112, 0.0184, 0.0067, 0.0116, 0.0110, 0.0070, 0.0185, 0.0102,\n",
      "        0.0081, 0.0115, 0.0122, 0.0129, 0.0148, 0.0130, 0.0165, 0.0182, 0.0164,\n",
      "        0.0191, 0.0096, 0.0147, 0.0159, 0.0143, 0.0148, 0.0160, 0.0135, 0.0127,\n",
      "        0.0140, 0.0156, 0.0127, 0.0145, 0.0109], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0191, 0.0144], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0092,  0.0688, -0.0010],\n",
      "        [ 0.0045,  0.0519, -0.0025],\n",
      "        [-0.0180,  0.0917, -0.0149],\n",
      "        [-0.0104,  0.0340, -0.0074],\n",
      "        [-0.0076,  0.0679, -0.0151],\n",
      "        [ 0.0034,  0.0561, -0.0144],\n",
      "        [-0.0038,  0.0435, -0.0091],\n",
      "        [-0.0261,  0.1035, -0.0106],\n",
      "        [-0.0071,  0.0656, -0.0134],\n",
      "        [ 0.0024,  0.0506, -0.0045],\n",
      "        [ 0.0037,  0.0397, -0.0112],\n",
      "        [-0.0042,  0.0566, -0.0227],\n",
      "        [-0.0191,  0.0732,  0.0040],\n",
      "        [-0.0224,  0.0960, -0.0129],\n",
      "        [-0.0189,  0.0678, -0.0073],\n",
      "        [-0.0212,  0.0790, -0.0067],\n",
      "        [-0.0299,  0.1021, -0.0105],\n",
      "        [-0.0302,  0.0972, -0.0194],\n",
      "        [-0.0159,  0.1091, -0.0070],\n",
      "        [-0.0048,  0.0593, -0.0170],\n",
      "        [-0.0051,  0.0789, -0.0082],\n",
      "        [-0.0245,  0.0899, -0.0104],\n",
      "        [-0.0208,  0.0785, -0.0106],\n",
      "        [-0.0146,  0.0755, -0.0054],\n",
      "        [-0.0180,  0.0952, -0.0109],\n",
      "        [-0.0212,  0.0872, -0.0116],\n",
      "        [-0.0042,  0.0706, -0.0143],\n",
      "        [-0.0146,  0.0769, -0.0064],\n",
      "        [-0.0269,  0.0792, -0.0142],\n",
      "        [-0.0177,  0.0734, -0.0077],\n",
      "        [-0.0111,  0.0733,  0.0012],\n",
      "        [-0.0214,  0.0802, -0.0100]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.4247, 0.4102, 0.6569, 0.2626, 0.3914, 0.3860, 0.2856, 0.6178, 0.3799,\n",
      "         0.3209, 0.3718, 0.4272, 0.4968, 0.4853, 0.5090, 0.5795, 0.6413, 0.5680,\n",
      "         0.6789, 0.3517, 0.5193, 0.5301, 0.5508, 0.5276, 0.5949, 0.4880, 0.4472,\n",
      "         0.5220, 0.5453, 0.4763, 0.5382, 0.4290],\n",
      "        [0.3391, 0.3156, 0.4958, 0.2177, 0.3227, 0.3378, 0.2489, 0.4934, 0.2947,\n",
      "         0.2425, 0.3594, 0.3272, 0.3606, 0.3961, 0.3854, 0.4752, 0.4759, 0.4233,\n",
      "         0.5494, 0.2811, 0.4064, 0.4245, 0.3871, 0.4162, 0.4075, 0.3781, 0.3456,\n",
      "         0.4153, 0.4056, 0.3572, 0.3927, 0.2946]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0120, 0.0114, 0.0188, 0.0069, 0.0118, 0.0112, 0.0072, 0.0188, 0.0104,\n",
      "        0.0082, 0.0118, 0.0125, 0.0133, 0.0151, 0.0133, 0.0169, 0.0185, 0.0168,\n",
      "        0.0195, 0.0099, 0.0150, 0.0162, 0.0147, 0.0151, 0.0164, 0.0138, 0.0131,\n",
      "        0.0142, 0.0160, 0.0130, 0.0148, 0.0112], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0195, 0.0147], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-6.0030e-03,  4.5552e-02,  5.9516e-03],\n",
      "        [-9.2988e-03,  3.1075e-02,  8.2036e-03],\n",
      "        [-1.7314e-02,  7.8173e-02, -2.4981e-03],\n",
      "        [-6.2457e-03,  3.5737e-02,  4.2348e-03],\n",
      "        [-1.5576e-02,  3.4561e-02, -2.8306e-03],\n",
      "        [-1.0362e-02,  4.0529e-02,  6.6749e-03],\n",
      "        [-2.2690e-03,  1.0933e-02,  1.7162e-03],\n",
      "        [-1.2191e-02,  8.6952e-02,  1.8913e-03],\n",
      "        [-8.6615e-03,  5.7740e-02, -2.4257e-03],\n",
      "        [-1.0414e-02,  2.0478e-02,  1.3613e-02],\n",
      "        [-2.3847e-02,  3.1472e-02,  6.3829e-03],\n",
      "        [-1.6139e-02,  5.0519e-02, -2.9941e-03],\n",
      "        [-1.3938e-03,  5.9801e-02,  7.6868e-04],\n",
      "        [-2.5215e-02,  7.2523e-02, -9.4482e-04],\n",
      "        [-5.3004e-03,  5.9995e-02, -2.1669e-03],\n",
      "        [-9.5011e-03,  7.1122e-02,  3.0932e-03],\n",
      "        [-2.1496e-02,  8.0355e-02,  3.4545e-03],\n",
      "        [-1.4698e-02,  8.1007e-02, -2.7449e-03],\n",
      "        [-1.7133e-02,  8.0662e-02, -3.6184e-03],\n",
      "        [-4.7850e-03,  2.9618e-02, -5.6713e-03],\n",
      "        [-1.2476e-02,  5.5426e-02, -7.9216e-03],\n",
      "        [-1.7132e-02,  7.3481e-02, -1.0614e-03],\n",
      "        [-1.1203e-02,  5.4638e-02, -2.9332e-03],\n",
      "        [-8.6601e-03,  7.3498e-02,  4.5493e-03],\n",
      "        [-1.3509e-02,  8.3158e-02, -2.6586e-03],\n",
      "        [-6.8848e-04,  4.9138e-02, -1.2392e-02],\n",
      "        [-1.7143e-02,  3.4341e-02, -1.5550e-02],\n",
      "        [-1.0538e-02,  6.1837e-02, -5.2875e-03],\n",
      "        [-1.2567e-02,  8.4916e-02, -1.5612e-03],\n",
      "        [-1.8565e-02,  3.4638e-02, -7.3626e-05],\n",
      "        [-1.9734e-02,  6.7642e-02, -8.2876e-04],\n",
      "        [-2.1596e-03,  3.8827e-02, -5.5837e-05]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.4426, 0.4283, 0.6844, 0.2731, 0.4078, 0.4030, 0.2972, 0.6444, 0.3967,\n",
      "         0.3359, 0.3873, 0.4456, 0.5180, 0.5060, 0.5305, 0.6038, 0.6685, 0.5916,\n",
      "         0.7079, 0.3654, 0.5421, 0.5533, 0.5739, 0.5501, 0.6205, 0.5089, 0.4649,\n",
      "         0.5444, 0.5688, 0.4965, 0.5608, 0.4467],\n",
      "        [0.3541, 0.3291, 0.5166, 0.2274, 0.3366, 0.3526, 0.2608, 0.5133, 0.3091,\n",
      "         0.2543, 0.3758, 0.3419, 0.3771, 0.4128, 0.4028, 0.4937, 0.4966, 0.4412,\n",
      "         0.5720, 0.2939, 0.4248, 0.4422, 0.4016, 0.4353, 0.4260, 0.3928, 0.3618,\n",
      "         0.4331, 0.4233, 0.3730, 0.4094, 0.3086]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0123, 0.0117, 0.0191, 0.0071, 0.0121, 0.0114, 0.0074, 0.0190, 0.0107,\n",
      "        0.0084, 0.0121, 0.0127, 0.0136, 0.0154, 0.0136, 0.0171, 0.0189, 0.0171,\n",
      "        0.0199, 0.0101, 0.0153, 0.0165, 0.0149, 0.0155, 0.0167, 0.0139, 0.0134,\n",
      "        0.0145, 0.0162, 0.0133, 0.0151, 0.0115], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0199, 0.0151], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0178,  0.0975, -0.0054],\n",
      "        [ 0.0190,  0.0800, -0.0048],\n",
      "        [ 0.0280,  0.1327, -0.0039],\n",
      "        [-0.0114,  0.0462,  0.0014],\n",
      "        [ 0.0114,  0.0876, -0.0019],\n",
      "        [ 0.0257,  0.0784, -0.0071],\n",
      "        [ 0.0166,  0.0582, -0.0147],\n",
      "        [ 0.0252,  0.1411,  0.0043],\n",
      "        [ 0.0071,  0.0785,  0.0134],\n",
      "        [ 0.0133,  0.0675, -0.0106],\n",
      "        [ 0.0178,  0.0822, -0.0052],\n",
      "        [ 0.0078,  0.0980, -0.0198],\n",
      "        [ 0.0219,  0.0982, -0.0004],\n",
      "        [ 0.0230,  0.1041,  0.0222],\n",
      "        [ 0.0175,  0.0883, -0.0034],\n",
      "        [ 0.0198,  0.1073,  0.0065],\n",
      "        [ 0.0283,  0.1494,  0.0062],\n",
      "        [ 0.0152,  0.1292,  0.0063],\n",
      "        [ 0.0261,  0.1348, -0.0035],\n",
      "        [ 0.0136,  0.0785,  0.0078],\n",
      "        [ 0.0127,  0.1137, -0.0050],\n",
      "        [ 0.0208,  0.1171,  0.0070],\n",
      "        [ 0.0233,  0.1154, -0.0094],\n",
      "        [ 0.0179,  0.1148, -0.0019],\n",
      "        [ 0.0070,  0.1164,  0.0124],\n",
      "        [ 0.0268,  0.0947,  0.0010],\n",
      "        [ 0.0148,  0.0797,  0.0115],\n",
      "        [ 0.0161,  0.0983, -0.0078],\n",
      "        [ 0.0158,  0.0999,  0.0149],\n",
      "        [ 0.0152,  0.0897,  0.0109],\n",
      "        [ 0.0215,  0.1061,  0.0057],\n",
      "        [ 0.0124,  0.1076,  0.0096]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.4614, 0.4473, 0.7146, 0.2820, 0.4252, 0.4204, 0.3077, 0.6751, 0.4127,\n",
      "         0.3499, 0.4030, 0.4649, 0.5398, 0.5296, 0.5518, 0.6325, 0.6977, 0.6179,\n",
      "         0.7411, 0.3786, 0.5655, 0.5796, 0.5990, 0.5725, 0.6467, 0.5329, 0.4825,\n",
      "         0.5680, 0.5939, 0.5176, 0.5853, 0.4636],\n",
      "        [0.3696, 0.3444, 0.5405, 0.2356, 0.3514, 0.3679, 0.2700, 0.5383, 0.3213,\n",
      "         0.2645, 0.3907, 0.3570, 0.3931, 0.4327, 0.4197, 0.5182, 0.5190, 0.4612,\n",
      "         0.5991, 0.3049, 0.4436, 0.4637, 0.4225, 0.4533, 0.4448, 0.4129, 0.3749,\n",
      "         0.4523, 0.4427, 0.3893, 0.4282, 0.3207]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0125, 0.0119, 0.0196, 0.0071, 0.0123, 0.0116, 0.0075, 0.0196, 0.0109,\n",
      "        0.0086, 0.0123, 0.0130, 0.0138, 0.0158, 0.0138, 0.0176, 0.0193, 0.0175,\n",
      "        0.0204, 0.0102, 0.0156, 0.0169, 0.0153, 0.0157, 0.0170, 0.0144, 0.0135,\n",
      "        0.0148, 0.0166, 0.0136, 0.0155, 0.0116], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0203, 0.0154], grad_fn=<MeanBackward1>)\n",
      "Epoch 5/10, Accuracy: 0.5063\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0075,  0.0965,  0.0083],\n",
      "        [-0.0189,  0.0719, -0.0076],\n",
      "        [-0.0028,  0.1243,  0.0100],\n",
      "        [ 0.0058,  0.0540,  0.0210],\n",
      "        [-0.0097,  0.0998,  0.0047],\n",
      "        [-0.0208,  0.0418,  0.0031],\n",
      "        [-0.0180,  0.0397, -0.0075],\n",
      "        [-0.0069,  0.1229,  0.0149],\n",
      "        [ 0.0011,  0.0591,  0.0223],\n",
      "        [-0.0055,  0.0414,  0.0110],\n",
      "        [-0.0198,  0.0747,  0.0105],\n",
      "        [-0.0156,  0.0967,  0.0087],\n",
      "        [-0.0007,  0.0977, -0.0017],\n",
      "        [ 0.0016,  0.0960,  0.0167],\n",
      "        [-0.0035,  0.0819,  0.0102],\n",
      "        [-0.0066,  0.1136,  0.0088],\n",
      "        [-0.0043,  0.1315,  0.0199],\n",
      "        [ 0.0004,  0.1216,  0.0241],\n",
      "        [-0.0082,  0.1356,  0.0023],\n",
      "        [-0.0032,  0.0747, -0.0034],\n",
      "        [-0.0052,  0.0993,  0.0050],\n",
      "        [-0.0038,  0.1114,  0.0186],\n",
      "        [-0.0066,  0.1033,  0.0115],\n",
      "        [-0.0053,  0.1059,  0.0094],\n",
      "        [ 0.0052,  0.0995,  0.0129],\n",
      "        [-0.0037,  0.1035,  0.0019],\n",
      "        [ 0.0045,  0.0874,  0.0098],\n",
      "        [-0.0111,  0.1052, -0.0024],\n",
      "        [ 0.0030,  0.1244,  0.0208],\n",
      "        [ 0.0042,  0.0656,  0.0081],\n",
      "        [-0.0031,  0.1124, -0.0039],\n",
      "        [ 0.0062,  0.0980,  0.0074]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.4814, 0.4657, 0.7447, 0.2951, 0.4437, 0.4384, 0.3213, 0.7041, 0.4297,\n",
      "         0.3640, 0.4213, 0.4851, 0.5628, 0.5526, 0.5755, 0.6581, 0.7271, 0.6438,\n",
      "         0.7712, 0.3963, 0.5900, 0.6035, 0.6239, 0.5976, 0.6745, 0.5548, 0.5053,\n",
      "         0.5920, 0.6192, 0.5398, 0.6100, 0.4841],\n",
      "        [0.3860, 0.3590, 0.5641, 0.2475, 0.3672, 0.3842, 0.2813, 0.5615, 0.3352,\n",
      "         0.2754, 0.4079, 0.3729, 0.4113, 0.4520, 0.4383, 0.5402, 0.5416, 0.4810,\n",
      "         0.6246, 0.3197, 0.4630, 0.4832, 0.4410, 0.4737, 0.4648, 0.4303, 0.3941,\n",
      "         0.4719, 0.4621, 0.4066, 0.4471, 0.3360]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0128, 0.0121, 0.0199, 0.0073, 0.0126, 0.0119, 0.0076, 0.0199, 0.0111,\n",
      "        0.0087, 0.0125, 0.0133, 0.0141, 0.0161, 0.0141, 0.0179, 0.0196, 0.0178,\n",
      "        0.0207, 0.0105, 0.0159, 0.0172, 0.0156, 0.0161, 0.0174, 0.0146, 0.0139,\n",
      "        0.0151, 0.0169, 0.0138, 0.0158, 0.0119], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0207, 0.0158], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0012,  0.0530,  0.0193],\n",
      "        [-0.0039,  0.0588,  0.0121],\n",
      "        [ 0.0127,  0.0741,  0.0157],\n",
      "        [-0.0018,  0.0155, -0.0095],\n",
      "        [-0.0098,  0.0601,  0.0239],\n",
      "        [-0.0014,  0.0324, -0.0042],\n",
      "        [ 0.0025,  0.0068,  0.0067],\n",
      "        [ 0.0145,  0.0795,  0.0109],\n",
      "        [-0.0017,  0.0300,  0.0026],\n",
      "        [-0.0043,  0.0282,  0.0159],\n",
      "        [-0.0035,  0.0526,  0.0111],\n",
      "        [-0.0011,  0.0499,  0.0061],\n",
      "        [ 0.0123,  0.0583,  0.0105],\n",
      "        [ 0.0107,  0.0571,  0.0147],\n",
      "        [ 0.0018,  0.0531,  0.0148],\n",
      "        [ 0.0024,  0.0605,  0.0124],\n",
      "        [ 0.0157,  0.0848,  0.0281],\n",
      "        [ 0.0174,  0.0706,  0.0145],\n",
      "        [ 0.0080,  0.0719,  0.0218],\n",
      "        [ 0.0027,  0.0346,  0.0084],\n",
      "        [ 0.0152,  0.0446,  0.0090],\n",
      "        [ 0.0170,  0.0576,  0.0238],\n",
      "        [ 0.0195,  0.0614,  0.0108],\n",
      "        [ 0.0025,  0.0579,  0.0137],\n",
      "        [ 0.0081,  0.0518, -0.0026],\n",
      "        [ 0.0250,  0.0768,  0.0151],\n",
      "        [ 0.0086,  0.0475,  0.0159],\n",
      "        [ 0.0013,  0.0744,  0.0095],\n",
      "        [-0.0031,  0.0725,  0.0145],\n",
      "        [ 0.0072,  0.0458,  0.0150],\n",
      "        [ 0.0003,  0.0561,  0.0124],\n",
      "        [ 0.0103,  0.0630,  0.0114]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.5018, 0.4853, 0.7755, 0.3064, 0.4623, 0.4563, 0.3356, 0.7321, 0.4486,\n",
      "         0.3813, 0.4413, 0.5061, 0.5867, 0.5751, 0.5997, 0.6845, 0.7578, 0.6723,\n",
      "         0.8031, 0.4127, 0.6157, 0.6291, 0.6481, 0.6236, 0.7036, 0.5767, 0.5264,\n",
      "         0.6169, 0.6461, 0.5628, 0.6356, 0.5043],\n",
      "        [0.4030, 0.3745, 0.5886, 0.2567, 0.3828, 0.3993, 0.2939, 0.5852, 0.3488,\n",
      "         0.2883, 0.4263, 0.3896, 0.4297, 0.4713, 0.4574, 0.5622, 0.5656, 0.5038,\n",
      "         0.6510, 0.3331, 0.4841, 0.5045, 0.4589, 0.4948, 0.4858, 0.4476, 0.4114,\n",
      "         0.4923, 0.4830, 0.4243, 0.4669, 0.3505]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0130, 0.0124, 0.0202, 0.0074, 0.0128, 0.0121, 0.0079, 0.0202, 0.0114,\n",
      "        0.0090, 0.0129, 0.0135, 0.0144, 0.0164, 0.0144, 0.0181, 0.0200, 0.0181,\n",
      "        0.0211, 0.0107, 0.0162, 0.0175, 0.0158, 0.0164, 0.0177, 0.0148, 0.0142,\n",
      "        0.0154, 0.0173, 0.0141, 0.0161, 0.0121], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0211, 0.0161], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0118,  0.0602,  0.0020],\n",
      "        [-0.0010,  0.0443, -0.0014],\n",
      "        [-0.0039,  0.0933,  0.0048],\n",
      "        [ 0.0089,  0.0401,  0.0041],\n",
      "        [ 0.0040,  0.0628,  0.0043],\n",
      "        [-0.0109,  0.0325, -0.0024],\n",
      "        [-0.0080,  0.0387, -0.0012],\n",
      "        [-0.0060,  0.1285,  0.0039],\n",
      "        [-0.0003,  0.0416,  0.0118],\n",
      "        [ 0.0018,  0.0154, -0.0063],\n",
      "        [ 0.0073,  0.0361, -0.0062],\n",
      "        [-0.0004,  0.0601,  0.0059],\n",
      "        [ 0.0002,  0.0932,  0.0115],\n",
      "        [ 0.0057,  0.0842, -0.0038],\n",
      "        [-0.0066,  0.0787,  0.0184],\n",
      "        [-0.0067,  0.0821,  0.0022],\n",
      "        [-0.0013,  0.1074,  0.0109],\n",
      "        [ 0.0028,  0.0965,  0.0130],\n",
      "        [-0.0010,  0.1036,  0.0100],\n",
      "        [-0.0164,  0.0643, -0.0008],\n",
      "        [-0.0078,  0.0718, -0.0011],\n",
      "        [-0.0037,  0.0835,  0.0042],\n",
      "        [ 0.0066,  0.0719,  0.0050],\n",
      "        [-0.0086,  0.0931,  0.0066],\n",
      "        [-0.0131,  0.1081,  0.0177],\n",
      "        [-0.0069,  0.0760,  0.0027],\n",
      "        [ 0.0093,  0.0814,  0.0042],\n",
      "        [-0.0075,  0.0712,  0.0138],\n",
      "        [-0.0052,  0.0792,  0.0121],\n",
      "        [-0.0031,  0.0661, -0.0109],\n",
      "        [-0.0065,  0.0637,  0.0073],\n",
      "        [ 0.0105,  0.0816,  0.0087]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.5245, 0.5060, 0.8094, 0.3207, 0.4835, 0.4766, 0.3495, 0.7634, 0.4670,\n",
      "         0.3946, 0.4599, 0.5280, 0.6114, 0.6013, 0.6251, 0.7153, 0.7905, 0.7002,\n",
      "         0.8375, 0.4311, 0.6421, 0.6568, 0.6782, 0.6504, 0.7332, 0.6026, 0.5509,\n",
      "         0.6433, 0.6736, 0.5868, 0.6633, 0.5265],\n",
      "        [0.4207, 0.3911, 0.6140, 0.2687, 0.4003, 0.4175, 0.3070, 0.6099, 0.3651,\n",
      "         0.3001, 0.4450, 0.4069, 0.4477, 0.4918, 0.4772, 0.5866, 0.5902, 0.5252,\n",
      "         0.6787, 0.3481, 0.5050, 0.5261, 0.4802, 0.5162, 0.5072, 0.4677, 0.4303,\n",
      "         0.5137, 0.5042, 0.4430, 0.4873, 0.3665]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0133, 0.0127, 0.0207, 0.0077, 0.0131, 0.0124, 0.0080, 0.0205, 0.0116,\n",
      "        0.0091, 0.0131, 0.0138, 0.0147, 0.0167, 0.0147, 0.0185, 0.0204, 0.0184,\n",
      "        0.0215, 0.0109, 0.0166, 0.0178, 0.0162, 0.0167, 0.0181, 0.0152, 0.0145,\n",
      "        0.0158, 0.0176, 0.0144, 0.0164, 0.0124], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0216, 0.0165], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 1.6847e-02,  8.6097e-02, -6.8044e-03],\n",
      "        [ 1.1606e-02,  8.5498e-02, -1.0960e-02],\n",
      "        [ 1.6678e-02,  1.2450e-01,  2.8668e-03],\n",
      "        [ 1.3661e-02,  4.6193e-02,  1.4758e-04],\n",
      "        [ 9.7089e-03,  9.2521e-02, -7.6474e-03],\n",
      "        [-1.7774e-03,  8.2864e-02, -3.5931e-03],\n",
      "        [ 9.1386e-03,  5.6062e-02, -1.0298e-02],\n",
      "        [ 1.7995e-02,  1.1944e-01, -8.9762e-03],\n",
      "        [-5.4572e-03,  5.7379e-02,  1.0940e-02],\n",
      "        [ 1.6189e-02,  6.1292e-02, -1.3734e-02],\n",
      "        [ 1.4844e-02,  6.8277e-02, -5.6628e-03],\n",
      "        [ 1.7333e-02,  7.7911e-02, -3.2770e-03],\n",
      "        [ 1.4638e-02,  9.5497e-02, -1.2038e-03],\n",
      "        [ 1.2230e-02,  8.5893e-02, -1.2969e-02],\n",
      "        [ 1.3852e-02,  1.2413e-01,  1.3644e-03],\n",
      "        [ 2.1999e-02,  1.2505e-01, -4.7845e-04],\n",
      "        [ 1.7535e-02,  1.1420e-01, -1.0979e-02],\n",
      "        [ 1.9239e-02,  1.0726e-01,  5.2097e-03],\n",
      "        [ 3.2351e-02,  1.3854e-01, -1.1382e-02],\n",
      "        [-7.1210e-03,  7.3495e-02, -4.7427e-03],\n",
      "        [ 2.0331e-02,  1.0125e-01,  1.8533e-03],\n",
      "        [ 2.1017e-02,  9.9800e-02, -4.8558e-03],\n",
      "        [ 3.3514e-02,  1.0198e-01, -4.3905e-03],\n",
      "        [ 9.1658e-03,  9.9968e-02, -3.1647e-03],\n",
      "        [ 2.0442e-02,  9.6814e-02,  1.5164e-03],\n",
      "        [ 9.3757e-03,  9.1046e-02, -1.3777e-02],\n",
      "        [ 1.5994e-02,  8.4737e-02, -2.6544e-03],\n",
      "        [ 1.6279e-02,  9.8811e-02,  7.9921e-04],\n",
      "        [ 1.6937e-02,  9.7669e-02,  7.3744e-04],\n",
      "        [ 1.8206e-02,  8.0812e-02, -6.1677e-03],\n",
      "        [ 2.2271e-02,  9.6536e-02,  2.3276e-03],\n",
      "        [ 1.1148e-04,  8.0201e-02, -1.8634e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.5466, 0.5281, 0.8434, 0.3320, 0.5035, 0.4972, 0.3624, 0.7995, 0.4865,\n",
      "         0.4120, 0.4778, 0.5505, 0.6373, 0.6281, 0.6506, 0.7464, 0.8254, 0.7312,\n",
      "         0.8741, 0.4469, 0.6694, 0.6870, 0.7069, 0.6770, 0.7643, 0.6293, 0.5718,\n",
      "         0.6707, 0.7029, 0.6115, 0.6913, 0.5459],\n",
      "        [0.4391, 0.4088, 0.6413, 0.2792, 0.4175, 0.4361, 0.3185, 0.6392, 0.3802,\n",
      "         0.3128, 0.4626, 0.4247, 0.4671, 0.5148, 0.4976, 0.6135, 0.6173, 0.5490,\n",
      "         0.7090, 0.3614, 0.5266, 0.5507, 0.5027, 0.5379, 0.5296, 0.4896, 0.4470,\n",
      "         0.5361, 0.5269, 0.4622, 0.5090, 0.3808]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0135, 0.0130, 0.0210, 0.0078, 0.0133, 0.0127, 0.0082, 0.0210, 0.0119,\n",
      "        0.0094, 0.0133, 0.0141, 0.0149, 0.0171, 0.0150, 0.0189, 0.0208, 0.0188,\n",
      "        0.0219, 0.0111, 0.0169, 0.0182, 0.0165, 0.0170, 0.0184, 0.0155, 0.0147,\n",
      "        0.0161, 0.0179, 0.0147, 0.0167, 0.0126], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0220, 0.0169], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0090,  0.0862, -0.0010],\n",
      "        [-0.0116,  0.0752,  0.0022],\n",
      "        [ 0.0107,  0.1378, -0.0076],\n",
      "        [ 0.0043,  0.0743, -0.0047],\n",
      "        [-0.0014,  0.0889,  0.0029],\n",
      "        [-0.0102,  0.0945, -0.0100],\n",
      "        [-0.0043,  0.0827, -0.0058],\n",
      "        [ 0.0107,  0.1345, -0.0158],\n",
      "        [ 0.0006,  0.0702, -0.0083],\n",
      "        [ 0.0012,  0.0548,  0.0052],\n",
      "        [ 0.0006,  0.1183,  0.0076],\n",
      "        [ 0.0077,  0.1239,  0.0031],\n",
      "        [ 0.0023,  0.0809, -0.0076],\n",
      "        [ 0.0091,  0.0949, -0.0147],\n",
      "        [ 0.0079,  0.1028, -0.0051],\n",
      "        [ 0.0048,  0.1295, -0.0067],\n",
      "        [ 0.0146,  0.1214, -0.0033],\n",
      "        [ 0.0024,  0.1299, -0.0087],\n",
      "        [ 0.0054,  0.1441, -0.0037],\n",
      "        [ 0.0035,  0.0690, -0.0102],\n",
      "        [-0.0008,  0.1266,  0.0058],\n",
      "        [-0.0027,  0.1134,  0.0018],\n",
      "        [-0.0026,  0.1279,  0.0014],\n",
      "        [ 0.0086,  0.1002,  0.0052],\n",
      "        [ 0.0141,  0.1050, -0.0147],\n",
      "        [ 0.0097,  0.1053, -0.0114],\n",
      "        [-0.0016,  0.0998, -0.0049],\n",
      "        [ 0.0169,  0.1076, -0.0055],\n",
      "        [ 0.0065,  0.0928, -0.0071],\n",
      "        [ 0.0112,  0.0843, -0.0045],\n",
      "        [ 0.0126,  0.0884,  0.0037],\n",
      "        [-0.0038,  0.0713, -0.0116]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.5698, 0.5509, 0.8787, 0.3473, 0.5253, 0.5187, 0.3792, 0.8319, 0.5072,\n",
      "         0.4303, 0.4999, 0.5742, 0.6638, 0.6549, 0.6788, 0.7771, 0.8590, 0.7616,\n",
      "         0.9101, 0.4676, 0.6974, 0.7144, 0.7340, 0.7058, 0.7968, 0.6552, 0.5968,\n",
      "         0.6988, 0.7327, 0.6376, 0.7201, 0.5700],\n",
      "        [0.4586, 0.4268, 0.6693, 0.2910, 0.4360, 0.4544, 0.3322, 0.6663, 0.3959,\n",
      "         0.3260, 0.4833, 0.4435, 0.4885, 0.5372, 0.5195, 0.6398, 0.6446, 0.5741,\n",
      "         0.7394, 0.3783, 0.5498, 0.5751, 0.5243, 0.5616, 0.5531, 0.5108, 0.4674,\n",
      "         0.5593, 0.5503, 0.4824, 0.5316, 0.3980]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0138, 0.0132, 0.0214, 0.0080, 0.0136, 0.0130, 0.0084, 0.0214, 0.0121,\n",
      "        0.0096, 0.0137, 0.0144, 0.0153, 0.0174, 0.0153, 0.0193, 0.0212, 0.0191,\n",
      "        0.0223, 0.0114, 0.0172, 0.0185, 0.0167, 0.0174, 0.0188, 0.0159, 0.0150,\n",
      "        0.0164, 0.0183, 0.0150, 0.0170, 0.0129], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0224, 0.0172], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 1.8249e-03,  8.7586e-02,  7.2974e-03],\n",
      "        [ 9.5758e-04,  6.7114e-02, -3.9710e-03],\n",
      "        [ 1.7391e-02,  1.4670e-01,  9.6369e-03],\n",
      "        [-2.4684e-03,  3.5915e-02,  3.9753e-03],\n",
      "        [-4.4772e-03,  7.3372e-02, -1.2708e-02],\n",
      "        [ 8.0823e-03,  6.4517e-02,  4.9750e-03],\n",
      "        [ 4.1455e-04,  2.8054e-02, -1.3145e-02],\n",
      "        [-2.4020e-03,  1.3117e-01,  1.1154e-03],\n",
      "        [ 7.7659e-03,  6.5907e-02,  7.8831e-03],\n",
      "        [ 7.2338e-03,  6.3709e-02, -1.3133e-02],\n",
      "        [ 3.2182e-03,  5.3903e-02,  1.0031e-02],\n",
      "        [ 4.0379e-03,  8.7189e-02, -3.6339e-03],\n",
      "        [ 2.8291e-03,  9.4542e-02, -3.9128e-03],\n",
      "        [ 1.9593e-03,  1.0680e-01,  8.4625e-03],\n",
      "        [-4.3257e-04,  9.7974e-02, -1.0172e-02],\n",
      "        [ 5.5613e-03,  1.0551e-01, -8.5303e-04],\n",
      "        [ 8.4191e-03,  1.2185e-01, -5.9646e-04],\n",
      "        [ 1.4491e-02,  1.2122e-01, -8.6191e-03],\n",
      "        [-1.3144e-04,  1.3972e-01, -2.8698e-03],\n",
      "        [ 5.6129e-03,  6.2820e-02, -1.5598e-03],\n",
      "        [ 6.3796e-03,  8.8974e-02,  8.5364e-03],\n",
      "        [ 9.7990e-03,  1.0448e-01, -1.5310e-03],\n",
      "        [ 5.4667e-03,  1.1814e-01,  2.4231e-03],\n",
      "        [ 6.0182e-05,  8.2207e-02,  3.3168e-03],\n",
      "        [ 4.9960e-03,  1.1967e-01,  7.1946e-03],\n",
      "        [ 8.2491e-03,  1.0251e-01,  2.1060e-03],\n",
      "        [ 1.3427e-03,  9.2421e-02,  4.0817e-03],\n",
      "        [-5.7310e-03,  1.1655e-01,  8.9049e-03],\n",
      "        [ 8.6719e-03,  1.1888e-01,  1.6679e-02],\n",
      "        [ 4.4664e-03,  9.9141e-02,  6.3947e-03],\n",
      "        [ 2.4544e-03,  1.0354e-01,  2.2811e-02],\n",
      "        [-4.6425e-03,  7.9113e-02, -5.0819e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.5947, 0.5739, 0.9164, 0.3615, 0.5484, 0.5409, 0.3932, 0.8683, 0.5272,\n",
      "         0.4459, 0.5203, 0.5989, 0.6932, 0.6835, 0.7078, 0.8120, 0.8966, 0.7963,\n",
      "         0.9494, 0.4879, 0.7276, 0.7468, 0.7681, 0.7361, 0.8304, 0.6834, 0.6232,\n",
      "         0.7284, 0.7637, 0.6646, 0.7505, 0.5942],\n",
      "        [0.4778, 0.4448, 0.6973, 0.3038, 0.4549, 0.4746, 0.3469, 0.6942, 0.4144,\n",
      "         0.3412, 0.5042, 0.4631, 0.5090, 0.5596, 0.5420, 0.6672, 0.6718, 0.5979,\n",
      "         0.7705, 0.3950, 0.5736, 0.5985, 0.5452, 0.5863, 0.5775, 0.5321, 0.4884,\n",
      "         0.5833, 0.5740, 0.5035, 0.5538, 0.4155]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0141, 0.0135, 0.0218, 0.0082, 0.0139, 0.0132, 0.0085, 0.0218, 0.0124,\n",
      "        0.0098, 0.0139, 0.0147, 0.0156, 0.0178, 0.0157, 0.0197, 0.0216, 0.0195,\n",
      "        0.0227, 0.0116, 0.0175, 0.0189, 0.0171, 0.0178, 0.0192, 0.0162, 0.0153,\n",
      "        0.0168, 0.0186, 0.0154, 0.0174, 0.0132], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0229, 0.0176], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0148,  0.1208,  0.0019],\n",
      "        [-0.0144,  0.0743, -0.0161],\n",
      "        [-0.0261,  0.1619,  0.0002],\n",
      "        [-0.0197,  0.0879,  0.0199],\n",
      "        [-0.0137,  0.1056, -0.0052],\n",
      "        [-0.0049,  0.0744, -0.0043],\n",
      "        [-0.0011,  0.0553, -0.0075],\n",
      "        [-0.0064,  0.1544,  0.0076],\n",
      "        [-0.0065,  0.0818, -0.0060],\n",
      "        [-0.0003,  0.0790,  0.0029],\n",
      "        [-0.0211,  0.0898, -0.0021],\n",
      "        [-0.0134,  0.1306,  0.0054],\n",
      "        [-0.0090,  0.1094,  0.0016],\n",
      "        [-0.0237,  0.1026,  0.0027],\n",
      "        [-0.0219,  0.1175,  0.0021],\n",
      "        [-0.0229,  0.1337,  0.0034],\n",
      "        [-0.0370,  0.1513, -0.0054],\n",
      "        [-0.0210,  0.1512, -0.0017],\n",
      "        [-0.0086,  0.1527,  0.0075],\n",
      "        [ 0.0023,  0.0974, -0.0128],\n",
      "        [-0.0033,  0.1261, -0.0148],\n",
      "        [-0.0141,  0.1237, -0.0094],\n",
      "        [-0.0127,  0.1352, -0.0069],\n",
      "        [-0.0261,  0.1220, -0.0047],\n",
      "        [-0.0147,  0.1420, -0.0065],\n",
      "        [-0.0224,  0.1308, -0.0106],\n",
      "        [ 0.0043,  0.1060, -0.0126],\n",
      "        [-0.0112,  0.1254,  0.0090],\n",
      "        [-0.0308,  0.1330,  0.0008],\n",
      "        [-0.0075,  0.0846, -0.0048],\n",
      "        [-0.0214,  0.1219, -0.0124],\n",
      "        [-0.0097,  0.1113, -0.0075]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.6204, 0.5976, 0.9546, 0.3780, 0.5723, 0.5640, 0.4109, 0.9038, 0.5494,\n",
      "         0.4638, 0.5442, 0.6245, 0.7222, 0.7137, 0.7374, 0.8463, 0.9337, 0.8279,\n",
      "         0.9892, 0.5105, 0.7587, 0.7778, 0.8001, 0.7677, 0.8655, 0.7118, 0.6530,\n",
      "         0.7589, 0.7962, 0.6929, 0.7827, 0.6206],\n",
      "        [0.4996, 0.4635, 0.7282, 0.3169, 0.4755, 0.4940, 0.3615, 0.7239, 0.4304,\n",
      "         0.3538, 0.5263, 0.4836, 0.5323, 0.5856, 0.5660, 0.6963, 0.7016, 0.6251,\n",
      "         0.8041, 0.4138, 0.5994, 0.6259, 0.5707, 0.6127, 0.6032, 0.5552, 0.5125,\n",
      "         0.6083, 0.5997, 0.5255, 0.5789, 0.4350]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0144, 0.0138, 0.0223, 0.0084, 0.0142, 0.0135, 0.0088, 0.0221, 0.0126,\n",
      "        0.0099, 0.0142, 0.0150, 0.0159, 0.0182, 0.0160, 0.0201, 0.0220, 0.0198,\n",
      "        0.0232, 0.0120, 0.0179, 0.0192, 0.0175, 0.0182, 0.0196, 0.0165, 0.0158,\n",
      "        0.0171, 0.0190, 0.0157, 0.0178, 0.0136], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0233, 0.0180], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-1.9086e-02,  5.2200e-02, -3.4772e-04],\n",
      "        [-1.0452e-02,  4.4341e-02,  5.9793e-03],\n",
      "        [-2.2707e-02,  8.0103e-02, -2.8738e-03],\n",
      "        [ 6.0672e-05,  2.7747e-02,  3.1684e-03],\n",
      "        [-6.9797e-03,  2.2313e-02,  6.8496e-03],\n",
      "        [-1.4395e-02,  6.3028e-02,  5.0727e-03],\n",
      "        [-1.4572e-02,  1.4321e-02,  5.5344e-03],\n",
      "        [-1.5035e-02,  7.7451e-02,  7.7157e-03],\n",
      "        [-1.0615e-02,  2.3100e-02,  1.1188e-02],\n",
      "        [-1.7421e-02,  3.0589e-02,  4.3886e-03],\n",
      "        [-4.4841e-03,  3.7157e-02,  2.3718e-02],\n",
      "        [-1.7450e-02,  6.9968e-02,  7.2715e-03],\n",
      "        [-1.3241e-02,  3.0905e-02, -1.4710e-02],\n",
      "        [-7.2654e-03,  6.7944e-02,  8.0096e-03],\n",
      "        [-1.3323e-02,  4.0300e-02,  6.9806e-03],\n",
      "        [-1.6675e-02,  5.8274e-02,  9.1698e-04],\n",
      "        [-1.8601e-02,  6.5950e-02,  5.0240e-03],\n",
      "        [-2.3995e-02,  5.5260e-02,  5.7408e-03],\n",
      "        [-2.0025e-02,  8.4349e-02, -1.0853e-03],\n",
      "        [-1.3659e-02,  3.9911e-02,  2.7133e-03],\n",
      "        [-1.4070e-02,  7.1143e-02,  1.6002e-03],\n",
      "        [-2.3123e-02,  6.1469e-02,  9.4035e-03],\n",
      "        [-2.6060e-02,  6.7619e-02, -9.3613e-04],\n",
      "        [-4.6125e-03,  4.7482e-02,  3.1367e-04],\n",
      "        [-9.1414e-03,  8.6475e-02,  7.1029e-03],\n",
      "        [-2.5963e-02,  7.2136e-02, -1.2199e-03],\n",
      "        [-9.8649e-03,  4.7909e-02,  1.3723e-02],\n",
      "        [-1.5416e-02,  7.0451e-02, -1.8958e-03],\n",
      "        [-1.5268e-02,  6.4698e-02, -2.7199e-03],\n",
      "        [-1.2247e-03,  4.4169e-02,  6.0622e-05],\n",
      "        [-1.4375e-02,  7.1354e-02, -7.5025e-03],\n",
      "        [-1.2742e-02,  1.5642e-02, -8.3260e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.6457, 0.6232, 0.9936, 0.3946, 0.5965, 0.5886, 0.4293, 0.9406, 0.5748,\n",
      "         0.4870, 0.5682, 0.6511, 0.7517, 0.7418, 0.7678, 0.8804, 0.9716, 0.8615,\n",
      "         1.0283, 0.5307, 0.7900, 0.8081, 0.8304, 0.8002, 0.9019, 0.7422, 0.6780,\n",
      "         0.7905, 0.8293, 0.7222, 0.8139, 0.6460],\n",
      "        [0.5204, 0.4842, 0.7584, 0.3312, 0.4957, 0.5159, 0.3779, 0.7543, 0.4516,\n",
      "         0.3720, 0.5497, 0.5048, 0.5550, 0.6090, 0.5897, 0.7251, 0.7310, 0.6510,\n",
      "         0.8368, 0.4304, 0.6250, 0.6507, 0.5927, 0.6393, 0.6297, 0.5790, 0.5331,\n",
      "         0.6343, 0.6256, 0.5484, 0.6031, 0.4532]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0147, 0.0140, 0.0226, 0.0086, 0.0145, 0.0138, 0.0090, 0.0225, 0.0130,\n",
      "        0.0103, 0.0146, 0.0153, 0.0162, 0.0184, 0.0163, 0.0204, 0.0224, 0.0202,\n",
      "        0.0235, 0.0122, 0.0182, 0.0195, 0.0177, 0.0186, 0.0200, 0.0168, 0.0160,\n",
      "        0.0174, 0.0194, 0.0160, 0.0180, 0.0138], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0238, 0.0184], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0078,  0.0603, -0.0100],\n",
      "        [ 0.0165,  0.0816, -0.0402],\n",
      "        [ 0.0138,  0.1100, -0.0375],\n",
      "        [-0.0012,  0.0234, -0.0135],\n",
      "        [ 0.0156,  0.0641, -0.0240],\n",
      "        [ 0.0063,  0.0781, -0.0345],\n",
      "        [ 0.0079,  0.0537, -0.0129],\n",
      "        [ 0.0057,  0.0998, -0.0307],\n",
      "        [ 0.0205,  0.0765, -0.0281],\n",
      "        [ 0.0080,  0.0539, -0.0200],\n",
      "        [-0.0014,  0.0636, -0.0349],\n",
      "        [ 0.0135,  0.0619, -0.0441],\n",
      "        [ 0.0141,  0.0971, -0.0104],\n",
      "        [ 0.0072,  0.0724, -0.0312],\n",
      "        [ 0.0074,  0.0767, -0.0170],\n",
      "        [-0.0063,  0.0960, -0.0298],\n",
      "        [ 0.0227,  0.0921, -0.0276],\n",
      "        [ 0.0188,  0.0957, -0.0272],\n",
      "        [ 0.0136,  0.0997, -0.0269],\n",
      "        [-0.0007,  0.0636, -0.0320],\n",
      "        [ 0.0141,  0.0757, -0.0201],\n",
      "        [ 0.0164,  0.0776, -0.0270],\n",
      "        [ 0.0119,  0.1031, -0.0183],\n",
      "        [ 0.0165,  0.0871, -0.0327],\n",
      "        [ 0.0180,  0.0928, -0.0300],\n",
      "        [ 0.0054,  0.0774, -0.0261],\n",
      "        [ 0.0073,  0.0805, -0.0262],\n",
      "        [ 0.0015,  0.0815, -0.0321],\n",
      "        [ 0.0131,  0.0854, -0.0394],\n",
      "        [-0.0020,  0.0789, -0.0152],\n",
      "        [ 0.0104,  0.0888, -0.0255],\n",
      "        [ 0.0215,  0.0899, -0.0147]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.6728, 0.6492, 1.0358, 0.4088, 0.6214, 0.6131, 0.4462, 0.9824, 0.5985,\n",
      "         0.5068, 0.5917, 0.6789, 0.7817, 0.7745, 0.7994, 0.9180, 1.0127, 0.8985,\n",
      "         1.0729, 0.5519, 0.8234, 0.8436, 0.8650, 0.8337, 0.9398, 0.7739, 0.7068,\n",
      "         0.8239, 0.8648, 0.7523, 0.8484, 0.6723],\n",
      "        [0.5427, 0.5049, 0.7914, 0.3452, 0.5174, 0.5383, 0.3938, 0.7877, 0.4715,\n",
      "         0.3873, 0.5726, 0.5268, 0.5773, 0.6366, 0.6148, 0.7565, 0.7621, 0.6776,\n",
      "         0.8733, 0.4485, 0.6514, 0.6789, 0.6195, 0.6661, 0.6572, 0.6061, 0.5556,\n",
      "         0.6616, 0.6529, 0.5721, 0.6293, 0.4734]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0149, 0.0144, 0.0231, 0.0087, 0.0148, 0.0141, 0.0092, 0.0230, 0.0133,\n",
      "        0.0105, 0.0148, 0.0156, 0.0164, 0.0188, 0.0166, 0.0208, 0.0228, 0.0205,\n",
      "        0.0240, 0.0124, 0.0185, 0.0199, 0.0180, 0.0189, 0.0204, 0.0172, 0.0163,\n",
      "        0.0178, 0.0198, 0.0163, 0.0184, 0.0141], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0243, 0.0188], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0258,  0.0505, -0.0084],\n",
      "        [ 0.0219,  0.0520,  0.0091],\n",
      "        [ 0.0271,  0.0914, -0.0196],\n",
      "        [ 0.0231,  0.0232, -0.0096],\n",
      "        [ 0.0141,  0.0477, -0.0179],\n",
      "        [ 0.0187,  0.0692, -0.0062],\n",
      "        [ 0.0026,  0.0571, -0.0140],\n",
      "        [ 0.0201,  0.0818, -0.0058],\n",
      "        [ 0.0085,  0.0252, -0.0043],\n",
      "        [ 0.0146,  0.0130, -0.0151],\n",
      "        [ 0.0060,  0.0567, -0.0153],\n",
      "        [ 0.0111,  0.0487, -0.0001],\n",
      "        [ 0.0192,  0.0607, -0.0031],\n",
      "        [ 0.0110,  0.0641, -0.0141],\n",
      "        [ 0.0319,  0.0710, -0.0193],\n",
      "        [ 0.0272,  0.0805, -0.0127],\n",
      "        [ 0.0196,  0.0915, -0.0183],\n",
      "        [ 0.0185,  0.0646, -0.0090],\n",
      "        [ 0.0365,  0.0825, -0.0150],\n",
      "        [ 0.0094,  0.0481, -0.0047],\n",
      "        [ 0.0298,  0.0660, -0.0036],\n",
      "        [ 0.0187,  0.0751, -0.0168],\n",
      "        [ 0.0161,  0.0821, -0.0050],\n",
      "        [ 0.0130,  0.0689, -0.0040],\n",
      "        [ 0.0277,  0.0551,  0.0059],\n",
      "        [ 0.0147,  0.0596, -0.0166],\n",
      "        [ 0.0055,  0.0616, -0.0017],\n",
      "        [ 0.0196,  0.0561,  0.0012],\n",
      "        [ 0.0171,  0.0584,  0.0015],\n",
      "        [ 0.0032,  0.0661, -0.0126],\n",
      "        [ 0.0255,  0.0700, -0.0071],\n",
      "        [ 0.0148,  0.0365, -0.0058]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.7012, 0.6768, 1.0782, 0.4252, 0.6469, 0.6385, 0.4652, 1.0232, 0.6230,\n",
      "         0.5284, 0.6180, 0.7075, 0.8144, 0.8061, 0.8331, 0.9543, 1.0551, 0.9368,\n",
      "         1.1174, 0.5742, 0.8588, 0.8799, 0.8988, 0.8681, 0.9792, 0.8050, 0.7349,\n",
      "         0.8583, 0.9012, 0.7837, 0.8834, 0.6985],\n",
      "        [0.5659, 0.5279, 0.8252, 0.3584, 0.5390, 0.5613, 0.4097, 0.8222, 0.4913,\n",
      "         0.4042, 0.5966, 0.5496, 0.6021, 0.6636, 0.6409, 0.7885, 0.7958, 0.7082,\n",
      "         0.9107, 0.4662, 0.6798, 0.7093, 0.6458, 0.6939, 0.6859, 0.6314, 0.5779,\n",
      "         0.6901, 0.6817, 0.5965, 0.6566, 0.4922]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0152, 0.0147, 0.0235, 0.0089, 0.0151, 0.0144, 0.0094, 0.0234, 0.0136,\n",
      "        0.0107, 0.0152, 0.0159, 0.0168, 0.0191, 0.0170, 0.0212, 0.0233, 0.0209,\n",
      "        0.0245, 0.0126, 0.0189, 0.0203, 0.0183, 0.0193, 0.0208, 0.0175, 0.0166,\n",
      "        0.0182, 0.0201, 0.0167, 0.0188, 0.0144], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0247, 0.0192], grad_fn=<MeanBackward1>)\n",
      "Epoch 6/10, Accuracy: 0.4719\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0007,  0.0585,  0.0185],\n",
      "        [ 0.0132,  0.0822,  0.0023],\n",
      "        [ 0.0040,  0.1235,  0.0276],\n",
      "        [ 0.0055,  0.0529,  0.0296],\n",
      "        [ 0.0124,  0.0808,  0.0074],\n",
      "        [-0.0023,  0.0661,  0.0098],\n",
      "        [-0.0070,  0.0346,  0.0068],\n",
      "        [ 0.0067,  0.1406,  0.0449],\n",
      "        [ 0.0097,  0.0571,  0.0321],\n",
      "        [ 0.0195,  0.0139, -0.0093],\n",
      "        [ 0.0180,  0.0766,  0.0048],\n",
      "        [ 0.0237,  0.0712,  0.0097],\n",
      "        [ 0.0002,  0.0915,  0.0254],\n",
      "        [-0.0018,  0.1019,  0.0281],\n",
      "        [ 0.0048,  0.0758,  0.0269],\n",
      "        [ 0.0124,  0.1225,  0.0354],\n",
      "        [ 0.0073,  0.1301,  0.0323],\n",
      "        [ 0.0091,  0.1135,  0.0378],\n",
      "        [ 0.0095,  0.1186,  0.0304],\n",
      "        [ 0.0004,  0.0575,  0.0129],\n",
      "        [-0.0069,  0.0962,  0.0175],\n",
      "        [ 0.0020,  0.1255,  0.0300],\n",
      "        [ 0.0046,  0.1027,  0.0204],\n",
      "        [ 0.0081,  0.0975,  0.0215],\n",
      "        [ 0.0074,  0.1121,  0.0473],\n",
      "        [-0.0008,  0.1060,  0.0304],\n",
      "        [ 0.0089,  0.0787,  0.0116],\n",
      "        [ 0.0141,  0.1032,  0.0388],\n",
      "        [ 0.0151,  0.1211,  0.0403],\n",
      "        [-0.0025,  0.1115,  0.0240],\n",
      "        [ 0.0033,  0.0961,  0.0190],\n",
      "        [ 0.0110,  0.0875,  0.0299]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.7322, 0.7035, 1.1242, 0.4433, 0.6754, 0.6645, 0.4834, 1.0656, 0.6473,\n",
      "         0.5458, 0.6451, 0.7379, 0.8500, 0.8416, 0.8679, 0.9954, 1.0997, 0.9764,\n",
      "         1.1650, 0.6005, 0.8956, 0.9166, 0.9397, 0.9059, 1.0202, 0.8389, 0.7704,\n",
      "         0.8940, 0.9389, 0.8167, 0.9213, 0.7296],\n",
      "        [0.5917, 0.5487, 0.8615, 0.3735, 0.5631, 0.5834, 0.4261, 0.8570, 0.5105,\n",
      "         0.4178, 0.6235, 0.5741, 0.6300, 0.6927, 0.6694, 0.8219, 0.8309, 0.7407,\n",
      "         0.9503, 0.4883, 0.7104, 0.7405, 0.6756, 0.7259, 0.7161, 0.6573, 0.6070,\n",
      "         0.7193, 0.7113, 0.6222, 0.6858, 0.5148]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0156, 0.0149, 0.0240, 0.0091, 0.0154, 0.0146, 0.0095, 0.0238, 0.0138,\n",
      "        0.0108, 0.0155, 0.0163, 0.0172, 0.0196, 0.0173, 0.0216, 0.0238, 0.0214,\n",
      "        0.0250, 0.0129, 0.0194, 0.0207, 0.0188, 0.0197, 0.0212, 0.0178, 0.0171,\n",
      "        0.0185, 0.0205, 0.0170, 0.0192, 0.0147], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0252, 0.0197], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0231,  0.0448, -0.0213],\n",
      "        [ 0.0091,  0.0620, -0.0363],\n",
      "        [ 0.0222,  0.0858, -0.0458],\n",
      "        [ 0.0058,  0.0070,  0.0006],\n",
      "        [ 0.0196,  0.0320, -0.0325],\n",
      "        [ 0.0085,  0.0685, -0.0276],\n",
      "        [ 0.0149,  0.0345, -0.0220],\n",
      "        [ 0.0074,  0.0844, -0.0358],\n",
      "        [ 0.0269,  0.0340, -0.0115],\n",
      "        [ 0.0063,  0.0456, -0.0185],\n",
      "        [ 0.0188,  0.0262, -0.0312],\n",
      "        [ 0.0134,  0.0463, -0.0239],\n",
      "        [ 0.0100,  0.0884, -0.0317],\n",
      "        [ 0.0135,  0.0574, -0.0312],\n",
      "        [ 0.0188,  0.0579, -0.0400],\n",
      "        [ 0.0155,  0.0816, -0.0489],\n",
      "        [ 0.0231,  0.0853, -0.0361],\n",
      "        [ 0.0261,  0.0739, -0.0345],\n",
      "        [ 0.0127,  0.0950, -0.0508],\n",
      "        [ 0.0012,  0.0269, -0.0243],\n",
      "        [ 0.0213,  0.0505, -0.0330],\n",
      "        [ 0.0149,  0.0629, -0.0372],\n",
      "        [ 0.0185,  0.0955, -0.0415],\n",
      "        [ 0.0077,  0.0568, -0.0252],\n",
      "        [ 0.0106,  0.0610, -0.0192],\n",
      "        [ 0.0151,  0.0828, -0.0434],\n",
      "        [ 0.0037,  0.0352, -0.0343],\n",
      "        [ 0.0200,  0.0767, -0.0321],\n",
      "        [ 0.0193,  0.0675, -0.0288],\n",
      "        [ 0.0069,  0.0648, -0.0308],\n",
      "        [ 0.0274,  0.0626, -0.0341],\n",
      "        [ 0.0136,  0.0654, -0.0255]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.7612, 0.7351, 1.1701, 0.4622, 0.7036, 0.6949, 0.5038, 1.1111, 0.6774,\n",
      "         0.5741, 0.6699, 0.7684, 0.8827, 0.8770, 0.9032, 1.0374, 1.1439, 1.0145,\n",
      "         1.2120, 0.6230, 0.9315, 0.9546, 0.9763, 0.9412, 1.0625, 0.8750, 0.7982,\n",
      "         0.9314, 0.9781, 0.8510, 0.9588, 0.7585],\n",
      "        [0.6158, 0.5738, 0.8973, 0.3907, 0.5873, 0.6105, 0.4456, 0.8933, 0.5349,\n",
      "         0.4398, 0.6490, 0.5986, 0.6549, 0.7224, 0.6972, 0.8570, 0.8650, 0.7696,\n",
      "         0.9892, 0.5078, 0.7394, 0.7702, 0.7021, 0.7549, 0.7469, 0.6862, 0.6303,\n",
      "         0.7500, 0.7418, 0.6493, 0.7144, 0.5371]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0158, 0.0153, 0.0244, 0.0094, 0.0157, 0.0151, 0.0098, 0.0243, 0.0143,\n",
      "        0.0113, 0.0158, 0.0166, 0.0174, 0.0199, 0.0177, 0.0220, 0.0241, 0.0217,\n",
      "        0.0254, 0.0131, 0.0197, 0.0210, 0.0190, 0.0200, 0.0216, 0.0182, 0.0172,\n",
      "        0.0189, 0.0209, 0.0174, 0.0195, 0.0150], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0257, 0.0201], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0254,  0.0941,  0.0008],\n",
      "        [-0.0152,  0.0691, -0.0118],\n",
      "        [-0.0340,  0.1093, -0.0060],\n",
      "        [-0.0199,  0.0391,  0.0062],\n",
      "        [-0.0201,  0.0749,  0.0118],\n",
      "        [-0.0256,  0.0848, -0.0078],\n",
      "        [-0.0118,  0.0287,  0.0009],\n",
      "        [-0.0331,  0.1130, -0.0010],\n",
      "        [-0.0319,  0.0751,  0.0151],\n",
      "        [-0.0235,  0.0655, -0.0021],\n",
      "        [-0.0223,  0.0737,  0.0141],\n",
      "        [-0.0221,  0.1003, -0.0059],\n",
      "        [-0.0104,  0.0605, -0.0108],\n",
      "        [-0.0420,  0.0952,  0.0036],\n",
      "        [-0.0250,  0.0549,  0.0096],\n",
      "        [-0.0220,  0.1021,  0.0146],\n",
      "        [-0.0341,  0.1141, -0.0028],\n",
      "        [-0.0296,  0.1068, -0.0010],\n",
      "        [-0.0247,  0.1221, -0.0008],\n",
      "        [-0.0281,  0.0605, -0.0018],\n",
      "        [-0.0245,  0.0846, -0.0037],\n",
      "        [-0.0221,  0.1003,  0.0056],\n",
      "        [-0.0140,  0.0844,  0.0041],\n",
      "        [-0.0241,  0.0799, -0.0037],\n",
      "        [-0.0327,  0.0759, -0.0167],\n",
      "        [-0.0338,  0.0828,  0.0046],\n",
      "        [-0.0209,  0.0450,  0.0236],\n",
      "        [-0.0252,  0.1073,  0.0025],\n",
      "        [-0.0201,  0.1110,  0.0168],\n",
      "        [-0.0240,  0.0550,  0.0165],\n",
      "        [-0.0209,  0.0910, -0.0074],\n",
      "        [-0.0213,  0.0729, -0.0011]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.7934, 0.7643, 1.2184, 0.4822, 0.7336, 0.7230, 0.5256, 1.1560, 0.7056,\n",
      "         0.5967, 0.7007, 0.8012, 0.9221, 0.9131, 0.9408, 1.0809, 1.1914, 1.0574,\n",
      "         1.2617, 0.6516, 0.9708, 0.9934, 1.0195, 0.9826, 1.1072, 0.9121, 0.8342,\n",
      "         0.9698, 1.0186, 0.8868, 0.9985, 0.7914],\n",
      "        [0.6433, 0.5975, 0.9367, 0.4078, 0.6132, 0.6351, 0.4638, 0.9313, 0.5565,\n",
      "         0.4558, 0.6777, 0.6250, 0.6861, 0.7544, 0.7279, 0.8947, 0.9033, 0.8044,\n",
      "         1.0321, 0.5318, 0.7719, 0.8039, 0.7363, 0.7893, 0.7798, 0.7163, 0.6599,\n",
      "         0.7818, 0.7740, 0.6773, 0.7460, 0.5612]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0162, 0.0155, 0.0249, 0.0096, 0.0161, 0.0153, 0.0100, 0.0247, 0.0145,\n",
      "        0.0114, 0.0162, 0.0169, 0.0179, 0.0204, 0.0181, 0.0225, 0.0246, 0.0221,\n",
      "        0.0259, 0.0135, 0.0201, 0.0214, 0.0196, 0.0205, 0.0221, 0.0186, 0.0177,\n",
      "        0.0193, 0.0213, 0.0177, 0.0199, 0.0154], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0262, 0.0205], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0127,  0.0567, -0.0113],\n",
      "        [-0.0170,  0.0762,  0.0041],\n",
      "        [-0.0152,  0.1000, -0.0201],\n",
      "        [-0.0149,  0.0131, -0.0325],\n",
      "        [-0.0097,  0.0429, -0.0059],\n",
      "        [-0.0193,  0.0675, -0.0121],\n",
      "        [-0.0042,  0.0426, -0.0129],\n",
      "        [-0.0265,  0.1063, -0.0168],\n",
      "        [ 0.0013,  0.0529, -0.0113],\n",
      "        [ 0.0186,  0.0423, -0.0247],\n",
      "        [-0.0118,  0.0577, -0.0147],\n",
      "        [-0.0134,  0.0493, -0.0266],\n",
      "        [ 0.0029,  0.0937, -0.0078],\n",
      "        [-0.0133,  0.0796,  0.0010],\n",
      "        [-0.0032,  0.0551, -0.0130],\n",
      "        [-0.0090,  0.0861, -0.0069],\n",
      "        [-0.0150,  0.1057, -0.0208],\n",
      "        [-0.0071,  0.0755, -0.0152],\n",
      "        [ 0.0012,  0.1057, -0.0120],\n",
      "        [-0.0130,  0.0574, -0.0129],\n",
      "        [-0.0152,  0.0742, -0.0127],\n",
      "        [-0.0179,  0.0953, -0.0055],\n",
      "        [-0.0045,  0.0725, -0.0136],\n",
      "        [-0.0130,  0.0983, -0.0091],\n",
      "        [-0.0068,  0.0942, -0.0274],\n",
      "        [-0.0053,  0.0803, -0.0038],\n",
      "        [-0.0009,  0.0563,  0.0041],\n",
      "        [-0.0158,  0.0697, -0.0108],\n",
      "        [-0.0257,  0.0766,  0.0034],\n",
      "        [-0.0087,  0.0646, -0.0094],\n",
      "        [-0.0149,  0.0879, -0.0094],\n",
      "        [-0.0090,  0.0609, -0.0098]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.8276, 0.7970, 1.2693, 0.5015, 0.7644, 0.7533, 0.5471, 1.2044, 0.7329,\n",
      "         0.6189, 0.7295, 0.8350, 0.9596, 0.9522, 0.9808, 1.1264, 1.2416, 1.1031,\n",
      "         1.3140, 0.6790, 1.0114, 1.0350, 1.0613, 1.0237, 1.1534, 0.9498, 0.8697,\n",
      "         1.0103, 1.0616, 0.9237, 1.0398, 0.8245],\n",
      "        [0.6699, 0.6245, 0.9757, 0.4236, 0.6390, 0.6627, 0.4828, 0.9718, 0.5806,\n",
      "         0.4758, 0.7054, 0.6517, 0.7136, 0.7863, 0.7583, 0.9321, 0.9413, 0.8379,\n",
      "         1.0750, 0.5528, 0.8047, 0.8377, 0.7667, 0.8222, 0.8135, 0.7479, 0.6870,\n",
      "         0.8153, 0.8077, 0.7061, 0.7772, 0.5843]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0165, 0.0159, 0.0253, 0.0098, 0.0164, 0.0157, 0.0103, 0.0252, 0.0148,\n",
      "        0.0116, 0.0165, 0.0173, 0.0182, 0.0208, 0.0184, 0.0229, 0.0251, 0.0226,\n",
      "        0.0264, 0.0138, 0.0205, 0.0218, 0.0199, 0.0209, 0.0225, 0.0190, 0.0181,\n",
      "        0.0197, 0.0218, 0.0181, 0.0203, 0.0157], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0267, 0.0209], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0240,  0.1437,  0.0065],\n",
      "        [ 0.0280,  0.1135,  0.0115],\n",
      "        [ 0.0222,  0.2212,  0.0066],\n",
      "        [-0.0031,  0.0957,  0.0056],\n",
      "        [ 0.0133,  0.1377,  0.0152],\n",
      "        [ 0.0254,  0.1090,  0.0052],\n",
      "        [ 0.0237,  0.0885,  0.0117],\n",
      "        [ 0.0209,  0.2257,  0.0142],\n",
      "        [ 0.0006,  0.1378,  0.0134],\n",
      "        [ 0.0103,  0.0971,  0.0088],\n",
      "        [ 0.0130,  0.1238,  0.0288],\n",
      "        [ 0.0044,  0.1487,  0.0205],\n",
      "        [ 0.0227,  0.1758,  0.0061],\n",
      "        [-0.0017,  0.1728,  0.0067],\n",
      "        [ 0.0219,  0.1660, -0.0029],\n",
      "        [ 0.0178,  0.2150,  0.0026],\n",
      "        [ 0.0126,  0.2252,  0.0178],\n",
      "        [-0.0060,  0.2116,  0.0118],\n",
      "        [ 0.0365,  0.2334,  0.0136],\n",
      "        [ 0.0110,  0.1013,  0.0010],\n",
      "        [ 0.0241,  0.1650,  0.0014],\n",
      "        [ 0.0199,  0.1952,  0.0118],\n",
      "        [ 0.0160,  0.1860,  0.0140],\n",
      "        [ 0.0231,  0.1707,  0.0069],\n",
      "        [ 0.0079,  0.1817,  0.0072],\n",
      "        [ 0.0057,  0.1550, -0.0026],\n",
      "        [ 0.0104,  0.1262,  0.0089],\n",
      "        [ 0.0193,  0.1922,  0.0145],\n",
      "        [ 0.0127,  0.1944,  0.0084],\n",
      "        [ 0.0134,  0.1616,  0.0066],\n",
      "        [ 0.0247,  0.1766,  0.0032],\n",
      "        [ 0.0026,  0.1456,  0.0086]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.8631, 0.8304, 1.3233, 0.5206, 0.7967, 0.7842, 0.5657, 1.2574, 0.7607,\n",
      "         0.6432, 0.7565, 0.8696, 1.0001, 0.9952, 1.0212, 1.1750, 1.2939, 1.1498,\n",
      "         1.3718, 0.7055, 1.0544, 1.0825, 1.1091, 1.0654, 1.2011, 0.9901, 0.9046,\n",
      "         1.0525, 1.1066, 0.9619, 1.0847, 0.8562],\n",
      "        [0.6994, 0.6509, 1.0181, 0.4395, 0.6664, 0.6902, 0.5013, 1.0143, 0.6037,\n",
      "         0.4950, 0.7333, 0.6799, 0.7456, 0.8211, 0.7906, 0.9718, 0.9829, 0.8760,\n",
      "         1.1225, 0.5758, 0.8399, 0.8765, 0.8007, 0.8576, 0.8487, 0.7794, 0.7166,\n",
      "         0.8499, 0.8432, 0.7361, 0.8117, 0.6082]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0169, 0.0162, 0.0259, 0.0099, 0.0167, 0.0160, 0.0104, 0.0257, 0.0150,\n",
      "        0.0118, 0.0167, 0.0176, 0.0186, 0.0212, 0.0188, 0.0234, 0.0257, 0.0231,\n",
      "        0.0270, 0.0140, 0.0209, 0.0224, 0.0204, 0.0213, 0.0230, 0.0194, 0.0184,\n",
      "        0.0201, 0.0222, 0.0185, 0.0208, 0.0160], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0272, 0.0214], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0206,  0.0837,  0.0159],\n",
      "        [ 0.0254,  0.0982,  0.0071],\n",
      "        [ 0.0117,  0.1152,  0.0358],\n",
      "        [-0.0084,  0.0346,  0.0215],\n",
      "        [ 0.0175,  0.0985,  0.0263],\n",
      "        [ 0.0089,  0.0992,  0.0277],\n",
      "        [ 0.0117,  0.0493,  0.0124],\n",
      "        [ 0.0378,  0.1401,  0.0481],\n",
      "        [-0.0048,  0.1142,  0.0378],\n",
      "        [ 0.0211,  0.0572,  0.0179],\n",
      "        [ 0.0047,  0.0531,  0.0127],\n",
      "        [ 0.0040,  0.0840,  0.0251],\n",
      "        [ 0.0307,  0.0801,  0.0270],\n",
      "        [ 0.0155,  0.1220,  0.0410],\n",
      "        [ 0.0172,  0.0981,  0.0321],\n",
      "        [ 0.0310,  0.0974,  0.0335],\n",
      "        [ 0.0200,  0.1205,  0.0395],\n",
      "        [ 0.0107,  0.1123,  0.0396],\n",
      "        [ 0.0336,  0.1304,  0.0476],\n",
      "        [ 0.0290,  0.0836,  0.0264],\n",
      "        [ 0.0093,  0.1045,  0.0253],\n",
      "        [ 0.0128,  0.1141,  0.0404],\n",
      "        [ 0.0103,  0.0915,  0.0216],\n",
      "        [ 0.0212,  0.1133,  0.0299],\n",
      "        [ 0.0288,  0.1224,  0.0433],\n",
      "        [ 0.0208,  0.0960,  0.0089],\n",
      "        [ 0.0182,  0.1205,  0.0234],\n",
      "        [ 0.0138,  0.0979,  0.0309],\n",
      "        [ 0.0145,  0.1305,  0.0324],\n",
      "        [ 0.0225,  0.1011,  0.0315],\n",
      "        [ 0.0163,  0.0712,  0.0260],\n",
      "        [ 0.0236,  0.0974,  0.0304]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.8986, 0.8622, 1.3762, 0.5414, 0.8290, 0.8157, 0.5917, 1.3061, 0.7958,\n",
      "         0.6722, 0.7917, 0.9064, 1.0418, 1.0329, 1.0629, 1.2212, 1.3471, 1.1971,\n",
      "         1.4258, 0.7366, 1.0987, 1.1265, 1.1501, 1.1110, 1.2511, 1.0269, 0.9450,\n",
      "         1.0956, 1.1521, 1.0019, 1.1285, 0.8925],\n",
      "        [0.7292, 0.6775, 1.0605, 0.4585, 0.6948, 0.7193, 0.5245, 1.0547, 0.6313,\n",
      "         0.5173, 0.7662, 0.7094, 0.7778, 0.8548, 0.8243, 1.0118, 1.0244, 0.9130,\n",
      "         1.1681, 0.6022, 0.8756, 0.9121, 0.8323, 0.8949, 0.8855, 0.8099, 0.7494,\n",
      "         0.8856, 0.8792, 0.7677, 0.8462, 0.6358]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0172, 0.0165, 0.0263, 0.0101, 0.0170, 0.0163, 0.0107, 0.0261, 0.0155,\n",
      "        0.0121, 0.0171, 0.0180, 0.0190, 0.0216, 0.0192, 0.0238, 0.0261, 0.0235,\n",
      "        0.0275, 0.0144, 0.0213, 0.0228, 0.0207, 0.0218, 0.0234, 0.0197, 0.0188,\n",
      "        0.0205, 0.0226, 0.0188, 0.0212, 0.0163], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0277, 0.0218], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0226,  0.1069,  0.0146],\n",
      "        [-0.0290,  0.0950,  0.0027],\n",
      "        [-0.0278,  0.1717, -0.0010],\n",
      "        [-0.0066,  0.0547, -0.0047],\n",
      "        [-0.0254,  0.0859,  0.0171],\n",
      "        [-0.0093,  0.0979, -0.0213],\n",
      "        [-0.0039,  0.0674,  0.0167],\n",
      "        [-0.0226,  0.1581,  0.0031],\n",
      "        [-0.0149,  0.0648, -0.0192],\n",
      "        [-0.0254,  0.0652,  0.0136],\n",
      "        [-0.0217,  0.1389,  0.0050],\n",
      "        [-0.0195,  0.1259,  0.0038],\n",
      "        [-0.0293,  0.1212,  0.0105],\n",
      "        [-0.0307,  0.1232,  0.0018],\n",
      "        [-0.0228,  0.0895,  0.0117],\n",
      "        [-0.0249,  0.1502,  0.0090],\n",
      "        [-0.0389,  0.1502,  0.0248],\n",
      "        [-0.0325,  0.1346,  0.0041],\n",
      "        [-0.0363,  0.1632,  0.0259],\n",
      "        [-0.0099,  0.0975, -0.0009],\n",
      "        [-0.0120,  0.1430,  0.0143],\n",
      "        [-0.0176,  0.1278,  0.0296],\n",
      "        [-0.0314,  0.1323,  0.0080],\n",
      "        [-0.0171,  0.1328,  0.0198],\n",
      "        [-0.0295,  0.1385,  0.0026],\n",
      "        [-0.0299,  0.1073,  0.0102],\n",
      "        [-0.0157,  0.1135,  0.0116],\n",
      "        [-0.0261,  0.1365, -0.0113],\n",
      "        [-0.0288,  0.1096,  0.0010],\n",
      "        [-0.0167,  0.1095, -0.0017],\n",
      "        [-0.0292,  0.1622,  0.0155],\n",
      "        [-0.0311,  0.0691,  0.0004]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.9368, 0.8991, 1.4336, 0.5672, 0.8652, 0.8494, 0.6166, 1.3603, 0.8241,\n",
      "         0.6977, 0.8263, 0.9444, 1.0850, 1.0790, 1.1083, 1.2727, 1.4022, 1.2469,\n",
      "         1.4853, 0.7697, 1.1431, 1.1699, 1.2001, 1.1568, 1.3029, 1.0723, 0.9855,\n",
      "         1.1407, 1.1999, 1.0439, 1.1744, 0.9308],\n",
      "        [0.7605, 0.7074, 1.1057, 0.4803, 0.7253, 0.7490, 0.5451, 1.1002, 0.6551,\n",
      "         0.5377, 0.7990, 0.7399, 0.8105, 0.8929, 0.8595, 1.0559, 1.0679, 0.9523,\n",
      "         1.2182, 0.6281, 0.9123, 0.9504, 0.8721, 0.9326, 0.9234, 0.8483, 0.7815,\n",
      "         0.9231, 0.9168, 0.8007, 0.8816, 0.6631]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0176, 0.0169, 0.0268, 0.0105, 0.0174, 0.0166, 0.0109, 0.0266, 0.0157,\n",
      "        0.0123, 0.0176, 0.0183, 0.0194, 0.0221, 0.0196, 0.0243, 0.0266, 0.0239,\n",
      "        0.0280, 0.0148, 0.0217, 0.0231, 0.0212, 0.0222, 0.0239, 0.0202, 0.0193,\n",
      "        0.0209, 0.0231, 0.0192, 0.0215, 0.0167], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0282, 0.0223], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0357,  0.1212, -0.0601],\n",
      "        [ 0.0613,  0.0709, -0.0383],\n",
      "        [ 0.0497,  0.1678, -0.0524],\n",
      "        [ 0.0067,  0.0485, -0.0073],\n",
      "        [ 0.0455,  0.1049, -0.0293],\n",
      "        [ 0.0470,  0.0753, -0.0303],\n",
      "        [ 0.0148,  0.0672, -0.0277],\n",
      "        [ 0.0637,  0.1637, -0.0386],\n",
      "        [ 0.0252,  0.0989, -0.0081],\n",
      "        [ 0.0210,  0.0908, -0.0454],\n",
      "        [ 0.0450,  0.0811, -0.0431],\n",
      "        [ 0.0439,  0.1069, -0.0413],\n",
      "        [ 0.0366,  0.1323, -0.0210],\n",
      "        [ 0.0611,  0.1167, -0.0344],\n",
      "        [ 0.0399,  0.1162, -0.0286],\n",
      "        [ 0.0621,  0.1268, -0.0353],\n",
      "        [ 0.0583,  0.1732, -0.0453],\n",
      "        [ 0.0525,  0.1369, -0.0268],\n",
      "        [ 0.0636,  0.1649, -0.0570],\n",
      "        [ 0.0390,  0.0962, -0.0337],\n",
      "        [ 0.0368,  0.1113, -0.0494],\n",
      "        [ 0.0548,  0.1314, -0.0380],\n",
      "        [ 0.0322,  0.1294, -0.0396],\n",
      "        [ 0.0568,  0.1398, -0.0298],\n",
      "        [ 0.0443,  0.1524, -0.0332],\n",
      "        [ 0.0529,  0.0985, -0.0438],\n",
      "        [ 0.0347,  0.1209, -0.0341],\n",
      "        [ 0.0504,  0.1176, -0.0379],\n",
      "        [ 0.0698,  0.1383, -0.0266],\n",
      "        [ 0.0236,  0.1274, -0.0208],\n",
      "        [ 0.0458,  0.1355, -0.0567],\n",
      "        [ 0.0280,  0.1087, -0.0094]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[0.9739, 0.9379, 1.4915, 0.5876, 0.8998, 0.8881, 0.6398, 1.4186, 0.8628,\n",
      "         0.7304, 0.8577, 0.9834, 1.1261, 1.1234, 1.1509, 1.3274, 1.4591, 1.2952,\n",
      "         1.5469, 0.7969, 1.1904, 1.2205, 1.2480, 1.2025, 1.3564, 1.1194, 1.0216,\n",
      "         1.1884, 1.2491, 1.0867, 1.2227, 0.9655],\n",
      "        [0.7907, 0.7387, 1.1514, 0.4971, 0.7551, 0.7831, 0.5681, 1.1473, 0.6871,\n",
      "         0.5646, 0.8315, 0.7714, 0.8417, 0.9297, 0.8938, 1.1006, 1.1124, 0.9894,\n",
      "         1.2692, 0.6514, 0.9507, 0.9906, 0.9059, 0.9704, 0.9629, 0.8844, 0.8105,\n",
      "         0.9622, 0.9556, 0.8344, 0.9187, 0.6889]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0178, 0.0173, 0.0273, 0.0106, 0.0177, 0.0170, 0.0111, 0.0272, 0.0162,\n",
      "        0.0128, 0.0178, 0.0187, 0.0196, 0.0225, 0.0199, 0.0248, 0.0271, 0.0243,\n",
      "        0.0286, 0.0149, 0.0221, 0.0236, 0.0215, 0.0226, 0.0244, 0.0207, 0.0194,\n",
      "        0.0214, 0.0235, 0.0196, 0.0220, 0.0169], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0288, 0.0228], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-1.2844e-02,  9.6498e-02,  6.2005e-03],\n",
      "        [-1.5029e-02,  8.9672e-02, -9.0462e-04],\n",
      "        [ 3.0507e-03,  1.4248e-01,  2.2027e-03],\n",
      "        [ 5.1337e-03,  7.5193e-02, -1.6701e-02],\n",
      "        [-2.7243e-03,  7.6253e-02,  1.1359e-03],\n",
      "        [-2.2588e-02,  1.0893e-01, -1.2628e-02],\n",
      "        [-1.1649e-02,  7.9992e-02, -1.0023e-02],\n",
      "        [-2.0388e-02,  1.3045e-01, -1.4346e-02],\n",
      "        [ 9.6099e-03,  6.9194e-02, -3.5592e-03],\n",
      "        [-5.0785e-03,  4.5414e-02,  1.8231e-02],\n",
      "        [-1.0728e-02,  1.3610e-01, -1.3686e-02],\n",
      "        [-5.2534e-03,  1.1268e-01, -1.7415e-02],\n",
      "        [-1.3965e-03,  9.3395e-02,  7.6924e-03],\n",
      "        [-1.1288e-02,  1.1005e-01, -5.1272e-03],\n",
      "        [ 6.6049e-03,  7.3493e-02,  5.4533e-03],\n",
      "        [-1.6601e-02,  1.1934e-01,  8.5856e-03],\n",
      "        [ 3.4692e-03,  1.1251e-01,  4.3286e-03],\n",
      "        [ 4.5038e-03,  1.1501e-01, -5.9500e-03],\n",
      "        [-1.9313e-02,  1.0993e-01,  4.2777e-03],\n",
      "        [-1.5015e-02,  7.5293e-02,  1.6081e-04],\n",
      "        [-9.9605e-03,  1.1125e-01, -8.6205e-04],\n",
      "        [ 9.3207e-05,  8.4582e-02,  1.5392e-03],\n",
      "        [-1.3856e-02,  1.1427e-01, -7.2654e-03],\n",
      "        [ 1.1072e-02,  1.2555e-01, -2.4101e-04],\n",
      "        [-1.4509e-02,  9.8782e-02, -6.5492e-03],\n",
      "        [-1.6408e-02,  9.3883e-02,  1.2300e-02],\n",
      "        [-1.9514e-03,  8.1934e-02, -7.4759e-03],\n",
      "        [-2.4705e-02,  1.0348e-01, -1.0997e-02],\n",
      "        [ 8.8940e-04,  1.0831e-01, -2.2086e-03],\n",
      "        [-2.0164e-02,  9.4682e-02,  6.0592e-03],\n",
      "        [-1.1030e-02,  9.5990e-02,  6.5713e-03],\n",
      "        [ 2.9804e-03,  5.4619e-02, -3.9952e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.0142, 0.9750, 1.5521, 0.6137, 0.9379, 0.9225, 0.6693, 1.4750, 0.8964,\n",
      "         0.7593, 0.8977, 1.0248, 1.1750, 1.1689, 1.2004, 1.3787, 1.5193, 1.3503,\n",
      "         1.6094, 0.8325, 1.2397, 1.2693, 1.2973, 1.2552, 1.4128, 1.1632, 1.0691,\n",
      "         1.2367, 1.3007, 1.1319, 1.2728, 1.0086],\n",
      "        [0.8257, 0.7693, 1.2003, 0.5211, 0.7886, 0.8142, 0.5924, 1.1950, 0.7130,\n",
      "         0.5853, 0.8685, 0.8047, 0.8803, 0.9707, 0.9336, 1.1464, 1.1606, 1.0337,\n",
      "         1.3228, 0.6815, 0.9913, 1.0332, 0.9461, 1.0138, 1.0043, 0.9223, 0.8501,\n",
      "         1.0026, 0.9966, 0.8701, 0.9588, 0.7216]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0182, 0.0176, 0.0278, 0.0109, 0.0182, 0.0173, 0.0114, 0.0276, 0.0165,\n",
      "        0.0130, 0.0183, 0.0191, 0.0201, 0.0229, 0.0204, 0.0253, 0.0277, 0.0248,\n",
      "        0.0291, 0.0153, 0.0226, 0.0240, 0.0219, 0.0232, 0.0249, 0.0210, 0.0200,\n",
      "        0.0218, 0.0240, 0.0200, 0.0224, 0.0175], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0293, 0.0232], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 7.9590e-03,  8.2854e-02, -7.6694e-03],\n",
      "        [ 3.3104e-03,  8.1460e-02, -1.0072e-02],\n",
      "        [ 6.4562e-03,  1.2781e-01, -9.9406e-03],\n",
      "        [ 1.5738e-02,  4.1550e-02, -9.9947e-03],\n",
      "        [ 1.1838e-02,  9.8620e-02, -2.5102e-03],\n",
      "        [-1.1238e-02,  9.9947e-02, -6.1713e-03],\n",
      "        [-3.5567e-03,  7.4834e-02, -1.1392e-03],\n",
      "        [-1.4987e-02,  1.0468e-01, -1.3426e-02],\n",
      "        [ 3.0406e-03,  1.2481e-01,  9.4521e-03],\n",
      "        [ 4.6217e-03,  4.7114e-02,  2.3124e-02],\n",
      "        [ 9.5911e-03,  7.1133e-02, -1.4198e-02],\n",
      "        [ 9.6235e-03,  4.4662e-02,  8.6521e-04],\n",
      "        [ 1.1658e-03,  9.0411e-02, -5.4749e-03],\n",
      "        [-6.2528e-03,  1.0096e-01, -1.0018e-02],\n",
      "        [ 5.8855e-03,  8.9518e-02, -1.1207e-02],\n",
      "        [ 1.1349e-02,  1.1638e-01, -1.2451e-02],\n",
      "        [ 6.0922e-03,  1.1090e-01, -1.8577e-02],\n",
      "        [ 5.2980e-03,  1.1415e-01, -4.2615e-03],\n",
      "        [ 9.8758e-03,  1.1372e-01, -1.1589e-02],\n",
      "        [-9.5761e-03,  7.9089e-02, -2.8403e-03],\n",
      "        [ 9.9696e-03,  1.2107e-01, -4.4147e-03],\n",
      "        [ 2.7181e-03,  1.1919e-01, -1.7939e-02],\n",
      "        [ 8.4106e-03,  1.0299e-01,  5.1180e-04],\n",
      "        [ 2.2844e-03,  9.2406e-02, -1.8157e-02],\n",
      "        [ 2.0352e-03,  9.7897e-02, -3.3888e-03],\n",
      "        [ 3.5467e-03,  6.8001e-02, -5.1081e-03],\n",
      "        [-6.2956e-03,  1.2096e-01, -2.7309e-03],\n",
      "        [ 7.1564e-03,  6.8445e-02, -9.0189e-04],\n",
      "        [ 1.2799e-02,  1.1398e-01, -2.2909e-02],\n",
      "        [-7.8786e-05,  1.3222e-01,  8.9172e-03],\n",
      "        [ 1.7045e-02,  9.5417e-02, -3.9032e-03],\n",
      "        [-1.8466e-03,  1.0239e-01,  1.0525e-02]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.0567, 1.0155, 1.6158, 0.6389, 0.9766, 0.9616, 0.6964, 1.5379, 0.9361,\n",
      "         0.7914, 0.9340, 1.0672, 1.2232, 1.2175, 1.2491, 1.4353, 1.5821, 1.4061,\n",
      "         1.6755, 0.8656, 1.2905, 1.3220, 1.3507, 1.3063, 1.4709, 1.2116, 1.1112,\n",
      "         1.2878, 1.3545, 1.1788, 1.3249, 1.0483],\n",
      "        [0.8598, 0.8023, 1.2503, 0.5427, 0.8214, 0.8499, 0.6176, 1.2461, 0.7472,\n",
      "         0.6115, 0.9045, 0.8390, 0.9166, 1.0101, 0.9720, 1.1935, 1.2092, 1.0766,\n",
      "         1.3776, 0.7090, 1.0325, 1.0755, 0.9856, 1.0560, 1.0472, 0.9607, 0.8840,\n",
      "         1.0449, 1.0391, 0.9069, 0.9986, 0.7510]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0186, 0.0180, 0.0284, 0.0112, 0.0185, 0.0177, 0.0117, 0.0282, 0.0169,\n",
      "        0.0133, 0.0186, 0.0195, 0.0205, 0.0234, 0.0208, 0.0257, 0.0282, 0.0252,\n",
      "        0.0297, 0.0156, 0.0230, 0.0245, 0.0224, 0.0236, 0.0254, 0.0215, 0.0203,\n",
      "        0.0222, 0.0245, 0.0205, 0.0228, 0.0178], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0299, 0.0237], grad_fn=<MeanBackward1>)\n",
      "Epoch 7/10, Accuracy: 0.5000\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-9.0150e-03,  1.2456e-01, -8.0705e-04],\n",
      "        [-7.6142e-03,  9.4644e-02, -2.1546e-02],\n",
      "        [-3.7188e-03,  1.7622e-01, -1.8579e-02],\n",
      "        [-7.0578e-03,  1.1526e-01, -1.4928e-02],\n",
      "        [-3.4758e-03,  1.2123e-01, -1.9837e-02],\n",
      "        [-1.1487e-02,  1.0127e-01, -1.9946e-02],\n",
      "        [-2.8185e-02,  4.1758e-02, -1.6999e-03],\n",
      "        [-1.3901e-02,  2.0812e-01, -2.3587e-02],\n",
      "        [ 1.7320e-02,  7.6425e-02, -4.9656e-03],\n",
      "        [ 3.2871e-03,  8.4055e-02, -7.1874e-03],\n",
      "        [-6.3341e-03,  1.2879e-01, -3.4366e-03],\n",
      "        [-6.8852e-03,  1.4486e-01, -4.5188e-02],\n",
      "        [-9.1447e-03,  1.2435e-01, -8.4093e-03],\n",
      "        [-3.7115e-03,  1.5522e-01, -6.2257e-03],\n",
      "        [-1.3935e-02,  1.3405e-01, -5.9684e-03],\n",
      "        [-4.2360e-03,  1.9048e-01, -1.7926e-02],\n",
      "        [-1.8706e-02,  1.8036e-01, -6.2224e-03],\n",
      "        [-7.7383e-03,  1.6128e-01, -1.9602e-02],\n",
      "        [-2.6080e-03,  1.9917e-01, -3.4529e-02],\n",
      "        [-1.4345e-02,  8.8823e-02, -3.4255e-02],\n",
      "        [ 1.1439e-03,  1.2252e-01, -2.8253e-02],\n",
      "        [-1.1477e-02,  1.4655e-01, -2.7876e-02],\n",
      "        [-6.9557e-03,  1.3620e-01, -6.8462e-03],\n",
      "        [-1.3958e-02,  1.5517e-01, -2.6108e-02],\n",
      "        [ 1.5054e-03,  1.6109e-01, -3.5101e-02],\n",
      "        [-7.7650e-03,  1.5618e-01,  2.2617e-03],\n",
      "        [ 1.7737e-02,  1.0810e-01, -3.7310e-02],\n",
      "        [ 8.0875e-03,  1.6931e-01, -1.6458e-02],\n",
      "        [ 3.8510e-03,  1.7775e-01, -3.2485e-02],\n",
      "        [ 1.4351e-02,  1.2672e-01, -2.5328e-03],\n",
      "        [ 5.0067e-03,  1.2780e-01, -9.3567e-03],\n",
      "        [ 5.6555e-05,  1.0969e-01,  3.0912e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.1003, 1.0576, 1.6825, 0.6644, 1.0174, 1.0021, 0.7221, 1.5998, 0.9710,\n",
      "         0.8208, 0.9715, 1.1117, 1.2731, 1.2693, 1.2998, 1.4956, 1.6468, 1.4640,\n",
      "         1.7446, 0.9020, 1.3439, 1.3781, 1.4094, 1.3590, 1.5316, 1.2629, 1.1604,\n",
      "         1.3404, 1.4103, 1.2277, 1.3800, 1.0920],\n",
      "        [0.8964, 0.8364, 1.3040, 0.5655, 0.8570, 0.8853, 0.6407, 1.2985, 0.7743,\n",
      "         0.6351, 0.9414, 0.8749, 0.9558, 1.0553, 1.0130, 1.2451, 1.2603, 1.1226,\n",
      "         1.4358, 0.7399, 1.0768, 1.1228, 1.0300, 1.1011, 1.0920, 1.0025, 0.9245,\n",
      "         1.0886, 1.0835, 0.9454, 1.0417, 0.7833]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0190, 0.0184, 0.0289, 0.0114, 0.0189, 0.0181, 0.0118, 0.0288, 0.0171,\n",
      "        0.0135, 0.0190, 0.0199, 0.0209, 0.0239, 0.0212, 0.0263, 0.0287, 0.0257,\n",
      "        0.0303, 0.0159, 0.0235, 0.0250, 0.0229, 0.0241, 0.0259, 0.0220, 0.0209,\n",
      "        0.0227, 0.0249, 0.0209, 0.0233, 0.0181], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0304, 0.0242], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0273,  0.0767,  0.0313],\n",
      "        [ 0.0008,  0.1161,  0.0221],\n",
      "        [ 0.0447,  0.1041,  0.0345],\n",
      "        [ 0.0177,  0.0547,  0.0373],\n",
      "        [ 0.0113,  0.0850,  0.0276],\n",
      "        [ 0.0164,  0.0835,  0.0321],\n",
      "        [-0.0036,  0.0442,  0.0177],\n",
      "        [ 0.0508,  0.0988,  0.0445],\n",
      "        [ 0.0354,  0.0536,  0.0442],\n",
      "        [ 0.0162,  0.0210,  0.0282],\n",
      "        [ 0.0089,  0.0789,  0.0288],\n",
      "        [ 0.0349,  0.0912,  0.0417],\n",
      "        [ 0.0055,  0.0777,  0.0164],\n",
      "        [ 0.0520,  0.0768,  0.0317],\n",
      "        [ 0.0267,  0.0756,  0.0384],\n",
      "        [ 0.0247,  0.0907,  0.0280],\n",
      "        [ 0.0426,  0.0998,  0.0378],\n",
      "        [ 0.0450,  0.0946,  0.0418],\n",
      "        [ 0.0338,  0.1099,  0.0434],\n",
      "        [ 0.0275,  0.0574,  0.0106],\n",
      "        [ 0.0272,  0.1297,  0.0447],\n",
      "        [ 0.0342,  0.0891,  0.0343],\n",
      "        [ 0.0333,  0.0864,  0.0237],\n",
      "        [ 0.0190,  0.1130,  0.0366],\n",
      "        [ 0.0437,  0.1070,  0.0487],\n",
      "        [ 0.0411,  0.0717,  0.0116],\n",
      "        [ 0.0321,  0.0795,  0.0197],\n",
      "        [ 0.0486,  0.0661,  0.0374],\n",
      "        [ 0.0441,  0.1006,  0.0244],\n",
      "        [ 0.0343,  0.0504,  0.0219],\n",
      "        [ 0.0279,  0.0942,  0.0223],\n",
      "        [ 0.0358,  0.0828,  0.0163]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.1452, 1.1003, 1.7506, 0.6897, 1.0579, 1.0419, 0.7523, 1.6655, 1.0119,\n",
      "         0.8569, 1.0121, 1.1575, 1.3248, 1.3207, 1.3526, 1.5559, 1.7146, 1.5238,\n",
      "         1.8153, 0.9387, 1.3996, 1.4347, 1.4634, 1.4147, 1.5945, 1.3113, 1.2060,\n",
      "         1.3956, 1.4685, 1.2778, 1.4360, 1.1361],\n",
      "        [0.9344, 0.8706, 1.3577, 0.5877, 0.8921, 0.9209, 0.6693, 1.3520, 0.8092,\n",
      "         0.6629, 0.9828, 0.9123, 0.9969, 1.0985, 1.0556, 1.2950, 1.3147, 1.1717,\n",
      "         1.4947, 0.7717, 1.1222, 1.1696, 1.0695, 1.1475, 1.1386, 1.0398, 0.9632,\n",
      "         1.1340, 1.1296, 0.9850, 1.0850, 0.8170]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0193, 0.0187, 0.0295, 0.0116, 0.0192, 0.0184, 0.0121, 0.0293, 0.0176,\n",
      "        0.0138, 0.0194, 0.0203, 0.0213, 0.0243, 0.0216, 0.0267, 0.0293, 0.0262,\n",
      "        0.0308, 0.0163, 0.0239, 0.0255, 0.0232, 0.0246, 0.0264, 0.0222, 0.0212,\n",
      "        0.0231, 0.0254, 0.0213, 0.0238, 0.0185], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0310, 0.0247], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0182,  0.1884, -0.0263],\n",
      "        [-0.0077,  0.1373, -0.0272],\n",
      "        [-0.0183,  0.2708, -0.0239],\n",
      "        [-0.0024,  0.1490,  0.0183],\n",
      "        [-0.0225,  0.1836, -0.0144],\n",
      "        [-0.0092,  0.1631, -0.0104],\n",
      "        [-0.0128,  0.1008, -0.0273],\n",
      "        [-0.0288,  0.2731, -0.0101],\n",
      "        [ 0.0030,  0.1841,  0.0071],\n",
      "        [-0.0023,  0.1740, -0.0167],\n",
      "        [-0.0076,  0.2220, -0.0087],\n",
      "        [-0.0240,  0.1807, -0.0280],\n",
      "        [-0.0066,  0.2033, -0.0206],\n",
      "        [-0.0267,  0.2387,  0.0032],\n",
      "        [-0.0335,  0.2081, -0.0148],\n",
      "        [-0.0270,  0.2733, -0.0174],\n",
      "        [-0.0298,  0.2844, -0.0260],\n",
      "        [-0.0290,  0.2524, -0.0171],\n",
      "        [-0.0156,  0.2777, -0.0243],\n",
      "        [-0.0185,  0.0959, -0.0223],\n",
      "        [-0.0088,  0.1786, -0.0156],\n",
      "        [-0.0172,  0.2162, -0.0196],\n",
      "        [-0.0129,  0.2311, -0.0304],\n",
      "        [-0.0209,  0.2328, -0.0195],\n",
      "        [-0.0105,  0.2237, -0.0154],\n",
      "        [-0.0226,  0.1858, -0.0226],\n",
      "        [-0.0124,  0.1711, -0.0146],\n",
      "        [-0.0243,  0.2054, -0.0105],\n",
      "        [-0.0236,  0.2339, -0.0221],\n",
      "        [-0.0125,  0.2198,  0.0042],\n",
      "        [-0.0127,  0.2088, -0.0287],\n",
      "        [-0.0108,  0.1786, -0.0099]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.1942, 1.1466, 1.8233, 0.7225, 1.1039, 1.0872, 0.7824, 1.7345, 1.0531,\n",
      "         0.8882, 1.0536, 1.2056, 1.3811, 1.3775, 1.4088, 1.6221, 1.7842, 1.5860,\n",
      "         1.8911, 0.9784, 1.4563, 1.4935, 1.5283, 1.4736, 1.6598, 1.3690, 1.2569,\n",
      "         1.4532, 1.5288, 1.3311, 1.4956, 1.1842],\n",
      "        [0.9749, 0.9080, 1.4156, 0.6143, 0.9311, 0.9598, 0.6955, 1.4098, 0.8406,\n",
      "         0.6878, 1.0235, 0.9511, 1.0401, 1.1463, 1.1003, 1.3507, 1.3695, 1.2205,\n",
      "         1.5585, 0.8041, 1.1695, 1.2196, 1.1190, 1.1961, 1.1868, 1.0867, 1.0038,\n",
      "         1.1818, 1.1776, 1.0267, 1.1320, 0.8523]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0198, 0.0191, 0.0301, 0.0120, 0.0197, 0.0189, 0.0123, 0.0299, 0.0179,\n",
      "        0.0140, 0.0198, 0.0207, 0.0218, 0.0249, 0.0221, 0.0273, 0.0299, 0.0267,\n",
      "        0.0315, 0.0166, 0.0244, 0.0260, 0.0239, 0.0251, 0.0269, 0.0228, 0.0217,\n",
      "        0.0236, 0.0259, 0.0217, 0.0243, 0.0189], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0316, 0.0252], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0194,  0.0823, -0.0003],\n",
      "        [ 0.0369,  0.0766,  0.0082],\n",
      "        [ 0.0325,  0.1620,  0.0165],\n",
      "        [ 0.0046,  0.0655, -0.0024],\n",
      "        [ 0.0319,  0.1265,  0.0069],\n",
      "        [ 0.0311,  0.0760, -0.0092],\n",
      "        [ 0.0111,  0.0421, -0.0115],\n",
      "        [ 0.0358,  0.1444,  0.0098],\n",
      "        [ 0.0333,  0.0812,  0.0007],\n",
      "        [ 0.0099,  0.0472,  0.0150],\n",
      "        [ 0.0284,  0.0753,  0.0208],\n",
      "        [ 0.0135,  0.0868,  0.0170],\n",
      "        [ 0.0253,  0.0877, -0.0048],\n",
      "        [ 0.0386,  0.1472,  0.0247],\n",
      "        [ 0.0197,  0.1357,  0.0101],\n",
      "        [ 0.0413,  0.1359,  0.0129],\n",
      "        [ 0.0326,  0.1585,  0.0090],\n",
      "        [ 0.0185,  0.1392,  0.0076],\n",
      "        [ 0.0499,  0.1419,  0.0014],\n",
      "        [ 0.0251,  0.0989,  0.0133],\n",
      "        [ 0.0536,  0.1111, -0.0208],\n",
      "        [ 0.0358,  0.1361, -0.0084],\n",
      "        [ 0.0237,  0.1035, -0.0007],\n",
      "        [ 0.0320,  0.1131, -0.0020],\n",
      "        [ 0.0445,  0.1312,  0.0075],\n",
      "        [ 0.0179,  0.1378,  0.0123],\n",
      "        [ 0.0494,  0.1097,  0.0124],\n",
      "        [ 0.0250,  0.1209,  0.0218],\n",
      "        [ 0.0303,  0.1364,  0.0172],\n",
      "        [ 0.0531,  0.1422,  0.0154],\n",
      "        [ 0.0473,  0.1162,  0.0052],\n",
      "        [ 0.0178,  0.1055,  0.0030]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.2423, 1.1929, 1.8957, 0.7476, 1.1480, 1.1291, 0.8145, 1.8050, 1.0952,\n",
      "         0.9274, 1.0973, 1.2551, 1.4380, 1.4319, 1.4656, 1.6861, 1.8579, 1.6519,\n",
      "         1.9678, 1.0172, 1.5175, 1.5554, 1.5883, 1.5347, 1.7282, 1.4225, 1.3086,\n",
      "         1.5124, 1.5911, 1.3855, 1.5556, 1.2303],\n",
      "        [1.0148, 0.9465, 1.4733, 0.6378, 0.9698, 0.9995, 0.7251, 1.4680, 0.8759,\n",
      "         0.7197, 1.0649, 0.9911, 1.0828, 1.1929, 1.1461, 1.4065, 1.4265, 1.2704,\n",
      "         1.6226, 0.8374, 1.2192, 1.2694, 1.1635, 1.2468, 1.2373, 1.1322, 1.0464,\n",
      "         1.2309, 1.2271, 1.0700, 1.1785, 0.8870]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0201, 0.0195, 0.0306, 0.0121, 0.0200, 0.0192, 0.0126, 0.0304, 0.0183,\n",
      "        0.0144, 0.0202, 0.0211, 0.0222, 0.0253, 0.0225, 0.0278, 0.0305, 0.0272,\n",
      "        0.0321, 0.0169, 0.0249, 0.0265, 0.0242, 0.0256, 0.0275, 0.0232, 0.0221,\n",
      "        0.0241, 0.0264, 0.0222, 0.0247, 0.0193], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0322, 0.0257], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0486,  0.0945,  0.0153],\n",
      "        [ 0.0279,  0.1172,  0.0072],\n",
      "        [ 0.0544,  0.1720,  0.0109],\n",
      "        [ 0.0085,  0.0832, -0.0024],\n",
      "        [ 0.0276,  0.1234,  0.0014],\n",
      "        [ 0.0431,  0.1079,  0.0031],\n",
      "        [ 0.0206,  0.0721,  0.0133],\n",
      "        [ 0.0546,  0.1893,  0.0150],\n",
      "        [ 0.0326,  0.1024, -0.0055],\n",
      "        [ 0.0488,  0.0601, -0.0014],\n",
      "        [ 0.0096,  0.1343,  0.0033],\n",
      "        [ 0.0370,  0.1192,  0.0066],\n",
      "        [ 0.0354,  0.1499,  0.0010],\n",
      "        [ 0.0473,  0.1638,  0.0131],\n",
      "        [ 0.0324,  0.1123,  0.0166],\n",
      "        [ 0.0174,  0.1612,  0.0215],\n",
      "        [ 0.0540,  0.1756,  0.0181],\n",
      "        [ 0.0368,  0.1568,  0.0181],\n",
      "        [ 0.0466,  0.1701,  0.0193],\n",
      "        [ 0.0356,  0.0899,  0.0079],\n",
      "        [ 0.0334,  0.1329,  0.0113],\n",
      "        [ 0.0291,  0.1382,  0.0218],\n",
      "        [ 0.0278,  0.1256,  0.0208],\n",
      "        [ 0.0448,  0.1763, -0.0035],\n",
      "        [ 0.0537,  0.1635,  0.0114],\n",
      "        [ 0.0247,  0.1328,  0.0304],\n",
      "        [ 0.0310,  0.1481,  0.0131],\n",
      "        [ 0.0294,  0.1194,  0.0156],\n",
      "        [ 0.0319,  0.1464,  0.0200],\n",
      "        [ 0.0308,  0.1288,  0.0063],\n",
      "        [ 0.0374,  0.1362,  0.0126],\n",
      "        [ 0.0414,  0.1364,  0.0090]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.2936, 1.2418, 1.9736, 0.7770, 1.1947, 1.1760, 0.8476, 1.8776, 1.1396,\n",
      "         0.9640, 1.1417, 1.3070, 1.4951, 1.4912, 1.5252, 1.7556, 1.9331, 1.7190,\n",
      "         2.0476, 1.0586, 1.5790, 1.6183, 1.6518, 1.5975, 1.7990, 1.4832, 1.3609,\n",
      "         1.5743, 1.6567, 1.4421, 1.6189, 1.2810],\n",
      "        [1.0576, 0.9862, 1.5348, 0.6650, 1.0107, 1.0413, 0.7558, 1.5280, 0.9134,\n",
      "         0.7475, 1.1099, 1.0332, 1.1277, 1.2433, 1.1941, 1.4646, 1.4863, 1.3240,\n",
      "         1.6898, 0.8728, 1.2697, 1.3219, 1.2134, 1.2995, 1.2896, 1.1803, 1.0890,\n",
      "         1.2823, 1.2788, 1.1147, 1.2276, 0.9252]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0205, 0.0199, 0.0312, 0.0123, 0.0205, 0.0196, 0.0129, 0.0310, 0.0187,\n",
      "        0.0146, 0.0206, 0.0215, 0.0226, 0.0258, 0.0230, 0.0284, 0.0311, 0.0278,\n",
      "        0.0327, 0.0173, 0.0254, 0.0269, 0.0247, 0.0261, 0.0280, 0.0238, 0.0225,\n",
      "        0.0246, 0.0270, 0.0226, 0.0252, 0.0197], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0328, 0.0262], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0062,  0.0775, -0.0224],\n",
      "        [-0.0048,  0.0694,  0.0024],\n",
      "        [ 0.0005,  0.1368, -0.0197],\n",
      "        [ 0.0115,  0.0621, -0.0080],\n",
      "        [-0.0039,  0.0996, -0.0062],\n",
      "        [ 0.0040,  0.0534,  0.0053],\n",
      "        [ 0.0121,  0.0312, -0.0009],\n",
      "        [-0.0084,  0.0957, -0.0056],\n",
      "        [-0.0042,  0.0934,  0.0037],\n",
      "        [ 0.0057,  0.0206, -0.0065],\n",
      "        [ 0.0015,  0.1013, -0.0273],\n",
      "        [ 0.0046,  0.0878,  0.0004],\n",
      "        [-0.0094,  0.0885, -0.0135],\n",
      "        [-0.0054,  0.1079, -0.0123],\n",
      "        [ 0.0097,  0.0899, -0.0215],\n",
      "        [-0.0147,  0.1031, -0.0214],\n",
      "        [-0.0035,  0.1296, -0.0120],\n",
      "        [-0.0032,  0.1432, -0.0077],\n",
      "        [-0.0049,  0.1212, -0.0299],\n",
      "        [ 0.0016,  0.0473,  0.0211],\n",
      "        [ 0.0051,  0.1253, -0.0109],\n",
      "        [-0.0041,  0.1253, -0.0133],\n",
      "        [ 0.0027,  0.0900, -0.0193],\n",
      "        [ 0.0075,  0.1134, -0.0162],\n",
      "        [-0.0008,  0.1053,  0.0067],\n",
      "        [-0.0222,  0.0812, -0.0034],\n",
      "        [-0.0043,  0.1203, -0.0158],\n",
      "        [-0.0099,  0.0719, -0.0092],\n",
      "        [-0.0112,  0.1261, -0.0129],\n",
      "        [-0.0090,  0.0610, -0.0038],\n",
      "        [ 0.0012,  0.1113, -0.0178],\n",
      "        [-0.0076,  0.0709,  0.0118]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.3465, 1.2928, 2.0527, 0.8132, 1.2442, 1.2259, 0.8847, 1.9545, 1.1897,\n",
      "         1.0053, 1.1925, 1.3608, 1.5556, 1.5520, 1.5889, 1.8264, 2.0100, 1.7855,\n",
      "         2.1298, 1.1038, 1.6428, 1.6808, 1.7189, 1.6629, 1.8724, 1.5429, 1.4186,\n",
      "         1.6384, 1.7235, 1.5017, 1.6839, 1.3341],\n",
      "        [1.1008, 1.0288, 1.5979, 0.6933, 1.0530, 1.0868, 0.7880, 1.5928, 0.9545,\n",
      "         0.7809, 1.1579, 1.0767, 1.1738, 1.2951, 1.2441, 1.5251, 1.5480, 1.3774,\n",
      "         1.7593, 0.9082, 1.3218, 1.3752, 1.2630, 1.3531, 1.3437, 1.2302, 1.1355,\n",
      "         1.3357, 1.3321, 1.1616, 1.2781, 0.9633]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0210, 0.0203, 0.0318, 0.0127, 0.0209, 0.0201, 0.0132, 0.0316, 0.0192,\n",
      "        0.0150, 0.0211, 0.0220, 0.0231, 0.0263, 0.0235, 0.0289, 0.0316, 0.0282,\n",
      "        0.0333, 0.0177, 0.0258, 0.0274, 0.0251, 0.0267, 0.0286, 0.0242, 0.0230,\n",
      "        0.0251, 0.0275, 0.0231, 0.0257, 0.0201], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0334, 0.0268], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0152,  0.0754, -0.0074],\n",
      "        [-0.0260,  0.0692, -0.0325],\n",
      "        [-0.0270,  0.1062, -0.0154],\n",
      "        [-0.0198,  0.0588, -0.0072],\n",
      "        [-0.0260,  0.0660, -0.0362],\n",
      "        [-0.0123,  0.1158, -0.0301],\n",
      "        [-0.0180,  0.0758, -0.0181],\n",
      "        [-0.0178,  0.1281, -0.0234],\n",
      "        [-0.0131,  0.0697, -0.0096],\n",
      "        [-0.0289,  0.0478, -0.0201],\n",
      "        [-0.0201,  0.0769, -0.0270],\n",
      "        [-0.0308,  0.0807, -0.0211],\n",
      "        [-0.0273,  0.0633, -0.0094],\n",
      "        [ 0.0172,  0.1139, -0.0167],\n",
      "        [-0.0349,  0.0794, -0.0229],\n",
      "        [-0.0176,  0.1051, -0.0210],\n",
      "        [-0.0314,  0.1240, -0.0230],\n",
      "        [-0.0022,  0.1093, -0.0220],\n",
      "        [-0.0387,  0.1053, -0.0141],\n",
      "        [-0.0025,  0.0762, -0.0151],\n",
      "        [-0.0252,  0.1123, -0.0014],\n",
      "        [-0.0129,  0.1142, -0.0255],\n",
      "        [-0.0213,  0.0912, -0.0091],\n",
      "        [-0.0271,  0.0960, -0.0232],\n",
      "        [-0.0429,  0.0947, -0.0031],\n",
      "        [-0.0001,  0.1020, -0.0189],\n",
      "        [-0.0034,  0.0626, -0.0015],\n",
      "        [-0.0319,  0.0688, -0.0154],\n",
      "        [-0.0030,  0.0860, -0.0233],\n",
      "        [-0.0239,  0.0910, -0.0024],\n",
      "        [-0.0345,  0.0653, -0.0062],\n",
      "        [-0.0124,  0.0430, -0.0221]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.4018, 1.3443, 2.1361, 0.8470, 1.2961, 1.2750, 0.9231, 2.0305, 1.2373,\n",
      "         1.0471, 1.2411, 1.4169, 1.6196, 1.6153, 1.6542, 1.9001, 2.0916, 1.8590,\n",
      "         2.2158, 1.1524, 1.7094, 1.7485, 1.7876, 1.7305, 1.9492, 1.6028, 1.4781,\n",
      "         1.7051, 1.7939, 1.5634, 1.7532, 1.3903],\n",
      "        [1.1470, 1.0707, 1.6645, 0.7227, 1.0977, 1.1302, 0.8221, 1.6565, 0.9936,\n",
      "         0.8140, 1.2055, 1.1222, 1.2237, 1.3499, 1.2961, 1.5885, 1.6126, 1.4354,\n",
      "         1.8325, 0.9486, 1.3769, 1.4328, 1.3148, 1.4096, 1.4003, 1.2794, 1.1842,\n",
      "         1.3911, 1.3881, 1.2103, 1.3325, 1.0057]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0214, 0.0207, 0.0324, 0.0130, 0.0213, 0.0204, 0.0136, 0.0321, 0.0196,\n",
      "        0.0154, 0.0215, 0.0224, 0.0235, 0.0268, 0.0239, 0.0295, 0.0323, 0.0288,\n",
      "        0.0339, 0.0181, 0.0263, 0.0279, 0.0256, 0.0272, 0.0292, 0.0246, 0.0235,\n",
      "        0.0256, 0.0280, 0.0236, 0.0262, 0.0206], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0340, 0.0273], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0008,  0.1165, -0.0191],\n",
      "        [-0.0257,  0.0965, -0.0152],\n",
      "        [-0.0051,  0.2037, -0.0302],\n",
      "        [ 0.0135,  0.0521, -0.0282],\n",
      "        [ 0.0127,  0.1282, -0.0164],\n",
      "        [-0.0180,  0.1029, -0.0264],\n",
      "        [ 0.0006,  0.0680, -0.0376],\n",
      "        [-0.0093,  0.1891, -0.0310],\n",
      "        [ 0.0076,  0.1057, -0.0169],\n",
      "        [ 0.0215,  0.0507, -0.0059],\n",
      "        [ 0.0033,  0.1277, -0.0298],\n",
      "        [ 0.0017,  0.1312, -0.0408],\n",
      "        [-0.0117,  0.1342,  0.0027],\n",
      "        [ 0.0034,  0.1645,  0.0021],\n",
      "        [ 0.0180,  0.1426, -0.0239],\n",
      "        [ 0.0036,  0.1750, -0.0070],\n",
      "        [ 0.0082,  0.1850, -0.0305],\n",
      "        [ 0.0054,  0.1402, -0.0199],\n",
      "        [-0.0028,  0.1943,  0.0031],\n",
      "        [-0.0138,  0.1263, -0.0103],\n",
      "        [-0.0231,  0.1582, -0.0124],\n",
      "        [-0.0052,  0.1549, -0.0119],\n",
      "        [-0.0019,  0.1180, -0.0300],\n",
      "        [-0.0114,  0.1868, -0.0140],\n",
      "        [-0.0077,  0.1505, -0.0114],\n",
      "        [-0.0059,  0.1438, -0.0196],\n",
      "        [-0.0003,  0.1606,  0.0065],\n",
      "        [-0.0045,  0.1654, -0.0280],\n",
      "        [-0.0010,  0.1698, -0.0131],\n",
      "        [ 0.0066,  0.1505, -0.0196],\n",
      "        [-0.0112,  0.1779,  0.0043],\n",
      "        [-0.0108,  0.1079, -0.0133]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.4596, 1.4017, 2.2235, 0.8809, 1.3497, 1.3281, 0.9560, 2.1169, 1.2857,\n",
      "         1.0861, 1.2900, 1.4752, 1.6857, 1.6829, 1.7219, 1.9801, 2.1786, 1.9366,\n",
      "         2.3074, 1.1956, 1.7795, 1.8229, 1.8663, 1.8003, 2.0287, 1.6719, 1.5364,\n",
      "         1.7748, 1.8672, 1.6275, 1.8240, 1.4454],\n",
      "        [1.1960, 1.1162, 1.7341, 0.7527, 1.1444, 1.1768, 0.8534, 1.7272, 1.0326,\n",
      "         0.8442, 1.2554, 1.1696, 1.2748, 1.4070, 1.3512, 1.6550, 1.6805, 1.4965,\n",
      "         1.9087, 0.9870, 1.4351, 1.4936, 1.3751, 1.4685, 1.4592, 1.3349, 1.2330,\n",
      "         1.4487, 1.4464, 1.2609, 1.3877, 1.0475]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0218, 0.0212, 0.0330, 0.0133, 0.0218, 0.0209, 0.0138, 0.0328, 0.0199,\n",
      "        0.0156, 0.0219, 0.0229, 0.0240, 0.0274, 0.0245, 0.0301, 0.0329, 0.0294,\n",
      "        0.0346, 0.0184, 0.0269, 0.0285, 0.0263, 0.0277, 0.0298, 0.0252, 0.0239,\n",
      "        0.0261, 0.0286, 0.0241, 0.0267, 0.0210], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0347, 0.0278], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 3.3625e-03,  8.9413e-02,  1.0336e-02],\n",
      "        [-7.9279e-03,  8.8741e-02, -2.2836e-02],\n",
      "        [ 9.0599e-03,  1.9480e-01, -1.2147e-02],\n",
      "        [-1.0321e-03,  1.3011e-01, -3.7263e-03],\n",
      "        [-6.2929e-03,  1.2079e-01, -5.1332e-03],\n",
      "        [-1.6773e-02,  8.7782e-02, -2.0612e-02],\n",
      "        [-4.5733e-03,  3.0044e-02,  6.4619e-03],\n",
      "        [-2.2939e-02,  1.6008e-01,  3.6979e-03],\n",
      "        [-2.9987e-03,  1.1942e-01,  7.3534e-03],\n",
      "        [-1.4031e-02,  9.7650e-02,  2.1404e-02],\n",
      "        [-4.2065e-03,  1.3284e-01, -1.9463e-02],\n",
      "        [-1.5799e-02,  1.6589e-01, -1.0675e-02],\n",
      "        [-6.4546e-03,  1.1293e-01, -3.7365e-03],\n",
      "        [-1.6895e-02,  1.3001e-01,  3.0973e-03],\n",
      "        [-3.3886e-03,  1.6555e-01, -5.6435e-03],\n",
      "        [-5.0249e-03,  1.4720e-01, -1.7023e-02],\n",
      "        [-4.2641e-03,  1.5650e-01,  2.5917e-03],\n",
      "        [-4.2354e-03,  1.6589e-01, -8.9853e-03],\n",
      "        [-1.9244e-02,  1.8915e-01, -1.3168e-02],\n",
      "        [-9.5889e-03,  6.4235e-02,  8.7276e-03],\n",
      "        [-6.1071e-06,  1.4875e-01, -2.1174e-02],\n",
      "        [ 2.8716e-03,  1.2492e-01, -1.3266e-02],\n",
      "        [-1.7152e-04,  1.4714e-01, -1.5535e-02],\n",
      "        [-1.9185e-02,  1.4341e-01, -5.8429e-03],\n",
      "        [-1.4886e-02,  1.9050e-01, -4.2385e-03],\n",
      "        [ 2.2828e-02,  8.1034e-02, -9.8951e-03],\n",
      "        [-1.0269e-02,  1.4802e-01, -1.2758e-02],\n",
      "        [-3.9055e-03,  1.4686e-01, -4.4273e-03],\n",
      "        [ 3.5497e-04,  1.3457e-01, -1.2545e-02],\n",
      "        [-1.0344e-02,  1.2905e-01,  1.1736e-02],\n",
      "        [ 6.3321e-03,  1.2724e-01, -1.6269e-02],\n",
      "        [-1.1435e-02,  8.2025e-02,  8.8124e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.5194, 1.4567, 2.3136, 0.9166, 1.4048, 1.3805, 0.9944, 2.2033, 1.3390,\n",
      "         1.1336, 1.3438, 1.5357, 1.7557, 1.7528, 1.7920, 2.0604, 2.2666, 2.0149,\n",
      "         2.4018, 1.2451, 1.8530, 1.8991, 1.9398, 1.8738, 2.1117, 1.7392, 1.6016,\n",
      "         1.8470, 1.9439, 1.6940, 1.8999, 1.5034],\n",
      "        [1.2451, 1.1620, 1.8054, 0.7845, 1.1918, 1.2259, 0.8889, 1.7996, 1.0768,\n",
      "         0.8828, 1.3081, 1.2185, 1.3297, 1.4663, 1.4064, 1.7234, 1.7500, 1.5579,\n",
      "         1.9878, 1.0279, 1.4947, 1.5557, 1.4283, 1.5300, 1.5206, 1.3897, 1.2863,\n",
      "         1.5088, 1.5070, 1.3133, 1.4465, 1.0913]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0222, 0.0216, 0.0337, 0.0136, 0.0222, 0.0213, 0.0141, 0.0335, 0.0204,\n",
      "        0.0160, 0.0224, 0.0233, 0.0245, 0.0280, 0.0249, 0.0307, 0.0336, 0.0299,\n",
      "        0.0353, 0.0188, 0.0274, 0.0291, 0.0267, 0.0283, 0.0304, 0.0257, 0.0245,\n",
      "        0.0266, 0.0292, 0.0246, 0.0273, 0.0214], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0353, 0.0284], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-1.1037e-02,  8.1819e-02,  4.6072e-03],\n",
      "        [-7.0951e-03,  9.0142e-02,  2.5923e-02],\n",
      "        [-1.2947e-03,  1.3407e-01,  1.9125e-02],\n",
      "        [ 1.2631e-02,  3.2314e-02, -2.8767e-04],\n",
      "        [-9.4179e-03,  7.3912e-02,  1.7483e-02],\n",
      "        [ 1.9399e-02,  9.1589e-02,  1.5850e-02],\n",
      "        [ 1.8515e-02,  8.4839e-02,  6.5991e-03],\n",
      "        [-1.4728e-02,  7.3559e-02,  1.3839e-03],\n",
      "        [ 1.6143e-02,  5.9577e-02, -4.1572e-03],\n",
      "        [-1.1940e-02,  5.6579e-02, -9.3386e-03],\n",
      "        [-1.1212e-02,  5.7303e-02,  2.1867e-02],\n",
      "        [-6.2070e-03,  5.8854e-02,  1.5713e-02],\n",
      "        [-2.2838e-02,  8.6828e-02,  1.9049e-02],\n",
      "        [-2.5054e-02,  7.4913e-02, -1.4423e-02],\n",
      "        [ 4.0099e-03,  1.1127e-01,  1.3285e-02],\n",
      "        [ 4.8860e-03,  7.7099e-02, -3.0268e-05],\n",
      "        [-1.5306e-02,  1.1427e-01,  1.5420e-02],\n",
      "        [-1.2610e-02,  9.8150e-02, -9.9212e-03],\n",
      "        [-2.4039e-02,  1.2714e-01,  1.6758e-02],\n",
      "        [-9.9226e-03,  5.7773e-02,  1.7271e-03],\n",
      "        [-1.7179e-02,  1.0331e-01,  1.1250e-02],\n",
      "        [-1.1877e-03,  1.0583e-01,  1.0421e-04],\n",
      "        [-4.9950e-03,  1.1775e-01, -5.0844e-03],\n",
      "        [-1.2777e-02,  7.5867e-02,  3.1531e-02],\n",
      "        [-1.5389e-02,  1.0281e-01,  1.0331e-02],\n",
      "        [-1.0772e-02,  1.0997e-01, -1.1307e-02],\n",
      "        [-2.4944e-02,  8.0772e-02,  2.2075e-03],\n",
      "        [ 2.6696e-03,  5.4233e-02,  4.9213e-03],\n",
      "        [ 1.1451e-02,  7.8492e-02,  3.0363e-03],\n",
      "        [ 8.3685e-03,  6.3445e-02, -1.2128e-02],\n",
      "        [-2.0340e-02,  8.3537e-02,  2.2338e-02],\n",
      "        [-1.2906e-02,  7.3504e-02,  6.0127e-03]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.5811, 1.5171, 2.4062, 0.9551, 1.4618, 1.4385, 1.0396, 2.2916, 1.3933,\n",
      "         1.1796, 1.3981, 1.5985, 1.8251, 1.8235, 1.8653, 2.1431, 2.3582, 2.0971,\n",
      "         2.4967, 1.2974, 1.9279, 1.9724, 2.0145, 1.9499, 2.1979, 1.8067, 1.6664,\n",
      "         1.9222, 2.0223, 1.7633, 1.9752, 1.5659],\n",
      "        [1.2965, 1.2110, 1.8790, 0.8162, 1.2414, 1.2769, 0.9287, 1.8724, 1.1208,\n",
      "         0.9202, 1.3619, 1.2696, 1.3832, 1.5261, 1.4653, 1.7943, 1.8229, 1.6241,\n",
      "         2.0685, 1.0714, 1.5567, 1.6190, 1.4851, 1.5934, 1.5842, 1.4441, 1.3395,\n",
      "         1.5713, 1.5700, 1.3680, 1.5052, 1.1365]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0227, 0.0220, 0.0343, 0.0139, 0.0227, 0.0217, 0.0145, 0.0341, 0.0208,\n",
      "        0.0163, 0.0229, 0.0238, 0.0249, 0.0285, 0.0255, 0.0312, 0.0342, 0.0305,\n",
      "        0.0360, 0.0193, 0.0280, 0.0295, 0.0271, 0.0288, 0.0310, 0.0261, 0.0249,\n",
      "        0.0272, 0.0297, 0.0251, 0.0278, 0.0219], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0360, 0.0290], grad_fn=<MeanBackward1>)\n",
      "Epoch 8/10, Accuracy: 0.4812\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0163,  0.1832,  0.0271],\n",
      "        [ 0.0152,  0.1216,  0.0209],\n",
      "        [ 0.0454,  0.2229,  0.0300],\n",
      "        [ 0.0119,  0.1204,  0.0215],\n",
      "        [ 0.0191,  0.1470,  0.0226],\n",
      "        [ 0.0528,  0.1271,  0.0318],\n",
      "        [ 0.0188,  0.0888,  0.0058],\n",
      "        [ 0.0348,  0.2118,  0.0486],\n",
      "        [ 0.0394,  0.1257,  0.0326],\n",
      "        [ 0.0145,  0.1070,  0.0163],\n",
      "        [ 0.0280,  0.1356,  0.0070],\n",
      "        [ 0.0105,  0.1374,  0.0033],\n",
      "        [ 0.0350,  0.1534,  0.0169],\n",
      "        [ 0.0404,  0.1824,  0.0379],\n",
      "        [ 0.0118,  0.1954,  0.0196],\n",
      "        [ 0.0277,  0.1961,  0.0272],\n",
      "        [ 0.0210,  0.2269,  0.0358],\n",
      "        [ 0.0176,  0.2066,  0.0305],\n",
      "        [ 0.0357,  0.2144,  0.0311],\n",
      "        [ 0.0133,  0.1320,  0.0153],\n",
      "        [ 0.0442,  0.1520,  0.0182],\n",
      "        [ 0.0224,  0.1527,  0.0387],\n",
      "        [ 0.0314,  0.1439,  0.0149],\n",
      "        [ 0.0308,  0.1575,  0.0138],\n",
      "        [ 0.0250,  0.2084,  0.0202],\n",
      "        [ 0.0199,  0.1788,  0.0129],\n",
      "        [ 0.0308,  0.1257, -0.0170],\n",
      "        [ 0.0275,  0.1767,  0.0431],\n",
      "        [ 0.0157,  0.1737,  0.0276],\n",
      "        [ 0.0520,  0.1179,  0.0367],\n",
      "        [ 0.0409,  0.1731,  0.0212],\n",
      "        [ 0.0201,  0.1621,  0.0449]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.6454, 1.5785, 2.5043, 0.9916, 1.5213, 1.4965, 1.0773, 2.3846, 1.4485,\n",
      "         1.2257, 1.4542, 1.6642, 1.9020, 1.8984, 1.9397, 2.2306, 2.4547, 2.1819,\n",
      "         2.6010, 1.3481, 2.0072, 2.0567, 2.1018, 2.0304, 2.2876, 1.8820, 1.7368,\n",
      "         2.0005, 2.1054, 1.8354, 2.0568, 1.6284],\n",
      "        [1.3504, 1.2613, 1.9577, 0.8493, 1.2934, 1.3289, 0.9634, 1.9507, 1.1655,\n",
      "         0.9541, 1.4179, 1.3229, 1.4433, 1.5911, 1.5255, 1.8686, 1.8989, 1.6916,\n",
      "         2.1566, 1.1154, 1.6222, 1.6894, 1.5527, 1.6613, 1.6507, 1.5056, 1.3977,\n",
      "         1.6365, 1.6362, 1.4249, 1.5690, 1.1839]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0231, 0.0225, 0.0350, 0.0141, 0.0231, 0.0222, 0.0147, 0.0347, 0.0212,\n",
      "        0.0166, 0.0233, 0.0243, 0.0255, 0.0291, 0.0259, 0.0319, 0.0349, 0.0311,\n",
      "        0.0367, 0.0196, 0.0285, 0.0302, 0.0278, 0.0295, 0.0316, 0.0267, 0.0255,\n",
      "        0.0277, 0.0303, 0.0256, 0.0284, 0.0223], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0366, 0.0295], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0414,  0.0931,  0.0089],\n",
      "        [-0.0137,  0.0948, -0.0045],\n",
      "        [-0.0505,  0.1501,  0.0113],\n",
      "        [-0.0388,  0.0833,  0.0093],\n",
      "        [-0.0269,  0.1177,  0.0117],\n",
      "        [-0.0249,  0.0701,  0.0138],\n",
      "        [-0.0154,  0.0559,  0.0181],\n",
      "        [-0.0473,  0.1934,  0.0289],\n",
      "        [-0.0283,  0.1110,  0.0164],\n",
      "        [-0.0256,  0.0693,  0.0035],\n",
      "        [-0.0160,  0.1391,  0.0200],\n",
      "        [-0.0389,  0.1317,  0.0118],\n",
      "        [-0.0245,  0.1387,  0.0008],\n",
      "        [-0.0315,  0.1882,  0.0280],\n",
      "        [-0.0428,  0.1287,  0.0075],\n",
      "        [-0.0491,  0.1366,  0.0112],\n",
      "        [-0.0425,  0.2069,  0.0291],\n",
      "        [-0.0281,  0.1818,  0.0234],\n",
      "        [-0.0504,  0.1911,  0.0072],\n",
      "        [-0.0224,  0.0735,  0.0003],\n",
      "        [-0.0335,  0.1182, -0.0039],\n",
      "        [-0.0326,  0.1501,  0.0181],\n",
      "        [-0.0286,  0.1330,  0.0110],\n",
      "        [-0.0306,  0.1678,  0.0073],\n",
      "        [-0.0394,  0.1801,  0.0013],\n",
      "        [-0.0332,  0.1192,  0.0124],\n",
      "        [-0.0118,  0.1172, -0.0071],\n",
      "        [-0.0490,  0.1499,  0.0115],\n",
      "        [-0.0478,  0.1377,  0.0148],\n",
      "        [-0.0379,  0.1050,  0.0173],\n",
      "        [-0.0349,  0.1421, -0.0045],\n",
      "        [-0.0091,  0.1199,  0.0170]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.7131, 1.6413, 2.6062, 1.0332, 1.5844, 1.5581, 1.1230, 2.4790, 1.5092,\n",
      "         1.2754, 1.5169, 1.7322, 1.9785, 1.9737, 2.0196, 2.3216, 2.5519, 2.2678,\n",
      "         2.7049, 1.4072, 2.0883, 2.1356, 2.1860, 2.1139, 2.3808, 1.9609, 1.8109,\n",
      "         2.0815, 2.1902, 1.9103, 2.1397, 1.6980],\n",
      "        [1.4066, 1.3133, 2.0386, 0.8852, 1.3479, 1.3854, 1.0045, 2.0310, 1.2163,\n",
      "         0.9946, 1.4780, 1.3780, 1.5030, 1.6563, 1.5893, 1.9456, 1.9766, 1.7594,\n",
      "         2.2441, 1.1633, 1.6887, 1.7560, 1.6146, 1.7305, 1.7195, 1.5700, 1.4574,\n",
      "         1.7038, 1.7032, 1.4841, 1.6338, 1.2349]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0236, 0.0229, 0.0357, 0.0144, 0.0236, 0.0226, 0.0150, 0.0354, 0.0217,\n",
      "        0.0170, 0.0238, 0.0248, 0.0260, 0.0296, 0.0265, 0.0325, 0.0356, 0.0316,\n",
      "        0.0374, 0.0201, 0.0291, 0.0307, 0.0283, 0.0301, 0.0322, 0.0273, 0.0261,\n",
      "        0.0283, 0.0309, 0.0261, 0.0289, 0.0228], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0373, 0.0301], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0115,  0.0909,  0.0264],\n",
      "        [-0.0089,  0.1153,  0.0375],\n",
      "        [-0.0004,  0.1325,  0.0334],\n",
      "        [ 0.0217,  0.0290, -0.0040],\n",
      "        [ 0.0169,  0.0838,  0.0045],\n",
      "        [-0.0200,  0.1033,  0.0151],\n",
      "        [ 0.0050,  0.0490,  0.0095],\n",
      "        [-0.0056,  0.0927,  0.0293],\n",
      "        [ 0.0058,  0.1013, -0.0039],\n",
      "        [ 0.0088,  0.0302, -0.0050],\n",
      "        [-0.0112,  0.1021,  0.0297],\n",
      "        [ 0.0135,  0.0816,  0.0130],\n",
      "        [-0.0019,  0.0620,  0.0400],\n",
      "        [ 0.0041,  0.0937,  0.0252],\n",
      "        [-0.0033,  0.0877,  0.0122],\n",
      "        [-0.0042,  0.0689,  0.0179],\n",
      "        [ 0.0124,  0.1377,  0.0302],\n",
      "        [-0.0006,  0.1114,  0.0205],\n",
      "        [ 0.0133,  0.0968,  0.0373],\n",
      "        [-0.0113,  0.0568,  0.0015],\n",
      "        [ 0.0157,  0.1356,  0.0257],\n",
      "        [ 0.0029,  0.1171,  0.0242],\n",
      "        [-0.0064,  0.1087,  0.0486],\n",
      "        [ 0.0048,  0.0884,  0.0276],\n",
      "        [ 0.0280,  0.0838,  0.0209],\n",
      "        [ 0.0039,  0.1340,  0.0403],\n",
      "        [ 0.0021,  0.0925,  0.0292],\n",
      "        [ 0.0016,  0.0895,  0.0348],\n",
      "        [ 0.0038,  0.0860,  0.0391],\n",
      "        [ 0.0127,  0.0458,  0.0112],\n",
      "        [ 0.0194,  0.0988,  0.0383],\n",
      "        [ 0.0004,  0.0859,  0.0123]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.7821, 1.7093, 2.7102, 1.0750, 1.6480, 1.6206, 1.1702, 2.5815, 1.5705,\n",
      "         1.3290, 1.5793, 1.8031, 2.0575, 2.0543, 2.1014, 2.4136, 2.6561, 2.3625,\n",
      "         2.8140, 1.4618, 2.1727, 2.2224, 2.2704, 2.1994, 2.4777, 2.0380, 1.8811,\n",
      "         2.1661, 2.2793, 1.9879, 2.2255, 1.7645],\n",
      "        [1.4649, 1.3679, 2.1211, 0.9231, 1.4038, 1.4411, 1.0475, 2.1147, 1.2667,\n",
      "         1.0357, 1.5395, 1.4355, 1.5635, 1.7249, 1.6553, 2.0251, 2.0584, 1.8325,\n",
      "         2.3357, 1.2110, 1.7582, 1.8273, 1.6780, 1.8022, 1.7910, 1.6336, 1.5168,\n",
      "         1.7738, 1.7739, 1.5456, 1.7004, 1.2863]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0240, 0.0234, 0.0363, 0.0148, 0.0241, 0.0231, 0.0154, 0.0361, 0.0222,\n",
      "        0.0174, 0.0243, 0.0253, 0.0265, 0.0302, 0.0270, 0.0331, 0.0363, 0.0323,\n",
      "        0.0382, 0.0204, 0.0296, 0.0313, 0.0287, 0.0307, 0.0329, 0.0278, 0.0265,\n",
      "        0.0288, 0.0315, 0.0266, 0.0295, 0.0233], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0380, 0.0307], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 3.7626e-02,  9.0262e-02, -1.2733e-02],\n",
      "        [ 3.6729e-02,  1.3368e-01, -3.0804e-03],\n",
      "        [ 5.1828e-02,  1.6693e-01, -1.9505e-02],\n",
      "        [ 4.0678e-02,  5.6936e-02, -1.5437e-02],\n",
      "        [ 2.1277e-02,  1.3911e-01, -2.4040e-02],\n",
      "        [ 5.3766e-02,  1.4446e-01, -1.7639e-02],\n",
      "        [ 1.8614e-02,  1.0858e-01,  3.2334e-03],\n",
      "        [ 8.2366e-02,  1.6912e-01,  1.3735e-02],\n",
      "        [ 5.7673e-02,  1.1020e-01, -5.4720e-02],\n",
      "        [ 1.3609e-02,  8.0041e-02, -1.2245e-03],\n",
      "        [ 4.2539e-02,  9.5945e-02, -4.7467e-03],\n",
      "        [ 4.0374e-02,  1.0556e-01,  2.0279e-02],\n",
      "        [ 4.9670e-02,  1.3323e-01, -7.5479e-05],\n",
      "        [ 6.7654e-02,  1.4064e-01, -2.3667e-02],\n",
      "        [ 4.3622e-02,  1.6113e-01, -2.6710e-02],\n",
      "        [ 7.2935e-02,  1.7109e-01, -1.9898e-02],\n",
      "        [ 6.0090e-02,  1.7181e-01, -3.6982e-03],\n",
      "        [ 6.9684e-02,  1.5422e-01, -1.2633e-02],\n",
      "        [ 6.4631e-02,  2.0806e-01, -1.0990e-02],\n",
      "        [ 2.4580e-02,  1.0066e-01, -1.2049e-03],\n",
      "        [ 4.6877e-02,  1.5834e-01, -2.7174e-02],\n",
      "        [ 4.8261e-02,  1.8265e-01, -1.0848e-02],\n",
      "        [ 6.2998e-02,  1.3882e-01,  6.0236e-03],\n",
      "        [ 4.6667e-02,  1.5853e-01,  1.5528e-03],\n",
      "        [ 7.1788e-02,  1.5296e-01, -5.1570e-03],\n",
      "        [ 7.6542e-02,  1.2622e-01,  1.1795e-02],\n",
      "        [ 2.8285e-02,  1.5393e-01, -1.5323e-02],\n",
      "        [ 7.7532e-02,  1.1386e-01,  6.0758e-03],\n",
      "        [ 7.0322e-02,  1.3341e-01, -9.3074e-03],\n",
      "        [ 4.0564e-02,  1.2821e-01, -9.9093e-03],\n",
      "        [ 4.6685e-02,  1.3275e-01, -2.9645e-02],\n",
      "        [ 5.2206e-02,  1.4020e-01, -2.2696e-02]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.8541, 1.7801, 2.8205, 1.1173, 1.7134, 1.6875, 1.2155, 2.6856, 1.6318,\n",
      "         1.3858, 1.6388, 1.8761, 2.1403, 2.1397, 2.1861, 2.5122, 2.7646, 2.4573,\n",
      "         2.9280, 1.5177, 2.2610, 2.3132, 2.3653, 2.2864, 2.5783, 2.1244, 1.9530,\n",
      "         2.2544, 2.3719, 2.0688, 2.3163, 1.8352],\n",
      "        [1.5245, 1.4258, 2.2090, 0.9580, 1.4604, 1.5007, 1.0889, 2.2021, 1.3167,\n",
      "         1.0818, 1.6007, 1.4948, 1.6282, 1.7966, 1.7224, 2.1085, 2.1445, 1.9093,\n",
      "         2.4320, 1.2572, 1.8312, 1.9042, 1.7519, 1.8746, 1.8653, 1.7040, 1.5750,\n",
      "         1.8473, 1.8477, 1.6092, 1.7715, 1.3384]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0245, 0.0239, 0.0371, 0.0150, 0.0245, 0.0236, 0.0157, 0.0368, 0.0226,\n",
      "        0.0178, 0.0247, 0.0258, 0.0270, 0.0308, 0.0275, 0.0338, 0.0370, 0.0329,\n",
      "        0.0389, 0.0208, 0.0302, 0.0319, 0.0294, 0.0312, 0.0335, 0.0285, 0.0269,\n",
      "        0.0294, 0.0321, 0.0272, 0.0301, 0.0237], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0387, 0.0313], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0098,  0.0693, -0.0159],\n",
      "        [-0.0135,  0.1234, -0.0478],\n",
      "        [-0.0360,  0.1750, -0.0402],\n",
      "        [-0.0285,  0.0414, -0.0311],\n",
      "        [-0.0384,  0.1180, -0.0320],\n",
      "        [-0.0030,  0.1079, -0.0376],\n",
      "        [-0.0003,  0.0940, -0.0215],\n",
      "        [-0.0208,  0.1692, -0.0199],\n",
      "        [-0.0100,  0.0822, -0.0116],\n",
      "        [-0.0142,  0.0755,  0.0063],\n",
      "        [-0.0440,  0.0922, -0.0378],\n",
      "        [-0.0381,  0.1401, -0.0224],\n",
      "        [-0.0226,  0.1513, -0.0258],\n",
      "        [-0.0189,  0.1371, -0.0151],\n",
      "        [-0.0178,  0.1659, -0.0315],\n",
      "        [-0.0490,  0.1601, -0.0567],\n",
      "        [-0.0261,  0.2002, -0.0278],\n",
      "        [-0.0438,  0.1697, -0.0238],\n",
      "        [-0.0236,  0.1966, -0.0339],\n",
      "        [-0.0173,  0.0922, -0.0098],\n",
      "        [-0.0125,  0.1432, -0.0358],\n",
      "        [-0.0263,  0.1675, -0.0284],\n",
      "        [-0.0236,  0.1861, -0.0428],\n",
      "        [-0.0275,  0.1558, -0.0210],\n",
      "        [-0.0014,  0.1662, -0.0213],\n",
      "        [-0.0048,  0.1509, -0.0426],\n",
      "        [-0.0288,  0.1394,  0.0013],\n",
      "        [-0.0115,  0.1409, -0.0512],\n",
      "        [-0.0428,  0.1388, -0.0403],\n",
      "        [-0.0200,  0.1313, -0.0307],\n",
      "        [-0.0139,  0.1517, -0.0486],\n",
      "        [-0.0151,  0.1220, -0.0260]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[1.9308, 1.8513, 2.9349, 1.1642, 1.7848, 1.7564, 1.2647, 2.7944, 1.6993,\n",
      "         1.4392, 1.7051, 1.9529, 2.2282, 2.2285, 2.2757, 2.6150, 2.8753, 2.5552,\n",
      "         3.0469, 1.5826, 2.3522, 2.4066, 2.4604, 2.3796, 2.6830, 2.2102, 2.0346,\n",
      "         2.3459, 2.4681, 2.1535, 2.4103, 1.9113],\n",
      "        [1.5876, 1.4844, 2.2992, 1.0006, 1.5222, 1.5641, 1.1360, 2.2916, 1.3753,\n",
      "         1.1261, 1.6670, 1.5570, 1.6953, 1.8708, 1.7942, 2.1949, 2.2315, 1.9851,\n",
      "         2.5314, 1.3119, 1.9053, 1.9802, 1.8196, 1.9527, 1.9426, 1.7731, 1.6415,\n",
      "         1.9228, 1.9236, 1.6762, 1.8439, 1.3956]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0250, 0.0243, 0.0378, 0.0154, 0.0250, 0.0241, 0.0160, 0.0375, 0.0231,\n",
      "        0.0181, 0.0252, 0.0263, 0.0275, 0.0315, 0.0281, 0.0344, 0.0377, 0.0335,\n",
      "        0.0397, 0.0213, 0.0308, 0.0325, 0.0299, 0.0319, 0.0342, 0.0290, 0.0275,\n",
      "        0.0300, 0.0328, 0.0277, 0.0307, 0.0243], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0395, 0.0319], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0257,  0.1640, -0.0194],\n",
      "        [-0.0459,  0.1270,  0.0077],\n",
      "        [-0.0378,  0.2680, -0.0225],\n",
      "        [ 0.0029,  0.1242,  0.0078],\n",
      "        [-0.0120,  0.1850,  0.0095],\n",
      "        [-0.0303,  0.1634,  0.0148],\n",
      "        [-0.0322,  0.0947,  0.0075],\n",
      "        [-0.0239,  0.2608,  0.0201],\n",
      "        [-0.0112,  0.1855, -0.0077],\n",
      "        [ 0.0046,  0.1143,  0.0101],\n",
      "        [-0.0255,  0.1739,  0.0150],\n",
      "        [-0.0104,  0.2108,  0.0015],\n",
      "        [-0.0446,  0.1395, -0.0053],\n",
      "        [-0.0157,  0.2367,  0.0201],\n",
      "        [-0.0079,  0.1897, -0.0094],\n",
      "        [-0.0206,  0.2371,  0.0056],\n",
      "        [-0.0263,  0.2925, -0.0127],\n",
      "        [-0.0248,  0.2404,  0.0013],\n",
      "        [-0.0398,  0.2181, -0.0059],\n",
      "        [-0.0102,  0.1764,  0.0181],\n",
      "        [-0.0449,  0.1983, -0.0233],\n",
      "        [-0.0442,  0.2271, -0.0047],\n",
      "        [-0.0478,  0.1738, -0.0141],\n",
      "        [-0.0348,  0.2294,  0.0041],\n",
      "        [-0.0087,  0.2220, -0.0126],\n",
      "        [-0.0197,  0.2052, -0.0217],\n",
      "        [-0.0150,  0.1678,  0.0078],\n",
      "        [-0.0198,  0.2089, -0.0073],\n",
      "        [-0.0302,  0.2446, -0.0054],\n",
      "        [-0.0067,  0.2050,  0.0068],\n",
      "        [-0.0413,  0.2097, -0.0270],\n",
      "        [-0.0316,  0.1719,  0.0156]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.0101, 1.9282, 3.0532, 1.2135, 1.8584, 1.8291, 1.3154, 2.9073, 1.7677,\n",
      "         1.4943, 1.7761, 2.0329, 2.3204, 2.3180, 2.3695, 2.7215, 2.9923, 2.6587,\n",
      "         3.1730, 1.6487, 2.4481, 2.5048, 2.5659, 2.4770, 2.7923, 2.2989, 2.1193,\n",
      "         2.4412, 2.5677, 2.2415, 2.5083, 1.9886],\n",
      "        [1.6544, 1.5463, 2.3940, 1.0414, 1.5864, 1.6275, 1.1805, 2.3857, 1.4289,\n",
      "         1.1677, 1.7367, 1.6220, 1.7674, 1.9483, 1.8696, 2.2857, 2.3246, 2.0685,\n",
      "         2.6378, 1.3684, 1.9852, 2.0643, 1.9010, 2.0347, 2.0233, 1.8443, 1.7128,\n",
      "         2.0021, 2.0033, 1.7456, 1.9209, 1.4538]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0255, 0.0249, 0.0385, 0.0158, 0.0256, 0.0246, 0.0163, 0.0382, 0.0235,\n",
      "        0.0184, 0.0258, 0.0268, 0.0281, 0.0321, 0.0287, 0.0352, 0.0385, 0.0342,\n",
      "        0.0405, 0.0218, 0.0314, 0.0332, 0.0307, 0.0326, 0.0349, 0.0295, 0.0281,\n",
      "        0.0306, 0.0334, 0.0283, 0.0313, 0.0248], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0402, 0.0325], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0409,  0.1510,  0.0086],\n",
      "        [ 0.0683,  0.1356,  0.0023],\n",
      "        [ 0.0454,  0.2403,  0.0052],\n",
      "        [ 0.0080,  0.1090,  0.0096],\n",
      "        [ 0.0372,  0.1647,  0.0066],\n",
      "        [ 0.0432,  0.1341, -0.0174],\n",
      "        [ 0.0251,  0.0826, -0.0125],\n",
      "        [ 0.0707,  0.2584,  0.0315],\n",
      "        [ 0.0132,  0.1515,  0.0181],\n",
      "        [ 0.0094,  0.0955,  0.0201],\n",
      "        [ 0.0512,  0.1401,  0.0096],\n",
      "        [ 0.0270,  0.1695,  0.0125],\n",
      "        [ 0.0476,  0.1973,  0.0053],\n",
      "        [ 0.0555,  0.1468,  0.0227],\n",
      "        [ 0.0307,  0.1622,  0.0061],\n",
      "        [ 0.0637,  0.2266,  0.0191],\n",
      "        [ 0.0605,  0.2152,  0.0101],\n",
      "        [ 0.0336,  0.2124,  0.0173],\n",
      "        [ 0.0622,  0.2483,  0.0059],\n",
      "        [ 0.0278,  0.1473,  0.0041],\n",
      "        [ 0.0621,  0.2042, -0.0130],\n",
      "        [ 0.0593,  0.1956, -0.0006],\n",
      "        [ 0.0435,  0.1794,  0.0178],\n",
      "        [ 0.0700,  0.1946, -0.0003],\n",
      "        [ 0.0465,  0.2146,  0.0060],\n",
      "        [ 0.0404,  0.1884,  0.0137],\n",
      "        [ 0.0415,  0.1760,  0.0221],\n",
      "        [ 0.0408,  0.2209,  0.0277],\n",
      "        [ 0.0547,  0.2003,  0.0265],\n",
      "        [ 0.0478,  0.2026,  0.0374],\n",
      "        [ 0.0647,  0.1602, -0.0163],\n",
      "        [ 0.0324,  0.1701,  0.0182]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.0901, 2.0044, 3.1760, 1.2569, 1.9321, 1.9002, 1.3680, 3.0243, 1.8385,\n",
      "         1.5608, 1.8486, 2.1155, 2.4134, 2.4131, 2.4631, 2.8303, 3.1139, 2.7677,\n",
      "         3.2996, 1.7129, 2.5480, 2.6080, 2.6659, 2.5780, 2.9059, 2.3934, 2.2032,\n",
      "         2.5402, 2.6725, 2.3321, 2.6107, 2.0668],\n",
      "        [1.7209, 1.6105, 2.4920, 1.0818, 1.6510, 1.6934, 1.2273, 2.4846, 1.4870,\n",
      "         1.2190, 1.8069, 1.6890, 1.8392, 2.0308, 1.9448, 2.3798, 2.4204, 2.1532,\n",
      "         2.7455, 1.4216, 2.0665, 2.1504, 1.9787, 2.1184, 2.1070, 1.9244, 1.7811,\n",
      "         2.0845, 2.0862, 1.8172, 2.0004, 1.5115]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0260, 0.0254, 0.0393, 0.0160, 0.0261, 0.0250, 0.0166, 0.0390, 0.0240,\n",
      "        0.0189, 0.0263, 0.0274, 0.0287, 0.0328, 0.0293, 0.0358, 0.0393, 0.0349,\n",
      "        0.0413, 0.0222, 0.0321, 0.0339, 0.0312, 0.0332, 0.0356, 0.0302, 0.0286,\n",
      "        0.0312, 0.0341, 0.0289, 0.0319, 0.0252], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0409, 0.0332], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0301,  0.1164,  0.0036],\n",
      "        [-0.0269,  0.0865,  0.0073],\n",
      "        [-0.0204,  0.1167,  0.0228],\n",
      "        [-0.0206,  0.0120, -0.0134],\n",
      "        [ 0.0049,  0.0686, -0.0098],\n",
      "        [-0.0327,  0.0456,  0.0185],\n",
      "        [-0.0178,  0.0481, -0.0317],\n",
      "        [-0.0232,  0.1550,  0.0167],\n",
      "        [ 0.0093,  0.0310,  0.0157],\n",
      "        [-0.0318,  0.0580,  0.0142],\n",
      "        [-0.0311,  0.0434, -0.0036],\n",
      "        [-0.0239,  0.0685,  0.0266],\n",
      "        [-0.0244,  0.1194, -0.0034],\n",
      "        [-0.0176,  0.0956,  0.0374],\n",
      "        [-0.0031,  0.1001,  0.0075],\n",
      "        [-0.0272,  0.1395,  0.0101],\n",
      "        [ 0.0006,  0.1512,  0.0139],\n",
      "        [ 0.0032,  0.1259,  0.0322],\n",
      "        [-0.0409,  0.1707,  0.0098],\n",
      "        [-0.0271,  0.0920,  0.0186],\n",
      "        [-0.0363,  0.0999,  0.0086],\n",
      "        [-0.0061,  0.1406,  0.0060],\n",
      "        [-0.0107,  0.1438,  0.0039],\n",
      "        [-0.0288,  0.0873,  0.0141],\n",
      "        [-0.0246,  0.1389,  0.0151],\n",
      "        [-0.0137,  0.1674,  0.0169],\n",
      "        [-0.0395,  0.0973,  0.0066],\n",
      "        [ 0.0054,  0.1240,  0.0215],\n",
      "        [ 0.0023,  0.1330,  0.0221],\n",
      "        [ 0.0147,  0.0869, -0.0093],\n",
      "        [-0.0261,  0.1179,  0.0147],\n",
      "        [ 0.0089,  0.1077,  0.0190]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.1757, 2.0860, 3.3046, 1.3106, 2.0125, 1.9794, 1.4250, 3.1456, 1.9116,\n",
      "         1.6223, 1.9254, 2.2017, 2.5130, 2.5102, 2.5651, 2.9442, 3.2399, 2.8782,\n",
      "         3.4312, 1.7846, 2.6507, 2.7114, 2.7713, 2.6831, 3.0239, 2.4891, 2.2961,\n",
      "         2.6430, 2.7798, 2.4273, 2.7146, 2.1543],\n",
      "        [1.7918, 1.6764, 2.5933, 1.1275, 1.7203, 1.7646, 1.2808, 2.5849, 1.5490,\n",
      "         1.2700, 1.8829, 1.7589, 1.9147, 2.1128, 2.0261, 2.4760, 2.5189, 2.2402,\n",
      "         2.8562, 1.4829, 2.1509, 2.2364, 2.0557, 2.2057, 2.1940, 1.9986, 1.8567,\n",
      "         2.1695, 2.1714, 1.8923, 2.0807, 1.5772]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0265, 0.0259, 0.0400, 0.0164, 0.0266, 0.0256, 0.0170, 0.0397, 0.0245,\n",
      "        0.0193, 0.0269, 0.0279, 0.0292, 0.0334, 0.0299, 0.0365, 0.0400, 0.0355,\n",
      "        0.0421, 0.0227, 0.0327, 0.0345, 0.0317, 0.0339, 0.0363, 0.0307, 0.0293,\n",
      "        0.0319, 0.0347, 0.0295, 0.0325, 0.0258], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0417, 0.0338], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0249,  0.2139, -0.0594],\n",
      "        [ 0.0364,  0.2048, -0.0394],\n",
      "        [ 0.0259,  0.3061, -0.0726],\n",
      "        [-0.0036,  0.1408, -0.0501],\n",
      "        [ 0.0071,  0.2521, -0.0437],\n",
      "        [ 0.0205,  0.2074, -0.0484],\n",
      "        [ 0.0240,  0.1418, -0.0225],\n",
      "        [ 0.0492,  0.2779, -0.0649],\n",
      "        [ 0.0006,  0.1884, -0.0540],\n",
      "        [ 0.0056,  0.1743, -0.0572],\n",
      "        [ 0.0151,  0.2221, -0.0293],\n",
      "        [ 0.0348,  0.2062, -0.0434],\n",
      "        [ 0.0221,  0.2225, -0.0662],\n",
      "        [ 0.0270,  0.2999, -0.0440],\n",
      "        [ 0.0165,  0.2219, -0.0820],\n",
      "        [ 0.0196,  0.2664, -0.0526],\n",
      "        [ 0.0331,  0.3116, -0.0870],\n",
      "        [ 0.0214,  0.2670, -0.0634],\n",
      "        [ 0.0462,  0.3199, -0.0871],\n",
      "        [ 0.0282,  0.1999, -0.0136],\n",
      "        [ 0.0300,  0.2639, -0.0531],\n",
      "        [ 0.0433,  0.2590, -0.0574],\n",
      "        [ 0.0282,  0.2140, -0.0729],\n",
      "        [ 0.0460,  0.2735, -0.0620],\n",
      "        [ 0.0349,  0.2540, -0.0778],\n",
      "        [ 0.0219,  0.2177, -0.0672],\n",
      "        [ 0.0429,  0.2307, -0.0176],\n",
      "        [ 0.0164,  0.1882, -0.0626],\n",
      "        [ 0.0412,  0.2369, -0.0629],\n",
      "        [ 0.0091,  0.2165, -0.0346],\n",
      "        [ 0.0088,  0.2633, -0.0585],\n",
      "        [-0.0020,  0.2064, -0.0529]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.2629, 2.1734, 3.4378, 1.3626, 2.0926, 2.0623, 1.4818, 3.2740, 1.9913,\n",
      "         1.6884, 1.9997, 2.2911, 2.6136, 2.6112, 2.6672, 3.0664, 3.3698, 2.9944,\n",
      "         3.5710, 1.8544, 2.7564, 2.8197, 2.8901, 2.7909, 3.1466, 2.5960, 2.3855,\n",
      "         2.7509, 2.8929, 2.5257, 2.8242, 2.2385],\n",
      "        [1.8655, 1.7470, 2.6993, 1.1725, 1.7900, 1.8378, 1.3314, 2.6922, 1.6129,\n",
      "         1.3220, 1.9583, 1.8315, 1.9932, 2.1994, 2.1082, 2.5796, 2.6223, 2.3322,\n",
      "         2.9741, 1.5416, 2.2385, 2.3276, 2.1462, 2.2959, 2.2841, 2.0855, 1.9307,\n",
      "         2.2593, 2.2615, 1.9699, 2.1665, 1.6386]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0270, 0.0265, 0.0408, 0.0167, 0.0271, 0.0262, 0.0173, 0.0405, 0.0251,\n",
      "        0.0197, 0.0273, 0.0285, 0.0298, 0.0341, 0.0305, 0.0373, 0.0408, 0.0362,\n",
      "        0.0429, 0.0231, 0.0333, 0.0352, 0.0325, 0.0346, 0.0370, 0.0315, 0.0298,\n",
      "        0.0325, 0.0355, 0.0300, 0.0332, 0.0263], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0425, 0.0345], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0249,  0.1226, -0.0319],\n",
      "        [-0.0195,  0.1074, -0.0273],\n",
      "        [-0.0074,  0.1563, -0.0281],\n",
      "        [ 0.0223,  0.0858, -0.0226],\n",
      "        [-0.0218,  0.0993, -0.0235],\n",
      "        [-0.0166,  0.0810, -0.0398],\n",
      "        [ 0.0028,  0.0680, -0.0253],\n",
      "        [ 0.0082,  0.1548, -0.0323],\n",
      "        [-0.0217,  0.0602, -0.0210],\n",
      "        [-0.0127,  0.0893, -0.0212],\n",
      "        [ 0.0110,  0.0776, -0.0337],\n",
      "        [ 0.0457,  0.1208,  0.0081],\n",
      "        [-0.0141,  0.1003, -0.0250],\n",
      "        [-0.0296,  0.0994, -0.0330],\n",
      "        [-0.0261,  0.1436, -0.0229],\n",
      "        [-0.0210,  0.1706, -0.0434],\n",
      "        [-0.0098,  0.1595, -0.0416],\n",
      "        [ 0.0108,  0.1408, -0.0192],\n",
      "        [-0.0190,  0.1468, -0.0246],\n",
      "        [-0.0033,  0.0567, -0.0114],\n",
      "        [-0.0060,  0.0561, -0.0394],\n",
      "        [-0.0060,  0.1086, -0.0366],\n",
      "        [ 0.0098,  0.1288, -0.0431],\n",
      "        [-0.0093,  0.0962, -0.0292],\n",
      "        [ 0.0187,  0.1246, -0.0196],\n",
      "        [-0.0158,  0.1060, -0.0185],\n",
      "        [ 0.0135,  0.0296, -0.0191],\n",
      "        [-0.0094,  0.1491,  0.0033],\n",
      "        [-0.0182,  0.1641, -0.0208],\n",
      "        [-0.0259,  0.1085, -0.0492],\n",
      "        [-0.0284,  0.0976, -0.0398],\n",
      "        [-0.0192,  0.0908, -0.0289]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.3547, 2.2595, 3.5761, 1.4213, 2.1784, 2.1425, 1.5447, 3.4044, 2.0713,\n",
      "         1.7562, 2.0850, 2.3845, 2.7197, 2.7179, 2.7757, 3.1868, 3.5063, 3.1139,\n",
      "         3.7153, 1.9326, 2.8695, 2.9347, 3.0040, 2.9038, 3.2741, 2.6976, 2.4857,\n",
      "         2.8619, 3.0095, 2.6282, 2.9393, 2.3310],\n",
      "        [1.9412, 1.8181, 2.8091, 1.2243, 1.8641, 1.9111, 1.3897, 2.8002, 1.6790,\n",
      "         1.3766, 2.0421, 1.9070, 2.0758, 2.2903, 2.1947, 2.6823, 2.7297, 2.4273,\n",
      "         3.0955, 1.6069, 2.3308, 2.4225, 2.2283, 2.3905, 2.3784, 2.1690, 2.0130,\n",
      "         2.3511, 2.3538, 2.0507, 2.2555, 1.7080]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0275, 0.0270, 0.0416, 0.0171, 0.0277, 0.0266, 0.0178, 0.0413, 0.0256,\n",
      "        0.0201, 0.0280, 0.0291, 0.0304, 0.0347, 0.0311, 0.0380, 0.0416, 0.0369,\n",
      "        0.0438, 0.0236, 0.0340, 0.0359, 0.0330, 0.0353, 0.0378, 0.0320, 0.0305,\n",
      "        0.0332, 0.0361, 0.0307, 0.0338, 0.0268], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0433, 0.0351], grad_fn=<MeanBackward1>)\n",
      "Epoch 9/10, Accuracy: 0.4875\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0129,  0.1346, -0.0014],\n",
      "        [-0.0065,  0.1288, -0.0314],\n",
      "        [-0.0147,  0.2339,  0.0281],\n",
      "        [-0.0242,  0.1116,  0.0502],\n",
      "        [ 0.0242,  0.1431,  0.0188],\n",
      "        [-0.0043,  0.1262, -0.0307],\n",
      "        [ 0.0142,  0.0454, -0.0065],\n",
      "        [-0.0127,  0.2296,  0.0084],\n",
      "        [-0.0119,  0.1266,  0.0223],\n",
      "        [ 0.0037,  0.1429, -0.0220],\n",
      "        [-0.0079,  0.1222, -0.0230],\n",
      "        [-0.0073,  0.1969,  0.0205],\n",
      "        [-0.0189,  0.1887,  0.0071],\n",
      "        [-0.0131,  0.1667, -0.0031],\n",
      "        [ 0.0055,  0.1833,  0.0446],\n",
      "        [-0.0177,  0.2287,  0.0224],\n",
      "        [ 0.0128,  0.2454,  0.0252],\n",
      "        [-0.0118,  0.2155,  0.0426],\n",
      "        [-0.0167,  0.2601,  0.0076],\n",
      "        [-0.0121,  0.1037,  0.0106],\n",
      "        [-0.0037,  0.1504,  0.0209],\n",
      "        [-0.0078,  0.1712,  0.0231],\n",
      "        [-0.0053,  0.1533,  0.0179],\n",
      "        [-0.0020,  0.2089,  0.0106],\n",
      "        [-0.0185,  0.2478,  0.0364],\n",
      "        [ 0.0054,  0.1139,  0.0054],\n",
      "        [-0.0142,  0.1035,  0.0151],\n",
      "        [-0.0071,  0.2108,  0.0223],\n",
      "        [-0.0116,  0.2082,  0.0369],\n",
      "        [ 0.0162,  0.1676,  0.0231],\n",
      "        [-0.0044,  0.1932,  0.0159],\n",
      "        [ 0.0065,  0.1353,  0.0329]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.4539, 2.3485, 3.7212, 1.4771, 2.2681, 2.2269, 1.6027, 3.5433, 2.1528,\n",
      "         1.8240, 2.1681, 2.4817, 2.8313, 2.8297, 2.8895, 3.3178, 3.6490, 3.2412,\n",
      "         3.8669, 2.0114, 2.9861, 3.0557, 3.1288, 3.0225, 3.4071, 2.8073, 2.5885,\n",
      "         2.9777, 3.1315, 2.7355, 3.0587, 2.4267],\n",
      "        [2.0229, 1.8917, 2.9244, 1.2736, 1.9422, 1.9886, 1.4431, 2.9163, 1.7465,\n",
      "         1.4288, 2.1250, 1.9858, 2.1606, 2.3855, 2.2858, 2.7932, 2.8423, 2.5273,\n",
      "         3.2230, 1.6732, 2.4260, 2.5232, 2.3246, 2.4892, 2.4761, 2.2590, 2.0953,\n",
      "         2.4475, 2.4504, 2.1353, 2.3479, 1.7797]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0282, 0.0275, 0.0424, 0.0174, 0.0283, 0.0271, 0.0181, 0.0421, 0.0261,\n",
      "        0.0204, 0.0285, 0.0297, 0.0310, 0.0355, 0.0317, 0.0388, 0.0424, 0.0376,\n",
      "        0.0447, 0.0241, 0.0346, 0.0366, 0.0338, 0.0360, 0.0385, 0.0327, 0.0311,\n",
      "        0.0338, 0.0369, 0.0313, 0.0345, 0.0274], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0441, 0.0358], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0587,  0.2355,  0.0793],\n",
      "        [-0.0618,  0.2166,  0.0709],\n",
      "        [-0.0693,  0.2821,  0.0700],\n",
      "        [-0.0253,  0.0930,  0.0173],\n",
      "        [-0.0739,  0.2430,  0.0422],\n",
      "        [-0.0713,  0.1518,  0.0706],\n",
      "        [-0.0610,  0.1381,  0.0437],\n",
      "        [-0.0936,  0.2830,  0.0725],\n",
      "        [-0.0663,  0.1557,  0.0484],\n",
      "        [-0.0473,  0.1678,  0.0267],\n",
      "        [-0.0490,  0.2233,  0.0705],\n",
      "        [-0.0188,  0.2576,  0.0616],\n",
      "        [-0.0797,  0.2203,  0.0227],\n",
      "        [-0.0882,  0.2342,  0.0698],\n",
      "        [-0.0688,  0.2000,  0.0499],\n",
      "        [-0.0648,  0.2581,  0.0585],\n",
      "        [-0.0859,  0.3149,  0.0704],\n",
      "        [-0.0587,  0.2834,  0.0700],\n",
      "        [-0.0994,  0.3203,  0.0515],\n",
      "        [-0.0512,  0.1806,  0.0553],\n",
      "        [-0.0680,  0.2402,  0.0648],\n",
      "        [-0.0767,  0.2546,  0.0558],\n",
      "        [-0.0658,  0.2323,  0.0617],\n",
      "        [-0.0755,  0.2609,  0.0610],\n",
      "        [-0.0591,  0.2251,  0.0630],\n",
      "        [-0.0334,  0.2627,  0.0818],\n",
      "        [-0.0722,  0.2191,  0.0527],\n",
      "        [-0.0395,  0.2502,  0.0649],\n",
      "        [-0.0456,  0.2615,  0.0764],\n",
      "        [-0.0782,  0.1606,  0.0325],\n",
      "        [-0.0632,  0.2360,  0.0544],\n",
      "        [-0.0824,  0.2221,  0.0336]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.5507, 2.4456, 3.8716, 1.5395, 2.3589, 2.3209, 1.6704, 3.6862, 2.2395,\n",
      "         1.8973, 2.2573, 2.5829, 2.9474, 2.9432, 3.0083, 3.4521, 3.7955, 3.3730,\n",
      "         4.0217, 2.0946, 3.1061, 3.1765, 3.2549, 3.1445, 3.5456, 2.9200, 2.6950,\n",
      "         3.0983, 3.2582, 2.8464, 3.1826, 2.5245],\n",
      "        [2.1048, 1.9698, 3.0439, 1.3263, 2.0214, 2.0712, 1.5022, 3.0356, 1.8160,\n",
      "         1.4863, 2.2132, 2.0676, 2.2523, 2.4832, 2.3801, 2.9075, 2.9584, 2.6319,\n",
      "         3.3538, 1.7427, 2.5258, 2.6256, 2.4212, 2.5919, 2.5781, 2.3498, 2.1856,\n",
      "         2.5476, 2.5510, 2.2224, 2.4450, 1.8521]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0287, 0.0280, 0.0433, 0.0179, 0.0288, 0.0277, 0.0185, 0.0430, 0.0266,\n",
      "        0.0208, 0.0291, 0.0303, 0.0317, 0.0362, 0.0324, 0.0395, 0.0433, 0.0384,\n",
      "        0.0455, 0.0246, 0.0353, 0.0373, 0.0344, 0.0367, 0.0393, 0.0333, 0.0318,\n",
      "        0.0345, 0.0376, 0.0319, 0.0352, 0.0280], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0450, 0.0365], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0273,  0.1800, -0.0238],\n",
      "        [ 0.0546,  0.0913, -0.0301],\n",
      "        [ 0.0208,  0.2259, -0.0504],\n",
      "        [ 0.0177,  0.0947, -0.0071],\n",
      "        [ 0.0478,  0.1957, -0.0336],\n",
      "        [ 0.0353,  0.1391, -0.0450],\n",
      "        [ 0.0431,  0.1116, -0.0015],\n",
      "        [ 0.0330,  0.2349, -0.0721],\n",
      "        [ 0.0052,  0.1347, -0.0359],\n",
      "        [ 0.0027,  0.1204, -0.0118],\n",
      "        [ 0.0467,  0.1567, -0.0164],\n",
      "        [-0.0074,  0.1536, -0.0370],\n",
      "        [ 0.0440,  0.1634, -0.0292],\n",
      "        [ 0.0299,  0.2535, -0.0864],\n",
      "        [ 0.0253,  0.1606, -0.0038],\n",
      "        [ 0.0536,  0.2262, -0.0309],\n",
      "        [ 0.0251,  0.3032, -0.0592],\n",
      "        [ 0.0195,  0.2256, -0.0599],\n",
      "        [ 0.0569,  0.2337, -0.0346],\n",
      "        [-0.0013,  0.1577, -0.0509],\n",
      "        [ 0.0354,  0.1745, -0.0509],\n",
      "        [ 0.0385,  0.2258, -0.0504],\n",
      "        [ 0.0296,  0.1435, -0.0228],\n",
      "        [ 0.0190,  0.2327, -0.0499],\n",
      "        [-0.0015,  0.1673, -0.0419],\n",
      "        [ 0.0094,  0.2045, -0.0663],\n",
      "        [ 0.0116,  0.1533, -0.0315],\n",
      "        [ 0.0198,  0.1404, -0.0436],\n",
      "        [ 0.0188,  0.2064, -0.0405],\n",
      "        [ 0.0267,  0.1781, -0.0501],\n",
      "        [ 0.0396,  0.1909, -0.0337],\n",
      "        [ 0.0356,  0.1590, -0.0531]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.6531, 2.5460, 4.0267, 1.6005, 2.4539, 2.4146, 1.7405, 3.8339, 2.3349,\n",
      "         1.9827, 2.3477, 2.6869, 3.0633, 3.0586, 3.1270, 3.5903, 3.9475, 3.5073,\n",
      "         4.1836, 2.1756, 3.2314, 3.3027, 3.3850, 3.2710, 3.6890, 3.0380, 2.7992,\n",
      "         3.2244, 3.3898, 2.9618, 3.3100, 2.6264],\n",
      "        [2.1896, 2.0533, 3.1671, 1.3785, 2.1034, 2.1572, 1.5652, 3.1589, 1.8945,\n",
      "         1.5540, 2.3017, 2.1519, 2.3408, 2.5815, 2.4753, 3.0257, 3.0779, 2.7372,\n",
      "         3.4908, 1.8101, 2.6282, 2.7312, 2.5190, 2.6960, 2.6834, 2.4474, 2.2689,\n",
      "         2.6521, 2.6555, 2.3133, 2.5435, 1.9279]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0292, 0.0287, 0.0441, 0.0182, 0.0294, 0.0283, 0.0189, 0.0438, 0.0272,\n",
      "        0.0214, 0.0297, 0.0309, 0.0322, 0.0368, 0.0330, 0.0403, 0.0441, 0.0391,\n",
      "        0.0464, 0.0250, 0.0360, 0.0380, 0.0351, 0.0374, 0.0401, 0.0340, 0.0323,\n",
      "        0.0352, 0.0383, 0.0326, 0.0359, 0.0285], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0458, 0.0372], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 1.8320e-02,  1.2489e-01,  3.0330e-02],\n",
      "        [ 1.7185e-02,  1.1846e-01,  5.0738e-02],\n",
      "        [ 1.6428e-02,  2.1104e-01,  4.5062e-02],\n",
      "        [-1.0452e-03,  7.7975e-02,  2.4184e-02],\n",
      "        [ 1.3683e-02,  1.3959e-01,  5.5184e-02],\n",
      "        [-1.5848e-03,  1.1248e-01,  1.4483e-02],\n",
      "        [ 1.1343e-02,  9.2026e-02,  1.8923e-02],\n",
      "        [ 1.7881e-02,  1.7593e-01,  2.4705e-02],\n",
      "        [ 4.7742e-03,  1.6688e-01,  1.6259e-02],\n",
      "        [ 4.7724e-02,  8.9558e-02,  4.8604e-02],\n",
      "        [ 9.6833e-03,  9.0552e-02,  8.1284e-02],\n",
      "        [-2.0782e-03,  1.0873e-01,  5.2513e-02],\n",
      "        [ 5.0624e-02,  1.1703e-01,  1.0292e-02],\n",
      "        [ 2.2953e-02,  1.6682e-01,  2.9107e-02],\n",
      "        [-5.2507e-03,  2.0414e-01,  4.3376e-02],\n",
      "        [ 1.9597e-02,  1.6228e-01,  5.4580e-02],\n",
      "        [ 3.9871e-02,  2.2330e-01,  6.4649e-02],\n",
      "        [ 1.8361e-02,  1.7925e-01,  4.6133e-02],\n",
      "        [ 3.9840e-02,  2.0208e-01,  4.5663e-02],\n",
      "        [-9.4326e-03,  1.0696e-01,  8.7766e-05],\n",
      "        [-9.7733e-03,  1.7791e-01,  3.5613e-02],\n",
      "        [ 2.7534e-02,  1.8187e-01,  4.7721e-02],\n",
      "        [ 2.0327e-02,  1.3741e-01,  6.6210e-02],\n",
      "        [ 3.2232e-02,  1.4516e-01,  2.6135e-02],\n",
      "        [ 7.6391e-03,  1.8858e-01,  1.7697e-02],\n",
      "        [ 1.6037e-02,  1.5146e-01,  5.0152e-02],\n",
      "        [-2.7164e-03,  1.3530e-01,  3.6197e-02],\n",
      "        [-6.8433e-03,  1.4137e-01,  4.0087e-02],\n",
      "        [ 1.2485e-02,  1.3560e-01,  3.9381e-02],\n",
      "        [ 1.3748e-03,  1.7217e-01,  4.9816e-02],\n",
      "        [ 2.5336e-02,  1.3785e-01,  3.6613e-02],\n",
      "        [ 4.5902e-02,  1.3245e-01,  1.5673e-02]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.7622, 2.6488, 4.1896, 1.6625, 2.5535, 2.5112, 1.8092, 3.9888, 2.4276,\n",
      "         2.0581, 2.4414, 2.7966, 3.1908, 3.1846, 3.2543, 3.7351, 4.1076, 3.6503,\n",
      "         4.3539, 2.2660, 3.3625, 3.4363, 3.5220, 3.4054, 3.8391, 3.1613, 2.9166,\n",
      "         3.3547, 3.5275, 3.0819, 3.4451, 2.7349],\n",
      "        [2.2803, 2.1357, 3.2961, 1.4354, 2.1899, 2.2429, 1.6300, 3.2876, 1.9714,\n",
      "         1.6142, 2.3958, 2.2406, 2.4397, 2.6891, 2.5770, 3.1483, 3.2039, 2.8493,\n",
      "         3.6325, 1.8869, 2.7361, 2.8427, 2.6186, 2.8085, 2.7939, 2.5464, 2.3653,\n",
      "         2.7598, 2.7644, 2.4080, 2.6481, 2.0089]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0298, 0.0292, 0.0450, 0.0185, 0.0300, 0.0289, 0.0193, 0.0446, 0.0278,\n",
      "        0.0218, 0.0303, 0.0315, 0.0330, 0.0376, 0.0337, 0.0411, 0.0450, 0.0399,\n",
      "        0.0474, 0.0256, 0.0367, 0.0387, 0.0357, 0.0382, 0.0409, 0.0347, 0.0330,\n",
      "        0.0359, 0.0391, 0.0332, 0.0366, 0.0292], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0467, 0.0379], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0302,  0.1658, -0.0380],\n",
      "        [ 0.0091,  0.1480, -0.0799],\n",
      "        [ 0.0553,  0.2595, -0.0573],\n",
      "        [ 0.0164,  0.1472, -0.0445],\n",
      "        [ 0.0409,  0.1847, -0.0397],\n",
      "        [ 0.0301,  0.1747, -0.0518],\n",
      "        [ 0.0106,  0.1325, -0.0069],\n",
      "        [ 0.0543,  0.2686, -0.0486],\n",
      "        [ 0.0506,  0.1470, -0.0578],\n",
      "        [ 0.0206,  0.1125, -0.0298],\n",
      "        [-0.0005,  0.1717, -0.0310],\n",
      "        [ 0.0200,  0.1397, -0.0274],\n",
      "        [ 0.0403,  0.1930, -0.0381],\n",
      "        [ 0.0453,  0.2236, -0.0571],\n",
      "        [ 0.0596,  0.1755, -0.0530],\n",
      "        [ 0.0567,  0.2241, -0.0329],\n",
      "        [ 0.0348,  0.2594, -0.0599],\n",
      "        [ 0.0384,  0.2199, -0.0482],\n",
      "        [ 0.0754,  0.2403, -0.0739],\n",
      "        [ 0.0594,  0.1288, -0.0008],\n",
      "        [ 0.0478,  0.1867, -0.0733],\n",
      "        [ 0.0444,  0.2195, -0.0620],\n",
      "        [ 0.0153,  0.1805, -0.0511],\n",
      "        [ 0.0388,  0.2179, -0.0573],\n",
      "        [ 0.0619,  0.2189, -0.0795],\n",
      "        [ 0.0435,  0.1325, -0.0366],\n",
      "        [ 0.0598,  0.1323, -0.0479],\n",
      "        [ 0.0484,  0.1593, -0.0197],\n",
      "        [ 0.0452,  0.2015, -0.0475],\n",
      "        [ 0.0438,  0.2338, -0.0210],\n",
      "        [ 0.0441,  0.1797, -0.0467],\n",
      "        [ 0.0432,  0.1898, -0.0633]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.8723, 2.7564, 4.3587, 1.7322, 2.6568, 2.6150, 1.8817, 4.1492, 2.5245,\n",
      "         2.1441, 2.5386, 2.9098, 3.3168, 3.3129, 3.3880, 3.8880, 4.2746, 3.7960,\n",
      "         4.5302, 2.3564, 3.4982, 3.5768, 3.6659, 3.5413, 3.9946, 3.2942, 3.0331,\n",
      "         3.4910, 3.6696, 3.2073, 3.5837, 2.8436],\n",
      "        [2.3722, 2.2237, 3.4298, 1.4927, 2.2800, 2.3367, 1.6954, 3.4212, 2.0507,\n",
      "         1.6816, 2.4934, 2.3321, 2.5369, 2.7978, 2.6832, 3.2780, 3.3353, 2.9646,\n",
      "         3.7818, 1.9630, 2.8475, 2.9592, 2.7280, 2.9221, 2.9080, 2.6544, 2.4612,\n",
      "         2.8729, 2.8769, 2.5068, 2.7558, 2.0892]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0304, 0.0298, 0.0459, 0.0189, 0.0306, 0.0295, 0.0197, 0.0455, 0.0283,\n",
      "        0.0223, 0.0309, 0.0321, 0.0335, 0.0383, 0.0344, 0.0420, 0.0459, 0.0406,\n",
      "        0.0483, 0.0261, 0.0375, 0.0395, 0.0365, 0.0390, 0.0417, 0.0355, 0.0336,\n",
      "        0.0367, 0.0399, 0.0339, 0.0373, 0.0297], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0476, 0.0387], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0043,  0.1658, -0.0164],\n",
      "        [ 0.0386,  0.1903, -0.0233],\n",
      "        [ 0.0044,  0.1806, -0.0293],\n",
      "        [ 0.0351,  0.0400, -0.0023],\n",
      "        [ 0.0478,  0.1683, -0.0319],\n",
      "        [-0.0059,  0.1707, -0.0285],\n",
      "        [-0.0043,  0.1531,  0.0036],\n",
      "        [ 0.0220,  0.1965, -0.0448],\n",
      "        [-0.0086,  0.1214, -0.0139],\n",
      "        [ 0.0061,  0.0778, -0.0291],\n",
      "        [ 0.0486,  0.1782, -0.0345],\n",
      "        [ 0.0529,  0.1382, -0.0182],\n",
      "        [ 0.0137,  0.1297, -0.0065],\n",
      "        [ 0.0091,  0.1650, -0.0406],\n",
      "        [ 0.0053,  0.1360,  0.0021],\n",
      "        [ 0.0288,  0.1862, -0.0393],\n",
      "        [ 0.0284,  0.1838, -0.0318],\n",
      "        [ 0.0250,  0.1548, -0.0036],\n",
      "        [ 0.0347,  0.2121, -0.0172],\n",
      "        [-0.0025,  0.1574, -0.0351],\n",
      "        [ 0.0257,  0.1605, -0.0313],\n",
      "        [ 0.0150,  0.1973, -0.0334],\n",
      "        [ 0.0299,  0.1347, -0.0140],\n",
      "        [ 0.0208,  0.1824, -0.0376],\n",
      "        [ 0.0211,  0.1076, -0.0119],\n",
      "        [ 0.0294,  0.1096, -0.0200],\n",
      "        [ 0.0083,  0.1838, -0.0341],\n",
      "        [ 0.0426,  0.1328, -0.0152],\n",
      "        [ 0.0257,  0.2013, -0.0256],\n",
      "        [ 0.0114,  0.1051, -0.0717],\n",
      "        [ 0.0261,  0.1435, -0.0278],\n",
      "        [ 0.0211,  0.1093, -0.0056]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[2.9887, 2.8670, 4.5341, 1.8035, 2.7641, 2.7199, 1.9617, 4.3164, 2.6308,\n",
      "         2.2312, 2.6491, 3.0282, 3.4508, 3.4462, 3.5234, 4.0427, 4.4462, 3.9480,\n",
      "         4.7113, 2.4524, 3.6397, 3.7192, 3.8115, 3.6856, 4.1562, 3.4253, 3.1571,\n",
      "         3.6319, 3.8177, 3.3371, 3.7281, 2.9583],\n",
      "        [2.4689, 2.3144, 3.5690, 1.5548, 2.3733, 2.4321, 1.7665, 3.5607, 2.1361,\n",
      "         1.7483, 2.5989, 2.4280, 2.6401, 2.9129, 2.7918, 3.4102, 3.4709, 3.0848,\n",
      "         3.9346, 2.0433, 2.9630, 3.0785, 2.8379, 3.0423, 3.0267, 2.7623, 2.5628,\n",
      "         2.9896, 2.9941, 2.6088, 2.8677, 2.1749]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0310, 0.0304, 0.0468, 0.0194, 0.0312, 0.0301, 0.0202, 0.0464, 0.0290,\n",
      "        0.0228, 0.0316, 0.0328, 0.0342, 0.0391, 0.0350, 0.0427, 0.0468, 0.0414,\n",
      "        0.0492, 0.0266, 0.0382, 0.0403, 0.0371, 0.0398, 0.0426, 0.0362, 0.0343,\n",
      "        0.0374, 0.0407, 0.0346, 0.0381, 0.0303], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0485, 0.0394], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0096,  0.2783,  0.0322],\n",
      "        [-0.0117,  0.2008, -0.0009],\n",
      "        [-0.0102,  0.3384,  0.0109],\n",
      "        [-0.0083,  0.1407,  0.0413],\n",
      "        [-0.0046,  0.2311,  0.0057],\n",
      "        [-0.0176,  0.1491,  0.0278],\n",
      "        [ 0.0011,  0.1089,  0.0084],\n",
      "        [-0.0222,  0.3355, -0.0291],\n",
      "        [ 0.0219,  0.2241,  0.0375],\n",
      "        [-0.0032,  0.2151, -0.0060],\n",
      "        [-0.0131,  0.2324,  0.0042],\n",
      "        [-0.0033,  0.2277, -0.0335],\n",
      "        [-0.0435,  0.2482, -0.0226],\n",
      "        [ 0.0038,  0.3116,  0.0032],\n",
      "        [-0.0114,  0.2420,  0.0400],\n",
      "        [-0.0355,  0.3061,  0.0284],\n",
      "        [ 0.0291,  0.3802,  0.0043],\n",
      "        [-0.0024,  0.3143,  0.0031],\n",
      "        [-0.0415,  0.3361,  0.0176],\n",
      "        [-0.0148,  0.1864, -0.0257],\n",
      "        [-0.0243,  0.2250,  0.0379],\n",
      "        [ 0.0059,  0.2766,  0.0354],\n",
      "        [-0.0007,  0.2333, -0.0053],\n",
      "        [-0.0254,  0.2992, -0.0063],\n",
      "        [-0.0109,  0.3132, -0.0043],\n",
      "        [ 0.0100,  0.2706,  0.0010],\n",
      "        [-0.0228,  0.2297, -0.0226],\n",
      "        [-0.0137,  0.2788, -0.0122],\n",
      "        [-0.0025,  0.3108,  0.0210],\n",
      "        [ 0.0051,  0.2304, -0.0172],\n",
      "        [-0.0209,  0.3035,  0.0256],\n",
      "        [ 0.0022,  0.2458, -0.0181]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[3.1108, 2.9848, 4.7182, 1.8758, 2.8780, 2.8321, 2.0366, 4.4914, 2.7342,\n",
      "         2.3175, 2.7514, 3.1516, 3.5925, 3.5880, 3.6673, 4.2086, 4.6260, 4.1090,\n",
      "         4.9041, 2.5534, 3.7865, 3.8692, 3.9717, 3.8350, 4.3249, 3.5648, 3.2869,\n",
      "         3.7793, 3.9724, 3.4731, 3.8796, 3.0811],\n",
      "        [2.5706, 2.4096, 3.7148, 1.6205, 2.4716, 2.5316, 1.8370, 3.7055, 2.2207,\n",
      "         1.8165, 2.7030, 2.5277, 2.7489, 3.0335, 2.9072, 3.5498, 3.6117, 3.2112,\n",
      "         4.0957, 2.1295, 3.0836, 3.2036, 2.9584, 3.1667, 3.1504, 2.8718, 2.6689,\n",
      "         3.1114, 3.1163, 2.7158, 2.9844, 2.2670]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0316, 0.0310, 0.0477, 0.0198, 0.0319, 0.0307, 0.0205, 0.0473, 0.0295,\n",
      "        0.0232, 0.0322, 0.0334, 0.0349, 0.0399, 0.0358, 0.0436, 0.0477, 0.0423,\n",
      "        0.0503, 0.0272, 0.0389, 0.0411, 0.0380, 0.0406, 0.0434, 0.0368, 0.0350,\n",
      "        0.0382, 0.0415, 0.0353, 0.0388, 0.0310], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0494, 0.0401], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0006,  0.1464,  0.0083],\n",
      "        [ 0.0124,  0.0729,  0.0360],\n",
      "        [ 0.0574,  0.1563,  0.0299],\n",
      "        [ 0.0302,  0.0725,  0.0123],\n",
      "        [ 0.0109,  0.1330,  0.0378],\n",
      "        [ 0.0456,  0.1250,  0.0312],\n",
      "        [ 0.0287,  0.0710,  0.0023],\n",
      "        [ 0.0586,  0.1726,  0.0363],\n",
      "        [ 0.0297,  0.1474,  0.0194],\n",
      "        [ 0.0071,  0.1023,  0.0353],\n",
      "        [ 0.0314,  0.1028,  0.0020],\n",
      "        [ 0.0285,  0.1387,  0.0098],\n",
      "        [ 0.0538,  0.0766,  0.0136],\n",
      "        [ 0.0502,  0.1671,  0.0500],\n",
      "        [ 0.0192,  0.1264,  0.0201],\n",
      "        [ 0.0336,  0.1301,  0.0209],\n",
      "        [ 0.0359,  0.1575,  0.0427],\n",
      "        [ 0.0472,  0.1763,  0.0173],\n",
      "        [ 0.0428,  0.1408,  0.0430],\n",
      "        [ 0.0420,  0.1278,  0.0365],\n",
      "        [ 0.0411,  0.1225,  0.0302],\n",
      "        [ 0.0382,  0.1172,  0.0496],\n",
      "        [ 0.0223,  0.1386, -0.0007],\n",
      "        [ 0.0588,  0.1124,  0.0239],\n",
      "        [ 0.0542,  0.1027,  0.0397],\n",
      "        [ 0.0205,  0.1749,  0.0504],\n",
      "        [ 0.0265,  0.1232,  0.0225],\n",
      "        [ 0.0073,  0.1595,  0.0013],\n",
      "        [ 0.0105,  0.1671,  0.0160],\n",
      "        [ 0.0254,  0.1189,  0.0324],\n",
      "        [ 0.0286,  0.0873,  0.0115],\n",
      "        [ 0.0403,  0.1508,  0.0279]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[3.2353, 3.1058, 4.9078, 1.9520, 2.9925, 2.9450, 2.1224, 4.6704, 2.8479,\n",
      "         2.4183, 2.8643, 3.2792, 3.7389, 3.7303, 3.8163, 4.3764, 4.8136, 4.2747,\n",
      "         5.1011, 2.6566, 3.9402, 4.0258, 4.1258, 3.9898, 4.5004, 3.7068, 3.4177,\n",
      "         3.9320, 4.1331, 3.6135, 4.0372, 3.2048],\n",
      "        [2.6739, 2.5083, 3.8650, 1.6847, 2.5711, 2.6340, 1.9138, 3.8547, 2.3142,\n",
      "         1.8977, 2.8145, 2.6306, 2.8616, 3.1546, 3.0249, 3.6935, 3.7592, 3.3410,\n",
      "         4.2616, 2.2147, 3.2096, 3.3341, 3.0708, 3.2953, 3.2790, 2.9916, 2.7764,\n",
      "         3.2381, 3.2433, 2.8263, 3.1066, 2.3561]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0322, 0.0317, 0.0486, 0.0202, 0.0325, 0.0313, 0.0210, 0.0482, 0.0302,\n",
      "        0.0238, 0.0329, 0.0341, 0.0356, 0.0407, 0.0365, 0.0445, 0.0487, 0.0431,\n",
      "        0.0513, 0.0278, 0.0397, 0.0419, 0.0386, 0.0414, 0.0443, 0.0376, 0.0357,\n",
      "        0.0389, 0.0423, 0.0360, 0.0396, 0.0316], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0503, 0.0409], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0243,  0.1663,  0.0343],\n",
      "        [-0.0174,  0.2234,  0.0383],\n",
      "        [-0.0117,  0.3218,  0.0223],\n",
      "        [ 0.0095,  0.1266,  0.0160],\n",
      "        [ 0.0047,  0.2717,  0.0423],\n",
      "        [-0.0197,  0.1920,  0.0160],\n",
      "        [ 0.0123,  0.1066,  0.0251],\n",
      "        [-0.0408,  0.2714,  0.0157],\n",
      "        [-0.0095,  0.2557,  0.0609],\n",
      "        [-0.0183,  0.1366,  0.0310],\n",
      "        [ 0.0079,  0.2469,  0.0444],\n",
      "        [-0.0235,  0.3109,  0.0204],\n",
      "        [-0.0066,  0.2002,  0.0309],\n",
      "        [-0.0192,  0.2338,  0.0115],\n",
      "        [-0.0044,  0.2400,  0.0356],\n",
      "        [ 0.0121,  0.2749,  0.0446],\n",
      "        [-0.0240,  0.3000,  0.0411],\n",
      "        [-0.0152,  0.3057,  0.0312],\n",
      "        [-0.0248,  0.3251,  0.0251],\n",
      "        [-0.0198,  0.1792,  0.0052],\n",
      "        [-0.0116,  0.2868,  0.0309],\n",
      "        [-0.0067,  0.2605,  0.0098],\n",
      "        [ 0.0004,  0.2289,  0.0114],\n",
      "        [-0.0077,  0.2852,  0.0321],\n",
      "        [-0.0452,  0.2643,  0.0451],\n",
      "        [-0.0286,  0.2080,  0.0311],\n",
      "        [ 0.0061,  0.2749,  0.0299],\n",
      "        [-0.0444,  0.2668,  0.0280],\n",
      "        [-0.0130,  0.2705,  0.0295],\n",
      "        [ 0.0077,  0.1988,  0.0218],\n",
      "        [-0.0164,  0.2345,  0.0427],\n",
      "        [-0.0259,  0.1979,  0.0410]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[3.3699, 3.2318, 5.1068, 2.0318, 3.1160, 3.0640, 2.2080, 4.8612, 2.9621,\n",
      "         2.5105, 2.9822, 3.4124, 3.8906, 3.8851, 3.9730, 4.5535, 5.0078, 4.4478,\n",
      "         5.3078, 2.7660, 4.0995, 4.1888, 4.2970, 4.1526, 4.6828, 3.8582, 3.5604,\n",
      "         4.0914, 4.3004, 3.7606, 4.2006, 3.3343],\n",
      "        [2.7839, 2.6108, 4.0223, 1.7547, 2.6772, 2.7416, 1.9908, 4.0133, 2.4092,\n",
      "         1.9705, 2.9297, 2.7383, 2.9782, 3.2864, 3.1494, 3.8439, 3.9121, 3.4771,\n",
      "         4.4350, 2.3067, 3.3395, 3.4696, 3.1998, 3.4304, 3.4125, 3.1131, 2.8926,\n",
      "         3.3699, 3.3753, 2.9417, 3.2325, 2.4529]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0329, 0.0323, 0.0496, 0.0206, 0.0332, 0.0320, 0.0214, 0.0492, 0.0308,\n",
      "        0.0241, 0.0335, 0.0348, 0.0363, 0.0415, 0.0373, 0.0454, 0.0497, 0.0440,\n",
      "        0.0523, 0.0284, 0.0405, 0.0427, 0.0394, 0.0422, 0.0452, 0.0384, 0.0365,\n",
      "        0.0397, 0.0432, 0.0367, 0.0404, 0.0322], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0513, 0.0417], grad_fn=<MeanBackward1>)\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0336,  0.1138, -0.0869],\n",
      "        [ 0.0348,  0.0602, -0.0666],\n",
      "        [ 0.0151,  0.0951, -0.0835],\n",
      "        [-0.0129,  0.0759, -0.0163],\n",
      "        [ 0.0327,  0.0821, -0.0900],\n",
      "        [ 0.0274,  0.0552, -0.0489],\n",
      "        [ 0.0240,  0.0808, -0.0579],\n",
      "        [ 0.0516,  0.1191, -0.1033],\n",
      "        [ 0.0122,  0.0599, -0.0419],\n",
      "        [ 0.0213,  0.0908, -0.0948],\n",
      "        [ 0.0151,  0.0769, -0.0958],\n",
      "        [ 0.0220,  0.0598, -0.0807],\n",
      "        [ 0.0279,  0.0972, -0.0652],\n",
      "        [ 0.0490,  0.1304, -0.1101],\n",
      "        [ 0.0120,  0.1521, -0.0618],\n",
      "        [ 0.0384,  0.1242, -0.0825],\n",
      "        [ 0.0407,  0.1483, -0.1034],\n",
      "        [ 0.0369,  0.1417, -0.0834],\n",
      "        [ 0.0497,  0.1538, -0.1114],\n",
      "        [ 0.0282,  0.0309, -0.0860],\n",
      "        [ 0.0367,  0.0765, -0.0527],\n",
      "        [ 0.0479,  0.1060, -0.0751],\n",
      "        [ 0.0184,  0.1424, -0.0878],\n",
      "        [ 0.0409,  0.0899, -0.0765],\n",
      "        [ 0.0234,  0.1166, -0.0675],\n",
      "        [ 0.0318,  0.1205, -0.1209],\n",
      "        [ 0.0405,  0.0662, -0.1053],\n",
      "        [ 0.0141,  0.0876, -0.0717],\n",
      "        [ 0.0414,  0.0842, -0.0789],\n",
      "        [ 0.0272,  0.0568, -0.0579],\n",
      "        [ 0.0177,  0.0965, -0.0783],\n",
      "        [ 0.0158,  0.1021, -0.0923]], grad_fn=<DivBackward0>)\n",
      "Layer 1: tensor([[3.5046, 3.3627, 5.3129, 2.1122, 3.2410, 3.1905, 2.2987, 5.0555, 3.0825,\n",
      "         2.6144, 3.0989, 3.5507, 4.0453, 4.0397, 4.1315, 4.7374, 5.2105, 4.6255,\n",
      "         5.5207, 2.8765, 4.2644, 4.3561, 4.4661, 4.3190, 4.8724, 4.0123, 3.7028,\n",
      "         4.2575, 4.4737, 3.9130, 4.3697, 3.4694],\n",
      "        [2.8964, 2.7182, 4.1851, 1.8249, 2.7864, 2.8556, 2.0743, 4.1750, 2.5076,\n",
      "         2.0532, 3.0480, 2.8498, 3.0967, 3.4180, 3.2762, 3.9993, 4.0706, 3.6162,\n",
      "         4.6144, 2.3994, 3.4742, 3.6091, 3.3250, 3.5685, 3.5512, 3.2364, 3.0081,\n",
      "         3.5072, 3.5118, 3.0617, 3.3631, 2.5532]], grad_fn=<DivBackward0>)\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0335, 0.0330, 0.0506, 0.0210, 0.0338, 0.0327, 0.0219, 0.0502, 0.0315,\n",
      "        0.0247, 0.0342, 0.0355, 0.0370, 0.0423, 0.0379, 0.0462, 0.0507, 0.0448,\n",
      "        0.0533, 0.0289, 0.0413, 0.0435, 0.0401, 0.0431, 0.0461, 0.0391, 0.0372,\n",
      "        0.0405, 0.0440, 0.0375, 0.0412, 0.0329], grad_fn=<MeanBackward1>)\n",
      "Layer 1: tensor([0.0523, 0.0425], grad_fn=<MeanBackward1>)\n",
      "Epoch 10/10, Accuracy: 0.4750\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-0.0424,  0.1358,  0.0138],\n",
      "        [-0.0300,  0.1408,  0.0086],\n",
      "        [-0.0460,  0.3277,  0.0329],\n",
      "        [-0.0332,  0.0842,  0.0470],\n",
      "        [-0.0252,  0.1244,  0.0570],\n",
      "        [-0.0134,  0.1794, -0.0064],\n",
      "        [-0.0145,  0.0926,  0.0134],\n",
      "        [-0.0585,  0.2607,  0.0136],\n",
      "        [-0.0196,  0.2357,  0.0312],\n",
      "        [-0.0074,  0.1158, -0.0190],\n",
      "        [-0.0386,  0.1784,  0.0242],\n",
      "        [-0.0630,  0.2016,  0.0320],\n",
      "        [-0.0504,  0.2212,  0.0097],\n",
      "        [-0.0102,  0.2684,  0.0127],\n",
      "        [-0.0320,  0.1868,  0.0422],\n",
      "        [-0.0478,  0.2609,  0.0426],\n",
      "        [-0.0364,  0.2531,  0.0359],\n",
      "        [-0.0462,  0.2850,  0.0356],\n",
      "        [-0.0598,  0.2731,  0.0233],\n",
      "        [-0.0424,  0.1448,  0.0067],\n",
      "        [-0.0630,  0.1959,  0.0257],\n",
      "        [-0.0358,  0.2070,  0.0216],\n",
      "        [-0.0459,  0.2008,  0.0309],\n",
      "        [-0.0640,  0.2455,  0.0174],\n",
      "        [-0.0670,  0.2801,  0.0347],\n",
      "        [-0.0560,  0.1870,  0.0049],\n",
      "        [-0.0458,  0.2142,  0.0187],\n",
      "        [-0.0654,  0.2424,  0.0471],\n",
      "        [-0.0480,  0.2544,  0.0522],\n",
      "        [-0.0104,  0.2226,  0.0530],\n",
      "        [-0.0471,  0.2381,  0.0410],\n",
      "        [-0.0264,  0.1793,  0.0382]])\n",
      "Layer 1: tensor([[3.6494, 3.4969, 5.5277, 2.1997, 3.3743, 3.3156, 2.3890, 5.2597, 3.2026,\n",
      "         2.7131, 3.2246, 3.6952, 4.2135, 4.2058, 4.3022, 4.9299, 5.4226, 4.8148,\n",
      "         5.7461, 2.9949, 4.4384, 4.5340, 4.6523, 4.4943, 5.0707, 4.1744, 3.8550,\n",
      "         4.4298, 4.6547, 4.0723, 4.5472, 3.6128],\n",
      "        [3.0163, 2.8269, 4.3549, 1.9020, 2.9015, 2.9682, 2.1575, 4.3441, 2.6055,\n",
      "         2.1309, 3.1728, 2.9662, 3.2262, 3.5585, 3.4122, 4.1622, 4.2371, 3.7644,\n",
      "         4.8028, 2.4992, 3.6167, 3.7563, 3.4660, 3.7148, 3.6965, 3.3696, 3.1328,\n",
      "         3.6500, 3.6548, 3.1867, 3.5004, 2.6605]])\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0342, 0.0336, 0.0516, 0.0215, 0.0346, 0.0332, 0.0223, 0.0512, 0.0321,\n",
      "        0.0251, 0.0349, 0.0362, 0.0378, 0.0432, 0.0388, 0.0472, 0.0517, 0.0457,\n",
      "        0.0544, 0.0296, 0.0421, 0.0444, 0.0410, 0.0439, 0.0470, 0.0399, 0.0380,\n",
      "        0.0413, 0.0449, 0.0383, 0.0420, 0.0336])\n",
      "Layer 1: tensor([0.0533, 0.0433])\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[-2.6095e-02,  1.1064e-01, -1.0113e-02],\n",
      "        [-1.5326e-02,  5.4073e-02,  1.5886e-02],\n",
      "        [-9.1126e-03,  1.9651e-01,  8.3887e-03],\n",
      "        [-3.7037e-02,  8.5903e-02, -1.8139e-02],\n",
      "        [-2.4687e-02,  7.6631e-02, -2.8640e-02],\n",
      "        [ 6.7111e-03,  6.3681e-02,  5.1666e-03],\n",
      "        [ 2.2968e-02,  5.6324e-02,  1.7267e-02],\n",
      "        [-3.4730e-02,  1.9622e-01, -2.9814e-02],\n",
      "        [-3.3932e-02,  1.3231e-01, -8.2117e-03],\n",
      "        [-1.4168e-02,  8.6769e-02, -1.8257e-02],\n",
      "        [-2.7958e-02,  7.3910e-02, -1.1511e-03],\n",
      "        [-2.7127e-02,  1.5527e-01, -2.3760e-02],\n",
      "        [ 8.0159e-03,  1.4402e-01,  5.9488e-03],\n",
      "        [ 1.7086e-02,  1.8594e-01, -3.5821e-02],\n",
      "        [-4.3033e-02,  1.1659e-01, -6.3217e-03],\n",
      "        [-2.2990e-02,  1.2690e-01,  5.7299e-04],\n",
      "        [-1.4340e-02,  1.7697e-01, -1.7141e-02],\n",
      "        [ 3.3127e-03,  1.7354e-01,  6.7415e-03],\n",
      "        [-4.9992e-03,  2.1606e-01, -1.0463e-02],\n",
      "        [ 1.8163e-03,  1.3718e-01, -2.7516e-02],\n",
      "        [ 9.5228e-03,  1.2143e-01, -1.3243e-05],\n",
      "        [ 2.5837e-03,  1.5989e-01,  6.0051e-03],\n",
      "        [ 1.9867e-02,  1.3481e-01,  2.3940e-02],\n",
      "        [-3.4134e-02,  1.4293e-01, -3.2577e-02],\n",
      "        [-1.8829e-02,  1.9631e-01, -3.3354e-02],\n",
      "        [ 5.3078e-02,  1.6000e-01, -1.8156e-02],\n",
      "        [-5.9547e-03,  1.8714e-01, -1.9983e-02],\n",
      "        [-3.7898e-02,  1.7471e-01, -1.3244e-02],\n",
      "        [-3.9844e-02,  1.7505e-01, -1.2836e-02],\n",
      "        [-2.3687e-03,  8.6847e-02, -9.5185e-03],\n",
      "        [-8.9325e-03,  1.4829e-01, -1.2535e-02],\n",
      "        [-1.6558e-02,  1.2553e-01, -1.1832e-02]])\n",
      "Layer 1: tensor([[3.7959, 3.6415, 5.7509, 2.2881, 3.5097, 3.4529, 2.4895, 5.4720, 3.3344,\n",
      "         2.8298, 3.3552, 3.8448, 4.3824, 4.3739, 4.4754, 5.1292, 5.6408, 5.0077,\n",
      "         5.9769, 3.1167, 4.6169, 4.7149, 4.8402, 4.6774, 5.2762, 4.3439, 4.0116,\n",
      "         4.6093, 4.8433, 4.2371, 4.7311, 3.7570],\n",
      "        [3.1373, 2.9443, 4.5313, 1.9774, 3.0185, 3.0913, 2.2471, 4.5201, 2.7117,\n",
      "         2.2201, 3.3014, 3.0870, 3.3559, 3.7016, 3.5494, 4.3314, 4.4085, 3.9159,\n",
      "         4.9969, 2.6011, 3.7630, 3.9074, 3.6056, 3.8670, 3.8469, 3.5047, 3.2608,\n",
      "         3.7983, 3.8035, 3.3159, 3.6419, 2.7664]])\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0349, 0.0343, 0.0526, 0.0219, 0.0352, 0.0340, 0.0228, 0.0522, 0.0328,\n",
      "        0.0257, 0.0356, 0.0369, 0.0385, 0.0440, 0.0395, 0.0481, 0.0527, 0.0466,\n",
      "        0.0555, 0.0302, 0.0429, 0.0452, 0.0418, 0.0448, 0.0480, 0.0406, 0.0387,\n",
      "        0.0422, 0.0458, 0.0390, 0.0429, 0.0343])\n",
      "Layer 1: tensor([0.0543, 0.0441])\n",
      "Weights Gradients:\n",
      "Layer 0: tensor([[ 0.0004,  0.0531, -0.0061],\n",
      "        [-0.0030,  0.0245,  0.0040],\n",
      "        [-0.0061,  0.0553, -0.0009],\n",
      "        [ 0.0007,  0.0225, -0.0033],\n",
      "        [-0.0049,  0.0331, -0.0006],\n",
      "        [-0.0086,  0.0164, -0.0026],\n",
      "        [-0.0049,  0.0247, -0.0004],\n",
      "        [-0.0083,  0.0622, -0.0062],\n",
      "        [ 0.0004,  0.0221, -0.0031],\n",
      "        [ 0.0009,  0.0331, -0.0045],\n",
      "        [-0.0029,  0.0293,  0.0032],\n",
      "        [-0.0057,  0.0411,  0.0011],\n",
      "        [-0.0090,  0.0325,  0.0021],\n",
      "        [-0.0057,  0.0430,  0.0004],\n",
      "        [-0.0076,  0.0370,  0.0003],\n",
      "        [-0.0004,  0.0638,  0.0005],\n",
      "        [-0.0038,  0.0668,  0.0038],\n",
      "        [-0.0119,  0.0494,  0.0023],\n",
      "        [-0.0063,  0.0680,  0.0047],\n",
      "        [-0.0008,  0.0211,  0.0076],\n",
      "        [-0.0078,  0.0454, -0.0025],\n",
      "        [-0.0109,  0.0591, -0.0022],\n",
      "        [-0.0072,  0.0462,  0.0045],\n",
      "        [-0.0127,  0.0324,  0.0001],\n",
      "        [-0.0013,  0.0368, -0.0008],\n",
      "        [-0.0068,  0.0503, -0.0025],\n",
      "        [-0.0035,  0.0509,  0.0048],\n",
      "        [-0.0046,  0.0385,  0.0028],\n",
      "        [-0.0042,  0.0510,  0.0017],\n",
      "        [-0.0015,  0.0240,  0.0001],\n",
      "        [-0.0071,  0.0520,  0.0046],\n",
      "        [ 0.0022,  0.0251, -0.0068]])\n",
      "Layer 1: tensor([[0.1210, 0.0859, 0.1107, 0.0802, 0.0937, 0.0988, 0.0881, 0.1050, 0.0894,\n",
      "         0.0700, 0.1034, 0.0837, 0.1027, 0.0897, 0.1152, 0.1030, 0.1227, 0.1300,\n",
      "         0.1109, 0.0766, 0.1118, 0.1370, 0.1010, 0.0844, 0.1011, 0.1326, 0.1046,\n",
      "         0.0977, 0.1108, 0.0990, 0.1400, 0.0914],\n",
      "        [0.1152, 0.0763, 0.1022, 0.0831, 0.0757, 0.0880, 0.0851, 0.0979, 0.0809,\n",
      "         0.0674, 0.0947, 0.0836, 0.1010, 0.0869, 0.0973, 0.1006, 0.1199, 0.1157,\n",
      "         0.1001, 0.0719, 0.0974, 0.1199, 0.0948, 0.0657, 0.0969, 0.1284, 0.0924,\n",
      "         0.0844, 0.1019, 0.0907, 0.1258, 0.0878]])\n",
      "Biases Gradients:\n",
      "Layer 0: tensor([0.0076, 0.0046, 0.0081, 0.0035, 0.0051, 0.0050, 0.0040, 0.0083, 0.0035,\n",
      "        0.0029, 0.0053, 0.0052, 0.0065, 0.0060, 0.0064, 0.0069, 0.0083, 0.0092,\n",
      "        0.0079, 0.0036, 0.0073, 0.0092, 0.0070, 0.0044, 0.0061, 0.0073, 0.0060,\n",
      "        0.0055, 0.0072, 0.0054, 0.0084, 0.0046])\n",
      "Layer 1: tensor([0.0139, 0.0120])\n",
      "Test Accuracy: 0.4850\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from model import EnergyBasedModel as EBM\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_3d_circle_data(center, radius, normal_vector, num_points=100):\n",
    "    \"\"\"\n",
    "    Generate points on a 3D circle with given center, radius, and normal vector.\n",
    "    \n",
    "    Parameters:\n",
    "    - center: 3D coordinates of circle center\n",
    "    - radius: radius of the circle\n",
    "    - normal_vector: normal vector to the circle plane\n",
    "    - num_points: number of points to generate\n",
    "    \n",
    "    Returns:\n",
    "    - points on the circle\n",
    "    \"\"\"\n",
    "    # Normalize the normal vector\n",
    "    normal = np.array(normal_vector)\n",
    "    normal = normal / np.linalg.norm(normal)\n",
    "    \n",
    "    # Find two orthogonal vectors in the circle plane\n",
    "    if np.allclose(normal, [1, 0, 0]):\n",
    "        v1 = np.array([0, 1, 0])\n",
    "    else:\n",
    "        v1 = np.cross(normal, [1, 0, 0])\n",
    "        v1 = v1 / np.linalg.norm(v1)\n",
    "    \n",
    "    v2 = np.cross(normal, v1)\n",
    "    v2 = v2 / np.linalg.norm(v2)\n",
    "    \n",
    "    # Generate circle points\n",
    "    theta = np.linspace(0, 2 * np.pi, num_points)\n",
    "    circle_points = center + radius * (np.outer(np.cos(theta), v1) + np.outer(np.sin(theta), v2))\n",
    "    \n",
    "    return circle_points\n",
    "\n",
    "# Create the dataset\n",
    "def create_circles_dataset(num_points=100):\n",
    "    # Circle 1: centered at the origin, on the xy-plane\n",
    "    center1 = np.array([0, 0, 0])\n",
    "    radius1 = 1.0\n",
    "    normal1 = np.array([0, 0, 1])  # Normal to xy-plane\n",
    "    \n",
    "    # Circle 2: centered at (0, 1, 0), on the yz-plane (perpendicular to Circle 1)\n",
    "    center2 = np.array([0, 1, 0])\n",
    "    radius2 = 1.0\n",
    "    normal2 = np.array([1, 0, 0])  # Normal to yz-plane\n",
    "    \n",
    "    # Generate points\n",
    "    circle1_points = generate_3d_circle_data(center1, radius1, normal1, num_points)\n",
    "    circle2_points = generate_3d_circle_data(center2, radius2, normal2, num_points)\n",
    "    \n",
    "    # Combine into a dataset with labels\n",
    "    X = np.vstack([circle1_points, circle2_points])\n",
    "    y = np.array([0] * num_points + [1] * num_points)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Generate the dataset\n",
    "X, y = create_circles_dataset(num_points=200)\n",
    "\n",
    "# Visualize\n",
    "def visualize_circles(X, y):\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Plot points for each circle\n",
    "    colors = ['blue', 'red']\n",
    "    for i, color in enumerate(colors):\n",
    "        mask = (y == i)\n",
    "        ax.scatter(X[mask, 0], X[mask, 1], X[mask, 2], c=color, s=10, label=f'Circle {i+1}')\n",
    "    \n",
    "    # Add circle centers\n",
    "    centers = [np.array([0, 0, 0]), np.array([1, 0, 0])]\n",
    "    ax.scatter([c[0] for c in centers], [c[1] for c in centers], [c[2] for c in centers], \n",
    "               c='black', s=100, marker='x', label='Centers')\n",
    "    \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title('Two 3D Circles')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the dataset\n",
    "visualize_circles(X, y)\n",
    "\n",
    "# Now you can use this dataset (X, y) for training your model.\n",
    "# Test, train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "import torch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "# Create a DataLoader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# Define the model \n",
    "model_config = {\n",
    "    'input_size': 3,  # 3D input\n",
    "    'hidden_sizes': [32, 2],  # Hidden layer sizes\n",
    "    'beta': 0.1,  # Temperature parameter\n",
    "    'dt': 0.01,   # Step size\n",
    "    'n_steps': 10  # Number of steps\n",
    "}\n",
    "\n",
    "model = EBM(\n",
    "    input_size=model_config['input_size'],\n",
    "    hidden_sizes=model_config['hidden_sizes'],\n",
    "    beta=model_config['beta'],\n",
    "    dt=model_config['dt'],\n",
    "    optimizer=None,  # Optimizer will be set separately\n",
    "    n_steps=model_config['n_steps']\n",
    ")\n",
    "\n",
    "# Define the optimizer\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Set the optimizer in the model\n",
    "model.optimizer = optimizer\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    targets = []\n",
    "    preds = []\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_X)\n",
    "        preds.append(output)\n",
    "        targets.append(batch_y)\n",
    "    accuracy = (torch.cat(preds).argmax(dim=1) == torch.cat(targets)).float().mean()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Accuracy: {accuracy.item():.4f}\")\n",
    "\n",
    "for batch_X, batch_y in test_loader:\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_X)\n",
    "        preds.append(output)\n",
    "        targets.append(batch_y)\n",
    "accuracy = (torch.cat(preds).argmax(dim=1) == torch.cat(targets)).float().mean()\n",
    "print(f\"Test Accuracy: {accuracy.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7462, 0.5635],\n",
       "        [1.0044, 0.5266],\n",
       "        [0.5852, 0.6654],\n",
       "        [0.1369, 0.3500],\n",
       "        [0.3875, 0.5967],\n",
       "        [0.3503, 0.1660],\n",
       "        [0.3257, 0.9605],\n",
       "        [0.5277, 0.1067],\n",
       "        [0.7359, 0.7476],\n",
       "        [0.6065, 1.0038],\n",
       "        [0.4815, 1.0045],\n",
       "        [0.9189, 0.3106],\n",
       "        [0.3412, 0.5391],\n",
       "        [0.5793, 0.8001],\n",
       "        [0.8517, 0.5397],\n",
       "        [0.3919, 0.8106]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
